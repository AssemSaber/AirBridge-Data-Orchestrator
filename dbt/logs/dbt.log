

============================== 2025-11-10 16:01:51.626532 | 412d3c71-c66b-4179-98cf-f07bc2c13e7c ==============================
[0m16:01:51.626532 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:01:51.628826 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m16:01:51.629114 [debug] [MainThread]: Tracking: tracking
[0m16:01:51.631189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd82fab0b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd82ecabec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd82ecabda0>]}
[0m16:01:51.648427 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m16:01:51.649079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '412d3c71-c66b-4179-98cf-f07bc2c13e7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd82ecabad0>]}
[0m16:01:52.449419 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m16:01:52.499561 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m16:01:52.507197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '412d3c71-c66b-4179-98cf-f07bc2c13e7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd82eba3290>]}
[0m16:01:52.514511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '412d3c71-c66b-4179-98cf-f07bc2c13e7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd82e11cc20>]}
[0m16:01:52.515167 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 289 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:01:52.515716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '412d3c71-c66b-4179-98cf-f07bc2c13e7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd82fb9af60>]}
[0m16:01:52.517994 [info ] [MainThread]: 
[0m16:01:52.523386 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:01:52.527464 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:01:52.565692 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:01:52.566245 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:01:52.566611 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:01:52.575965 [debug] [ThreadPool]: SQL status: SELECT 4 in 0 seconds
[0m16:01:52.579214 [debug] [ThreadPool]: On list_airflow: Close
[0m16:01:52.581117 [debug] [ThreadPool]: Acquiring new postgres connection 'create_airflow_dbt_models'
[0m16:01:52.581977 [debug] [ThreadPool]: Acquiring new postgres connection 'create_airflow_dbt_models'
[0m16:01:52.582392 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='airflow', schema='dbt_models', identifier=None)"
[0m16:01:52.592682 [debug] [ThreadPool]: Using postgres connection "create_airflow_dbt_models"
[0m16:01:52.593180 [debug] [ThreadPool]: On create_airflow_dbt_models: BEGIN
[0m16:01:52.593508 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:01:52.598909 [debug] [ThreadPool]: SQL status: BEGIN in 0 seconds
[0m16:01:52.599386 [debug] [ThreadPool]: Using postgres connection "create_airflow_dbt_models"
[0m16:01:52.599692 [debug] [ThreadPool]: On create_airflow_dbt_models: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "connection_name": "create_airflow_dbt_models"} */
create schema if not exists "dbt_models"
[0m16:01:52.611197 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0 seconds
[0m16:01:52.613289 [debug] [ThreadPool]: On create_airflow_dbt_models: COMMIT
[0m16:01:52.613763 [debug] [ThreadPool]: Using postgres connection "create_airflow_dbt_models"
[0m16:01:52.614179 [debug] [ThreadPool]: On create_airflow_dbt_models: COMMIT
[0m16:01:52.620248 [debug] [ThreadPool]: SQL status: COMMIT in 0 seconds
[0m16:01:52.620783 [debug] [ThreadPool]: On create_airflow_dbt_models: Close
[0m16:01:52.624034 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_dbt_models'
[0m16:01:52.635890 [debug] [ThreadPool]: Using postgres connection "list_airflow_dbt_models"
[0m16:01:52.636351 [debug] [ThreadPool]: On list_airflow_dbt_models: BEGIN
[0m16:01:52.636659 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:01:52.643130 [debug] [ThreadPool]: SQL status: BEGIN in 0 seconds
[0m16:01:52.643678 [debug] [ThreadPool]: Using postgres connection "list_airflow_dbt_models"
[0m16:01:52.644111 [debug] [ThreadPool]: On list_airflow_dbt_models: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "connection_name": "list_airflow_dbt_models"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_models'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_models'
  
[0m16:01:52.652092 [debug] [ThreadPool]: SQL status: SELECT 0 in 0 seconds
[0m16:01:52.654431 [debug] [ThreadPool]: On list_airflow_dbt_models: ROLLBACK
[0m16:01:52.655192 [debug] [ThreadPool]: On list_airflow_dbt_models: Close
[0m16:01:52.664035 [debug] [MainThread]: Using postgres connection "master"
[0m16:01:52.664493 [debug] [MainThread]: On master: BEGIN
[0m16:01:52.664838 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:01:52.670745 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m16:01:52.671369 [debug] [MainThread]: Using postgres connection "master"
[0m16:01:52.671787 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:01:52.679752 [debug] [MainThread]: SQL status: SELECT 0 in 0 seconds
[0m16:01:52.682491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '412d3c71-c66b-4179-98cf-f07bc2c13e7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd82e11e450>]}
[0m16:01:52.683229 [debug] [MainThread]: On master: ROLLBACK
[0m16:01:52.684027 [debug] [MainThread]: Using postgres connection "master"
[0m16:01:52.684525 [debug] [MainThread]: On master: BEGIN
[0m16:01:52.685452 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m16:01:52.686028 [debug] [MainThread]: On master: COMMIT
[0m16:01:52.686462 [debug] [MainThread]: Using postgres connection "master"
[0m16:01:52.686861 [debug] [MainThread]: On master: COMMIT
[0m16:01:52.687435 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m16:01:52.687886 [debug] [MainThread]: On master: Close
[0m16:01:52.689109 [info ] [MainThread]: Concurrency: 2 threads (target='dev')
[0m16:01:52.689766 [info ] [MainThread]: 
[0m16:01:52.739485 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.test_model
[0m16:01:52.740627 [info ] [Thread-1 (]: 1 of 1 START sql view model dbt_models.test_model .............................. [RUN]
[0m16:01:52.742284 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.airflow_dbt_project.test_model'
[0m16:01:52.742929 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.test_model
[0m16:01:52.750625 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.test_model"
[0m16:01:52.753208 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.test_model (compile): 2025-11-10 16:01:52.743334 => 2025-11-10 16:01:52.752737
[0m16:01:52.754387 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.test_model
[0m16:01:52.883440 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.test_model"
[0m16:01:52.885412 [debug] [Thread-1 (]: Using postgres connection "model.airflow_dbt_project.test_model"
[0m16:01:52.886198 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: BEGIN
[0m16:01:52.886932 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:01:52.899707 [debug] [Thread-1 (]: SQL status: BEGIN in 0 seconds
[0m16:01:52.900638 [debug] [Thread-1 (]: Using postgres connection "model.airflow_dbt_project.test_model"
[0m16:01:52.901280 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "node_id": "model.airflow_dbt_project.test_model"} */

  create view "airflow"."dbt_models"."test_model__dbt_tmp" as (
    

select 
  1 as id,
  'hello_dbt' as message
  );
[0m16:01:52.918963 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0 seconds
[0m16:01:52.948515 [debug] [Thread-1 (]: Using postgres connection "model.airflow_dbt_project.test_model"
[0m16:01:52.949433 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "node_id": "model.airflow_dbt_project.test_model"} */
alter table "airflow"."dbt_models"."test_model__dbt_tmp" rename to "test_model"
[0m16:01:52.951434 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0 seconds
[0m16:01:53.018319 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: COMMIT
[0m16:01:53.019282 [debug] [Thread-1 (]: Using postgres connection "model.airflow_dbt_project.test_model"
[0m16:01:53.019942 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: COMMIT
[0m16:01:53.027229 [debug] [Thread-1 (]: SQL status: COMMIT in 0 seconds
[0m16:01:53.046495 [debug] [Thread-1 (]: Using postgres connection "model.airflow_dbt_project.test_model"
[0m16:01:53.047214 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "node_id": "model.airflow_dbt_project.test_model"} */
drop view if exists "airflow"."dbt_models"."test_model__dbt_backup" cascade
[0m16:01:53.048667 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0 seconds
[0m16:01:53.053265 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.test_model (execute): 2025-11-10 16:01:52.755055 => 2025-11-10 16:01:53.053091
[0m16:01:53.054031 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: Close
[0m16:01:53.056542 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '412d3c71-c66b-4179-98cf-f07bc2c13e7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd82e18c8f0>]}
[0m16:01:53.058154 [info ] [Thread-1 (]: 1 of 1 OK created sql view model dbt_models.test_model ......................... [[32mCREATE VIEW[0m in 0.31s]
[0m16:01:53.065054 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.test_model
[0m16:01:53.071784 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:01:53.072956 [debug] [MainThread]: Using postgres connection "master"
[0m16:01:53.073714 [debug] [MainThread]: On master: BEGIN
[0m16:01:53.074352 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:01:53.084462 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m16:01:53.085460 [debug] [MainThread]: On master: COMMIT
[0m16:01:53.086099 [debug] [MainThread]: Using postgres connection "master"
[0m16:01:53.086667 [debug] [MainThread]: On master: COMMIT
[0m16:01:53.088077 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m16:01:53.088967 [debug] [MainThread]: On master: Close
[0m16:01:53.091154 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:01:53.091965 [debug] [MainThread]: Connection 'model.airflow_dbt_project.test_model' was properly closed.
[0m16:01:53.092719 [info ] [MainThread]: 
[0m16:01:53.093913 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.57 seconds (0.57s).
[0m16:01:53.095298 [debug] [MainThread]: Command end result
[0m16:01:53.116914 [info ] [MainThread]: 
[0m16:01:53.118291 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:01:53.119826 [info ] [MainThread]: 
[0m16:01:53.121143 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m16:01:53.122601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd82e1dd700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd82e1dc560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd82e1dd6d0>]}
[0m16:01:53.123532 [debug] [MainThread]: Flushing usage events


============================== 2025-11-10 17:43:05.623384 | 4f2505d6-320d-42b5-836b-82c051903629 ==============================
[0m17:43:05.623384 [info ] [MainThread]: Running with dbt=1.4.0
[0m17:43:05.635001 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m17:43:05.635540 [debug] [MainThread]: Tracking: tracking
[0m17:43:05.638672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f089ab57140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08999a75f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0899846f60>]}
[0m17:43:05.704745 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:43:05.705247 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:43:05.706131 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m17:43:05.719160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4f2505d6-320d-42b5-836b-82c051903629', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08999a7650>]}
[0m17:43:05.732456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4f2505d6-320d-42b5-836b-82c051903629', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f089975a570>]}
[0m17:43:05.733687 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 289 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m17:43:05.734638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4f2505d6-320d-42b5-836b-82c051903629', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f089a94bd70>]}
[0m17:43:05.738248 [info ] [MainThread]: 
[0m17:43:05.746060 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:43:05.750209 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m17:43:05.787113 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m17:43:05.787824 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m17:43:05.788340 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:43:05.799992 [debug] [ThreadPool]: SQL status: SELECT 5 in 0 seconds
[0m17:43:05.804871 [debug] [ThreadPool]: On list_airflow: Close
[0m17:43:05.809056 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_dbt_models'
[0m17:43:05.822683 [debug] [ThreadPool]: Using postgres connection "list_airflow_dbt_models"
[0m17:43:05.823290 [debug] [ThreadPool]: On list_airflow_dbt_models: BEGIN
[0m17:43:05.823680 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:43:05.830851 [debug] [ThreadPool]: SQL status: BEGIN in 0 seconds
[0m17:43:05.831500 [debug] [ThreadPool]: Using postgres connection "list_airflow_dbt_models"
[0m17:43:05.831906 [debug] [ThreadPool]: On list_airflow_dbt_models: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "connection_name": "list_airflow_dbt_models"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_models'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_models'
  
[0m17:43:05.842508 [debug] [ThreadPool]: SQL status: SELECT 1 in 0 seconds
[0m17:43:05.846472 [debug] [ThreadPool]: On list_airflow_dbt_models: ROLLBACK
[0m17:43:05.847756 [debug] [ThreadPool]: On list_airflow_dbt_models: Close
[0m17:43:05.862974 [debug] [MainThread]: Using postgres connection "master"
[0m17:43:05.863594 [debug] [MainThread]: On master: BEGIN
[0m17:43:05.864024 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:43:05.872090 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m17:43:05.872836 [debug] [MainThread]: Using postgres connection "master"
[0m17:43:05.873403 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:43:05.897463 [debug] [MainThread]: SQL status: SELECT 0 in 0 seconds
[0m17:43:05.901094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4f2505d6-320d-42b5-836b-82c051903629', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f089a17a000>]}
[0m17:43:05.902138 [debug] [MainThread]: On master: ROLLBACK
[0m17:43:05.903300 [debug] [MainThread]: Using postgres connection "master"
[0m17:43:05.904016 [debug] [MainThread]: On master: BEGIN
[0m17:43:05.905277 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m17:43:05.906009 [debug] [MainThread]: On master: COMMIT
[0m17:43:05.906607 [debug] [MainThread]: Using postgres connection "master"
[0m17:43:05.907158 [debug] [MainThread]: On master: COMMIT
[0m17:43:05.908129 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m17:43:05.908870 [debug] [MainThread]: On master: Close
[0m17:43:05.910709 [info ] [MainThread]: Concurrency: 2 threads (target='dev')
[0m17:43:05.911774 [info ] [MainThread]: 
[0m17:43:05.980257 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.test_model
[0m17:43:05.981245 [info ] [Thread-1 (]: 1 of 1 START sql view model dbt_models.test_model .............................. [RUN]
[0m17:43:05.982980 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.airflow_dbt_project.test_model'
[0m17:43:05.983570 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.test_model
[0m17:43:05.988734 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.test_model"
[0m17:43:05.989737 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.test_model (compile): 2025-11-10 17:43:05.983918 => 2025-11-10 17:43:05.989566
[0m17:43:05.990294 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.test_model
[0m17:43:06.085893 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.test_model"
[0m17:43:06.086857 [debug] [Thread-1 (]: Using postgres connection "model.airflow_dbt_project.test_model"
[0m17:43:06.087256 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: BEGIN
[0m17:43:06.087552 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:43:06.093944 [debug] [Thread-1 (]: SQL status: BEGIN in 0 seconds
[0m17:43:06.094520 [debug] [Thread-1 (]: Using postgres connection "model.airflow_dbt_project.test_model"
[0m17:43:06.094939 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "node_id": "model.airflow_dbt_project.test_model"} */

  create view "airflow"."dbt_models"."test_model__dbt_tmp" as (
    

select 
  1 as id,
  'hello_dbt' as message
  );
[0m17:43:06.105701 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0 seconds
[0m17:43:06.120883 [debug] [Thread-1 (]: Using postgres connection "model.airflow_dbt_project.test_model"
[0m17:43:06.121467 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "node_id": "model.airflow_dbt_project.test_model"} */
alter table "airflow"."dbt_models"."test_model" rename to "test_model__dbt_backup"
[0m17:43:06.122745 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0 seconds
[0m17:43:06.129086 [debug] [Thread-1 (]: Using postgres connection "model.airflow_dbt_project.test_model"
[0m17:43:06.129611 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "node_id": "model.airflow_dbt_project.test_model"} */
alter table "airflow"."dbt_models"."test_model__dbt_tmp" rename to "test_model"
[0m17:43:06.130793 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0 seconds
[0m17:43:06.168711 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: COMMIT
[0m17:43:06.169203 [debug] [Thread-1 (]: Using postgres connection "model.airflow_dbt_project.test_model"
[0m17:43:06.169477 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: COMMIT
[0m17:43:06.175890 [debug] [Thread-1 (]: SQL status: COMMIT in 0 seconds
[0m17:43:06.186087 [debug] [Thread-1 (]: Using postgres connection "model.airflow_dbt_project.test_model"
[0m17:43:06.186510 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "node_id": "model.airflow_dbt_project.test_model"} */
drop view if exists "airflow"."dbt_models"."test_model__dbt_backup" cascade
[0m17:43:06.195299 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0 seconds
[0m17:43:06.197498 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.test_model (execute): 2025-11-10 17:43:05.990595 => 2025-11-10 17:43:06.197413
[0m17:43:06.197824 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: Close
[0m17:43:06.198790 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f2505d6-320d-42b5-836b-82c051903629', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0898f7a810>]}
[0m17:43:06.199419 [info ] [Thread-1 (]: 1 of 1 OK created sql view model dbt_models.test_model ......................... [[32mCREATE VIEW[0m in 0.22s]
[0m17:43:06.202113 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.test_model
[0m17:43:06.204547 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:43:06.205003 [debug] [MainThread]: Using postgres connection "master"
[0m17:43:06.205290 [debug] [MainThread]: On master: BEGIN
[0m17:43:06.205575 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:43:06.212020 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m17:43:06.212630 [debug] [MainThread]: On master: COMMIT
[0m17:43:06.213098 [debug] [MainThread]: Using postgres connection "master"
[0m17:43:06.213518 [debug] [MainThread]: On master: COMMIT
[0m17:43:06.214217 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m17:43:06.214714 [debug] [MainThread]: On master: Close
[0m17:43:06.216055 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:43:06.216637 [debug] [MainThread]: Connection 'model.airflow_dbt_project.test_model' was properly closed.
[0m17:43:06.217227 [info ] [MainThread]: 
[0m17:43:06.217911 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.48 seconds (0.48s).
[0m17:43:06.218860 [debug] [MainThread]: Command end result
[0m17:43:06.234160 [info ] [MainThread]: 
[0m17:43:06.235287 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:43:06.236093 [info ] [MainThread]: 
[0m17:43:06.236816 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m17:43:06.237673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f089a1e56d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f089a17a000>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0898b0f7d0>]}
[0m17:43:06.238382 [debug] [MainThread]: Flushing usage events


============================== 2025-11-11 13:44:03.312415 | 0e17fb39-56d5-4ce4-9889-1da59bca6491 ==============================
[0m13:44:03.312415 [info ] [MainThread]: Running with dbt=1.4.0
[0m13:44:03.314636 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:44:03.314939 [debug] [MainThread]: Tracking: tracking
[0m13:44:03.315225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd7efdd700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd6190e2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd618cb2f0>]}
[0m13:44:03.340296 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m13:44:03.341063 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m13:44:03.341543 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:44:03.342039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0e17fb39-56d5-4ce4-9889-1da59bca6491', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd61587ef0>]}
[0m13:44:04.059229 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m13:44:04.100057 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m13:44:04.105732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0e17fb39-56d5-4ce4-9889-1da59bca6491', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd615af2c0>]}
[0m13:44:04.112397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0e17fb39-56d5-4ce4-9889-1da59bca6491', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd615af2f0>]}
[0m13:44:04.112880 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m13:44:04.113246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0e17fb39-56d5-4ce4-9889-1da59bca6491', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd619fc620>]}
[0m13:44:04.114756 [info ] [MainThread]: 
[0m13:44:04.117746 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:44:04.119996 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m13:44:04.160879 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m13:44:04.161384 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m13:44:04.161719 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:44:06.860882 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 3 seconds
[0m13:44:06.864050 [debug] [ThreadPool]: On list_GP: Close
[0m13:44:07.271838 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m13:44:07.282316 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m13:44:07.282673 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m13:44:07.282972 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:44:08.153438 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1 seconds
[0m13:44:08.156426 [debug] [ThreadPool]: On list_GP_test: Close
[0m13:44:08.599996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0e17fb39-56d5-4ce4-9889-1da59bca6491', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd615af290>]}
[0m13:44:08.602120 [info ] [MainThread]: Concurrency: 2 threads (target='dev')
[0m13:44:08.603312 [info ] [MainThread]: 
[0m13:44:08.666619 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.test_model
[0m13:44:08.667612 [info ] [Thread-1 (]: 1 of 1 START sql view model test.test_model .................................... [RUN]
[0m13:44:08.669369 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.test_model'
[0m13:44:08.669947 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.test_model
[0m13:44:08.676162 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.test_model"
[0m13:44:08.677519 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.test_model (compile): 2025-11-11 13:44:08.670281 => 2025-11-11 13:44:08.677309
[0m13:44:08.678378 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.test_model
[0m13:44:08.759688 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.test_model"
[0m13:44:08.760914 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.test_model"
[0m13:44:08.761296 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "dev", "node_id": "model.airflow_dbt_project.test_model"} */
create or replace   view GP.test.test_model
  
   as (
    

select 
  1 as id,
  'hello_dbt' as message
  );
[0m13:44:08.761578 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:44:10.030884 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:44:10.062567 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.test_model (execute): 2025-11-11 13:44:08.678824 => 2025-11-11 13:44:10.062451
[0m13:44:10.063048 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: Close
[0m13:44:10.546114 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e17fb39-56d5-4ce4-9889-1da59bca6491', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd3b3747a0>]}
[0m13:44:10.547108 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.test_model ............................... [[32mSUCCESS 1[0m in 1.88s]
[0m13:44:10.550233 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.test_model
[0m13:44:10.553018 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:44:10.554113 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:44:10.554504 [debug] [MainThread]: Connection 'model.airflow_dbt_project.test_model' was properly closed.
[0m13:44:10.554870 [info ] [MainThread]: 
[0m13:44:10.555250 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 6.44 seconds (6.44s).
[0m13:44:10.555742 [debug] [MainThread]: Command end result
[0m13:44:10.567150 [info ] [MainThread]: 
[0m13:44:10.567875 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:44:10.568331 [info ] [MainThread]: 
[0m13:44:10.568723 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:44:10.569576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd62435730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd61fe3fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd631a6a50>]}
[0m13:44:10.570908 [debug] [MainThread]: Flushing usage events


============================== 2025-11-11 15:13:59.634302 | 0781d1b8-7552-4b85-af0a-dd1f3f58e89a ==============================
[0m15:13:59.634302 [info ] [MainThread]: Running with dbt=1.4.0
[0m15:13:59.638261 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:13:59.638791 [debug] [MainThread]: Tracking: tracking
[0m15:13:59.639310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9379a56240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938a3c0aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9379a56090>]}
[0m15:13:59.677962 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m15:13:59.679039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0781d1b8-7552-4b85-af0a-dd1f3f58e89a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93798ac620>]}
[0m15:14:00.535133 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m15:14:00.580395 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m15:14:00.587321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0781d1b8-7552-4b85-af0a-dd1f3f58e89a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9379884d10>]}
[0m15:14:00.595733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0781d1b8-7552-4b85-af0a-dd1f3f58e89a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9379888e90>]}
[0m15:14:00.596312 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m15:14:00.596751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0781d1b8-7552-4b85-af0a-dd1f3f58e89a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9379862900>]}
[0m15:14:00.598658 [info ] [MainThread]: 
[0m15:14:00.603211 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m15:14:00.605859 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m15:14:00.640999 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m15:14:00.641554 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m15:14:00.641957 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:14:02.132032 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1 seconds
[0m15:14:02.134955 [debug] [ThreadPool]: On list_GP: Close
[0m15:14:02.524591 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m15:14:02.538246 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m15:14:02.538703 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m15:14:02.539025 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:14:03.557895 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m15:14:03.561088 [debug] [ThreadPool]: On list_GP_test: Close
[0m15:14:03.959527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0781d1b8-7552-4b85-af0a-dd1f3f58e89a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9379a566f0>]}
[0m15:14:03.960782 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m15:14:03.961331 [info ] [MainThread]: 
[0m15:14:04.016560 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.test_model
[0m15:14:04.017425 [info ] [Thread-1 (]: 1 of 1 START sql view model test.test_model .................................... [RUN]
[0m15:14:04.018591 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.test_model'
[0m15:14:04.019018 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.test_model
[0m15:14:04.023141 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.test_model"
[0m15:14:04.023839 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.test_model (compile): 2025-11-11 15:14:04.019269 => 2025-11-11 15:14:04.023723
[0m15:14:04.024225 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.test_model
[0m15:14:04.122275 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.test_model"
[0m15:14:04.123921 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.test_model"
[0m15:14:04.124423 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.test_model"} */
create or replace   view GP.test.test_model
  
   as (
    

select 
  1 as id,
  'hello_dbt' as message
  );
[0m15:14:04.124823 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:14:05.173327 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m15:14:05.201312 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.test_model (execute): 2025-11-11 15:14:04.024459 => 2025-11-11 15:14:05.201217
[0m15:14:05.201712 [debug] [Thread-1 (]: On model.airflow_dbt_project.test_model: Close
[0m15:14:05.594087 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0781d1b8-7552-4b85-af0a-dd1f3f58e89a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93536b0800>]}
[0m15:14:05.594938 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.test_model ............................... [[32mSUCCESS 1[0m in 1.58s]
[0m15:14:05.597853 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.test_model
[0m15:14:05.600596 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m15:14:05.601690 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:14:05.602172 [debug] [MainThread]: Connection 'model.airflow_dbt_project.test_model' was properly closed.
[0m15:14:05.602629 [info ] [MainThread]: 
[0m15:14:05.603345 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.00 seconds (5.00s).
[0m15:14:05.604075 [debug] [MainThread]: Command end result
[0m15:14:05.616829 [info ] [MainThread]: 
[0m15:14:05.617774 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:14:05.619370 [info ] [MainThread]: 
[0m15:14:05.620359 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:14:05.621413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f937a41b890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f939bbd7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938a30fd40>]}
[0m15:14:05.622301 [debug] [MainThread]: Flushing usage events


============================== 2025-11-11 16:31:14.637888 | 8ff47ac3-9836-4168-9470-e906062daca5 ==============================
[0m16:31:14.637888 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:31:14.641642 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['customer'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m16:31:14.642194 [debug] [MainThread]: Tracking: tracking
[0m16:31:14.642717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe06924df40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe06924df70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe06924e0f0>]}
[0m16:31:14.713001 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m16:31:14.713816 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/customer.sql
[0m16:31:14.736583 [debug] [MainThread]: 1699: static parser successfully parsed customer.sql
[0m16:31:14.773184 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m16:31:14.783256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8ff47ac3-9836-4168-9470-e906062daca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe069a6ea80>]}
[0m16:31:14.794360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8ff47ac3-9836-4168-9470-e906062daca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0692a1ca0>]}
[0m16:31:14.795073 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:31:14.795731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8ff47ac3-9836-4168-9470-e906062daca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe090924e90>]}
[0m16:31:14.798465 [info ] [MainThread]: 
[0m16:31:14.804906 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:31:14.809250 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m16:31:14.851676 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m16:31:14.852282 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m16:31:14.852769 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:31:16.436215 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 2 seconds
[0m16:31:16.439408 [debug] [ThreadPool]: On list_GP: Close
[0m16:31:16.985041 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m16:31:16.996055 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m16:31:16.996470 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m16:31:16.996754 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:31:18.182014 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1 seconds
[0m16:31:18.185481 [debug] [ThreadPool]: On list_GP_test: Close
[0m16:31:18.692372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8ff47ac3-9836-4168-9470-e906062daca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0691035c0>]}
[0m16:31:18.693598 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:31:18.694128 [info ] [MainThread]: 
[0m16:31:18.747933 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.customer
[0m16:31:18.748665 [info ] [Thread-1 (]: 1 of 1 START sql view model test.customer ...................................... [RUN]
[0m16:31:18.749843 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.customer'
[0m16:31:18.750253 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.customer
[0m16:31:18.752948 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.customer"
[0m16:31:18.753793 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (compile): 2025-11-11 16:31:18.750522 => 2025-11-11 16:31:18.753663
[0m16:31:18.754205 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.customer
[0m16:31:18.824680 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.customer"
[0m16:31:18.826200 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.customer"
[0m16:31:18.826594 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.customer"} */
create or replace   view GP.test.customer
  
   as (
    with cus as( -- in conection we define wharehouse,database,and schema, so we use directly the table names
    select customer_id,email from CUSTOMERS 
    where status='active'
),
alls as(
    select 
    order_id,
    order_date,
    total_amount,
    shipping_address
    from products p join cus c using (customer_id) 
    where is_active=True 
)
select * from alls;
[0m16:31:18.826869 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:31:20.144262 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c052bf-0000-a5d9-0000-0000eb0d7f3d
[0m16:31:20.144780 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 17 at position 18 unexpected ';'.
[0m16:31:20.145404 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (execute): 2025-11-11 16:31:18.754512 => 2025-11-11 16:31:20.145259
[0m16:31:20.145781 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: Close
[0m16:31:20.668220 [debug] [Thread-1 (]: Database Error in model customer (models/customer.sql)
  001003 (42000): SQL compilation error:
  syntax error line 17 at position 18 unexpected ';'.
  compiled Code at target/run/airflow_dbt_project/models/customer.sql
[0m16:31:20.668902 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8ff47ac3-9836-4168-9470-e906062daca5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe04aebb560>]}
[0m16:31:20.669562 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test.customer ............................. [[31mERROR[0m in 1.92s]
[0m16:31:20.672238 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.customer
[0m16:31:20.675231 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:31:20.676219 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:31:20.676562 [debug] [MainThread]: Connection 'model.airflow_dbt_project.customer' was properly closed.
[0m16:31:20.676861 [info ] [MainThread]: 
[0m16:31:20.677276 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.88 seconds (5.88s).
[0m16:31:20.677837 [debug] [MainThread]: Command end result
[0m16:31:20.687669 [info ] [MainThread]: 
[0m16:31:20.688581 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:31:20.689211 [info ] [MainThread]: 
[0m16:31:20.690297 [error] [MainThread]: [33mDatabase Error in model customer (models/customer.sql)[0m
[0m16:31:20.690888 [error] [MainThread]:   001003 (42000): SQL compilation error:
[0m16:31:20.691367 [error] [MainThread]:   syntax error line 17 at position 18 unexpected ';'.
[0m16:31:20.691875 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/customer.sql
[0m16:31:20.692343 [info ] [MainThread]: 
[0m16:31:20.693104 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m16:31:20.694213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe04ae0bce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe04b7a7d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe04b7223f0>]}
[0m16:31:20.695244 [debug] [MainThread]: Flushing usage events


============================== 2025-11-11 16:32:39.883479 | 739f101b-07c2-458d-9d1a-8b4409039d0b ==============================
[0m16:32:39.883479 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:32:39.885498 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['customer'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m16:32:39.885745 [debug] [MainThread]: Tracking: tracking
[0m16:32:39.886015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b69cdfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b4980ce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b41aa000>]}
[0m16:32:39.931229 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:32:39.932013 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/customer.sql
[0m16:32:39.950961 [debug] [MainThread]: 1699: static parser successfully parsed customer.sql
[0m16:32:39.980033 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m16:32:39.987990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '739f101b-07c2-458d-9d1a-8b4409039d0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86affaa7b0>]}
[0m16:32:39.997732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '739f101b-07c2-458d-9d1a-8b4409039d0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b48af0b0>]}
[0m16:32:39.998624 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:32:39.999379 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '739f101b-07c2-458d-9d1a-8b4409039d0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b69b0b90>]}
[0m16:32:40.002010 [info ] [MainThread]: 
[0m16:32:40.007591 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:32:40.011035 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m16:32:40.049135 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m16:32:40.049693 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m16:32:40.050048 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:32:41.731573 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 2 seconds
[0m16:32:41.733776 [debug] [ThreadPool]: On list_GP: Close
[0m16:32:42.245830 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m16:32:42.257253 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m16:32:42.257658 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m16:32:42.257927 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:32:43.512634 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1 seconds
[0m16:32:43.516118 [debug] [ThreadPool]: On list_GP_test: Close
[0m16:32:44.021609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '739f101b-07c2-458d-9d1a-8b4409039d0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86ae0905f0>]}
[0m16:32:44.022770 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:32:44.023249 [info ] [MainThread]: 
[0m16:32:44.067674 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.customer
[0m16:32:44.068586 [info ] [Thread-1 (]: 1 of 1 START sql view model test.customer ...................................... [RUN]
[0m16:32:44.070088 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.customer'
[0m16:32:44.070666 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.customer
[0m16:32:44.073642 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.customer"
[0m16:32:44.074432 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (compile): 2025-11-11 16:32:44.071032 => 2025-11-11 16:32:44.074270
[0m16:32:44.074841 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.customer
[0m16:32:44.138506 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.customer"
[0m16:32:44.140104 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.customer"
[0m16:32:44.140507 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.customer"} */
create or replace   view GP.test.customer
  
   as (
    with cus as( -- in conection we define wharehouse,database,and schema, so we use directly the table names
    select customer_id,email 
    from CUSTOMERS 
    where status='active'
),
alls as(
    select 
    order_id,
    order_date,
    total_amount,
    shipping_address
    from products p join cus c using (customer_id) 
    where is_active=True 
)
select * from alls
  );
[0m16:32:44.140800 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:32:45.252436 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c052c0-0000-a5d9-0000-0000eb0d7f4d
[0m16:32:45.252905 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002004 (42601): SQL compilation error:
Invalid identifier CUSTOMER_ID
[0m16:32:45.253533 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (execute): 2025-11-11 16:32:44.075112 => 2025-11-11 16:32:45.253397
[0m16:32:45.253865 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: Close
[0m16:32:45.767522 [debug] [Thread-1 (]: Database Error in model customer (models/customer.sql)
  002004 (42601): SQL compilation error:
  Invalid identifier CUSTOMER_ID
  compiled Code at target/run/airflow_dbt_project/models/customer.sql
[0m16:32:45.768173 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '739f101b-07c2-458d-9d1a-8b4409039d0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86adf79ca0>]}
[0m16:32:45.768853 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test.customer ............................. [[31mERROR[0m in 1.70s]
[0m16:32:45.771650 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.customer
[0m16:32:45.774653 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:32:45.775637 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:32:45.775987 [debug] [MainThread]: Connection 'model.airflow_dbt_project.customer' was properly closed.
[0m16:32:45.776353 [info ] [MainThread]: 
[0m16:32:45.776771 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.77 seconds (5.77s).
[0m16:32:45.777364 [debug] [MainThread]: Command end result
[0m16:32:45.787723 [info ] [MainThread]: 
[0m16:32:45.788720 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:32:45.789340 [info ] [MainThread]: 
[0m16:32:45.789849 [error] [MainThread]: [33mDatabase Error in model customer (models/customer.sql)[0m
[0m16:32:45.790380 [error] [MainThread]:   002004 (42601): SQL compilation error:
[0m16:32:45.790838 [error] [MainThread]:   Invalid identifier CUSTOMER_ID
[0m16:32:45.791281 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/customer.sql
[0m16:32:45.791783 [info ] [MainThread]: 
[0m16:32:45.792357 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m16:32:45.793130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86db820980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86db821700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86affc4e60>]}
[0m16:32:45.793743 [debug] [MainThread]: Flushing usage events


============================== 2025-11-11 16:33:59.433410 | e6e032f6-40cf-4b7a-b0f0-eb1d07fbb8dd ==============================
[0m16:33:59.433410 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:33:59.435387 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['customer'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m16:33:59.435645 [debug] [MainThread]: Tracking: tracking
[0m16:33:59.435936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07bb2ecfe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07c024d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07bba46d50>]}
[0m16:33:59.480455 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:33:59.481266 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/customer.sql
[0m16:33:59.500245 [debug] [MainThread]: 1699: static parser successfully parsed customer.sql
[0m16:33:59.530660 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m16:33:59.539408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e6e032f6-40cf-4b7a-b0f0-eb1d07fbb8dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07baf202f0>]}
[0m16:33:59.550433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e6e032f6-40cf-4b7a-b0f0-eb1d07fbb8dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07bb0c6030>]}
[0m16:33:59.551289 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:33:59.552052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e6e032f6-40cf-4b7a-b0f0-eb1d07fbb8dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07bb2269c0>]}
[0m16:33:59.555292 [info ] [MainThread]: 
[0m16:33:59.560907 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:33:59.565025 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m16:33:59.601013 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m16:33:59.601634 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m16:33:59.602043 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:34:01.296639 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 2 seconds
[0m16:34:01.298964 [debug] [ThreadPool]: On list_GP: Close
[0m16:34:01.745131 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m16:34:01.757538 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m16:34:01.758052 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m16:34:01.758415 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:34:02.953204 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1 seconds
[0m16:34:02.955238 [debug] [ThreadPool]: On list_GP_test: Close
[0m16:34:03.550864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e6e032f6-40cf-4b7a-b0f0-eb1d07fbb8dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07b8e71c40>]}
[0m16:34:03.551682 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:34:03.552027 [info ] [MainThread]: 
[0m16:34:03.592843 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.customer
[0m16:34:03.593635 [info ] [Thread-1 (]: 1 of 1 START sql view model test.customer ...................................... [RUN]
[0m16:34:03.594849 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.customer'
[0m16:34:03.595323 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.customer
[0m16:34:03.597647 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.customer"
[0m16:34:03.598376 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (compile): 2025-11-11 16:34:03.595584 => 2025-11-11 16:34:03.598245
[0m16:34:03.598784 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.customer
[0m16:34:03.658764 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.customer"
[0m16:34:03.660090 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.customer"
[0m16:34:03.660441 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.customer"} */
create or replace   view GP.test.customer
  
   as (
    with cus as( -- in conection we define wharehouse,database,and schema, so we use directly the table names
    select customer_id,email 
    from CUSTOMERS 
    where status='active'
),
alls as(
    select 
    order_id,
    order_date,
    total_amount,
    shipping_address
    from orders o join cus c using (customer_id) 
    where is_active=True 
)
select * from alls
  );
[0m16:34:03.660700 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:34:05.019293 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c052c2-0000-a5d9-0000-0000eb0d7f59
[0m16:34:05.019743 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 16 at position 10
invalid identifier 'IS_ACTIVE'
[0m16:34:05.020347 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (execute): 2025-11-11 16:34:03.599026 => 2025-11-11 16:34:05.020205
[0m16:34:05.020709 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: Close
[0m16:34:06.731711 [debug] [Thread-1 (]: Database Error in model customer (models/customer.sql)
  000904 (42000): SQL compilation error: error line 16 at position 10
  invalid identifier 'IS_ACTIVE'
  compiled Code at target/run/airflow_dbt_project/models/customer.sql
[0m16:34:06.732540 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6e032f6-40cf-4b7a-b0f0-eb1d07fbb8dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07b8d16450>]}
[0m16:34:06.733366 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test.customer ............................. [[31mERROR[0m in 3.14s]
[0m16:34:06.736776 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.customer
[0m16:34:06.740201 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:34:06.741907 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:34:06.742533 [debug] [MainThread]: Connection 'model.airflow_dbt_project.customer' was properly closed.
[0m16:34:06.743160 [info ] [MainThread]: 
[0m16:34:06.743827 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 7.19 seconds (7.19s).
[0m16:34:06.744515 [debug] [MainThread]: Command end result
[0m16:34:06.757489 [info ] [MainThread]: 
[0m16:34:06.758680 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:34:06.762087 [info ] [MainThread]: 
[0m16:34:06.763242 [error] [MainThread]: [33mDatabase Error in model customer (models/customer.sql)[0m
[0m16:34:06.764245 [error] [MainThread]:   000904 (42000): SQL compilation error: error line 16 at position 10
[0m16:34:06.765093 [error] [MainThread]:   invalid identifier 'IS_ACTIVE'
[0m16:34:06.765717 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/customer.sql
[0m16:34:06.766240 [info ] [MainThread]: 
[0m16:34:06.766812 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m16:34:06.767541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07bb0ad160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07baf69cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07b8e3abd0>]}
[0m16:34:06.768101 [debug] [MainThread]: Flushing usage events


============================== 2025-11-11 16:34:48.522599 | 2e4ebb2f-b702-4883-8236-78ae2b3a174e ==============================
[0m16:34:48.522599 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:34:48.525901 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['customer'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m16:34:48.526275 [debug] [MainThread]: Tracking: tracking
[0m16:34:48.526691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde460b23c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde45f0a930>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde45f0a120>]}
[0m16:34:48.580570 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:34:48.581396 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/customer.sql
[0m16:34:48.602203 [debug] [MainThread]: 1699: static parser successfully parsed customer.sql
[0m16:34:48.633542 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m16:34:48.642509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2e4ebb2f-b702-4883-8236-78ae2b3a174e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde466d14f0>]}
[0m16:34:48.653694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2e4ebb2f-b702-4883-8236-78ae2b3a174e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde45f5dca0>]}
[0m16:34:48.654525 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:34:48.655235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2e4ebb2f-b702-4883-8236-78ae2b3a174e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde462c69f0>]}
[0m16:34:48.658163 [info ] [MainThread]: 
[0m16:34:48.664720 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:34:48.668467 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m16:34:48.704055 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m16:34:48.704559 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m16:34:48.704898 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:34:50.145121 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1 seconds
[0m16:34:50.148275 [debug] [ThreadPool]: On list_GP: Close
[0m16:34:50.659471 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m16:34:50.671263 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m16:34:50.671650 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m16:34:50.671926 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:34:51.814027 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1 seconds
[0m16:34:51.817018 [debug] [ThreadPool]: On list_GP_test: Close
[0m16:34:52.401130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2e4ebb2f-b702-4883-8236-78ae2b3a174e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde46079430>]}
[0m16:34:52.402285 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:34:52.402761 [info ] [MainThread]: 
[0m16:34:52.446687 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.customer
[0m16:34:52.447520 [info ] [Thread-1 (]: 1 of 1 START sql view model test.customer ...................................... [RUN]
[0m16:34:52.448870 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.customer'
[0m16:34:52.449370 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.customer
[0m16:34:52.451910 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.customer"
[0m16:34:52.452825 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (compile): 2025-11-11 16:34:52.449682 => 2025-11-11 16:34:52.452551
[0m16:34:52.453266 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.customer
[0m16:34:52.508758 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.customer"
[0m16:34:52.509888 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.customer"
[0m16:34:52.510165 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.customer"} */
create or replace   view GP.test.customer
  
   as (
    with cus as( -- in conection we define wharehouse,database,and schema, so we use directly the table names
    select customer_id,email 
    from CUSTOMERS 
    where status='active'
),
alls as(
    select 
    order_id,
    order_date,
    total_amount,
    shipping_address
    from orders o join cus c using (customer_id) 
)
select * from alls
  );
[0m16:34:52.510377 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:34:53.929472 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:34:53.957223 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (execute): 2025-11-11 16:34:52.453505 => 2025-11-11 16:34:53.957126
[0m16:34:53.957630 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: Close
[0m16:34:54.445463 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e4ebb2f-b702-4883-8236-78ae2b3a174e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde445a2300>]}
[0m16:34:54.446438 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.customer ................................. [[32mSUCCESS 1[0m in 2.00s]
[0m16:34:54.449494 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.customer
[0m16:34:54.452131 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:34:54.453058 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:34:54.453388 [debug] [MainThread]: Connection 'model.airflow_dbt_project.customer' was properly closed.
[0m16:34:54.453695 [info ] [MainThread]: 
[0m16:34:54.454097 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.79 seconds (5.79s).
[0m16:34:54.454646 [debug] [MainThread]: Command end result
[0m16:34:54.464272 [info ] [MainThread]: 
[0m16:34:54.465016 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:34:54.465587 [info ] [MainThread]: 
[0m16:34:54.466024 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m16:34:54.466658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde46079430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde44627a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde46a23e60>]}
[0m16:34:54.467169 [debug] [MainThread]: Flushing usage events


============================== 2025-11-11 16:38:22.009846 | 92cf0bfa-af54-4135-85f8-bdd7d887ce12 ==============================
[0m16:38:22.009846 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:38:22.017600 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['customer'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m16:38:22.018568 [debug] [MainThread]: Tracking: tracking
[0m16:38:22.019469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b5e99e600>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b6db24aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b5f04dd90>]}
[0m16:38:22.129124 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:38:22.131315 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/customer.sql
[0m16:38:22.187836 [debug] [MainThread]: 1699: static parser successfully parsed customer.sql
[0m16:38:22.265593 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m16:38:22.293257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '92cf0bfa-af54-4135-85f8-bdd7d887ce12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b5e697380>]}
[0m16:38:22.318102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '92cf0bfa-af54-4135-85f8-bdd7d887ce12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b5e849d00>]}
[0m16:38:22.319451 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:38:22.320698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '92cf0bfa-af54-4135-85f8-bdd7d887ce12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b5efa6420>]}
[0m16:38:22.324842 [info ] [MainThread]: 
[0m16:38:22.333802 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:38:22.338222 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m16:38:22.409643 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m16:38:22.410949 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m16:38:22.411807 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:38:24.672806 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 2 seconds
[0m16:38:24.680612 [debug] [ThreadPool]: On list_GP: Close
[0m16:38:25.195280 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m16:38:25.232448 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m16:38:25.233601 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m16:38:25.234455 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:38:26.066718 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m16:38:26.070991 [debug] [ThreadPool]: On list_GP_test: Close
[0m16:38:26.519998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '92cf0bfa-af54-4135-85f8-bdd7d887ce12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b5e99e6c0>]}
[0m16:38:26.521573 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:38:26.522252 [info ] [MainThread]: 
[0m16:38:26.587128 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.customer
[0m16:38:26.588201 [info ] [Thread-1 (]: 1 of 1 START sql view model test.customer ...................................... [RUN]
[0m16:38:26.589715 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.customer'
[0m16:38:26.590235 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.customer
[0m16:38:26.593193 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.customer"
[0m16:38:26.594633 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (compile): 2025-11-11 16:38:26.590558 => 2025-11-11 16:38:26.594425
[0m16:38:26.595369 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.customer
[0m16:38:26.662606 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.customer"
[0m16:38:26.664119 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.customer"
[0m16:38:26.664523 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.customer"} */
create or replace   view GP.test.customer
  
   as (
    with cus as( -- in conection we define wharehouse,database,and schema, so we use directly the table names
    select customer_id,email 
    from CUSTOMERS 
    where status='active'
),
alls as(
    select 
    order_id,
    order_date,
    total_amount,
    shipping_address
    from orders o join cus c on
    o.customer_id=c.customer_id 
)
select * from alls
  );
[0m16:38:26.664814 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:38:28.151076 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:38:28.183696 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (execute): 2025-11-11 16:38:26.595822 => 2025-11-11 16:38:28.183595
[0m16:38:28.184101 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: Close
[0m16:38:28.603348 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92cf0bfa-af54-4135-85f8-bdd7d887ce12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b5c6520c0>]}
[0m16:38:28.604223 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.customer ................................. [[32mSUCCESS 1[0m in 2.01s]
[0m16:38:28.607398 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.customer
[0m16:38:28.609815 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:38:28.610746 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:38:28.611084 [debug] [MainThread]: Connection 'model.airflow_dbt_project.customer' was properly closed.
[0m16:38:28.611464 [info ] [MainThread]: 
[0m16:38:28.611857 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 6.29 seconds (6.29s).
[0m16:38:28.612710 [debug] [MainThread]: Command end result
[0m16:38:28.624674 [info ] [MainThread]: 
[0m16:38:28.625610 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:38:28.626247 [info ] [MainThread]: 
[0m16:38:28.626928 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m16:38:28.627940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b5c727bc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b5efa6330>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b5f009eb0>]}
[0m16:38:28.628933 [debug] [MainThread]: Flushing usage events


============================== 2025-11-11 16:40:52.282823 | 24f61011-777e-485c-9383-0cb69cb6e83d ==============================
[0m16:40:52.282823 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:40:52.285515 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['customer'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m16:40:52.285843 [debug] [MainThread]: Tracking: tracking
[0m16:40:52.286186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f386f9a6ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38748b4a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38748389b0>]}
[0m16:40:52.335477 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:40:52.336286 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/customer.sql
[0m16:40:52.357694 [debug] [MainThread]: 1699: static parser successfully parsed customer.sql
[0m16:40:52.389013 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m16:40:52.397432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '24f61011-777e-485c-9383-0cb69cb6e83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f386f701d90>]}
[0m16:40:52.408576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '24f61011-777e-485c-9383-0cb69cb6e83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f386f82dcd0>]}
[0m16:40:52.409618 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:40:52.410578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '24f61011-777e-485c-9383-0cb69cb6e83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f386f92dfa0>]}
[0m16:40:52.414583 [info ] [MainThread]: 
[0m16:40:52.420210 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:40:52.423574 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m16:40:52.461944 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m16:40:52.462468 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m16:40:52.462812 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:40:53.958235 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1 seconds
[0m16:40:53.961972 [debug] [ThreadPool]: On list_GP: Close
[0m16:40:54.380534 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m16:40:54.394855 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m16:40:54.395402 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m16:40:54.395751 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:40:55.341800 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m16:40:55.344458 [debug] [ThreadPool]: On list_GP_test: Close
[0m16:40:55.828279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '24f61011-777e-485c-9383-0cb69cb6e83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389b966cf0>]}
[0m16:40:55.829540 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:40:55.830086 [info ] [MainThread]: 
[0m16:40:55.877547 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.customer
[0m16:40:55.878283 [info ] [Thread-1 (]: 1 of 1 START sql view model test.customer ...................................... [RUN]
[0m16:40:55.879390 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.customer'
[0m16:40:55.879781 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.customer
[0m16:40:55.882158 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.customer"
[0m16:40:55.882933 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (compile): 2025-11-11 16:40:55.880019 => 2025-11-11 16:40:55.882815
[0m16:40:55.883346 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.customer
[0m16:40:55.950345 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.customer"
[0m16:40:55.951862 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.customer"
[0m16:40:55.952245 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.customer"} */
create or replace   view GP.test.customer
  
   as (
    with cus as( -- in conection we define wharehouse,database,and schema, so we use directly the table names
    select customer_id,email 
    from CUSTOMERS 
    where status='active'
),
alls as(
    select 
    order_id,
    order_date,
    total_amount,
    shipping_address
    from ORDERS o join cus c on
    o.customer_id=c.customer_id 
)
select * from alls
  );
[0m16:40:55.952536 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:40:57.347639 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:40:57.383406 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (execute): 2025-11-11 16:40:55.883584 => 2025-11-11 16:40:57.383282
[0m16:40:57.383872 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: Close
[0m16:40:57.861353 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24f61011-777e-485c-9383-0cb69cb6e83d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f386d8d19d0>]}
[0m16:40:57.862038 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.customer ................................. [[32mSUCCESS 1[0m in 1.98s]
[0m16:40:57.864524 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.customer
[0m16:40:57.867222 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:40:57.868025 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:40:57.868296 [debug] [MainThread]: Connection 'model.airflow_dbt_project.customer' was properly closed.
[0m16:40:57.868576 [info ] [MainThread]: 
[0m16:40:57.869015 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.45 seconds (5.45s).
[0m16:40:57.869695 [debug] [MainThread]: Command end result
[0m16:40:57.881662 [info ] [MainThread]: 
[0m16:40:57.882621 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:40:57.883410 [info ] [MainThread]: 
[0m16:40:57.884094 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m16:40:57.885101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f386f7b3530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f386f6f6bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f386fd9b620>]}
[0m16:40:57.885859 [debug] [MainThread]: Flushing usage events


============================== 2025-11-11 16:41:53.117842 | be81220f-1f35-4f25-abf3-5c3b5227e6ff ==============================
[0m16:41:53.117842 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:41:53.120729 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['customer'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m16:41:53.121105 [debug] [MainThread]: Tracking: tracking
[0m16:41:53.121519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ffa9c75c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fd6c00290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fd685e870>]}
[0m16:41:53.172405 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:41:53.173147 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/customer.sql
[0m16:41:53.191659 [debug] [MainThread]: 1699: static parser successfully parsed customer.sql
[0m16:41:53.220086 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m16:41:53.228810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'be81220f-1f35-4f25-abf3-5c3b5227e6ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fd69cf410>]}
[0m16:41:53.238551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'be81220f-1f35-4f25-abf3-5c3b5227e6ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fd68b1a00>]}
[0m16:41:53.239224 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:41:53.239773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'be81220f-1f35-4f25-abf3-5c3b5227e6ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fd70dd3a0>]}
[0m16:41:53.241961 [info ] [MainThread]: 
[0m16:41:53.246384 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:41:53.249520 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m16:41:53.285767 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m16:41:53.286549 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m16:41:53.286995 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:41:54.882449 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 2 seconds
[0m16:41:54.885477 [debug] [ThreadPool]: On list_GP: Close
[0m16:41:55.312068 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m16:41:55.325335 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m16:41:55.325818 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m16:41:55.326167 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:41:56.231055 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m16:41:56.234870 [debug] [ThreadPool]: On list_GP_test: Close
[0m16:41:57.251596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'be81220f-1f35-4f25-abf3-5c3b5227e6ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fd6a50590>]}
[0m16:41:57.252764 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:41:57.253241 [info ] [MainThread]: 
[0m16:41:57.297435 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.customer
[0m16:41:57.298236 [info ] [Thread-1 (]: 1 of 1 START sql view model test.customer ...................................... [RUN]
[0m16:41:57.299508 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.customer'
[0m16:41:57.299944 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.customer
[0m16:41:57.302361 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.customer"
[0m16:41:57.303128 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (compile): 2025-11-11 16:41:57.300194 => 2025-11-11 16:41:57.303005
[0m16:41:57.303582 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.customer
[0m16:41:57.364718 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.customer"
[0m16:41:57.366385 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.customer"
[0m16:41:57.366851 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.customer"} */
create or replace   view GP.test.customer
  
   as (
    with cus as( -- in conection we define wharehouse,database,and schema, so we use directly the table names
    select customer_id,email 
    from CUSTOMERS 
    where status='active'
),
alls as(
    select 
    order_id,
    order_date,
    total_amount,
    shipping_address,
    order_date
    from ORDERS o join cus c on
    o.customer_id=c.customer_id 
)
select * from alls
  );
[0m16:41:57.367145 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:41:58.220443 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c052c9-0000-a5d9-0000-0000eb0da019
[0m16:41:58.220954 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002025 (42S21): SQL compilation error:
duplicate column name 'ORDER_DATE'
[0m16:41:58.221531 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (execute): 2025-11-11 16:41:57.303841 => 2025-11-11 16:41:58.221417
[0m16:41:58.221879 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: Close
[0m16:41:58.596173 [debug] [Thread-1 (]: Database Error in model customer (models/customer.sql)
  002025 (42S21): SQL compilation error:
  duplicate column name 'ORDER_DATE'
  compiled Code at target/run/airflow_dbt_project/models/customer.sql
[0m16:41:58.596972 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be81220f-1f35-4f25-abf3-5c3b5227e6ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fd46d5e50>]}
[0m16:41:58.597742 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test.customer ............................. [[31mERROR[0m in 1.30s]
[0m16:41:58.600925 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.customer
[0m16:41:58.604163 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:41:58.605203 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:41:58.605586 [debug] [MainThread]: Connection 'model.airflow_dbt_project.customer' was properly closed.
[0m16:41:58.605967 [info ] [MainThread]: 
[0m16:41:58.606500 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.36 seconds (5.36s).
[0m16:41:58.607093 [debug] [MainThread]: Command end result
[0m16:41:58.621625 [info ] [MainThread]: 
[0m16:41:58.623085 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:41:58.623846 [info ] [MainThread]: 
[0m16:41:58.624484 [error] [MainThread]: [33mDatabase Error in model customer (models/customer.sql)[0m
[0m16:41:58.625009 [error] [MainThread]:   002025 (42S21): SQL compilation error:
[0m16:41:58.625497 [error] [MainThread]:   duplicate column name 'ORDER_DATE'
[0m16:41:58.626182 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/customer.sql
[0m16:41:58.627024 [info ] [MainThread]: 
[0m16:41:58.628612 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m16:41:58.629807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fd47e8320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fdc41b680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fd6d9e660>]}
[0m16:41:58.630711 [debug] [MainThread]: Flushing usage events


============================== 2025-11-11 16:45:06.503601 | f014c3a6-eb3c-40fa-a0d4-da1cf277af63 ==============================
[0m16:45:06.503601 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:45:06.506144 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['customer'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m16:45:06.506493 [debug] [MainThread]: Tracking: tracking
[0m16:45:06.506810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9bf0fcb5c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9bd398b980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9bd18f05c0>]}
[0m16:45:06.562281 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:45:06.563125 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/customer.sql
[0m16:45:06.593596 [debug] [MainThread]: 1699: static parser successfully parsed customer.sql
[0m16:45:06.659518 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m16:45:06.679834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f014c3a6-eb3c-40fa-a0d4-da1cf277af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9bd1623ec0>]}
[0m16:45:06.702127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f014c3a6-eb3c-40fa-a0d4-da1cf277af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9bd17d59d0>]}
[0m16:45:06.703619 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:45:06.704779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f014c3a6-eb3c-40fa-a0d4-da1cf277af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9bd1a63470>]}
[0m16:45:06.708886 [info ] [MainThread]: 
[0m16:45:06.717034 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:45:06.721889 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m16:45:06.791903 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m16:45:06.793357 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m16:45:06.794604 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:45:09.844256 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 3 seconds
[0m16:45:09.847420 [debug] [ThreadPool]: On list_GP: Close
[0m16:45:10.275115 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m16:45:10.287294 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m16:45:10.287719 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m16:45:10.287988 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:45:11.548202 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m16:45:11.552098 [debug] [ThreadPool]: On list_GP_test: Close
[0m16:45:12.124069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f014c3a6-eb3c-40fa-a0d4-da1cf277af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9bd39881a0>]}
[0m16:45:12.125109 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:45:12.125747 [info ] [MainThread]: 
[0m16:45:12.168813 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.customer
[0m16:45:12.169588 [info ] [Thread-1 (]: 1 of 1 START sql view model test.customer ...................................... [RUN]
[0m16:45:12.170633 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.customer'
[0m16:45:12.170983 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.customer
[0m16:45:12.173057 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.customer"
[0m16:45:12.173750 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (compile): 2025-11-11 16:45:12.171193 => 2025-11-11 16:45:12.173645
[0m16:45:12.174096 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.customer
[0m16:45:12.234376 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.customer"
[0m16:45:12.235685 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.customer"
[0m16:45:12.235998 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.customer"} */
create or replace   view GP.test.customer
  
   as (
    with cus as(
    select customer_id, email 
    from CUSTOMERS 
    where status = 'active'
),
alls as(
    select 
    order_id,
    order_date,
    total_amount,
    shipping_address
    from ORDERS o join cus c on
    o.customer_id = c.customer_id 
)
select * from alls;
[0m16:45:12.236237 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:13.212226 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c052cd-0000-a5a8-0000-0000eb0d6fd9
[0m16:45:13.212735 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 18 at position 18 unexpected ';'.
[0m16:45:13.213309 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (execute): 2025-11-11 16:45:12.174313 => 2025-11-11 16:45:13.213201
[0m16:45:13.213645 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: Close
[0m16:45:13.662666 [debug] [Thread-1 (]: Database Error in model customer (models/customer.sql)
  001003 (42000): SQL compilation error:
  syntax error line 18 at position 18 unexpected ';'.
  compiled Code at target/run/airflow_dbt_project/models/customer.sql
[0m16:45:13.663337 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f014c3a6-eb3c-40fa-a0d4-da1cf277af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9bb3393ec0>]}
[0m16:45:13.663971 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test.customer ............................. [[31mERROR[0m in 1.49s]
[0m16:45:13.666697 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.customer
[0m16:45:13.669454 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:45:13.670297 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:45:13.670610 [debug] [MainThread]: Connection 'model.airflow_dbt_project.customer' was properly closed.
[0m16:45:13.670934 [info ] [MainThread]: 
[0m16:45:13.671311 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 6.96 seconds (6.96s).
[0m16:45:13.671834 [debug] [MainThread]: Command end result
[0m16:45:13.681782 [info ] [MainThread]: 
[0m16:45:13.682576 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:45:13.683098 [info ] [MainThread]: 
[0m16:45:13.683637 [error] [MainThread]: [33mDatabase Error in model customer (models/customer.sql)[0m
[0m16:45:13.684119 [error] [MainThread]:   001003 (42000): SQL compilation error:
[0m16:45:13.684546 [error] [MainThread]:   syntax error line 18 at position 18 unexpected ';'.
[0m16:45:13.684954 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/customer.sql
[0m16:45:13.685403 [info ] [MainThread]: 
[0m16:45:13.685841 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m16:45:13.686482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9bd013e570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9bd1669280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9bb3309730>]}
[0m16:45:13.687043 [debug] [MainThread]: Flushing usage events


============================== 2025-11-11 16:45:29.494331 | d78748b5-33e7-462e-b3f0-e18c81de4bab ==============================
[0m16:45:29.494331 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:45:29.498887 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['customer'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m16:45:29.499574 [debug] [MainThread]: Tracking: tracking
[0m16:45:29.500283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17c24c3800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17c3501fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17c24ea900>]}
[0m16:45:29.598158 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:45:29.599918 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/customer.sql
[0m16:45:29.640983 [debug] [MainThread]: 1699: static parser successfully parsed customer.sql
[0m16:45:29.683482 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m16:45:29.695394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd78748b5-33e7-462e-b3f0-e18c81de4bab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17c2389070>]}
[0m16:45:29.709663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd78748b5-33e7-462e-b3f0-e18c81de4bab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17c252e180>]}
[0m16:45:29.710824 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:45:29.711890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd78748b5-33e7-462e-b3f0-e18c81de4bab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17c260f7a0>]}
[0m16:45:29.715554 [info ] [MainThread]: 
[0m16:45:29.721945 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:45:29.724789 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m16:45:29.782593 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m16:45:29.784226 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m16:45:29.785343 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:45:31.074042 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1 seconds
[0m16:45:31.077853 [debug] [ThreadPool]: On list_GP: Close
[0m16:45:32.094741 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m16:45:32.116933 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m16:45:32.117812 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m16:45:32.118444 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:45:33.150793 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m16:45:33.155161 [debug] [ThreadPool]: On list_GP_test: Close
[0m16:45:33.630029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd78748b5-33e7-462e-b3f0-e18c81de4bab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17c03efa40>]}
[0m16:45:33.631675 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:45:33.632424 [info ] [MainThread]: 
[0m16:45:33.681882 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.customer
[0m16:45:33.682610 [info ] [Thread-1 (]: 1 of 1 START sql view model test.customer ...................................... [RUN]
[0m16:45:33.683738 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.customer'
[0m16:45:33.684145 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.customer
[0m16:45:33.686513 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.customer"
[0m16:45:33.687213 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (compile): 2025-11-11 16:45:33.684397 => 2025-11-11 16:45:33.687096
[0m16:45:33.687623 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.customer
[0m16:45:33.762057 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.customer"
[0m16:45:33.764015 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.customer"
[0m16:45:33.764641 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.customer"} */
create or replace   view GP.test.customer
  
   as (
    with cus as(
    select customer_id, email 
    from CUSTOMERS 
    where status = 'active'
),
alls as(
    select 
    order_id,
    order_date,
    total_amount,
    shipping_address
    from ORDERS o join cus c on
    o.customer_id = c.customer_id 
)
select * from alls
  );
[0m16:45:33.765077 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:45:34.852387 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:45:34.889144 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.customer (execute): 2025-11-11 16:45:33.687854 => 2025-11-11 16:45:34.889023
[0m16:45:34.889626 [debug] [Thread-1 (]: On model.airflow_dbt_project.customer: Close
[0m16:45:35.269221 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd78748b5-33e7-462e-b3f0-e18c81de4bab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17c035fd40>]}
[0m16:45:35.270099 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.customer ................................. [[32mSUCCESS 1[0m in 1.59s]
[0m16:45:35.273133 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.customer
[0m16:45:35.275932 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:45:35.276849 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:45:35.277166 [debug] [MainThread]: Connection 'model.airflow_dbt_project.customer' was properly closed.
[0m16:45:35.277500 [info ] [MainThread]: 
[0m16:45:35.277907 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.56 seconds (5.56s).
[0m16:45:35.278472 [debug] [MainThread]: Command end result
[0m16:45:35.288897 [info ] [MainThread]: 
[0m16:45:35.289657 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:45:35.290134 [info ] [MainThread]: 
[0m16:45:35.290589 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m16:45:35.291211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17c2878860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17c265b650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17c041bf20>]}
[0m16:45:35.291822 [debug] [MainThread]: Flushing usage events


============================== 2025-11-11 16:49:26.818625 | b4e82afe-fc41-4b14-8835-e723eb92e41d ==============================
[0m16:49:26.818625 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:49:26.820747 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['customer'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m16:49:26.821036 [debug] [MainThread]: Tracking: tracking
[0m16:49:26.821356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd64d6b920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd64c901a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd65eda930>]}
[0m16:49:26.865506 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:49:26.866256 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/customer.sql
[0m16:49:26.885405 [debug] [MainThread]: 1699: static parser successfully parsed customer.sql
[0m16:49:26.908127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd821cf680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd649a23c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd649a2480>]}
[0m16:49:26.908673 [debug] [MainThread]: Flushing usage events
[0m16:49:28.121774 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.airflow_dbt_project.customer' (models/customer.sql) depends on a source named 'test.orders' which was not found


============================== 2025-11-12 11:13:27.887080 | 1b0f65f3-12bf-40a3-b7e2-35fa660a210b ==============================
[0m11:13:27.887080 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:13:27.892402 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['cus_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:13:27.893051 [debug] [MainThread]: Tracking: tracking
[0m11:13:27.893777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53221e18b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53051cf980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f532a021af0>]}
[0m11:13:28.005003 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m11:13:28.006122 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/cus_orders.sql
[0m11:13:28.006770 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://models/customer.sql
[0m11:13:28.053853 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:13:28.102853 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m11:13:28.115698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1b0f65f3-12bf-40a3-b7e2-35fa660a210b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f530445a930>]}
[0m11:13:28.133335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1b0f65f3-12bf-40a3-b7e2-35fa660a210b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52fe886900>]}
[0m11:13:28.134625 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m11:13:28.136063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1b0f65f3-12bf-40a3-b7e2-35fa660a210b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f532a19b740>]}
[0m11:13:28.140320 [info ] [MainThread]: 
[0m11:13:28.149792 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:13:28.155658 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:13:28.213410 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:13:28.214222 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:13:28.214885 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:13:34.192576 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 6 seconds
[0m11:13:34.196863 [debug] [ThreadPool]: On list_GP: Close
[0m11:13:34.717793 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m11:13:34.739306 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m11:13:34.740068 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m11:13:34.740725 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:13:35.829325 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m11:13:35.833636 [debug] [ThreadPool]: On list_GP_test: Close
[0m11:13:36.349470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1b0f65f3-12bf-40a3-b7e2-35fa660a210b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52fe8d4ad0>]}
[0m11:13:36.351470 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:13:36.352436 [info ] [MainThread]: 
[0m11:13:36.470660 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.cus_orders
[0m11:13:36.484152 [info ] [Thread-1 (]: 1 of 1 START sql view model test.cus_orders .................................... [RUN]
[0m11:13:36.486379 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m11:13:36.487326 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m11:13:36.491678 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m11:13:36.494439 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-12 11:13:36.487936 => 2025-11-12 11:13:36.494133
[0m11:13:36.495625 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m11:13:36.620811 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.cus_orders"
[0m11:13:36.622773 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.cus_orders"
[0m11:13:36.623252 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.cus_orders"} */
create or replace   view GP.test.cus_orders
  
   as (
    with cus as(
    select customer_id, email 
    from CUSTOMERS 
    where status = 'active'
),
alls as(
    select 
    order_id,
    order_date,
    total_amount,
    shipping_address
    from ORDERS o join cus c on
    o.customer_id = c.customer_id 
)
select * from alls
  );
[0m11:13:36.623645 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:13:38.082731 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:13:38.129210 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-12 11:13:36.496486 => 2025-11-12 11:13:38.129034
[0m11:13:38.129873 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: Close
[0m11:13:38.595076 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b0f65f3-12bf-40a3-b7e2-35fa660a210b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52fc5df590>]}
[0m11:13:38.596099 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.cus_orders ............................... [[32mSUCCESS 1[0m in 2.11s]
[0m11:13:38.599920 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m11:13:38.603427 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:13:38.604615 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:13:38.605038 [debug] [MainThread]: Connection 'model.airflow_dbt_project.cus_orders' was properly closed.
[0m11:13:38.605453 [info ] [MainThread]: 
[0m11:13:38.605998 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 10.46 seconds (10.46s).
[0m11:13:38.607165 [debug] [MainThread]: Command end result
[0m11:13:38.623287 [info ] [MainThread]: 
[0m11:13:38.624427 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:13:38.625331 [info ] [MainThread]: 
[0m11:13:38.626164 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:13:38.627493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5304d5cb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53047d3740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52fef07260>]}
[0m11:13:38.628660 [debug] [MainThread]: Flushing usage events


============================== 2025-11-12 11:23:34.491756 | 8e688e23-7bf1-48fc-b805-4edf159bebd2 ==============================
[0m11:23:34.491756 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:23:34.497010 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['cus_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:23:34.497786 [debug] [MainThread]: Tracking: tracking
[0m11:23:34.498549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f814cc9f2f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8147837920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81474a4ef0>]}
[0m11:23:34.584138 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:23:34.585417 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/cus_orders.sql
[0m11:23:34.622000 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:23:34.673078 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.airflow_dbt_project.staging
[0m11:23:34.688193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8e688e23-7bf1-48fc-b805-4edf159bebd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f814cfdfa70>]}
[0m11:23:34.702878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8e688e23-7bf1-48fc-b805-4edf159bebd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f814715efc0>]}
[0m11:23:34.703707 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m11:23:34.704339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e688e23-7bf1-48fc-b805-4edf159bebd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8147a2f680>]}
[0m11:23:34.706512 [info ] [MainThread]: 
[0m11:23:34.710442 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:23:34.713008 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:23:34.745660 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:23:34.746311 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:23:34.746845 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:23:37.597676 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 3 seconds
[0m11:23:37.601390 [debug] [ThreadPool]: On list_GP: Close
[0m11:23:38.031273 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m11:23:38.046538 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m11:23:38.047108 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m11:23:38.047502 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:23:39.279238 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m11:23:39.282427 [debug] [ThreadPool]: On list_GP_test: Close
[0m11:23:39.899926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e688e23-7bf1-48fc-b805-4edf159bebd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8147afdd00>]}
[0m11:23:39.902509 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:23:39.903490 [info ] [MainThread]: 
[0m11:23:39.957146 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.cus_orders
[0m11:23:39.957973 [info ] [Thread-1 (]: 1 of 1 START sql view model test.cus_orders .................................... [RUN]
[0m11:23:39.959363 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m11:23:39.959885 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m11:23:39.962727 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m11:23:39.963732 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-12 11:23:39.960239 => 2025-11-12 11:23:39.963574
[0m11:23:39.964272 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m11:23:40.028853 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.cus_orders"
[0m11:23:40.030633 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.cus_orders"
[0m11:23:40.031034 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.cus_orders"} */
create or replace   view GP.test.cus_orders
  
   as (
    with cus as(
    select customer_id,first_name,last_name, email 
    from CUSTOMERS 
    where status = 'active'
),
alls as(
    select 
    email,
    concat(first_name,' ',last_name),
    order_id,
    order_date,
    total_amount,
    shipping_address
    from ORDERS o join cus c on
    o.customer_id = c.customer_id 
)
select * from alls
  );
[0m11:23:40.031335 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:23:41.430511 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:23:41.475031 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-12 11:23:39.964635 => 2025-11-12 11:23:41.474887
[0m11:23:41.475602 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: Close
[0m11:23:41.942358 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e688e23-7bf1-48fc-b805-4edf159bebd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81472a7a10>]}
[0m11:23:41.943420 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.cus_orders ............................... [[32mSUCCESS 1[0m in 1.98s]
[0m11:23:41.947127 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m11:23:41.950229 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:23:41.951367 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:23:41.951769 [debug] [MainThread]: Connection 'model.airflow_dbt_project.cus_orders' was properly closed.
[0m11:23:41.952149 [info ] [MainThread]: 
[0m11:23:41.952692 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 7.24 seconds (7.24s).
[0m11:23:41.953340 [debug] [MainThread]: Command end result
[0m11:23:41.965152 [info ] [MainThread]: 
[0m11:23:41.966317 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:23:41.967196 [info ] [MainThread]: 
[0m11:23:41.968127 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:23:41.969053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8158d3fd70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81475418e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8147367c80>]}
[0m11:23:41.969824 [debug] [MainThread]: Flushing usage events


============================== 2025-11-13 14:12:50.319095 | 3e186387-a4ba-4e2f-b791-2087a6010415 ==============================
[0m14:12:50.319095 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:12:50.325532 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:12:50.326520 [debug] [MainThread]: Tracking: tracking
[0m14:12:50.327550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb33df32ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3129b04a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb313003530>]}
[0m14:12:50.442308 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m14:12:50.443338 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/staging/stg_customers.sql
[0m14:12:50.444301 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m14:12:50.486950 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:12:50.522607 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m14:12:50.532798 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m14:12:50.554989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3e186387-a4ba-4e2f-b791-2087a6010415', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3391ec3e0>]}
[0m14:12:50.567632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3e186387-a4ba-4e2f-b791-2087a6010415', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb312889e20>]}
[0m14:12:50.568385 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:12:50.569039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e186387-a4ba-4e2f-b791-2087a6010415', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3129885c0>]}
[0m14:12:50.571379 [info ] [MainThread]: 
[0m14:12:50.575549 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:12:50.578155 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:12:50.626920 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:12:50.627723 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:12:50.628339 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:12:59.797401 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 9 seconds
[0m14:12:59.801465 [debug] [ThreadPool]: On list_GP: Close
[0m14:13:00.211159 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m14:13:00.231455 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m14:13:00.232152 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m14:13:00.232700 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:13:01.447544 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m14:13:01.453606 [debug] [ThreadPool]: On list_GP_test: Close
[0m14:13:01.875586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e186387-a4ba-4e2f-b791-2087a6010415', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3127bb8f0>]}
[0m14:13:01.877232 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:13:01.877972 [info ] [MainThread]: 
[0m14:13:01.945007 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_customers
[0m14:13:01.946216 [info ] [Thread-1 (]: 1 of 1 START sql view model test.dim_customers ................................. [RUN]
[0m14:13:01.948380 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_customers'
[0m14:13:01.949241 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_customers
[0m14:13:01.958169 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_customers"
[0m14:13:01.959886 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (compile): 2025-11-13 14:13:01.949819 => 2025-11-13 14:13:01.959623
[0m14:13:01.960813 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_customers
[0m14:13:02.066567 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_customers"
[0m14:13:02.068529 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_customers"
[0m14:13:02.069199 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_customers"} */
create or replace   view GP.test.dim_customers
  
   as (
    select * 
from GP.test.stg_customers
where  signup_date> (select max('date') from GP.test.dim_customers )
  );
[0m14:13:02.069837 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:13:03.096318 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c05d75-0000-a64f-0000-eb0d00015a36
[0m14:13:03.097052 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'GP.TEST.STG_CUSTOMERS' does not exist or not authorized.
[0m14:13:03.098324 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (execute): 2025-11-13 14:13:01.961421 => 2025-11-13 14:13:03.098069
[0m14:13:03.098949 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: Close
[0m14:13:03.615248 [debug] [Thread-1 (]: Database Error in model dim_customers (models/marts/core/dim_customers.sql)
  002003 (42S02): SQL compilation error:
  Object 'GP.TEST.STG_CUSTOMERS' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/marts/core/dim_customers.sql
[0m14:13:03.616201 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e186387-a4ba-4e2f-b791-2087a6010415', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb31051b9e0>]}
[0m14:13:03.617082 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test.dim_customers ........................ [[31mERROR[0m in 1.67s]
[0m14:13:03.621138 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_customers
[0m14:13:03.625600 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:13:03.627178 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:13:03.627701 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_customers' was properly closed.
[0m14:13:03.628296 [info ] [MainThread]: 
[0m14:13:03.629044 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 13.06 seconds (13.06s).
[0m14:13:03.630282 [debug] [MainThread]: Command end result
[0m14:13:03.659778 [info ] [MainThread]: 
[0m14:13:03.661597 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:13:03.664366 [info ] [MainThread]: 
[0m14:13:03.665943 [error] [MainThread]: [33mDatabase Error in model dim_customers (models/marts/core/dim_customers.sql)[0m
[0m14:13:03.667930 [error] [MainThread]:   002003 (42S02): SQL compilation error:
[0m14:13:03.669191 [error] [MainThread]:   Object 'GP.TEST.STG_CUSTOMERS' does not exist or not authorized.
[0m14:13:03.673986 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/marts/core/dim_customers.sql
[0m14:13:03.678431 [info ] [MainThread]: 
[0m14:13:03.681741 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:13:03.684011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb312911970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb33df32ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3128446b0>]}
[0m14:13:03.685578 [debug] [MainThread]: Flushing usage events


============================== 2025-11-13 14:15:06.829470 | 1a0b0f89-f85e-4831-8690-1da84cb5fe3b ==============================
[0m14:15:06.829470 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:15:06.833552 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:15:06.834173 [debug] [MainThread]: Tracking: tracking
[0m14:15:06.834683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ee2990b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ed30c1b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ed30c1d30>]}
[0m14:15:06.938878 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m14:15:06.941337 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/stg_customers.sql
[0m14:15:06.943787 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m14:15:07.009088 [debug] [MainThread]: 1603: static parser failed on staging/stg_customers.sql
[0m14:15:07.024540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ed3096f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ee2990c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ed3003650>]}
[0m14:15:07.025659 [debug] [MainThread]: Flushing usage events
[0m14:15:08.687809 [error] [MainThread]: Encountered an error:
'str' object has no attribute 'items'
[0m14:15:08.701720 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/main.py", line 135, in main
    results, succeeded = handle_and_check(args)
                         ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/main.py", line 198, in handle_and_check
    task, res = run_from_args(parsed)
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/main.py", line 245, in run_from_args
    results = task.run()
              ^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/runnable.py", line 454, in run
    self._runtime_initialize()
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/runnable.py", line 165, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/runnable.py", line 94, in _runtime_initialize
    self.load_manifest()
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/runnable.py", line 81, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/parser/manifest.py", line 203, in get_full_manifest
    manifest = loader.load()
               ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/parser/manifest.py", line 339, in load
    self.parse_project(
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/parser/manifest.py", line 467, in parse_project
    parser.parse_file(block)
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/parser/base.py", line 425, in parse_file
    self.parse_node(file_block)
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/parser/base.py", line 386, in parse_node
    self.render_update(node, config)
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/parser/models.py", line 362, in render_update
    super().render_update(node, config)
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/parser/base.py", line 362, in render_update
    context = self.render_with_context(node, config)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/parser/base.py", line 240, in render_with_context
    get_rendered(parsed_node.raw_code, context, parsed_node, capture_macros=True)
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/clients/jinja.py", line 590, in get_rendered
    return render_template(template, ctx, node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/clients/jinja.py", line 545, in render_template
    return template.render(ctx)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/environment.py", line 1301, in render
    self.environment.handle_exception()
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/environment.py", line 936, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "<template>", line 1, in top-level template code
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 393, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/context/providers.py", line 342, in __call__
    self.context_config.add_config_call(opts)
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/context/context_config.py", line 270, in add_config_call
    self._add_config_call(dct, opts)
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/context/context_config.py", line 277, in _add_config_call
    for k, v in opts.items():
                ^^^^^^^^^^
AttributeError: 'str' object has no attribute 'items'



============================== 2025-11-13 14:16:44.527138 | 0307c103-c0ba-4220-b9fc-95e79a7afac5 ==============================
[0m14:16:44.527138 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:16:44.529504 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:16:44.529849 [debug] [MainThread]: Tracking: tracking
[0m14:16:44.530197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9a2f61d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9a2f62810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9a2f637d0>]}
[0m14:16:44.575967 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m14:16:44.576742 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/stg_customers.sql
[0m14:16:44.577435 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m14:16:44.596460 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:16:44.619212 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m14:16:44.625692 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m14:16:44.640805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0307c103-c0ba-4220-b9fc-95e79a7afac5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9a2e20c50>]}
[0m14:16:44.649266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0307c103-c0ba-4220-b9fc-95e79a7afac5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9a2dfb290>]}
[0m14:16:44.649784 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:16:44.650198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0307c103-c0ba-4220-b9fc-95e79a7afac5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9a9373ad0>]}
[0m14:16:44.651930 [info ] [MainThread]: 
[0m14:16:44.654867 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:16:44.656730 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:16:44.687806 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:16:44.688351 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:16:44.688732 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:16:47.356584 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 3 seconds
[0m14:16:47.359394 [debug] [ThreadPool]: On list_GP: Close
[0m14:16:47.929071 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_test_staging'
[0m14:16:47.930106 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_test_staging'
[0m14:16:47.930599 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='test_staging', identifier=None)"
[0m14:16:47.940150 [debug] [ThreadPool]: Using snowflake connection "create_GP_test_staging"
[0m14:16:47.940675 [debug] [ThreadPool]: On create_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_test_staging"} */
create schema if not exists GP.test_staging
[0m14:16:47.941042 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:16:49.641717 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m14:16:49.643551 [debug] [ThreadPool]: On create_GP_test_staging: Close
[0m14:16:50.529789 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m14:16:50.533437 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m14:16:50.544448 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m14:16:50.544861 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m14:16:50.545160 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:16:50.549403 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m14:16:50.549784 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m14:16:50.550062 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:16:53.333920 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 3 seconds
[0m14:16:53.336245 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m14:16:53.397405 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m14:16:53.400032 [debug] [ThreadPool]: On list_GP_test: Close
[0m14:16:55.200663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0307c103-c0ba-4220-b9fc-95e79a7afac5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9a17179e0>]}
[0m14:16:55.201813 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:16:55.202316 [info ] [MainThread]: 
[0m14:16:55.254832 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m14:16:55.255859 [info ] [Thread-1 (]: 1 of 1 START sql view model test_staging.stg_customers ......................... [RUN]
[0m14:16:55.257443 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m14:16:55.258233 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m14:16:55.263183 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m14:16:55.264509 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-13 14:16:55.258704 => 2025-11-13 14:16:55.264327
[0m14:16:55.265161 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m14:16:55.335531 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m14:16:55.336983 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m14:16:55.337432 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.test_staging.stg_customers
  
   as (
    
select * from customers;
[0m14:16:55.337801 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:16:56.791633 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c05d78-0000-a656-0000-eb0d000160c2
[0m14:16:56.792090 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 5 at position 23 unexpected ';'.
[0m14:16:56.792701 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-13 14:16:55.265570 => 2025-11-13 14:16:56.792599
[0m14:16:56.793071 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m14:16:58.041026 [debug] [Thread-1 (]: Database Error in model stg_customers (models/staging/stg_customers.sql)
  001003 (42000): SQL compilation error:
  syntax error line 5 at position 23 unexpected ';'.
  compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m14:16:58.041843 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0307c103-c0ba-4220-b9fc-95e79a7afac5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9a2f92510>]}
[0m14:16:58.042706 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test_staging.stg_customers ................ [[31mERROR[0m in 2.79s]
[0m14:16:58.046169 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m14:16:58.050099 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:16:58.051489 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:16:58.052059 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m14:16:58.052580 [debug] [MainThread]: Connection 'list_GP_test_staging' was properly closed.
[0m14:16:58.053210 [info ] [MainThread]: 
[0m14:16:58.054009 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 13.40 seconds (13.40s).
[0m14:16:58.055016 [debug] [MainThread]: Command end result
[0m14:16:58.075783 [info ] [MainThread]: 
[0m14:16:58.077807 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:16:58.079612 [info ] [MainThread]: 
[0m14:16:58.080898 [error] [MainThread]: [33mDatabase Error in model stg_customers (models/staging/stg_customers.sql)[0m
[0m14:16:58.082338 [error] [MainThread]:   001003 (42000): SQL compilation error:
[0m14:16:58.083837 [error] [MainThread]:   syntax error line 5 at position 23 unexpected ';'.
[0m14:16:58.085308 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m14:16:58.086709 [info ] [MainThread]: 
[0m14:16:58.088495 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:16:58.090799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9a2e20440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9a3087680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9cf584b30>]}
[0m14:16:58.092375 [debug] [MainThread]: Flushing usage events


============================== 2025-11-13 14:17:12.820849 | 4284f282-faa7-425c-b39c-7485c72f5e16 ==============================
[0m14:17:12.820849 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:17:12.822921 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:17:12.823204 [debug] [MainThread]: Tracking: tracking
[0m14:17:12.823506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce291a6d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce299bc9b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce291a4800>]}
[0m14:17:12.871536 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:17:12.872576 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/stg_customers.sql
[0m14:17:12.895092 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:17:12.939053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4284f282-faa7-425c-b39c-7485c72f5e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce290496a0>]}
[0m14:17:12.950800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4284f282-faa7-425c-b39c-7485c72f5e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce291fa180>]}
[0m14:17:12.951499 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:17:12.952071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4284f282-faa7-425c-b39c-7485c72f5e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce349d1eb0>]}
[0m14:17:12.954400 [info ] [MainThread]: 
[0m14:17:12.958374 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:17:12.960916 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:17:13.005268 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:17:13.006045 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:17:13.006705 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:17:15.224057 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m14:17:15.227043 [debug] [ThreadPool]: On list_GP: Close
[0m14:17:15.834126 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m14:17:15.835571 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m14:17:15.857521 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m14:17:15.858016 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m14:17:15.858306 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:17:15.859313 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m14:17:15.859962 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m14:17:15.860233 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:17:18.347800 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2 seconds
[0m14:17:18.351294 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m14:17:18.379986 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m14:17:18.383319 [debug] [ThreadPool]: On list_GP_test: Close
[0m14:17:19.776125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4284f282-faa7-425c-b39c-7485c72f5e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce291a7c20>]}
[0m14:17:19.777873 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:17:19.779185 [info ] [MainThread]: 
[0m14:17:19.825252 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m14:17:19.826576 [info ] [Thread-1 (]: 1 of 1 START sql view model test_staging.stg_customers ......................... [RUN]
[0m14:17:19.828653 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m14:17:19.829427 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m14:17:19.835014 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m14:17:19.835881 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-13 14:17:19.829855 => 2025-11-13 14:17:19.835713
[0m14:17:19.836353 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m14:17:19.908591 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m14:17:19.909595 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m14:17:19.909944 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.test_staging.stg_customers
  
   as (
    
select * from customers
  );
[0m14:17:19.910184 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:17:22.429057 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c05d79-0000-a656-0000-eb0d000160d2
[0m14:17:22.429547 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m14:17:22.430144 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-13 14:17:19.836623 => 2025-11-13 14:17:22.430039
[0m14:17:22.430501 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m14:17:23.929495 [debug] [Thread-1 (]: Database Error in model stg_customers (models/staging/stg_customers.sql)
  002003 (42S02): SQL compilation error:
  Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m14:17:23.930140 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4284f282-faa7-425c-b39c-7485c72f5e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce0edc09b0>]}
[0m14:17:23.930797 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test_staging.stg_customers ................ [[31mERROR[0m in 4.10s]
[0m14:17:23.933506 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m14:17:23.935965 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:17:23.936821 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:17:23.937116 [debug] [MainThread]: Connection 'list_GP_test_staging' was properly closed.
[0m14:17:23.937344 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m14:17:23.937606 [info ] [MainThread]: 
[0m14:17:23.938003 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 10.98 seconds (10.98s).
[0m14:17:23.938485 [debug] [MainThread]: Command end result
[0m14:17:23.952041 [info ] [MainThread]: 
[0m14:17:23.953637 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:17:23.954635 [info ] [MainThread]: 
[0m14:17:23.955427 [error] [MainThread]: [33mDatabase Error in model stg_customers (models/staging/stg_customers.sql)[0m
[0m14:17:23.956493 [error] [MainThread]:   002003 (42S02): SQL compilation error:
[0m14:17:23.957065 [error] [MainThread]:   Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m14:17:23.958065 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m14:17:23.958711 [info ] [MainThread]: 
[0m14:17:23.959901 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:17:23.961529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce349d0470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce349f4050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce29317c80>]}
[0m14:17:23.962828 [debug] [MainThread]: Flushing usage events


============================== 2025-11-13 14:18:35.692899 | bfce4264-f5fc-4014-b766-1690bf813f46 ==============================
[0m14:18:35.692899 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:18:35.695239 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:18:35.695507 [debug] [MainThread]: Tracking: tracking
[0m14:18:35.695820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cc7198800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cc7198a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ce19cf8f0>]}
[0m14:18:35.747499 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:18:35.747958 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:18:35.760975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bfce4264-f5fc-4014-b766-1690bf813f46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cc4b48440>]}
[0m14:18:35.775310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bfce4264-f5fc-4014-b766-1690bf813f46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cc4ad2690>]}
[0m14:18:35.776301 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:18:35.777092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bfce4264-f5fc-4014-b766-1690bf813f46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cc4d774d0>]}
[0m14:18:35.779692 [info ] [MainThread]: 
[0m14:18:35.784719 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:18:35.787861 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:18:35.833081 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:18:35.833638 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:18:35.834007 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:18:39.717285 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 4 seconds
[0m14:18:39.719956 [debug] [ThreadPool]: On list_GP: Close
[0m14:18:40.818362 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m14:18:40.825136 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m14:18:40.836787 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m14:18:40.837215 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m14:18:40.841421 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m14:18:40.842048 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:18:40.842596 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m14:18:40.845212 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:18:42.249987 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1 seconds
[0m14:18:42.258948 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m14:18:42.808152 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m14:18:42.811623 [debug] [ThreadPool]: On list_GP_test: Close
[0m14:18:43.413792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bfce4264-f5fc-4014-b766-1690bf813f46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cc46e8170>]}
[0m14:18:43.415589 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:18:43.416420 [info ] [MainThread]: 
[0m14:18:43.474558 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m14:18:43.475494 [info ] [Thread-1 (]: 1 of 1 START sql view model test_staging.stg_customers ......................... [RUN]
[0m14:18:43.477223 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m14:18:43.477870 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m14:18:43.483671 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m14:18:43.484770 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-13 14:18:43.478266 => 2025-11-13 14:18:43.484589
[0m14:18:43.485276 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m14:18:43.554272 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m14:18:43.555378 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m14:18:43.555758 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.test_staging.stg_customers
  
   as (
    
select * from customers
  );
[0m14:18:43.556050 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:18:45.764293 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c05d7a-0000-a656-0000-eb0d000160de
[0m14:18:45.764778 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m14:18:45.765347 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-13 14:18:43.485559 => 2025-11-13 14:18:45.765236
[0m14:18:45.765674 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m14:18:46.613256 [debug] [Thread-1 (]: Database Error in model stg_customers (models/staging/stg_customers.sql)
  002003 (42S02): SQL compilation error:
  Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m14:18:46.613806 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bfce4264-f5fc-4014-b766-1690bf813f46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cc4528c20>]}
[0m14:18:46.614364 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test_staging.stg_customers ................ [[31mERROR[0m in 3.14s]
[0m14:18:46.616713 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m14:18:46.619521 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:18:46.620317 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:18:46.620592 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m14:18:46.620809 [debug] [MainThread]: Connection 'list_GP_test_staging' was properly closed.
[0m14:18:46.621058 [info ] [MainThread]: 
[0m14:18:46.621422 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 10.84 seconds (10.84s).
[0m14:18:46.622251 [debug] [MainThread]: Command end result
[0m14:18:46.631950 [info ] [MainThread]: 
[0m14:18:46.632741 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:18:46.633693 [info ] [MainThread]: 
[0m14:18:46.634573 [error] [MainThread]: [33mDatabase Error in model stg_customers (models/staging/stg_customers.sql)[0m
[0m14:18:46.635501 [error] [MainThread]:   002003 (42S02): SQL compilation error:
[0m14:18:46.636169 [error] [MainThread]:   Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m14:18:46.636785 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m14:18:46.637404 [info ] [MainThread]: 
[0m14:18:46.638042 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:18:46.638847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cc4a8f6b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cc46e8170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cc513e780>]}
[0m14:18:46.639532 [debug] [MainThread]: Flushing usage events


============================== 2025-11-13 14:20:15.666889 | 53b567cc-143a-4f64-8df0-9b0770cf2b0f ==============================
[0m14:20:15.666889 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:20:15.669665 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:20:15.670009 [debug] [MainThread]: Tracking: tracking
[0m14:20:15.670374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f975bbf3aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f975bc6c800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9772bb8a70>]}
[0m14:20:15.723948 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:20:15.724879 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/stg_customers.sql
[0m14:20:15.752003 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:20:15.821856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '53b567cc-143a-4f64-8df0-9b0770cf2b0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f975bb198e0>]}
[0m14:20:15.833239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '53b567cc-143a-4f64-8df0-9b0770cf2b0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f975b993500>]}
[0m14:20:15.833893 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:20:15.834411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53b567cc-143a-4f64-8df0-9b0770cf2b0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9772bba960>]}
[0m14:20:15.836477 [info ] [MainThread]: 
[0m14:20:15.840015 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:20:15.842391 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:20:15.876430 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:20:15.876954 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:20:15.877321 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:20:18.194028 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m14:20:18.197111 [debug] [ThreadPool]: On list_GP: Close
[0m14:20:19.121875 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m14:20:19.134114 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m14:20:19.134544 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m14:20:19.134839 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:20:21.994293 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m14:20:21.998083 [debug] [ThreadPool]: On list_GP_test: Close
[0m14:20:22.881715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53b567cc-143a-4f64-8df0-9b0770cf2b0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f975bac0590>]}
[0m14:20:22.882974 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:20:22.883604 [info ] [MainThread]: 
[0m14:20:22.932149 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m14:20:22.933396 [info ] [Thread-1 (]: 1 of 1 START sql view model test.stg_customers ................................. [RUN]
[0m14:20:22.935567 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m14:20:22.936291 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m14:20:22.940088 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m14:20:22.941263 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-13 14:20:22.936712 => 2025-11-13 14:20:22.941078
[0m14:20:22.941845 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m14:20:23.041619 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m14:20:23.042825 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m14:20:23.043224 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.test.stg_customers
  
   as (
    select * from customers
  );
[0m14:20:23.043517 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:20:26.388021 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m14:20:26.414715 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-13 14:20:22.942194 => 2025-11-13 14:20:26.414629
[0m14:20:26.415052 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m14:20:27.382269 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '53b567cc-143a-4f64-8df0-9b0770cf2b0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9759776ba0>]}
[0m14:20:27.383256 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.stg_customers ............................ [[32mSUCCESS 1[0m in 4.45s]
[0m14:20:27.386315 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m14:20:27.389390 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:20:27.390586 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:20:27.391047 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m14:20:27.391486 [info ] [MainThread]: 
[0m14:20:27.392054 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 11.55 seconds (11.55s).
[0m14:20:27.392843 [debug] [MainThread]: Command end result
[0m14:20:27.404120 [info ] [MainThread]: 
[0m14:20:27.404926 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:20:27.405447 [info ] [MainThread]: 
[0m14:20:27.406083 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:20:27.407019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97598254f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f975bca6ea0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9760b419a0>]}
[0m14:20:27.407686 [debug] [MainThread]: Flushing usage events


============================== 2025-11-13 14:21:38.023305 | 4ab18dd8-ee3a-4d46-be3d-5f17986c8aa4 ==============================
[0m14:21:38.023305 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:21:38.025583 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:21:38.025881 [debug] [MainThread]: Tracking: tracking
[0m14:21:38.026185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1aeb269c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1ae1c2690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1ae013ad0>]}
[0m14:21:38.072054 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:21:38.072865 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/stg_customers.sql
[0m14:21:38.091799 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:21:38.127838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4ab18dd8-ee3a-4d46-be3d-5f17986c8aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1adeb60c0>]}
[0m14:21:38.136345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4ab18dd8-ee3a-4d46-be3d-5f17986c8aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1ae065df0>]}
[0m14:21:38.136839 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:21:38.137215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4ab18dd8-ee3a-4d46-be3d-5f17986c8aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1afa68110>]}
[0m14:21:38.138800 [info ] [MainThread]: 
[0m14:21:38.141677 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:21:38.143530 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:21:38.174363 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:21:38.174945 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:21:38.175327 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:21:42.269925 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 4 seconds
[0m14:21:42.273027 [debug] [ThreadPool]: On list_GP: Close
[0m14:21:43.311640 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m14:21:43.319259 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m14:21:43.348546 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m14:21:43.345837 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m14:21:43.351837 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m14:21:43.353157 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m14:21:43.354335 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:21:43.355373 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:21:46.412921 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 3 seconds
[0m14:21:46.414287 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 3 seconds
[0m14:21:46.417132 [debug] [ThreadPool]: On list_GP_test: Close
[0m14:21:46.419477 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m14:21:47.457936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4ab18dd8-ee3a-4d46-be3d-5f17986c8aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1ac5ee210>]}
[0m14:21:47.461729 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:21:47.463980 [info ] [MainThread]: 
[0m14:21:47.565262 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m14:21:47.566219 [info ] [Thread-1 (]: 1 of 1 START sql table model test_staging.stg_customers ........................ [RUN]
[0m14:21:47.567988 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m14:21:47.568704 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m14:21:47.575059 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m14:21:47.576553 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-13 14:21:47.569173 => 2025-11-13 14:21:47.576311
[0m14:21:47.577604 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m14:21:47.661814 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m14:21:47.663165 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m14:21:47.663597 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace transient table GP.test_staging.stg_customers  as
        (
select * from customers
        );
[0m14:21:47.663923 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:22:07.406249 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 20 seconds
[0m14:22:07.437662 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-13 14:21:47.578379 => 2025-11-13 14:22:07.437581
[0m14:22:07.437982 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m14:22:08.290441 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4ab18dd8-ee3a-4d46-be3d-5f17986c8aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1ac473ec0>]}
[0m14:22:08.291369 [info ] [Thread-1 (]: 1 of 1 OK created sql table model test_staging.stg_customers ................... [[32mSUCCESS 1[0m in 20.72s]
[0m14:22:08.294663 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m14:22:08.297464 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:22:08.298330 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:22:08.298627 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m14:22:08.298877 [debug] [MainThread]: Connection 'list_GP_test' was properly closed.
[0m14:22:08.299155 [info ] [MainThread]: 
[0m14:22:08.299547 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 30.16 seconds (30.16s).
[0m14:22:08.300519 [debug] [MainThread]: Command end result
[0m14:22:08.314603 [info ] [MainThread]: 
[0m14:22:08.316250 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:22:08.317234 [info ] [MainThread]: 
[0m14:22:08.318030 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:22:08.319016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1aea630e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1ae3daea0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1ac4c6570>]}
[0m14:22:08.319973 [debug] [MainThread]: Flushing usage events
[0m14:22:15.026002 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.


============================== 2025-11-13 14:26:38.040317 | f51d29b8-0987-4488-bd72-3167d6ff68c1 ==============================
[0m14:26:38.040317 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:26:38.045085 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:26:38.045660 [debug] [MainThread]: Tracking: tracking
[0m14:26:38.046312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8de3579d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8de1239fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8de123a060>]}
[0m14:26:38.138242 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:26:38.139000 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:26:38.157718 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f51d29b8-0987-4488-bd72-3167d6ff68c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8de120f260>]}
[0m14:26:38.172325 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f51d29b8-0987-4488-bd72-3167d6ff68c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8de128de80>]}
[0m14:26:38.173255 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:26:38.174136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f51d29b8-0987-4488-bd72-3167d6ff68c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8de2bb2ed0>]}
[0m14:26:38.177102 [info ] [MainThread]: 
[0m14:26:38.182732 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:26:38.185526 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:26:38.236950 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:26:38.237591 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:26:38.238033 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:26:40.756921 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m14:26:40.762336 [debug] [ThreadPool]: On list_GP: Close
[0m14:26:42.082565 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m14:26:42.090259 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m14:26:42.100181 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m14:26:42.105404 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m14:26:42.106167 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m14:26:42.106889 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m14:26:42.107480 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:26:42.108041 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:26:44.050297 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 2 seconds
[0m14:26:44.053478 [debug] [ThreadPool]: On list_GP_test: Close
[0m14:26:50.543468 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 8 seconds
[0m14:26:50.559190 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m14:26:51.685558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f51d29b8-0987-4488-bd72-3167d6ff68c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8de123be90>]}
[0m14:26:51.687548 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:26:51.688625 [info ] [MainThread]: 
[0m14:26:51.759400 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m14:26:51.760699 [info ] [Thread-1 (]: 1 of 1 START sql table model test_staging.stg_customers ........................ [RUN]
[0m14:26:51.762701 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m14:26:51.763533 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m14:26:51.772823 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m14:26:51.774434 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-13 14:26:51.764098 => 2025-11-13 14:26:51.774186
[0m14:26:51.775551 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m14:26:51.865389 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m14:26:51.866762 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m14:26:51.867200 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace transient table GP.test_staging.stg_customers  as
        (
select * from customers
        );
[0m14:26:51.867538 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:26:56.363442 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 4 seconds
[0m14:26:56.439021 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-13 14:26:51.776111 => 2025-11-13 14:26:56.438812
[0m14:26:56.440059 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m14:26:56.993273 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f51d29b8-0987-4488-bd72-3167d6ff68c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8de069fb30>]}
[0m14:26:56.994701 [info ] [Thread-1 (]: 1 of 1 OK created sql table model test_staging.stg_customers ................... [[32mSUCCESS 1[0m in 5.23s]
[0m14:26:57.000058 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m14:26:57.004151 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:26:57.005999 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:26:57.007040 [debug] [MainThread]: Connection 'list_GP_test' was properly closed.
[0m14:26:57.007678 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m14:26:57.008356 [info ] [MainThread]: 
[0m14:26:57.009251 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 18.83 seconds (18.83s).
[0m14:26:57.010377 [debug] [MainThread]: Command end result
[0m14:26:57.028934 [info ] [MainThread]: 
[0m14:26:57.031017 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:26:57.032243 [info ] [MainThread]: 
[0m14:26:57.035195 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:26:57.036473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8de1c750d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8de113bdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8de069ef90>]}
[0m14:26:57.037497 [debug] [MainThread]: Flushing usage events


============================== 2025-11-13 14:33:27.750800 | 24031997-55e0-4467-b0ce-c74f82c9e390 ==============================
[0m14:33:27.750800 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:33:27.753603 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:33:27.753977 [debug] [MainThread]: Tracking: tracking
[0m14:33:27.754348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd937908830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd910a82000>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9233cd910>]}
[0m14:33:27.786219 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:33:27.787504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '24031997-55e0-4467-b0ce-c74f82c9e390', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd91011ca10>]}
[0m14:33:29.275161 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m14:33:29.298105 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m14:33:29.302873 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:33:29.308269 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m14:33:29.314625 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m14:33:29.359855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '24031997-55e0-4467-b0ce-c74f82c9e390', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd910122f30>]}
[0m14:33:29.368915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '24031997-55e0-4467-b0ce-c74f82c9e390', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9101209b0>]}
[0m14:33:29.369459 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:33:29.369907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '24031997-55e0-4467-b0ce-c74f82c9e390', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd910a80d70>]}
[0m14:33:29.371766 [info ] [MainThread]: 
[0m14:33:29.374974 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:33:29.376841 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:33:29.409384 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:33:29.410083 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:33:29.410575 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:33:31.639265 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m14:33:31.642386 [debug] [ThreadPool]: On list_GP: Close
[0m14:33:32.026279 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m14:33:32.034118 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_mart'
[0m14:33:32.054661 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m14:33:32.070228 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m14:33:32.072985 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_mart"
[0m14:33:32.073993 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:33:32.075282 [debug] [ThreadPool]: On list_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_mart"} */
show terse objects in GP.test_mart
[0m14:33:32.079578 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:33:33.086826 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c05d89-0000-a64f-0000-eb0d00015c4a
[0m14:33:33.087551 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m14:33:33.088630 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m14:33:33.089247 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m14:33:33.089841 [debug] [ThreadPool]: On list_GP_test_mart: Close
[0m14:33:33.375219 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1 seconds
[0m14:33:33.378565 [debug] [ThreadPool]: On list_GP_test: Close
[0m14:33:33.528276 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m14:33:33.532361 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m14:33:33.533075 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m14:33:33.533609 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:33:35.866248 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m14:33:35.869625 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m14:33:36.456243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '24031997-55e0-4467-b0ce-c74f82c9e390', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90a133d40>]}
[0m14:33:36.457527 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:33:36.458076 [info ] [MainThread]: 
[0m14:33:36.513326 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m14:33:36.515142 [info ] [Thread-1 (]: 1 of 1 START sql view model test_staging.stg_customers ......................... [RUN]
[0m14:33:36.518129 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m14:33:36.519358 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m14:33:36.525360 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m14:33:36.527077 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-13 14:33:36.520193 => 2025-11-13 14:33:36.526803
[0m14:33:36.527993 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m14:33:36.618924 [debug] [Thread-1 (]: Dropping relation "GP"."TEST_STAGING"."STG_CUSTOMERS" because it is of type table
[0m14:33:36.628462 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m14:33:36.628930 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
drop table if exists "GP"."TEST_STAGING"."STG_CUSTOMERS" cascade
[0m14:33:36.629250 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:33:37.922700 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:33:37.946017 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m14:33:37.947251 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m14:33:37.947651 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.test_staging.stg_customers
  
   as (
    select * from customers
  );
[0m14:33:38.306510 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c05d89-0000-a656-0000-eb0d000162ae
[0m14:33:38.307101 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m14:33:38.307812 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-13 14:33:36.528555 => 2025-11-13 14:33:38.307665
[0m14:33:38.308192 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m14:33:39.043345 [debug] [Thread-1 (]: Database Error in model stg_customers (models/staging/stg_customers.sql)
  002003 (42S02): SQL compilation error:
  Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m14:33:39.044295 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24031997-55e0-4467-b0ce-c74f82c9e390', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90974b350>]}
[0m14:33:39.045130 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test_staging.stg_customers ................ [[31mERROR[0m in 2.53s]
[0m14:33:39.048442 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m14:33:39.051790 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:33:39.052987 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:33:39.053401 [debug] [MainThread]: Connection 'list_GP_test' was properly closed.
[0m14:33:39.053673 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m14:33:39.054063 [info ] [MainThread]: 
[0m14:33:39.054541 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 9.68 seconds (9.68s).
[0m14:33:39.055185 [debug] [MainThread]: Command end result
[0m14:33:39.068172 [info ] [MainThread]: 
[0m14:33:39.069191 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:33:39.069980 [info ] [MainThread]: 
[0m14:33:39.070688 [error] [MainThread]: [33mDatabase Error in model stg_customers (models/staging/stg_customers.sql)[0m
[0m14:33:39.071363 [error] [MainThread]:   002003 (42S02): SQL compilation error:
[0m14:33:39.072009 [error] [MainThread]:   Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m14:33:39.072588 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m14:33:39.073221 [info ] [MainThread]: 
[0m14:33:39.074470 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:33:39.075486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd91031a000>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd91031b1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90a108bc0>]}
[0m14:33:39.076415 [debug] [MainThread]: Flushing usage events


============================== 2025-11-13 14:34:51.751294 | 8ab49cb6-15bf-47fa-996e-7d8c3357f757 ==============================
[0m14:34:51.751294 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:34:51.753640 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:34:51.753974 [debug] [MainThread]: Tracking: tracking
[0m14:34:51.754295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfaad83590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfaa90ac60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfaa908890>]}
[0m14:34:51.805892 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:34:51.806410 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:34:51.824316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8ab49cb6-15bf-47fa-996e-7d8c3357f757', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfb0b20410>]}
[0m14:34:51.842511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8ab49cb6-15bf-47fa-996e-7d8c3357f757', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfaa94e330>]}
[0m14:34:51.844245 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:34:51.845791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8ab49cb6-15bf-47fa-996e-7d8c3357f757', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfaad3a990>]}
[0m14:34:51.850085 [info ] [MainThread]: 
[0m14:34:51.856691 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:34:51.860415 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:34:51.926616 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:34:51.927593 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:34:51.928332 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:34:53.606505 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m14:34:53.611088 [debug] [ThreadPool]: On list_GP: Close
[0m14:34:54.039576 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_mart'
[0m14:34:54.042510 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m14:34:54.093722 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_mart"
[0m14:34:54.097378 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m14:34:54.098371 [debug] [ThreadPool]: On list_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_mart"} */
show terse objects in GP.test_mart
[0m14:34:54.099429 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m14:34:54.100483 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:34:54.101565 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:34:55.172377 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c05d8a-0000-a64f-0000-eb0d00015c52
[0m14:34:55.172902 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m14:34:55.173389 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m14:34:55.173654 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m14:34:55.173996 [debug] [ThreadPool]: On list_GP_test_mart: Close
[0m14:34:55.192980 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1 seconds
[0m14:34:55.196764 [debug] [ThreadPool]: On list_GP_test: Close
[0m14:34:55.694706 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m14:34:55.699370 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m14:34:55.703253 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m14:34:55.703630 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:34:56.705298 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1 seconds
[0m14:34:56.708439 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m14:34:57.204967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8ab49cb6-15bf-47fa-996e-7d8c3357f757', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfaa8436e0>]}
[0m14:34:57.207609 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:34:57.209368 [info ] [MainThread]: 
[0m14:34:57.270074 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m14:34:57.271348 [info ] [Thread-1 (]: 1 of 1 START sql view model test_staging.stg_customers ......................... [RUN]
[0m14:34:57.273550 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m14:34:57.274223 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m14:34:57.276997 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m14:34:57.278137 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-13 14:34:57.274596 => 2025-11-13 14:34:57.277947
[0m14:34:57.278730 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m14:34:57.350414 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m14:34:57.351318 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m14:34:57.351602 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.test_staging.stg_customers
  
   as (
    select * from customers
  );
[0m14:34:57.351830 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:34:58.343010 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c05d8a-0000-a64f-0000-eb0d00015c56
[0m14:34:58.343629 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m14:34:58.344488 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-13 14:34:57.279144 => 2025-11-13 14:34:58.344321
[0m14:34:58.345007 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m14:34:58.850099 [debug] [Thread-1 (]: Database Error in model stg_customers (models/staging/stg_customers.sql)
  002003 (42S02): SQL compilation error:
  Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m14:34:58.850777 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8ab49cb6-15bf-47fa-996e-7d8c3357f757', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfa9ded100>]}
[0m14:34:58.851395 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test_staging.stg_customers ................ [[31mERROR[0m in 1.58s]
[0m14:34:58.854130 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m14:34:58.856885 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:34:58.857926 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:34:58.858416 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m14:34:58.858932 [debug] [MainThread]: Connection 'list_GP_test' was properly closed.
[0m14:34:58.859497 [info ] [MainThread]: 
[0m14:34:58.859995 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 7.01 seconds (7.01s).
[0m14:34:58.860605 [debug] [MainThread]: Command end result
[0m14:34:58.871879 [info ] [MainThread]: 
[0m14:34:58.873099 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:34:58.873858 [info ] [MainThread]: 
[0m14:34:58.874595 [error] [MainThread]: [33mDatabase Error in model stg_customers (models/staging/stg_customers.sql)[0m
[0m14:34:58.875462 [error] [MainThread]:   002003 (42S02): SQL compilation error:
[0m14:34:58.876048 [error] [MainThread]:   Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m14:34:58.876544 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m14:34:58.877099 [info ] [MainThread]: 
[0m14:34:58.877958 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:34:58.879389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfce15ac00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfce1cc680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfbf1b8470>]}
[0m14:34:58.880207 [debug] [MainThread]: Flushing usage events


============================== 2025-11-13 14:42:30.901486 | bd339eca-e927-432b-a6c6-8e88fc95e1bc ==============================
[0m14:42:30.901486 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:42:30.903578 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:42:30.903844 [debug] [MainThread]: Tracking: tracking
[0m14:42:30.904124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb77e1aa8a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb789fa0aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb777e700b0>]}
[0m14:42:30.953396 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:42:30.954240 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/stg_customers.sql
[0m14:42:30.981440 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:42:31.020352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb77c130890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb777ea2570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb777d16330>]}
[0m14:42:31.021863 [debug] [MainThread]: Flushing usage events
[0m14:42:39.077392 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.airflow_dbt_project.stg_customers' (models/staging/stg_customers.sql) depends on a source named 'test.customers' which was not found


============================== 2025-11-13 14:43:24.668131 | 31e4c403-3d95-4e9b-98ad-41cd5c9e2703 ==============================
[0m14:43:24.668131 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:43:24.670763 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:43:24.671111 [debug] [MainThread]: Tracking: tracking
[0m14:43:24.671535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc60453350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc5be802c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc5be822a0>]}
[0m14:43:24.727779 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:43:24.729131 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/stg_customers.sql
[0m14:43:24.768149 [debug] [MainThread]: 1603: static parser failed on staging/stg_customers.sql
[0m14:43:24.784486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc5bdb5b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc60c4a630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc62118f80>]}
[0m14:43:24.786309 [debug] [MainThread]: Flushing usage events
[0m14:43:25.704612 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_customers (models/staging/stg_customers.sql)
  source() takes exactly two arguments (3 given)


============================== 2025-11-13 14:45:36.833814 | 37f9d5ea-fe88-40a6-b1ce-cee4fa8be34d ==============================
[0m14:45:36.833814 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:45:36.836445 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:45:36.836817 [debug] [MainThread]: Tracking: tracking
[0m14:45:36.837178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51188026f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5118802120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5118800bc0>]}
[0m14:45:36.901932 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:45:36.902890 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:45:36.920842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '37f9d5ea-fe88-40a6-b1ce-cee4fa8be34d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f511ab7a8d0>]}
[0m14:45:36.941057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '37f9d5ea-fe88-40a6-b1ce-cee4fa8be34d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5118855f10>]}
[0m14:45:36.942164 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:45:36.943480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '37f9d5ea-fe88-40a6-b1ce-cee4fa8be34d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f511ab33e90>]}
[0m14:45:36.947380 [info ] [MainThread]: 
[0m14:45:36.952699 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:45:36.955402 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:45:36.998091 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:45:36.998786 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:45:36.999277 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:46:01.837510 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 25 seconds
[0m14:46:01.840716 [debug] [ThreadPool]: On list_GP: Close
[0m14:46:02.226499 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m14:46:02.233290 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_mart'
[0m14:46:02.246494 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_mart"
[0m14:46:02.247117 [debug] [ThreadPool]: On list_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_mart"} */
show terse objects in GP.test_mart
[0m14:46:02.247456 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:46:02.248349 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m14:46:02.248832 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m14:46:02.250064 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:46:11.271375 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c05d96-0000-a64f-0000-eb0d00015cea
[0m14:46:11.271906 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m14:46:11.272447 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m14:46:11.272737 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m14:46:11.273106 [debug] [ThreadPool]: On list_GP_test_mart: Close
[0m14:46:12.315741 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m14:46:12.318745 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m14:46:12.319126 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m14:46:12.319397 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:46:17.529484 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 5 seconds
[0m14:46:17.532783 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m14:46:24.481480 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 22 seconds
[0m14:46:24.483600 [debug] [ThreadPool]: On list_GP_test: Close
[0m14:46:24.952302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '37f9d5ea-fe88-40a6-b1ce-cee4fa8be34d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51186b3d40>]}
[0m14:46:24.953934 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:46:24.954704 [info ] [MainThread]: 
[0m14:46:25.002341 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m14:46:25.003110 [info ] [Thread-1 (]: 1 of 1 START sql view model test_staging.stg_customers ......................... [RUN]
[0m14:46:25.004818 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m14:46:25.005578 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m14:46:25.009336 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m14:46:25.010589 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-13 14:46:25.006058 => 2025-11-13 14:46:25.010400
[0m14:46:25.011549 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m14:46:25.088436 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m14:46:25.089573 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m14:46:25.090007 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.test_staging.stg_customers
  
   as (
    select * from customers
  );
[0m14:46:25.090300 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:46:34.022607 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c05d96-0000-a61c-0000-eb0d00017016
[0m14:46:34.023162 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m14:46:34.023767 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-13 14:46:25.012021 => 2025-11-13 14:46:34.023623
[0m14:46:34.024139 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m14:46:34.394267 [debug] [Thread-1 (]: Database Error in model stg_customers (models/staging/stg_customers.sql)
  002003 (42S02): SQL compilation error:
  Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m14:46:34.394852 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '37f9d5ea-fe88-40a6-b1ce-cee4fa8be34d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51185a11c0>]}
[0m14:46:34.395431 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test_staging.stg_customers ................ [[31mERROR[0m in 9.39s]
[0m14:46:34.397913 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m14:46:34.400391 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:46:34.401205 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:46:34.401513 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m14:46:34.401737 [debug] [MainThread]: Connection 'list_GP_test_staging' was properly closed.
[0m14:46:34.402077 [info ] [MainThread]: 
[0m14:46:34.402484 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 57.45 seconds (57.45s).
[0m14:46:34.402978 [debug] [MainThread]: Command end result
[0m14:46:34.413159 [info ] [MainThread]: 
[0m14:46:34.414210 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:46:34.415126 [info ] [MainThread]: 
[0m14:46:34.415739 [error] [MainThread]: [33mDatabase Error in model stg_customers (models/staging/stg_customers.sql)[0m
[0m14:46:34.416230 [error] [MainThread]:   002003 (42S02): SQL compilation error:
[0m14:46:34.416700 [error] [MainThread]:   Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m14:46:34.417099 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m14:46:34.417574 [info ] [MainThread]: 
[0m14:46:34.418060 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:46:34.418725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51184fa810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f512b1caa80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f513a1c3860>]}
[0m14:46:34.419454 [debug] [MainThread]: Flushing usage events


============================== 2025-11-13 14:50:21.605343 | 5e10e4fa-3770-4c2e-a468-17020681af4a ==============================
[0m14:50:21.605343 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:50:21.607607 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:50:21.607882 [debug] [MainThread]: Tracking: tracking
[0m14:50:21.608167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa580a8bb30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa559202840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa559202750>]}
[0m14:50:21.638365 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:50:21.639448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5e10e4fa-3770-4c2e-a468-17020681af4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5590590a0>]}
[0m14:50:22.438163 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m14:50:22.454438 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m14:50:22.457894 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:50:22.461852 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m14:50:22.466508 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m14:50:22.497866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5e10e4fa-3770-4c2e-a468-17020681af4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa55903aff0>]}
[0m14:50:22.504546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5e10e4fa-3770-4c2e-a468-17020681af4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa55903a630>]}
[0m14:50:22.504976 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:50:22.505327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e10e4fa-3770-4c2e-a468-17020681af4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa559200da0>]}
[0m14:50:22.506688 [info ] [MainThread]: 
[0m14:50:22.509078 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:50:22.510556 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:50:22.541826 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:50:22.542208 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:50:22.542451 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:50:29.175543 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 7 seconds
[0m14:50:29.179151 [debug] [ThreadPool]: On list_GP: Close
[0m14:50:29.554306 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m14:50:29.568224 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m14:50:29.568736 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m14:50:29.569144 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:51.123293 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 22 seconds
[0m14:50:51.127094 [debug] [ThreadPool]: On list_GP_test: Close
[0m14:50:51.694585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e10e4fa-3770-4c2e-a468-17020681af4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa580a8a420>]}
[0m14:50:51.695741 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:50:51.696182 [info ] [MainThread]: 
[0m14:50:51.738620 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m14:50:51.740057 [info ] [Thread-1 (]: 1 of 1 START sql view model test.stg_customers ................................. [RUN]
[0m14:50:51.742375 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m14:50:51.743250 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m14:50:51.749289 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m14:50:51.750970 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-13 14:50:51.743817 => 2025-11-13 14:50:51.750726
[0m14:50:51.751653 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m14:50:51.858620 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m14:50:51.859894 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m14:50:51.860295 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.test.stg_customers
  
   as (
    select * from customers
  );
[0m14:50:51.860595 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:53.223052 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:50:53.255974 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-13 14:50:51.752045 => 2025-11-13 14:50:53.255863
[0m14:50:53.256399 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m14:50:53.642327 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e10e4fa-3770-4c2e-a468-17020681af4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5581a1070>]}
[0m14:50:53.643438 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.stg_customers ............................ [[32mSUCCESS 1[0m in 1.90s]
[0m14:50:53.647648 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m14:50:53.652697 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:50:53.654433 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:50:53.655245 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m14:50:53.655793 [info ] [MainThread]: 
[0m14:50:53.656314 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 31.15 seconds (31.15s).
[0m14:50:53.656956 [debug] [MainThread]: Command end result
[0m14:50:53.669046 [info ] [MainThread]: 
[0m14:50:53.670197 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:50:53.671509 [info ] [MainThread]: 
[0m14:50:53.672525 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:50:53.673875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa559283e30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa559283350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa559282510>]}
[0m14:50:53.674929 [debug] [MainThread]: Flushing usage events


============================== 2025-11-13 14:54:44.704340 | a83240b5-a46e-4637-84cf-f3a112fa3045 ==============================
[0m14:54:44.704340 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:54:44.715710 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['ord'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:54:44.716464 [debug] [MainThread]: Tracking: tracking
[0m14:54:44.717133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06fbe65bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06fbe65e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06fbe67650>]}
[0m14:54:44.782860 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m14:54:44.783592 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/core/ord.sql
[0m14:54:44.809071 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m14:54:44.916364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a83240b5-a46e-4637-84cf-f3a112fa3045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07018f2870>]}
[0m14:54:44.934678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a83240b5-a46e-4637-84cf-f3a112fa3045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0700687860>]}
[0m14:54:44.936511 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:54:44.938332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a83240b5-a46e-4637-84cf-f3a112fa3045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07290f8740>]}
[0m14:54:44.944345 [info ] [MainThread]: 
[0m14:54:44.955410 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:54:44.960774 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:54:45.033925 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:54:45.035207 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:54:45.035953 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:54:51.873358 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 7 seconds
[0m14:54:51.876823 [debug] [ThreadPool]: On list_GP: Close
[0m14:54:52.275840 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m14:54:52.287774 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m14:54:52.288181 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m14:54:52.288463 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:53.296294 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1 seconds
[0m14:54:53.299402 [debug] [ThreadPool]: On list_GP_test: Close
[0m14:54:53.809949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a83240b5-a46e-4637-84cf-f3a112fa3045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07006e25a0>]}
[0m14:54:53.811030 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:54:53.811496 [info ] [MainThread]: 
[0m14:54:53.854023 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.ord
[0m14:54:53.854976 [info ] [Thread-1 (]: 1 of 1 START sql table model test.ord .......................................... [RUN]
[0m14:54:53.856384 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.ord'
[0m14:54:53.856928 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.ord
[0m14:54:53.859599 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.ord"
[0m14:54:53.860599 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.ord (compile): 2025-11-13 14:54:53.857280 => 2025-11-13 14:54:53.860442
[0m14:54:53.861053 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.ord
[0m14:54:53.915202 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.ord"
[0m14:54:53.916107 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.ord"
[0m14:54:53.916396 [debug] [Thread-1 (]: On model.airflow_dbt_project.ord: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.ord"} */
create or replace transient table GP.test.ord  as
        (select * from orders
        );
[0m14:54:53.916601 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:59.589407 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 6 seconds
[0m14:54:59.623381 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.ord (execute): 2025-11-13 14:54:53.861276 => 2025-11-13 14:54:59.623296
[0m14:54:59.623707 [debug] [Thread-1 (]: On model.airflow_dbt_project.ord: Close
[0m14:55:00.036089 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a83240b5-a46e-4637-84cf-f3a112fa3045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06f9b29040>]}
[0m14:55:00.037375 [info ] [Thread-1 (]: 1 of 1 OK created sql table model test.ord ..................................... [[32mSUCCESS 1[0m in 6.18s]
[0m14:55:00.041061 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.ord
[0m14:55:00.043431 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:55:00.044267 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:55:00.044555 [debug] [MainThread]: Connection 'model.airflow_dbt_project.ord' was properly closed.
[0m14:55:00.044848 [info ] [MainThread]: 
[0m14:55:00.045350 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 15.10 seconds (15.10s).
[0m14:55:00.046129 [debug] [MainThread]: Command end result
[0m14:55:00.063024 [info ] [MainThread]: 
[0m14:55:00.063899 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:55:00.064393 [info ] [MainThread]: 
[0m14:55:00.064864 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:55:00.065470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06f9b073b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06f9b060f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06f9b04560>]}
[0m14:55:00.066018 [debug] [MainThread]: Flushing usage events


============================== 2025-11-13 14:56:24.593849 | 4e681016-58e9-45a9-9da0-bea0c540ad0e ==============================
[0m14:56:24.593849 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:56:24.596507 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['ord'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:56:24.596910 [debug] [MainThread]: Tracking: tracking
[0m14:56:24.597314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f841ec1de50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f844a3a6240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f841eb4fd70>]}
[0m14:56:24.624931 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:56:24.625775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4e681016-58e9-45a9-9da0-bea0c540ad0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f841e9a4f20>]}
[0m14:56:25.476850 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m14:56:25.492943 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m14:56:25.496449 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:56:25.500511 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m14:56:25.505780 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m14:56:25.507379 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m14:56:25.543424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4e681016-58e9-45a9-9da0-bea0c540ad0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f841e96f470>]}
[0m14:56:25.550024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4e681016-58e9-45a9-9da0-bea0c540ad0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f841e96f4a0>]}
[0m14:56:25.550419 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:56:25.550723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e681016-58e9-45a9-9da0-bea0c540ad0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f841e98ef90>]}
[0m14:56:25.552054 [info ] [MainThread]: 
[0m14:56:25.554423 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:56:25.555934 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:56:25.583363 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:56:25.583990 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:56:25.584407 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:56:31.961444 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 6 seconds
[0m14:56:31.963742 [debug] [ThreadPool]: On list_GP: Close
[0m14:56:32.428125 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_test_mart'
[0m14:56:32.429072 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_test_mart'
[0m14:56:32.429588 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='test_mart', identifier=None)"
[0m14:56:32.438174 [debug] [ThreadPool]: Using snowflake connection "create_GP_test_mart"
[0m14:56:32.438599 [debug] [ThreadPool]: On create_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_test_mart"} */
create schema if not exists GP.test_mart
[0m14:56:32.438893 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:56:33.869266 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m14:56:33.870929 [debug] [ThreadPool]: On create_GP_test_mart: Close
[0m14:56:34.340333 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_mart'
[0m14:56:34.347102 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m14:56:34.355698 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m14:56:34.356215 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m14:56:34.356491 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:56:34.356970 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_mart"
[0m14:56:34.358686 [debug] [ThreadPool]: On list_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_mart"} */
show terse objects in GP.test_mart
[0m14:56:34.360438 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:56:35.887853 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m14:56:35.891436 [debug] [ThreadPool]: On list_GP_test: Close
[0m14:56:46.584449 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 12 seconds
[0m14:56:46.587040 [debug] [ThreadPool]: On list_GP_test_mart: Close
[0m14:56:47.212584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e681016-58e9-45a9-9da0-bea0c540ad0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f841e94b590>]}
[0m14:56:47.214205 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:56:47.214819 [info ] [MainThread]: 
[0m14:56:47.261960 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.ord
[0m14:56:47.263008 [info ] [Thread-1 (]: 1 of 1 START sql table model test_mart.ord ..................................... [RUN]
[0m14:56:47.264733 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.ord'
[0m14:56:47.265453 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.ord
[0m14:56:47.269137 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.ord"
[0m14:56:47.270010 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.ord (compile): 2025-11-13 14:56:47.265904 => 2025-11-13 14:56:47.269876
[0m14:56:47.270457 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.ord
[0m14:56:47.351628 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.ord"
[0m14:56:47.353551 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.ord"
[0m14:56:47.354132 [debug] [Thread-1 (]: On model.airflow_dbt_project.ord: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.ord"} */
create or replace transient table GP.test_mart.ord  as
        (select * from orders
        );
[0m14:56:47.354541 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:56:49.296109 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:56:49.327831 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.ord (execute): 2025-11-13 14:56:47.270723 => 2025-11-13 14:56:49.327736
[0m14:56:49.328184 [debug] [Thread-1 (]: On model.airflow_dbt_project.ord: Close
[0m14:56:49.793189 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e681016-58e9-45a9-9da0-bea0c540ad0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f841c9d21e0>]}
[0m14:56:49.794122 [info ] [Thread-1 (]: 1 of 1 OK created sql table model test_mart.ord ................................ [[32mSUCCESS 1[0m in 2.53s]
[0m14:56:49.797145 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.ord
[0m14:56:49.800082 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:56:49.801014 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:56:49.801308 [debug] [MainThread]: Connection 'model.airflow_dbt_project.ord' was properly closed.
[0m14:56:49.801529 [debug] [MainThread]: Connection 'list_GP_test' was properly closed.
[0m14:56:49.801812 [info ] [MainThread]: 
[0m14:56:49.802179 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 24.25 seconds (24.25s).
[0m14:56:49.802702 [debug] [MainThread]: Command end result
[0m14:56:49.813163 [info ] [MainThread]: 
[0m14:56:49.813927 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:56:49.814439 [info ] [MainThread]: 
[0m14:56:49.814929 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:56:49.815603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f841f5038c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f841d315250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f841d251070>]}
[0m14:56:49.816176 [debug] [MainThread]: Flushing usage events


============================== 2025-11-13 14:57:21.429189 | 24f29b9e-a00a-402f-8e23-f79a862e596c ==============================
[0m14:57:21.429189 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:57:21.432553 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['ord'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:57:21.432955 [debug] [MainThread]: Tracking: tracking
[0m14:57:21.433375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ac2db45c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ac11ec5c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ac2411c40>]}
[0m14:57:21.461221 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:57:21.462184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '24f29b9e-a00a-402f-8e23-f79a862e596c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ac08fcbf0>]}
[0m14:57:22.953625 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m14:57:22.974426 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m14:57:22.978573 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:57:22.983417 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m14:57:22.989475 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m14:57:22.991353 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m14:57:23.037743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '24f29b9e-a00a-402f-8e23-f79a862e596c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ae0ba7680>]}
[0m14:57:23.047052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '24f29b9e-a00a-402f-8e23-f79a862e596c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ac0b32b10>]}
[0m14:57:23.047625 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:57:23.048073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '24f29b9e-a00a-402f-8e23-f79a862e596c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ae0ba7680>]}
[0m14:57:23.049930 [info ] [MainThread]: 
[0m14:57:23.053158 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:57:23.055031 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:57:23.082913 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:57:23.083486 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:57:23.083911 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:57:24.669458 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 2 seconds
[0m14:57:24.672282 [debug] [ThreadPool]: On list_GP: Close
[0m14:57:25.101875 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_mart'
[0m14:57:25.103448 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m14:57:25.117101 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m14:57:25.117510 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m14:57:25.117793 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:57:25.119181 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_mart"
[0m14:57:25.119596 [debug] [ThreadPool]: On list_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_mart"} */
show terse objects in GP.test_mart
[0m14:57:25.119967 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:57:27.155422 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m14:57:27.159346 [debug] [ThreadPool]: On list_GP_test: Close
[0m14:57:27.346744 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m14:57:27.349883 [debug] [ThreadPool]: On list_GP_test_mart: Close
[0m14:57:27.845555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '24f29b9e-a00a-402f-8e23-f79a862e596c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aba809460>]}
[0m14:57:27.847152 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:57:27.847708 [info ] [MainThread]: 
[0m14:57:27.892606 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.ord
[0m14:57:27.894443 [info ] [Thread-1 (]: 1 of 1 START sql table model test_mart.ord ..................................... [RUN]
[0m14:57:27.896947 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.ord'
[0m14:57:27.897784 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.ord
[0m14:57:27.910106 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.ord"
[0m14:57:27.911249 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.ord (compile): 2025-11-13 14:57:27.898162 => 2025-11-13 14:57:27.911066
[0m14:57:27.911866 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.ord
[0m14:57:28.054049 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.ord"
[0m14:57:28.056172 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.ord"
[0m14:57:28.056778 [debug] [Thread-1 (]: On model.airflow_dbt_project.ord: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.ord"} */
create or replace transient table GP.test_mart.ord  as
        (select * from orders
        );
[0m14:57:28.057201 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:57:29.563406 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:57:29.599777 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.ord (execute): 2025-11-13 14:57:27.912210 => 2025-11-13 14:57:29.599680
[0m14:57:29.600108 [debug] [Thread-1 (]: On model.airflow_dbt_project.ord: Close
[0m14:57:30.469906 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24f29b9e-a00a-402f-8e23-f79a862e596c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aba859ca0>]}
[0m14:57:30.470800 [info ] [Thread-1 (]: 1 of 1 OK created sql table model test_mart.ord ................................ [[32mSUCCESS 1[0m in 2.57s]
[0m14:57:30.473700 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.ord
[0m14:57:30.476260 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:57:30.477148 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:57:30.477472 [debug] [MainThread]: Connection 'model.airflow_dbt_project.ord' was properly closed.
[0m14:57:30.477719 [debug] [MainThread]: Connection 'list_GP_test' was properly closed.
[0m14:57:30.478133 [info ] [MainThread]: 
[0m14:57:30.478693 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 7.43 seconds (7.43s).
[0m14:57:30.479433 [debug] [MainThread]: Command end result
[0m14:57:30.489710 [info ] [MainThread]: 
[0m14:57:30.490399 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:57:30.491050 [info ] [MainThread]: 
[0m14:57:30.491489 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:57:30.492151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aba98dbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aba98f0b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aba98e5a0>]}
[0m14:57:30.492653 [debug] [MainThread]: Flushing usage events
[0m14:57:38.681869 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.


============================== 2025-11-13 15:00:17.147376 | ffdd0316-8b1c-4f5b-9148-ae305981de83 ==============================
[0m15:00:17.147376 [info ] [MainThread]: Running with dbt=1.4.0
[0m15:00:17.149418 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['ord'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:00:17.149712 [debug] [MainThread]: Tracking: tracking
[0m15:00:17.150031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbedcf44260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbedc023ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf03632330>]}
[0m15:00:17.174640 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m15:00:17.175320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ffdd0316-8b1c-4f5b-9148-ae305981de83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbedcb1acf0>]}
[0m15:00:17.950773 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m15:00:17.967686 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m15:00:17.971160 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m15:00:17.975232 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m15:00:17.980121 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m15:00:17.981604 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m15:00:18.018251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ffdd0316-8b1c-4f5b-9148-ae305981de83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbed7fd7c80>]}
[0m15:00:18.025621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ffdd0316-8b1c-4f5b-9148-ae305981de83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbedc75c2f0>]}
[0m15:00:18.026050 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m15:00:18.026380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ffdd0316-8b1c-4f5b-9148-ae305981de83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbed7dc7110>]}
[0m15:00:18.027822 [info ] [MainThread]: 
[0m15:00:18.030472 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m15:00:18.032075 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m15:00:18.062452 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m15:00:18.062979 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m15:00:18.063317 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:00:46.349876 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 28 seconds
[0m15:00:46.353214 [debug] [ThreadPool]: On list_GP: Close
[0m15:00:47.514686 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m15:00:47.526612 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_mart'
[0m15:00:47.525569 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m15:00:47.530213 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_mart"
[0m15:00:47.530831 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m15:00:47.531373 [debug] [ThreadPool]: On list_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_mart"} */
show terse objects in GP.test_mart
[0m15:00:47.531792 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:00:47.532237 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:00:48.642631 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m15:00:48.646254 [debug] [ThreadPool]: On list_GP_test: Close
[0m15:00:49.137487 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m15:00:49.139786 [debug] [ThreadPool]: On list_GP_test_mart: Close
[0m15:00:49.937991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ffdd0316-8b1c-4f5b-9148-ae305981de83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbed5cbb290>]}
[0m15:00:49.939417 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m15:00:49.940186 [info ] [MainThread]: 
[0m15:00:49.989829 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.ord
[0m15:00:49.990680 [info ] [Thread-1 (]: 1 of 1 START sql table model test_mart.ord ..................................... [RUN]
[0m15:00:49.992126 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.ord'
[0m15:00:49.992852 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.ord
[0m15:00:49.995575 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.ord"
[0m15:00:49.996486 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.ord (compile): 2025-11-13 15:00:49.993223 => 2025-11-13 15:00:49.996318
[0m15:00:49.997025 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.ord
[0m15:00:50.063854 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.ord"
[0m15:00:50.064883 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.ord"
[0m15:00:50.065219 [debug] [Thread-1 (]: On model.airflow_dbt_project.ord: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.ord"} */
create or replace transient table GP.test_mart.ord  as
        (select * from orders
        );
[0m15:00:50.065462 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:00:53.787338 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 4 seconds
[0m15:00:53.827283 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.ord (execute): 2025-11-13 15:00:49.997424 => 2025-11-13 15:00:53.827196
[0m15:00:53.827635 [debug] [Thread-1 (]: On model.airflow_dbt_project.ord: Close
[0m15:00:54.616051 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ffdd0316-8b1c-4f5b-9148-ae305981de83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbed5d2ecc0>]}
[0m15:00:54.616925 [info ] [Thread-1 (]: 1 of 1 OK created sql table model test_mart.ord ................................ [[32mSUCCESS 1[0m in 4.62s]
[0m15:00:54.620565 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.ord
[0m15:00:54.623155 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m15:00:54.624361 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:00:54.624774 [debug] [MainThread]: Connection 'list_GP_test' was properly closed.
[0m15:00:54.625096 [debug] [MainThread]: Connection 'model.airflow_dbt_project.ord' was properly closed.
[0m15:00:54.625399 [info ] [MainThread]: 
[0m15:00:54.625809 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 36.60 seconds (36.60s).
[0m15:00:54.626420 [debug] [MainThread]: Command end result
[0m15:00:54.637587 [info ] [MainThread]: 
[0m15:00:54.638440 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:00:54.639148 [info ] [MainThread]: 
[0m15:00:54.639647 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:00:54.640309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbed7ddb3b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbed7ddb530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbed5e30c20>]}
[0m15:00:54.640828 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 10:39:35.301199 | 7754e964-6735-483c-9674-0b22756afe2a ==============================
[0m10:39:35.301199 [info ] [MainThread]: Running with dbt=1.4.0
[0m10:39:35.309182 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['cus_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m10:39:35.310094 [debug] [MainThread]: Tracking: tracking
[0m10:39:35.310942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d7354e720>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d7354d520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d7354c5c0>]}
[0m10:39:35.405886 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m10:39:35.407561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7754e964-6735-483c-9674-0b22756afe2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d73429400>]}
[0m10:39:37.599810 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m10:39:37.623392 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m10:39:37.628403 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m10:39:37.633629 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m10:39:37.642418 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m10:39:37.645811 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m10:39:37.741223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7754e964-6735-483c-9674-0b22756afe2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d7345bf50>]}
[0m10:39:37.760042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7754e964-6735-483c-9674-0b22756afe2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d73f2b770>]}
[0m10:39:37.761038 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 305 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m10:39:37.761928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7754e964-6735-483c-9674-0b22756afe2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d7940a9c0>]}
[0m10:39:37.767108 [info ] [MainThread]: 
[0m10:39:37.772912 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m10:39:37.779341 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m10:39:37.851796 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m10:39:37.852834 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m10:39:37.853716 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:39:52.655103 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 15 seconds
[0m10:39:52.658379 [debug] [ThreadPool]: On list_GP: Close
[0m10:39:53.250357 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_test   -- use default schema when none is provided'
[0m10:39:53.251361 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_test   -- use default schema when none is provided'
[0m10:39:53.251844 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='test   -- use default schema when none is provided', identifier=None)"
[0m10:39:53.261042 [debug] [ThreadPool]: Using snowflake connection "create_GP_test   -- use default schema when none is provided"
[0m10:39:53.261527 [debug] [ThreadPool]: On create_GP_test   -- use default schema when none is provided: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_test   -- use default schema when none is provided"} */
create schema if not exists GP.test   -- use default schema when none is provided
[0m10:39:53.261868 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:39:55.284728 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m10:39:55.286553 [debug] [ThreadPool]: On create_GP_test   -- use default schema when none is provided: Close
[0m10:39:59.842836 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test   -- use default schema when none is provided'
[0m10:39:59.854402 [debug] [ThreadPool]: Using snowflake connection "list_GP_test   -- use default schema when none is provided"
[0m10:39:59.854817 [debug] [ThreadPool]: On list_GP_test   -- use default schema when none is provided: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test   -- use default schema when none is provided"} */
show terse objects in GP.test   -- use default schema when none is provided
[0m10:39:59.855095 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:39:59.856066 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_mart  -- use only the custom schema'
[0m10:39:59.862807 [debug] [ThreadPool]: Using snowflake connection "list_GP_mart  -- use only the custom schema"
[0m10:39:59.863169 [debug] [ThreadPool]: On list_GP_mart  -- use only the custom schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_mart  -- use only the custom schema"} */
show terse objects in GP.mart  -- use only the custom schema
[0m10:39:59.863397 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:40:02.239905 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m10:40:02.244019 [debug] [ThreadPool]: On list_GP_test   -- use default schema when none is provided: Close
[0m10:40:02.276121 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2 seconds
[0m10:40:02.279252 [debug] [ThreadPool]: On list_GP_mart  -- use only the custom schema: Close
[0m10:40:02.747652 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_staging  -- use only the custom schema'
[0m10:40:02.754148 [debug] [ThreadPool]: Using snowflake connection "list_GP_staging  -- use only the custom schema"
[0m10:40:02.754526 [debug] [ThreadPool]: On list_GP_staging  -- use only the custom schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_staging  -- use only the custom schema"} */
show terse objects in GP.staging  -- use only the custom schema
[0m10:40:02.754795 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:40:03.922363 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1 seconds
[0m10:40:03.925793 [debug] [ThreadPool]: On list_GP_staging  -- use only the custom schema: Close
[0m10:40:04.365128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7754e964-6735-483c-9674-0b22756afe2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d73486f30>]}
[0m10:40:04.366024 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m10:40:04.366432 [info ] [MainThread]: 
[0m10:40:04.418731 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.cus_orders
[0m10:40:04.419528 [info ] [Thread-1 (]: 1 of 1 START sql view model test   -- use default schema when none is provided.cus_orders  [RUN]
[0m10:40:04.421778 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m10:40:04.422293 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m10:40:04.424628 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m10:40:04.425387 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-14 10:40:04.422568 => 2025-11-14 10:40:04.425271
[0m10:40:04.425788 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m10:40:04.485722 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.cus_orders"
[0m10:40:04.487251 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.cus_orders"
[0m10:40:04.487630 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.cus_orders"} */
create or replace   view GP.test   -- use default schema when none is provided.cus_orders
  
   as (
    with cus as(
    select customer_id,first_name,last_name, email 
    from CUSTOMERS 
    where status = 'active'
),
alls as(
    select 
    email,
    concat(first_name,' ',last_name),
    order_id,
    order_date,
    total_amount,
    shipping_address
    from ORDERS o join cus c on
    o.customer_id = c.customer_id 
)
select * from alls
  );
[0m10:40:04.487917 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:40:11.473714 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c06240-0000-a67d-0000-eb0d0001c3c2
[0m10:40:11.474497 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Schema 'GP.GP' does not exist or not authorized.
[0m10:40:11.475646 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-14 10:40:04.426035 => 2025-11-14 10:40:11.475430
[0m10:40:11.476363 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: Close
[0m10:40:13.557659 [debug] [Thread-1 (]: Database Error in model cus_orders (models/cus_orders.sql)
  002003 (02000): SQL compilation error:
  Schema 'GP.GP' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/cus_orders.sql
[0m10:40:13.558525 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7754e964-6735-483c-9674-0b22756afe2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d711e8a40>]}
[0m10:40:13.559436 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test   -- use default schema when none is provided.cus_orders  [[31mERROR[0m in 9.14s]
[0m10:40:13.563361 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m10:40:13.566638 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m10:40:13.568060 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:40:13.568553 [debug] [MainThread]: Connection 'model.airflow_dbt_project.cus_orders' was properly closed.
[0m10:40:13.568998 [debug] [MainThread]: Connection 'list_GP_mart  -- use only the custom schema' was properly closed.
[0m10:40:13.569499 [info ] [MainThread]: 
[0m10:40:13.570215 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 35.80 seconds (35.80s).
[0m10:40:13.571070 [debug] [MainThread]: Command end result
[0m10:40:13.585158 [info ] [MainThread]: 
[0m10:40:13.586257 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m10:40:13.587165 [info ] [MainThread]: 
[0m10:40:13.588165 [error] [MainThread]: [33mDatabase Error in model cus_orders (models/cus_orders.sql)[0m
[0m10:40:13.589154 [error] [MainThread]:   002003 (02000): SQL compilation error:
[0m10:40:13.590107 [error] [MainThread]:   Schema 'GP.GP' does not exist or not authorized.
[0m10:40:13.591005 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/cus_orders.sql
[0m10:40:13.591780 [info ] [MainThread]: 
[0m10:40:13.592515 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m10:40:13.593341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d73862870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d735f2450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d7345bfe0>]}
[0m10:40:13.593978 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 10:47:11.990095 | 427f2134-4750-4570-98f6-70140e07f631 ==============================
[0m10:47:11.990095 [info ] [MainThread]: Running with dbt=1.4.0
[0m10:47:11.995630 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['cus_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m10:47:11.996592 [debug] [MainThread]: Tracking: tracking
[0m10:47:11.997399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9c6bb0b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9aba69d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9aba6b860>]}
[0m10:47:12.128274 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 0 files changed.
[0m10:47:12.130215 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://macros/generate_schema_name.sql
[0m10:47:12.133742 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m10:47:14.824146 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m10:47:14.867946 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m10:47:14.882757 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m10:47:14.896397 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m10:47:14.912853 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m10:47:14.916752 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m10:47:15.007867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '427f2134-4750-4570-98f6-70140e07f631', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9b07a4b30>]}
[0m10:47:15.029032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '427f2134-4750-4570-98f6-70140e07f631', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9ab907ad0>]}
[0m10:47:15.030144 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m10:47:15.031270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '427f2134-4750-4570-98f6-70140e07f631', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9abfd7ef0>]}
[0m10:47:15.035043 [info ] [MainThread]: 
[0m10:47:15.040304 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m10:47:15.043659 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m10:47:15.090036 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m10:47:15.090957 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m10:47:15.091478 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:47:18.231557 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 3 seconds
[0m10:47:18.246402 [debug] [ThreadPool]: On list_GP: Close
[0m10:47:18.764969 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m10:47:18.779455 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m10:47:18.808221 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m10:47:18.810718 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m10:47:18.811473 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m10:47:18.812498 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m10:47:18.813484 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:47:18.814382 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:47:20.404812 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m10:47:20.471418 [debug] [ThreadPool]: On list_GP_test: Close
[0m10:47:20.472569 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c06247-0000-a67d-0000-eb0d0001c3e6
[0m10:47:20.482834 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m10:47:20.493964 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m10:47:20.504129 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m10:47:20.507729 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m10:47:21.307596 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_mart'
[0m10:47:21.340516 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_mart"
[0m10:47:21.342287 [debug] [ThreadPool]: On list_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_mart"} */
show terse objects in GP.test_mart
[0m10:47:21.343966 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:47:23.773462 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c06247-0000-a67e-0000-eb0d00019d52
[0m10:47:23.779252 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m10:47:23.781271 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m10:47:23.784230 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m10:47:23.787759 [debug] [ThreadPool]: On list_GP_test_mart: Close
[0m10:48:22.110476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '427f2134-4750-4570-98f6-70140e07f631', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9a8fc8d70>]}
[0m10:48:22.112775 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m10:48:22.113832 [info ] [MainThread]: 
[0m10:48:22.182795 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.cus_orders
[0m10:48:22.184026 [info ] [Thread-1 (]: 1 of 1 START sql view model test.cus_orders .................................... [RUN]
[0m10:48:22.186837 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m10:48:22.187632 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m10:48:22.191464 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m10:48:22.193067 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-14 10:48:22.188233 => 2025-11-14 10:48:22.192836
[0m10:48:22.193965 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m10:48:22.307588 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.cus_orders"
[0m10:48:22.310300 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.cus_orders"
[0m10:48:22.311067 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.cus_orders"} */
create or replace   view GP.test.cus_orders
  
   as (
    with cus as(
    select customer_id,first_name,last_name, email 
    from CUSTOMERS 
    where status = 'active'
),
alls as(
    select 
    email,
    concat(first_name,' ',last_name),
    order_id,
    order_date,
    total_amount,
    shipping_address
    from ORDERS o join cus c on
    o.customer_id = c.customer_id 
)
select * from alls
  );
[0m10:48:22.311793 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:48:23.750150 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m10:48:23.793206 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-14 10:48:22.194507 => 2025-11-14 10:48:23.793070
[0m10:48:23.793750 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: Close
[0m10:48:24.299776 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427f2134-4750-4570-98f6-70140e07f631', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9ab93c320>]}
[0m10:48:24.301128 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.cus_orders ............................... [[32mSUCCESS 1[0m in 2.11s]
[0m10:48:24.306833 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m10:48:24.311739 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m10:48:24.314087 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:48:24.315078 [debug] [MainThread]: Connection 'list_GP_test_mart' was properly closed.
[0m10:48:24.316111 [debug] [MainThread]: Connection 'model.airflow_dbt_project.cus_orders' was properly closed.
[0m10:48:24.317411 [info ] [MainThread]: 
[0m10:48:24.319252 [info ] [MainThread]: Finished running 1 view model in 0 hours 1 minutes and 9.28 seconds (69.28s).
[0m10:48:24.321151 [debug] [MainThread]: Command end result
[0m10:48:24.341166 [info ] [MainThread]: 
[0m10:48:24.342763 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:48:24.343946 [info ] [MainThread]: 
[0m10:48:24.345779 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:48:24.347715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9abc1e510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9ab8c55b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9ab95ec00>]}
[0m10:48:24.349415 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 10:54:05.910190 | 71e64672-22a2-4f06-9529-06bc4622fc2d ==============================
[0m10:54:05.910190 [info ] [MainThread]: Running with dbt=1.4.0
[0m10:54:05.912288 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['cus_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m10:54:05.912556 [debug] [MainThread]: Tracking: tracking
[0m10:54:05.912839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef01f572f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef281d9f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feefbb70080>]}
[0m10:54:05.957037 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:54:05.957493 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:54:05.967847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '71e64672-22a2-4f06-9529-06bc4622fc2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feefbce7c50>]}
[0m10:54:05.977054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '71e64672-22a2-4f06-9529-06bc4622fc2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feefbcb7050>]}
[0m10:54:05.977580 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m10:54:05.978036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '71e64672-22a2-4f06-9529-06bc4622fc2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef01f572f0>]}
[0m10:54:05.979728 [info ] [MainThread]: 
[0m10:54:05.982752 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m10:54:05.984591 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m10:54:06.018919 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m10:54:06.019424 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m10:54:06.019789 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:54:18.512560 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 12 seconds
[0m10:54:18.515093 [debug] [ThreadPool]: On list_GP: Close
[0m10:54:26.396194 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m10:54:26.404656 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m10:54:26.435907 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m10:54:26.447834 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m10:54:26.448881 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m10:54:26.449859 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m10:54:26.450833 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:54:26.451957 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:54:32.680187 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c0624e-0000-a67e-0000-eb0d00019eaa
[0m10:54:32.680852 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m10:54:32.681480 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m10:54:32.681891 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m10:54:32.682353 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m10:54:32.828278 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 6 seconds
[0m10:54:32.831347 [debug] [ThreadPool]: On list_GP_test: Close
[0m10:54:33.172204 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_mart'
[0m10:54:33.176341 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_mart"
[0m10:54:33.176852 [debug] [ThreadPool]: On list_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_mart"} */
show terse objects in GP.test_mart
[0m10:54:33.177251 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:54:50.124908 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c0624e-0000-a67e-0000-eb0d00019eba
[0m10:54:50.125599 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m10:54:50.126255 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m10:54:50.126596 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m10:54:50.127024 [debug] [ThreadPool]: On list_GP_test_mart: Close
[0m10:54:50.690042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '71e64672-22a2-4f06-9529-06bc4622fc2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feefaf5a210>]}
[0m10:54:50.691497 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m10:54:50.692140 [info ] [MainThread]: 
[0m10:54:50.726600 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.cus_orders
[0m10:54:50.727238 [info ] [Thread-1 (]: 1 of 1 START sql view model test.cus_orders .................................... [RUN]
[0m10:54:50.728067 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m10:54:50.728366 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m10:54:50.730231 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m10:54:50.730787 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-14 10:54:50.728540 => 2025-11-14 10:54:50.730679
[0m10:54:50.731094 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m10:54:50.770772 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.cus_orders"
[0m10:54:50.771950 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.cus_orders"
[0m10:54:50.772215 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.cus_orders"} */
create or replace   view GP.test.cus_orders
  
   as (
    with cus as(
    select customer_id,first_name,last_name, email 
    from CUSTOMERS 
    where status = 'active'
),
alls as(
    select 
    email,
    concat(first_name,' ',last_name),
    order_id,
    order_date,
    total_amount,
    shipping_address
    from ORDERS o join cus c on
    o.customer_id = c.customer_id 
)
select * from alls
  );
[0m10:54:50.772436 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:54:52.374349 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m10:54:52.398971 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-14 10:54:50.731268 => 2025-11-14 10:54:52.398882
[0m10:54:52.399346 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: Close
[0m10:55:52.376054 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '71e64672-22a2-4f06-9529-06bc4622fc2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feefafd7fe0>]}
[0m10:55:52.376859 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.cus_orders ............................... [[32mSUCCESS 1[0m in 61.65s]
[0m10:55:52.380376 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m10:55:52.383162 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m10:55:52.384193 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:55:52.384519 [debug] [MainThread]: Connection 'list_GP_test' was properly closed.
[0m10:55:52.384763 [debug] [MainThread]: Connection 'model.airflow_dbt_project.cus_orders' was properly closed.
[0m10:55:52.385151 [info ] [MainThread]: 
[0m10:55:52.385562 [info ] [MainThread]: Finished running 1 view model in 0 hours 1 minutes and 46.40 seconds (106.40s).
[0m10:55:52.386160 [debug] [MainThread]: Command end result
[0m10:55:52.395790 [info ] [MainThread]: 
[0m10:55:52.396471 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:55:52.396963 [info ] [MainThread]: 
[0m10:55:52.397376 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:55:52.397945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feefb1e6510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef001476e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feefbbb68a0>]}
[0m10:55:52.398386 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 10:57:48.793746 | 7a67c511-c299-46ce-9e89-9f4825473b50 ==============================
[0m10:57:48.793746 [info ] [MainThread]: Running with dbt=1.4.0
[0m10:57:48.795831 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m10:57:48.796104 [debug] [MainThread]: Tracking: tracking
[0m10:57:48.796365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1f66a2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1f66a2a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1f668c80>]}
[0m10:57:48.841701 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:57:48.842722 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/stg_customers.sql
[0m10:57:48.863774 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m10:57:48.901406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7a67c511-c299-46ce-9e89-9f4825473b50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1f668110>]}
[0m10:57:48.910881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7a67c511-c299-46ce-9e89-9f4825473b50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1f6ae510>]}
[0m10:57:48.911511 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m10:57:48.912059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a67c511-c299-46ce-9e89-9f4825473b50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1f9dc080>]}
[0m10:57:48.914082 [info ] [MainThread]: 
[0m10:57:48.917803 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m10:57:48.920170 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m10:57:48.951477 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m10:57:48.952015 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m10:57:48.952420 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:57:52.449382 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 3 seconds
[0m10:57:52.452536 [debug] [ThreadPool]: On list_GP: Close
[0m10:57:52.997993 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_test_staging'
[0m10:57:52.999068 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_test_staging'
[0m10:57:52.999586 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='test_staging', identifier=None)"
[0m10:57:53.008815 [debug] [ThreadPool]: Using snowflake connection "create_GP_test_staging"
[0m10:57:53.009344 [debug] [ThreadPool]: On create_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_test_staging"} */
create schema if not exists GP.test_staging
[0m10:57:53.009715 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:57:54.093545 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m10:57:54.095646 [debug] [ThreadPool]: On create_GP_test_staging: Close
[0m10:57:55.021047 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_mart'
[0m10:57:55.026128 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m10:57:55.043565 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m10:57:55.045111 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_mart"
[0m10:57:55.045582 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m10:57:55.046052 [debug] [ThreadPool]: On list_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_mart"} */
show terse objects in GP.test_mart
[0m10:57:55.046471 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:57:55.046871 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:57:56.234916 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m10:57:56.242309 [debug] [ThreadPool]: On list_GP_test: Close
[0m10:57:57.751185 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m10:57:57.758883 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m10:57:57.759440 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m10:57:57.759856 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:57:58.692927 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1 seconds
[0m10:57:58.696023 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m10:58:39.541705 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c06252-0000-a67d-0000-eb0d0001c576
[0m10:58:39.542238 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m10:58:39.542809 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m10:58:39.543125 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m10:58:39.543465 [debug] [ThreadPool]: On list_GP_test_mart: Close
[0m10:58:49.719013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a67c511-c299-46ce-9e89-9f4825473b50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1fb6f0e0>]}
[0m10:58:49.720414 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m10:58:49.721000 [info ] [MainThread]: 
[0m10:58:49.766945 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m10:58:49.767752 [info ] [Thread-1 (]: 1 of 1 START sql view model test_staging.stg_customers ......................... [RUN]
[0m10:58:49.768990 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m10:58:49.769415 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m10:58:49.774048 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m10:58:49.774995 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-14 10:58:49.769704 => 2025-11-14 10:58:49.774854
[0m10:58:49.775479 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m10:58:49.836887 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m10:58:49.837721 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m10:58:49.838005 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.test_staging.stg_customers
  
   as (
    
select * from customers
  );
[0m10:58:49.838210 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:58:52.301427 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c06252-0000-a67d-0000-eb0d0001c57e
[0m10:58:52.302007 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m10:58:52.302823 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-14 10:58:49.775783 => 2025-11-14 10:58:52.302650
[0m10:58:52.303260 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m10:58:52.808643 [debug] [Thread-1 (]: Database Error in model stg_customers (models/staging/stg_customers.sql)
  002003 (42S02): SQL compilation error:
  Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m10:58:52.809368 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a67c511-c299-46ce-9e89-9f4825473b50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1cc8bec0>]}
[0m10:58:52.810078 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test_staging.stg_customers ................ [[31mERROR[0m in 3.04s]
[0m10:58:52.812667 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m10:58:52.815416 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m10:58:52.816266 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:58:52.816572 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m10:58:52.816882 [debug] [MainThread]: Connection 'list_GP_test_staging' was properly closed.
[0m10:58:52.817340 [info ] [MainThread]: 
[0m10:58:52.817959 [info ] [MainThread]: Finished running 1 view model in 0 hours 1 minutes and 3.90 seconds (63.90s).
[0m10:58:52.818618 [debug] [MainThread]: Command end result
[0m10:58:52.830253 [info ] [MainThread]: 
[0m10:58:52.830926 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m10:58:52.831335 [info ] [MainThread]: 
[0m10:58:52.831812 [error] [MainThread]: [33mDatabase Error in model stg_customers (models/staging/stg_customers.sql)[0m
[0m10:58:52.832180 [error] [MainThread]:   002003 (42S02): SQL compilation error:
[0m10:58:52.832521 [error] [MainThread]:   Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m10:58:52.832981 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m10:58:52.833383 [info ] [MainThread]: 
[0m10:58:52.833788 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m10:58:52.834370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1cc774a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b254c7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b24127350>]}
[0m10:58:52.834885 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 11:00:47.646120 | 6cb58f8f-78bc-414c-a6a2-3e2d3a5a080c ==============================
[0m11:00:47.646120 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:00:47.656902 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:00:47.658151 [debug] [MainThread]: Tracking: tracking
[0m11:00:47.660996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d4be7df70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d4be7f830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d4be7f950>]}
[0m11:00:47.736972 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m11:00:47.738430 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/generate_schema_name.sql
[0m11:00:47.739404 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/stg_customers.sql
[0m11:00:47.746120 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m11:00:49.236744 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m11:00:49.256184 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:00:49.260127 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:00:49.264873 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m11:00:49.273218 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m11:00:49.276244 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m11:00:49.330715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6cb58f8f-78bc-414c-a6a2-3e2d3a5a080c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d77534080>]}
[0m11:00:49.339980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6cb58f8f-78bc-414c-a6a2-3e2d3a5a080c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d4bd1ba40>]}
[0m11:00:49.340477 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 305 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m11:00:49.340875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6cb58f8f-78bc-414c-a6a2-3e2d3a5a080c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d500f5eb0>]}
[0m11:00:49.342462 [info ] [MainThread]: 
[0m11:00:49.345363 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:00:49.347273 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:00:49.379246 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:00:49.379944 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:00:49.380462 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:00:52.463955 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m11:00:52.470982 [debug] [ThreadPool]: On list_GP: Close
[0m11:00:53.183872 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_staging  -- use only the custom schema'
[0m11:00:53.185880 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_staging  -- use only the custom schema'
[0m11:00:53.186859 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='staging  -- use only the custom schema', identifier=None)"
[0m11:00:53.205542 [debug] [ThreadPool]: Using snowflake connection "create_GP_staging  -- use only the custom schema"
[0m11:00:53.206708 [debug] [ThreadPool]: On create_GP_staging  -- use only the custom schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_staging  -- use only the custom schema"} */
create schema if not exists GP.staging  -- use only the custom schema
[0m11:00:53.207528 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:00:55.425332 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m11:00:55.432876 [debug] [ThreadPool]: On create_GP_staging  -- use only the custom schema: Close
[0m11:00:56.945885 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_staging  -- use only the custom schema'
[0m11:00:56.956675 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_mart  -- use only the custom schema'
[0m11:00:56.998963 [debug] [ThreadPool]: Using snowflake connection "list_GP_staging  -- use only the custom schema"
[0m11:00:57.007136 [debug] [ThreadPool]: On list_GP_staging  -- use only the custom schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_staging  -- use only the custom schema"} */
show terse objects in GP.staging  -- use only the custom schema
[0m11:00:57.010797 [debug] [ThreadPool]: Using snowflake connection "list_GP_mart  -- use only the custom schema"
[0m11:00:57.012098 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:00:57.013515 [debug] [ThreadPool]: On list_GP_mart  -- use only the custom schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_mart  -- use only the custom schema"} */
show terse objects in GP.mart  -- use only the custom schema
[0m11:00:57.020949 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:00:58.467511 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1 seconds
[0m11:00:58.472816 [debug] [ThreadPool]: On list_GP_staging  -- use only the custom schema: Close
[0m11:00:58.664271 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2 seconds
[0m11:00:58.667368 [debug] [ThreadPool]: On list_GP_mart  -- use only the custom schema: Close
[0m11:00:59.717878 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test   -- use default schema when none is provided'
[0m11:00:59.721264 [debug] [ThreadPool]: Using snowflake connection "list_GP_test   -- use default schema when none is provided"
[0m11:00:59.721823 [debug] [ThreadPool]: On list_GP_test   -- use default schema when none is provided: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test   -- use default schema when none is provided"} */
show terse objects in GP.test   -- use default schema when none is provided
[0m11:00:59.722214 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:01:01.274312 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m11:01:01.277577 [debug] [ThreadPool]: On list_GP_test   -- use default schema when none is provided: Close
[0m11:01:02.033998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6cb58f8f-78bc-414c-a6a2-3e2d3a5a080c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d4bb7ce60>]}
[0m11:01:02.035267 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:01:02.035839 [info ] [MainThread]: 
[0m11:01:02.079024 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m11:01:02.079825 [info ] [Thread-1 (]: 1 of 1 START sql view model staging  -- use only the custom schema.stg_customers  [RUN]
[0m11:01:02.081035 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m11:01:02.081504 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m11:01:02.083807 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m11:01:02.084572 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-14 11:01:02.081822 => 2025-11-14 11:01:02.084450
[0m11:01:02.085003 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m11:01:02.141360 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m11:01:02.142212 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m11:01:02.142489 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.staging  -- use only the custom schema.stg_customers
  
   as (
    select * from customers
  );
[0m11:01:02.142703 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:01:05.955131 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c06255-0000-a67d-0000-eb0d0001c596
[0m11:01:05.955547 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Schema 'GP.GP' does not exist or not authorized.
[0m11:01:05.956190 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-14 11:01:02.085398 => 2025-11-14 11:01:05.956080
[0m11:01:05.956554 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m11:01:06.902871 [debug] [Thread-1 (]: Database Error in model stg_customers (models/staging/stg_customers.sql)
  002003 (02000): SQL compilation error:
  Schema 'GP.GP' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m11:01:06.903587 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cb58f8f-78bc-414c-a6a2-3e2d3a5a080c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d49cfe960>]}
[0m11:01:06.904303 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model staging  -- use only the custom schema.stg_customers  [[31mERROR[0m in 4.82s]
[0m11:01:06.907360 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m11:01:06.910367 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:01:06.911520 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:01:06.912019 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m11:01:06.912400 [debug] [MainThread]: Connection 'list_GP_mart  -- use only the custom schema' was properly closed.
[0m11:01:06.912855 [info ] [MainThread]: 
[0m11:01:06.913508 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 17.57 seconds (17.57s).
[0m11:01:06.914377 [debug] [MainThread]: Command end result
[0m11:01:06.926186 [info ] [MainThread]: 
[0m11:01:06.927048 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:01:06.927698 [info ] [MainThread]: 
[0m11:01:06.928257 [error] [MainThread]: [33mDatabase Error in model stg_customers (models/staging/stg_customers.sql)[0m
[0m11:01:06.931133 [error] [MainThread]:   002003 (02000): SQL compilation error:
[0m11:01:06.932054 [error] [MainThread]:   Schema 'GP.GP' does not exist or not authorized.
[0m11:01:06.932953 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m11:01:06.933593 [info ] [MainThread]: 
[0m11:01:06.934959 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m11:01:06.937000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d707dc680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d5ffccbf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d4bb7ce60>]}
[0m11:01:06.938224 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 11:03:14.868593 | 1566ef2d-61b1-4212-b0b4-a7d8b20e3f10 ==============================
[0m11:03:14.868593 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:03:14.870905 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:03:14.871177 [debug] [MainThread]: Tracking: tracking
[0m11:03:14.871471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a587f6600>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a5ab7b170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a586cf590>]}
[0m11:03:14.918895 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:03:14.919708 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/generate_schema_name.sql
[0m11:03:14.922849 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m11:03:15.690083 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m11:03:15.711976 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:03:15.718369 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:03:15.724657 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m11:03:15.733978 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m11:03:15.736505 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m11:03:15.781319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1566ef2d-61b1-4212-b0b4-a7d8b20e3f10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a584a68a0>]}
[0m11:03:15.789345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1566ef2d-61b1-4212-b0b4-a7d8b20e3f10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a585f7e60>]}
[0m11:03:15.789797 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 305 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m11:03:15.790137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1566ef2d-61b1-4212-b0b4-a7d8b20e3f10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a5a0d3470>]}
[0m11:03:15.791586 [info ] [MainThread]: 
[0m11:03:15.794171 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:03:15.795680 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:03:15.824505 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:03:15.824953 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:03:15.825229 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:03:18.289649 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m11:03:18.293015 [debug] [ThreadPool]: On list_GP: Close
[0m11:03:19.059221 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_staging  -- use only the custom schema'
[0m11:03:19.060359 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_staging  -- use only the custom schema'
[0m11:03:19.060885 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='staging  -- use only the custom schema', identifier=None)"
[0m11:03:19.068899 [debug] [ThreadPool]: Using snowflake connection "create_GP_staging  -- use only the custom schema"
[0m11:03:19.069261 [debug] [ThreadPool]: On create_GP_staging  -- use only the custom schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_staging  -- use only the custom schema"} */
create schema if not exists GP.staging  -- use only the custom schema
[0m11:03:19.069527 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:03:20.856142 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m11:03:20.858781 [debug] [ThreadPool]: On create_GP_staging  -- use only the custom schema: Close
[0m11:03:22.580876 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_PUBLIC  -- use default schema when none is provided'
[0m11:03:22.592060 [debug] [ThreadPool]: Using snowflake connection "list_GP_PUBLIC  -- use default schema when none is provided"
[0m11:03:22.592472 [debug] [ThreadPool]: On list_GP_PUBLIC  -- use default schema when none is provided: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_PUBLIC  -- use default schema when none is provided"} */
show terse objects in GP.PUBLIC  -- use default schema when none is provided
[0m11:03:22.593353 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_mart  -- use only the custom schema'
[0m11:03:22.593828 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:03:22.596743 [debug] [ThreadPool]: Using snowflake connection "list_GP_mart  -- use only the custom schema"
[0m11:03:22.598330 [debug] [ThreadPool]: On list_GP_mart  -- use only the custom schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_mart  -- use only the custom schema"} */
show terse objects in GP.mart  -- use only the custom schema
[0m11:03:22.598672 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:03:23.846067 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1 seconds
[0m11:03:23.848933 [debug] [ThreadPool]: On list_GP_PUBLIC  -- use default schema when none is provided: Close
[0m11:03:24.348358 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_staging  -- use only the custom schema'
[0m11:03:24.351617 [debug] [ThreadPool]: Using snowflake connection "list_GP_staging  -- use only the custom schema"
[0m11:03:24.352040 [debug] [ThreadPool]: On list_GP_staging  -- use only the custom schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_staging  -- use only the custom schema"} */
show terse objects in GP.staging  -- use only the custom schema
[0m11:03:24.352354 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:03:24.737639 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2 seconds
[0m11:03:24.740283 [debug] [ThreadPool]: On list_GP_mart  -- use only the custom schema: Close
[0m11:03:26.095800 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2 seconds
[0m11:03:26.098050 [debug] [ThreadPool]: On list_GP_staging  -- use only the custom schema: Close
[0m11:03:26.578169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1566ef2d-61b1-4212-b0b4-a7d8b20e3f10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a80e80e90>]}
[0m11:03:26.579491 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:03:26.580039 [info ] [MainThread]: 
[0m11:03:26.624981 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m11:03:26.625887 [info ] [Thread-1 (]: 1 of 1 START sql view model staging  -- use only the custom schema.stg_customers  [RUN]
[0m11:03:26.627314 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m11:03:26.627828 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m11:03:26.630268 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m11:03:26.631094 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-14 11:03:26.628164 => 2025-11-14 11:03:26.630961
[0m11:03:26.631539 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m11:03:26.686713 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m11:03:26.687518 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m11:03:26.687805 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.staging  -- use only the custom schema.stg_customers
  
   as (
    select * from customers
  );
[0m11:03:26.688010 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:03:33.897527 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c06257-0000-a67e-0000-eb0d00019f42
[0m11:03:33.898118 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Schema 'GP.GP' does not exist or not authorized.
[0m11:03:33.899020 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-14 11:03:26.631852 => 2025-11-14 11:03:33.898863
[0m11:03:33.899436 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m11:03:34.635835 [debug] [Thread-1 (]: Database Error in model stg_customers (models/staging/stg_customers.sql)
  002003 (02000): SQL compilation error:
  Schema 'GP.GP' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m11:03:34.636585 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1566ef2d-61b1-4212-b0b4-a7d8b20e3f10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a585f70e0>]}
[0m11:03:34.637425 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model staging  -- use only the custom schema.stg_customers  [[31mERROR[0m in 8.01s]
[0m11:03:34.640896 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m11:03:34.644133 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:03:34.645271 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:03:34.645664 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m11:03:34.645996 [debug] [MainThread]: Connection 'list_GP_mart  -- use only the custom schema' was properly closed.
[0m11:03:34.646362 [info ] [MainThread]: 
[0m11:03:34.646911 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 18.85 seconds (18.85s).
[0m11:03:34.647627 [debug] [MainThread]: Command end result
[0m11:03:34.661143 [info ] [MainThread]: 
[0m11:03:34.662475 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:03:34.663528 [info ] [MainThread]: 
[0m11:03:34.664743 [error] [MainThread]: [33mDatabase Error in model stg_customers (models/staging/stg_customers.sql)[0m
[0m11:03:34.665603 [error] [MainThread]:   002003 (02000): SQL compilation error:
[0m11:03:34.666426 [error] [MainThread]:   Schema 'GP.GP' does not exist or not authorized.
[0m11:03:34.667520 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m11:03:34.669015 [info ] [MainThread]: 
[0m11:03:34.670020 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m11:03:34.671138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a80e80e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a58f7e9c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a5879c830>]}
[0m11:03:34.671916 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 11:04:39.719455 | e4163b62-8d85-445b-97b2-98d850aff710 ==============================
[0m11:04:39.719455 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:04:39.721557 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:04:39.721827 [debug] [MainThread]: Tracking: tracking
[0m11:04:39.722093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9727acc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9787d28a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc99dd9ef60>]}
[0m11:04:39.768288 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 0 files changed.
[0m11:04:39.768813 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://macros/generate_schema_name.sql
[0m11:04:39.769636 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m11:04:40.464076 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m11:04:40.479944 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:04:40.483370 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:04:40.486930 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m11:04:40.491503 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m11:04:40.492978 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m11:04:40.529064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e4163b62-8d85-445b-97b2-98d850aff710', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc97228bf50>]}
[0m11:04:40.537990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e4163b62-8d85-445b-97b2-98d850aff710', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9723cfa40>]}
[0m11:04:40.538449 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m11:04:40.538892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4163b62-8d85-445b-97b2-98d850aff710', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc972853440>]}
[0m11:04:40.540343 [info ] [MainThread]: 
[0m11:04:40.543189 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:04:40.544973 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:04:40.579234 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:04:40.579997 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:04:40.580671 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:04:43.677228 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m11:04:43.680340 [debug] [ThreadPool]: On list_GP: Close
[0m11:04:44.888727 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m11:04:44.890136 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_mart'
[0m11:04:44.912790 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m11:04:44.913357 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m11:04:44.913799 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:04:44.915625 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_mart"
[0m11:04:44.916073 [debug] [ThreadPool]: On list_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_mart"} */
show terse objects in GP.test_mart
[0m11:04:44.916348 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:04:46.885761 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c06258-0000-a67e-0000-eb0d00019f4e
[0m11:04:46.886436 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m11:04:46.887281 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m11:04:46.887814 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m11:04:46.888397 [debug] [ThreadPool]: On list_GP_test_mart: Close
[0m11:04:47.013567 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m11:04:47.016693 [debug] [ThreadPool]: On list_GP_test: Close
[0m11:04:47.673036 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m11:04:47.675315 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m11:04:47.675602 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m11:04:47.675817 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:04:48.809823 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1 seconds
[0m11:04:48.813013 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m11:04:49.255303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4163b62-8d85-445b-97b2-98d850aff710', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc970384620>]}
[0m11:04:49.256709 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:04:49.257215 [info ] [MainThread]: 
[0m11:04:49.304181 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m11:04:49.305600 [info ] [Thread-1 (]: 1 of 1 START sql view model test_staging.stg_customers ......................... [RUN]
[0m11:04:49.307267 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m11:04:49.307907 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m11:04:49.310418 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m11:04:49.311264 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-14 11:04:49.308239 => 2025-11-14 11:04:49.311145
[0m11:04:49.311666 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m11:04:49.368504 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m11:04:49.369459 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m11:04:49.369776 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.test_staging.stg_customers
  
   as (
    select * from customers
  );
[0m11:04:49.369999 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:05:54.186396 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c06259-0000-a67d-0000-eb0d0001c5b6
[0m11:05:54.186770 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m11:05:54.187163 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-14 11:04:49.311936 => 2025-11-14 11:05:54.187081
[0m11:05:54.187421 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m11:05:54.663709 [debug] [Thread-1 (]: Database Error in model stg_customers (models/staging/stg_customers.sql)
  002003 (42S02): SQL compilation error:
  Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m11:05:54.664470 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4163b62-8d85-445b-97b2-98d850aff710', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9703b5520>]}
[0m11:05:54.665317 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test_staging.stg_customers ................ [[31mERROR[0m in 65.36s]
[0m11:05:54.669437 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m11:05:54.672720 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:05:54.673982 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:05:54.674478 [debug] [MainThread]: Connection 'list_GP_test' was properly closed.
[0m11:05:54.674962 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m11:05:54.675536 [info ] [MainThread]: 
[0m11:05:54.676201 [info ] [MainThread]: Finished running 1 view model in 0 hours 1 minutes and 14.13 seconds (74.13s).
[0m11:05:54.676984 [debug] [MainThread]: Command end result
[0m11:05:54.690707 [info ] [MainThread]: 
[0m11:05:54.691868 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:05:54.692601 [info ] [MainThread]: 
[0m11:05:54.693280 [error] [MainThread]: [33mDatabase Error in model stg_customers (models/staging/stg_customers.sql)[0m
[0m11:05:54.693977 [error] [MainThread]:   002003 (42S02): SQL compilation error:
[0m11:05:54.694595 [error] [MainThread]:   Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m11:05:54.695237 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m11:05:54.695826 [info ] [MainThread]: 
[0m11:05:54.696477 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m11:05:54.697482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc97238db50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc97238d100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc97238d040>]}
[0m11:05:54.698472 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 11:06:54.730659 | 35249e7b-8d8b-48ae-9014-5507c340d5e8 ==============================
[0m11:06:54.730659 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:06:54.732780 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:06:54.733058 [debug] [MainThread]: Tracking: tracking
[0m11:06:54.733363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9d0fe9fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9d0f2f860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9d12a8fe0>]}
[0m11:06:54.759069 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:06:54.759965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '35249e7b-8d8b-48ae-9014-5507c340d5e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9d0c15010>]}
[0m11:06:55.546258 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m11:06:55.562216 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:06:55.566084 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:06:55.570791 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m11:06:55.576498 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m11:06:55.578335 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m11:06:55.619269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '35249e7b-8d8b-48ae-9014-5507c340d5e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9d1033680>]}
[0m11:06:55.627344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '35249e7b-8d8b-48ae-9014-5507c340d5e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9d1031430>]}
[0m11:06:55.627867 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m11:06:55.628260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35249e7b-8d8b-48ae-9014-5507c340d5e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9d18d1520>]}
[0m11:06:55.629838 [info ] [MainThread]: 
[0m11:06:55.632581 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:06:55.634340 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:06:55.662855 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:06:55.663369 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:06:55.663706 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:06:57.553721 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m11:06:57.556338 [debug] [ThreadPool]: On list_GP: Close
[0m11:06:58.082455 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m11:06:58.093561 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_mart'
[0m11:06:58.136156 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m11:06:58.142442 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m11:06:58.143637 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_mart"
[0m11:06:58.144346 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:06:58.145045 [debug] [ThreadPool]: On list_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_mart"} */
show terse objects in GP.test_mart
[0m11:06:58.148892 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:06:59.264914 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c0625a-0000-a67d-0000-eb0d0001c5be
[0m11:06:59.265419 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m11:06:59.265916 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m11:06:59.266176 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m11:06:59.266501 [debug] [ThreadPool]: On list_GP_test_mart: Close
[0m11:06:59.710785 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m11:06:59.714208 [debug] [ThreadPool]: On list_GP_test: Close
[0m11:06:59.750543 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m11:06:59.753912 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m11:06:59.754253 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m11:06:59.754511 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:07:01.824334 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2 seconds
[0m11:07:01.826416 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m11:07:02.376993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35249e7b-8d8b-48ae-9014-5507c340d5e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9d15f2ed0>]}
[0m11:07:02.378200 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:07:02.378726 [info ] [MainThread]: 
[0m11:07:02.429056 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m11:07:02.429941 [info ] [Thread-1 (]: 1 of 1 START sql view model test_staging.stg_customers ......................... [RUN]
[0m11:07:02.431376 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m11:07:02.432001 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m11:07:02.437184 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m11:07:02.438272 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-14 11:07:02.432370 => 2025-11-14 11:07:02.438092
[0m11:07:02.438844 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m11:07:02.508851 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m11:07:02.509960 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m11:07:02.510346 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.test_staging.stg_customers
  
   as (
    
select * from customers
  );
[0m11:07:02.510631 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:07:03.691795 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c0625b-0000-a67e-0000-eb0d00019f72
[0m11:07:03.692257 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m11:07:03.692814 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-14 11:07:02.439195 => 2025-11-14 11:07:03.692669
[0m11:07:03.693164 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m11:07:04.325265 [debug] [Thread-1 (]: Database Error in model stg_customers (models/staging/stg_customers.sql)
  002003 (42S02): SQL compilation error:
  Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m11:07:04.325953 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35249e7b-8d8b-48ae-9014-5507c340d5e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9cab63c50>]}
[0m11:07:04.326613 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test_staging.stg_customers ................ [[31mERROR[0m in 1.90s]
[0m11:07:04.329442 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m11:07:04.332420 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:07:04.333333 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:07:04.333644 [debug] [MainThread]: Connection 'list_GP_test' was properly closed.
[0m11:07:04.333895 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m11:07:04.334217 [info ] [MainThread]: 
[0m11:07:04.334615 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 8.70 seconds (8.70s).
[0m11:07:04.335235 [debug] [MainThread]: Command end result
[0m11:07:04.345550 [info ] [MainThread]: 
[0m11:07:04.346779 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:07:04.347459 [info ] [MainThread]: 
[0m11:07:04.348053 [error] [MainThread]: [33mDatabase Error in model stg_customers (models/staging/stg_customers.sql)[0m
[0m11:07:04.348579 [error] [MainThread]:   002003 (42S02): SQL compilation error:
[0m11:07:04.349121 [error] [MainThread]:   Object 'GP.TEST_STAGING.CUSTOMERS' does not exist or not authorized.
[0m11:07:04.349644 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m11:07:04.350215 [info ] [MainThread]: 
[0m11:07:04.350783 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m11:07:04.351721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9d0c62cf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9d0c62bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9d2847290>]}
[0m11:07:04.353011 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 11:12:24.015762 | a8d59926-ee78-4597-99be-f51c80abccbc ==============================
[0m11:12:24.015762 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:12:24.018658 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:12:24.019057 [debug] [MainThread]: Tracking: tracking
[0m11:12:24.019466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a3efa9c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a33179910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a331799a0>]}
[0m11:12:24.051672 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:12:24.052809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a8d59926-ee78-4597-99be-f51c80abccbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a310b18e0>]}
[0m11:12:24.060592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a30e3bef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a30d18fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a30d18f80>]}
[0m11:12:24.061235 [debug] [MainThread]: Flushing usage events
[0m11:12:27.056440 [error] [MainThread]: Encountered an error:
Compilation Error
  The yml property file at models/staging/sources.yml is invalid because the yml property file models/staging/sources.yml is missing a version tag. Please consult the documentation for more information on yml property file syntax:
  
  https://docs.getdbt.com/reference/configs-and-properties


============================== 2025-11-14 11:13:55.037388 | e3ad8bb0-cfa4-44a2-987b-6a3b20af7eca ==============================
[0m11:13:55.037388 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:13:55.039469 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:13:55.039757 [debug] [MainThread]: Tracking: tracking
[0m11:13:55.040039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d5bb51c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d61b8caa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d5ba3faa0>]}
[0m11:13:55.067457 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:13:55.068449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e3ad8bb0-cfa4-44a2-987b-6a3b20af7eca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d612f3e30>]}
[0m11:13:55.822337 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m11:13:55.838580 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:13:55.842161 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:13:55.846725 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m11:13:55.852669 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m11:13:55.854532 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m11:13:55.908728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e3ad8bb0-cfa4-44a2-987b-6a3b20af7eca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d5b73ab10>]}
[0m11:13:55.917098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e3ad8bb0-cfa4-44a2-987b-6a3b20af7eca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d5b73a270>]}
[0m11:13:55.917523 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 304 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
[0m11:13:55.917879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e3ad8bb0-cfa4-44a2-987b-6a3b20af7eca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d5b753020>]}
[0m11:13:55.919401 [info ] [MainThread]: 
[0m11:13:55.921924 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:13:55.923437 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:13:55.955598 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:13:55.956142 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:13:55.956483 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:14:02.037287 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 6 seconds
[0m11:14:02.046354 [debug] [ThreadPool]: On list_GP: Close
[0m11:14:02.929293 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m11:14:02.936112 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m11:14:02.950839 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m11:14:02.951211 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m11:14:02.951594 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:14:02.952191 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m11:14:02.953777 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m11:14:02.954021 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:14:04.640317 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m11:14:04.648737 [debug] [ThreadPool]: On list_GP_test: Close
[0m11:14:04.834061 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2 seconds
[0m11:14:04.836697 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m11:14:05.206408 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_mart'
[0m11:14:05.209839 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_mart"
[0m11:14:05.210201 [debug] [ThreadPool]: On list_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_mart"} */
show terse objects in GP.test_mart
[0m11:14:05.213455 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:14:06.254660 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c06262-0000-a67d-0000-eb0d0001c5d6
[0m11:14:06.255531 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m11:14:06.256533 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m11:14:06.257103 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m11:14:06.257891 [debug] [ThreadPool]: On list_GP_test_mart: Close
[0m11:14:06.912927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e3ad8bb0-cfa4-44a2-987b-6a3b20af7eca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d596f6ea0>]}
[0m11:14:06.917235 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:14:06.919157 [info ] [MainThread]: 
[0m11:14:07.014043 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m11:14:07.014898 [info ] [Thread-1 (]: 1 of 1 START sql view model test_staging.stg_customers ......................... [RUN]
[0m11:14:07.016171 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m11:14:07.016728 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m11:14:07.020884 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m11:14:07.021802 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-14 11:14:07.017018 => 2025-11-14 11:14:07.021621
[0m11:14:07.022404 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m11:14:07.075760 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m11:14:07.076664 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m11:14:07.076988 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.test_staging.stg_customers
  
   as (
    select * from GP.test.customers
  );
[0m11:14:07.077201 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:14:16.792482 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 10 seconds
[0m11:14:16.851476 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-14 11:14:07.022657 => 2025-11-14 11:14:16.851315
[0m11:14:16.852286 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m11:14:19.700835 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e3ad8bb0-cfa4-44a2-987b-6a3b20af7eca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d5b7395e0>]}
[0m11:14:19.701673 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test_staging.stg_customers .................... [[32mSUCCESS 1[0m in 12.69s]
[0m11:14:19.704825 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m11:14:19.708925 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:14:19.710337 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:14:19.710919 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m11:14:19.711268 [debug] [MainThread]: Connection 'list_GP_test_staging' was properly closed.
[0m11:14:19.711620 [info ] [MainThread]: 
[0m11:14:19.712151 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 23.79 seconds (23.79s).
[0m11:14:19.712839 [debug] [MainThread]: Command end result
[0m11:14:19.725165 [info ] [MainThread]: 
[0m11:14:19.726117 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:14:19.726808 [info ] [MainThread]: 
[0m11:14:19.727578 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:14:19.728800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d5b7539b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d60076420>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d5b8f3620>]}
[0m11:14:19.729579 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 11:15:44.134717 | 3adba185-ba59-4a28-ac06-07c6ce941b74 ==============================
[0m11:15:44.134717 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:15:44.137823 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:15:44.138328 [debug] [MainThread]: Tracking: tracking
[0m11:15:44.138859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f033f541c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f032f96f020>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0321f04350>]}
[0m11:15:44.194846 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m11:15:44.195607 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/generate_schema_name.sql
[0m11:15:44.199281 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m11:15:45.520388 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m11:15:45.559207 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:15:45.567859 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:15:45.577156 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m11:15:45.590649 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m11:15:45.595165 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m11:15:45.758180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3adba185-ba59-4a28-ac06-07c6ce941b74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0321c91280>]}
[0m11:15:45.781514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3adba185-ba59-4a28-ac06-07c6ce941b74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0321da3ec0>]}
[0m11:15:45.782964 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 305 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
[0m11:15:45.784203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3adba185-ba59-4a28-ac06-07c6ce941b74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03223d8d10>]}
[0m11:15:45.789300 [info ] [MainThread]: 
[0m11:15:45.796468 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:15:45.800513 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:15:45.896806 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:15:45.898777 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:15:45.900999 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:15:48.532333 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m11:15:48.535796 [debug] [ThreadPool]: On list_GP: Close
[0m11:15:49.159584 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_staging  -- use only the custom schema'
[0m11:15:49.160590 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_staging  -- use only the custom schema'
[0m11:15:49.161075 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='staging  -- use only the custom schema', identifier=None)"
[0m11:15:49.172190 [debug] [ThreadPool]: Using snowflake connection "create_GP_staging  -- use only the custom schema"
[0m11:15:49.172697 [debug] [ThreadPool]: On create_GP_staging  -- use only the custom schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_staging  -- use only the custom schema"} */
create schema if not exists GP.staging  -- use only the custom schema
[0m11:15:49.173019 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:15:50.723261 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m11:15:50.725111 [debug] [ThreadPool]: On create_GP_staging  -- use only the custom schema: Close
[0m11:15:51.529263 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test   -- use default schema when none is provided'
[0m11:15:51.538548 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_mart  -- use only the custom schema'
[0m11:15:51.556595 [debug] [ThreadPool]: Using snowflake connection "list_GP_test   -- use default schema when none is provided"
[0m11:15:51.557231 [debug] [ThreadPool]: On list_GP_test   -- use default schema when none is provided: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test   -- use default schema when none is provided"} */
show terse objects in GP.test   -- use default schema when none is provided
[0m11:15:51.557706 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:15:51.560169 [debug] [ThreadPool]: Using snowflake connection "list_GP_mart  -- use only the custom schema"
[0m11:15:51.561879 [debug] [ThreadPool]: On list_GP_mart  -- use only the custom schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_mart  -- use only the custom schema"} */
show terse objects in GP.mart  -- use only the custom schema
[0m11:15:51.562215 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:15:52.839420 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1 seconds
[0m11:15:52.842842 [debug] [ThreadPool]: On list_GP_test   -- use default schema when none is provided: Close
[0m11:15:52.845746 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1 seconds
[0m11:15:52.847927 [debug] [ThreadPool]: On list_GP_mart  -- use only the custom schema: Close
[0m11:15:53.841494 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_staging  -- use only the custom schema'
[0m11:15:53.845946 [debug] [ThreadPool]: Using snowflake connection "list_GP_staging  -- use only the custom schema"
[0m11:15:53.846346 [debug] [ThreadPool]: On list_GP_staging  -- use only the custom schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_staging  -- use only the custom schema"} */
show terse objects in GP.staging  -- use only the custom schema
[0m11:15:53.846638 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:15:55.541819 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2 seconds
[0m11:15:55.544842 [debug] [ThreadPool]: On list_GP_staging  -- use only the custom schema: Close
[0m11:15:56.071257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3adba185-ba59-4a28-ac06-07c6ce941b74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0321dd5af0>]}
[0m11:15:56.072166 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:15:56.072567 [info ] [MainThread]: 
[0m11:15:56.114768 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m11:15:56.115623 [info ] [Thread-1 (]: 1 of 1 START sql view model staging  -- use only the custom schema.stg_customers  [RUN]
[0m11:15:56.117040 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m11:15:56.117573 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m11:15:56.122784 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m11:15:56.123661 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-14 11:15:56.117954 => 2025-11-14 11:15:56.123528
[0m11:15:56.124098 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m11:15:56.188106 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m11:15:56.189164 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m11:15:56.189556 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.staging  -- use only the custom schema.stg_customers
  
   as (
    select * from GP.test.customers
  );
[0m11:15:56.189838 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:15:57.464077 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c06263-0000-a67e-0000-eb0d0001f022
[0m11:15:57.464567 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Schema 'GP.GP' does not exist or not authorized.
[0m11:15:57.465152 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-14 11:15:56.124337 => 2025-11-14 11:15:57.465043
[0m11:15:57.465454 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m11:15:58.002307 [debug] [Thread-1 (]: Database Error in model stg_customers (models/staging/stg_customers.sql)
  002003 (02000): SQL compilation error:
  Schema 'GP.GP' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m11:15:58.003080 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3adba185-ba59-4a28-ac06-07c6ce941b74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0321c68080>]}
[0m11:15:58.003862 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model staging  -- use only the custom schema.stg_customers  [[31mERROR[0m in 1.89s]
[0m11:15:58.007103 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m11:15:58.010215 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:15:58.011249 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:15:58.011615 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m11:15:58.011902 [debug] [MainThread]: Connection 'list_GP_mart  -- use only the custom schema' was properly closed.
[0m11:15:58.012216 [info ] [MainThread]: 
[0m11:15:58.012636 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 12.22 seconds (12.22s).
[0m11:15:58.013203 [debug] [MainThread]: Command end result
[0m11:15:58.025857 [info ] [MainThread]: 
[0m11:15:58.026878 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:15:58.027672 [info ] [MainThread]: 
[0m11:15:58.028475 [error] [MainThread]: [33mDatabase Error in model stg_customers (models/staging/stg_customers.sql)[0m
[0m11:15:58.029207 [error] [MainThread]:   002003 (02000): SQL compilation error:
[0m11:15:58.029971 [error] [MainThread]:   Schema 'GP.GP' does not exist or not authorized.
[0m11:15:58.030650 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m11:15:58.032207 [info ] [MainThread]: 
[0m11:15:58.033350 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m11:15:58.034949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0321d60140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f032389f2c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0321def200>]}
[0m11:15:58.035865 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 11:16:32.456286 | faa2b7f9-f8dd-42ad-a0d2-e991549de829 ==============================
[0m11:16:32.456286 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:16:32.458524 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:16:32.458842 [debug] [MainThread]: Tracking: tracking
[0m11:16:32.459175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23c5d92e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23b6a07f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23b6d234a0>]}
[0m11:16:32.506918 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:16:32.507696 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/generate_schema_name.sql
[0m11:16:32.510717 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m11:16:33.220368 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m11:16:33.235292 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:16:33.238399 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:16:33.241467 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m11:16:33.246385 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m11:16:33.248460 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m11:16:33.309123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'faa2b7f9-f8dd-42ad-a0d2-e991549de829', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23dc3c87d0>]}
[0m11:16:33.317608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'faa2b7f9-f8dd-42ad-a0d2-e991549de829', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23cfbfbd10>]}
[0m11:16:33.318046 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 305 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
[0m11:16:33.318364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'faa2b7f9-f8dd-42ad-a0d2-e991549de829', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23b74c1f70>]}
[0m11:16:33.319771 [info ] [MainThread]: 
[0m11:16:33.322238 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:16:33.323760 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:16:33.352655 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:16:33.353220 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:16:33.353557 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:16:36.554346 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m11:16:36.561295 [debug] [ThreadPool]: On list_GP: Close
[0m11:16:37.873603 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_staging  -- use only the custom schema'
[0m11:16:37.874825 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_staging  -- use only the custom schema'
[0m11:16:37.875389 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='staging  -- use only the custom schema', identifier=None)"
[0m11:16:37.884573 [debug] [ThreadPool]: Using snowflake connection "create_GP_staging  -- use only the custom schema"
[0m11:16:37.884944 [debug] [ThreadPool]: On create_GP_staging  -- use only the custom schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_staging  -- use only the custom schema"} */
create schema if not exists GP.staging  -- use only the custom schema
[0m11:16:37.885190 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:16:38.997738 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m11:16:38.999723 [debug] [ThreadPool]: On create_GP_staging  -- use only the custom schema: Close
[0m11:16:39.499018 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_staging  -- use only the custom schema'
[0m11:16:39.508183 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_mart  -- use only the custom schema'
[0m11:16:39.514749 [debug] [ThreadPool]: Using snowflake connection "list_GP_staging  -- use only the custom schema"
[0m11:16:39.519277 [debug] [ThreadPool]: Using snowflake connection "list_GP_mart  -- use only the custom schema"
[0m11:16:39.519926 [debug] [ThreadPool]: On list_GP_staging  -- use only the custom schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_staging  -- use only the custom schema"} */
show terse objects in GP.staging  -- use only the custom schema
[0m11:16:39.520528 [debug] [ThreadPool]: On list_GP_mart  -- use only the custom schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_mart  -- use only the custom schema"} */
show terse objects in GP.mart  -- use only the custom schema
[0m11:16:39.521269 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:16:39.521780 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:16:40.693861 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1 seconds
[0m11:16:40.695999 [debug] [ThreadPool]: On list_GP_staging  -- use only the custom schema: Close
[0m11:16:41.930763 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_public   -- use default schema when none is provided'
[0m11:16:41.933973 [debug] [ThreadPool]: Using snowflake connection "list_GP_public   -- use default schema when none is provided"
[0m11:16:41.934384 [debug] [ThreadPool]: On list_GP_public   -- use default schema when none is provided: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_public   -- use default schema when none is provided"} */
show terse objects in GP.public   -- use default schema when none is provided
[0m11:16:41.934724 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:16:42.156703 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 3 seconds
[0m11:16:42.159356 [debug] [ThreadPool]: On list_GP_mart  -- use only the custom schema: Close
[0m11:16:43.648819 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2 seconds
[0m11:16:43.651836 [debug] [ThreadPool]: On list_GP_public   -- use default schema when none is provided: Close
[0m11:16:44.141506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'faa2b7f9-f8dd-42ad-a0d2-e991549de829', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23b7257020>]}
[0m11:16:44.142923 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:16:44.143442 [info ] [MainThread]: 
[0m11:16:44.188807 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m11:16:44.189576 [info ] [Thread-1 (]: 1 of 1 START sql view model staging  -- use only the custom schema.stg_customers  [RUN]
[0m11:16:44.190870 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m11:16:44.191319 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m11:16:44.195463 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m11:16:44.196194 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-14 11:16:44.191622 => 2025-11-14 11:16:44.196082
[0m11:16:44.196549 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m11:16:44.251616 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m11:16:44.252488 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m11:16:44.252805 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.staging  -- use only the custom schema.stg_customers
  
   as (
    select * from GP.test.customers
  );
[0m11:16:44.253012 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:16:45.835609 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c06264-0000-a67d-0000-eb0d0001c64e
[0m11:16:45.836026 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Schema 'GP.GP' does not exist or not authorized.
[0m11:16:45.836529 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-14 11:16:44.196775 => 2025-11-14 11:16:45.836441
[0m11:16:45.836808 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m11:16:46.585819 [debug] [Thread-1 (]: Database Error in model stg_customers (models/staging/stg_customers.sql)
  002003 (02000): SQL compilation error:
  Schema 'GP.GP' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m11:16:46.586523 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'faa2b7f9-f8dd-42ad-a0d2-e991549de829', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23b4adf0e0>]}
[0m11:16:46.587265 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model staging  -- use only the custom schema.stg_customers  [[31mERROR[0m in 2.40s]
[0m11:16:46.590010 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m11:16:46.593413 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:16:46.594391 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:16:46.594723 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m11:16:46.594959 [debug] [MainThread]: Connection 'list_GP_mart  -- use only the custom schema' was properly closed.
[0m11:16:46.595239 [info ] [MainThread]: 
[0m11:16:46.595613 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 13.28 seconds (13.28s).
[0m11:16:46.596097 [debug] [MainThread]: Command end result
[0m11:16:46.607173 [info ] [MainThread]: 
[0m11:16:46.607948 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:16:46.608439 [info ] [MainThread]: 
[0m11:16:46.608999 [error] [MainThread]: [33mDatabase Error in model stg_customers (models/staging/stg_customers.sql)[0m
[0m11:16:46.609643 [error] [MainThread]:   002003 (02000): SQL compilation error:
[0m11:16:46.610231 [error] [MainThread]:   Schema 'GP.GP' does not exist or not authorized.
[0m11:16:46.610756 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/stg_customers.sql
[0m11:16:46.611342 [info ] [MainThread]: 
[0m11:16:46.612053 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m11:16:46.612883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23b7754770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23b67d23c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23b4ab3500>]}
[0m11:16:46.613715 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 11:22:16.781697 | c617f683-4d98-444c-a796-555bf5f29848 ==============================
[0m11:22:16.781697 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:22:16.784344 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:22:16.784704 [debug] [MainThread]: Tracking: tracking
[0m11:22:16.785046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc51e800140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc51e801460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc51e803da0>]}
[0m11:22:16.837144 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m11:22:16.837979 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/stg_customers.sql
[0m11:22:16.838512 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/generate_schema_name.sql
[0m11:22:16.842609 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m11:22:17.761712 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m11:22:17.781311 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:22:17.785537 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:22:17.789748 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m11:22:17.796266 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m11:22:17.798510 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m11:22:17.873299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c617f683-4d98-444c-a796-555bf5f29848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc51e5956a0>]}
[0m11:22:17.885002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c617f683-4d98-444c-a796-555bf5f29848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc51e847ec0>]}
[0m11:22:17.885621 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 305 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
[0m11:22:17.886151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c617f683-4d98-444c-a796-555bf5f29848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc524bc73b0>]}
[0m11:22:17.888367 [info ] [MainThread]: 
[0m11:22:17.891873 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:22:17.894336 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:22:17.930065 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:22:17.930596 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:22:17.930970 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:22:22.061419 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 4 seconds
[0m11:22:22.063476 [debug] [ThreadPool]: On list_GP: Close
[0m11:22:22.579538 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m11:22:22.588175 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_mart'
[0m11:22:22.606172 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m11:22:22.606740 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m11:22:22.607107 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:22:22.607862 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_mart"
[0m11:22:22.608376 [debug] [ThreadPool]: On list_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_mart"} */
show terse objects in GP.test_mart
[0m11:22:22.608777 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:22:25.464555 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c0626a-0000-a67d-0000-eb0d0001c66a
[0m11:22:25.465106 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m11:22:25.465633 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m11:22:25.465942 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m11:22:25.466311 [debug] [ThreadPool]: On list_GP_test_mart: Close
[0m11:22:26.647918 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m11:22:26.651137 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m11:22:26.651500 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m11:22:26.651782 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:22:28.755045 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m11:22:28.758750 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m11:22:31.793804 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 9 seconds
[0m11:22:31.797558 [debug] [ThreadPool]: On list_GP_test: Close
[0m11:22:32.751915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c617f683-4d98-444c-a796-555bf5f29848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc51e5a1550>]}
[0m11:22:32.757374 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:22:32.760250 [info ] [MainThread]: 
[0m11:22:32.865652 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m11:22:32.867382 [info ] [Thread-1 (]: 1 of 1 START sql view model test_staging.stg_customers ......................... [RUN]
[0m11:22:32.870438 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m11:22:32.871897 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m11:22:32.881941 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m11:22:32.883612 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-14 11:22:32.873012 => 2025-11-14 11:22:32.883357
[0m11:22:32.884540 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m11:22:33.021769 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m11:22:33.023852 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m11:22:33.024532 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.test_staging.stg_customers
  
   as (
    select * from GP.test.customers -- we write the source name (containing db & schema) then table
  );
[0m11:22:33.025092 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:22:37.766564 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 5 seconds
[0m11:22:37.802442 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-14 11:22:32.885128 => 2025-11-14 11:22:37.802340
[0m11:22:37.802860 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m11:22:38.561282 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c617f683-4d98-444c-a796-555bf5f29848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc51e515730>]}
[0m11:22:38.562132 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test_staging.stg_customers .................... [[32mSUCCESS 1[0m in 5.69s]
[0m11:22:38.565241 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m11:22:38.568241 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:22:38.569400 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:22:38.569844 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m11:22:38.570141 [debug] [MainThread]: Connection 'list_GP_test_staging' was properly closed.
[0m11:22:38.570494 [info ] [MainThread]: 
[0m11:22:38.571063 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 20.68 seconds (20.68s).
[0m11:22:38.571803 [debug] [MainThread]: Command end result
[0m11:22:38.584992 [info ] [MainThread]: 
[0m11:22:38.586555 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:22:38.587510 [info ] [MainThread]: 
[0m11:22:38.588210 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:22:38.589046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc51f1b7410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc51e5623c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc51e515730>]}
[0m11:22:38.589670 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 11:31:30.808435 | 57138959-4dca-4e1b-84da-85fdbafc95e5 ==============================
[0m11:31:30.808435 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:31:30.810522 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:31:30.810799 [debug] [MainThread]: Tracking: tracking
[0m11:31:30.811078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f699c955c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69b39a0aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f699c9abb00>]}
[0m11:31:30.859493 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m11:31:30.860240 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/generate_alias_name.sql
[0m11:31:30.860794 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/generate_schema_name.sql
[0m11:31:30.868765 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m11:31:31.600901 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m11:31:31.613095 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:31:31.616035 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:31:31.618863 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m11:31:31.623373 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m11:31:31.624867 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m11:31:31.672417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '57138959-4dca-4e1b-84da-85fdbafc95e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f699c619550>]}
[0m11:31:31.680061 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '57138959-4dca-4e1b-84da-85fdbafc95e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69c4f79430>]}
[0m11:31:31.680514 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
[0m11:31:31.680867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '57138959-4dca-4e1b-84da-85fdbafc95e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f699d1804a0>]}
[0m11:31:31.682325 [info ] [MainThread]: 
[0m11:31:31.684819 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:31:31.686274 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:31:31.714267 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:31:31.714853 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:31:31.715223 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:31:33.851546 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m11:31:33.854786 [debug] [ThreadPool]: On list_GP: Close
[0m11:31:34.428894 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- check if the target schema is different to dev to use itstaging'
[0m11:31:34.429780 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- check if the target schema is different to dev to use itstaging'
[0m11:31:34.430176 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- check if the target schema is different to dev to use itstaging', identifier=None)"
[0m11:31:34.439075 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- check if the target schema is different to dev to use itstaging"
[0m11:31:34.439483 [debug] [ThreadPool]: On create_GP_-- check if the target schema is different to dev to use itstaging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- check if the target schema is different to dev to use itstaging"} */
create schema if not exists GP.-- check if the target schema is different to dev to use itstaging
[0m11:31:34.439779 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:31:35.933774 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c06273-0000-a67e-0000-eb0d0001f06a
[0m11:31:35.934753 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 97 unexpected '<EOF>'.
[0m11:31:35.936008 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro create_schema
[0m11:31:35.936631 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m11:31:35.937227 [debug] [ThreadPool]: On create_GP_-- check if the target schema is different to dev to use itstaging: Close
[0m11:31:36.396024 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:31:36.396845 [debug] [MainThread]: Connection 'create_GP_-- check if the target schema is different to dev to use itstaging' was properly closed.
[0m11:31:36.397415 [info ] [MainThread]: 
[0m11:31:36.398238 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 4.71 seconds (4.71s).
[0m11:31:36.400235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f699c64abd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f699c64b2f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f699c64bd70>]}
[0m11:31:36.401276 [debug] [MainThread]: Flushing usage events
[0m11:31:40.415526 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m11:31:40.416601 [error] [MainThread]: Encountered an error:
Database Error
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 97 unexpected '<EOF>'.


============================== 2025-11-14 11:33:35.313094 | 96626caa-0f7b-4d37-a996-29f81b2e439e ==============================
[0m11:33:35.313094 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:33:35.317252 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:33:35.317696 [debug] [MainThread]: Tracking: tracking
[0m11:33:35.318152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27314a600>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe2821a0aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe272ad3aa0>]}
[0m11:33:35.393000 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:33:35.394033 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/stg_customers.sql
[0m11:33:35.425677 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:33:35.476900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '96626caa-0f7b-4d37-a996-29f81b2e439e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe272960560>]}
[0m11:33:35.493454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '96626caa-0f7b-4d37-a996-29f81b2e439e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe2729a63f0>]}
[0m11:33:35.494330 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
[0m11:33:35.495170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96626caa-0f7b-4d37-a996-29f81b2e439e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe272c7dfa0>]}
[0m11:33:35.498232 [info ] [MainThread]: 
[0m11:33:35.504305 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:33:35.506860 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:33:35.559130 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:33:35.560306 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:33:35.563661 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:33:45.592092 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 10 seconds
[0m11:33:45.596040 [debug] [ThreadPool]: On list_GP: Close
[0m11:33:46.110172 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- check if the target schema is different to dev to use itstaging'
[0m11:33:46.111173 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- check if the target schema is different to dev to use itstaging'
[0m11:33:46.111632 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- check if the target schema is different to dev to use itstaging', identifier=None)"
[0m11:33:46.119695 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- check if the target schema is different to dev to use itstaging"
[0m11:33:46.120135 [debug] [ThreadPool]: On create_GP_-- check if the target schema is different to dev to use itstaging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- check if the target schema is different to dev to use itstaging"} */
create schema if not exists GP.-- check if the target schema is different to dev to use itstaging
[0m11:33:46.120432 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:33:47.354301 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c06275-0000-a67e-0000-eb0d0001f076
[0m11:33:47.354791 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 97 unexpected '<EOF>'.
[0m11:33:47.355405 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro create_schema
[0m11:33:47.355735 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m11:33:47.356146 [debug] [ThreadPool]: On create_GP_-- check if the target schema is different to dev to use itstaging: Close
[0m11:33:47.955802 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:33:47.956278 [debug] [MainThread]: Connection 'create_GP_-- check if the target schema is different to dev to use itstaging' was properly closed.
[0m11:33:47.956618 [info ] [MainThread]: 
[0m11:33:47.957071 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 12.46 seconds (12.46s).
[0m11:33:47.957722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe2707c36b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe2707c3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe2707c3fb0>]}
[0m11:33:47.958185 [debug] [MainThread]: Flushing usage events
[0m11:33:50.255011 [error] [MainThread]: Encountered an error:
Database Error
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 97 unexpected '<EOF>'.


============================== 2025-11-14 11:34:37.797395 | cbdf5e0e-1a71-40a5-95a0-97b293f8edc1 ==============================
[0m11:34:37.797395 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:34:37.799878 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:34:37.800185 [debug] [MainThread]: Tracking: tracking
[0m11:34:37.800512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2773164140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2773166630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2773165e80>]}
[0m11:34:37.852509 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:34:37.853455 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/stg_customers.sql
[0m11:34:37.875741 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:34:37.913171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cbdf5e0e-1a71-40a5-95a0-97b293f8edc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2773b78b00>]}
[0m11:34:37.927809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cbdf5e0e-1a71-40a5-95a0-97b293f8edc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27731b9d90>]}
[0m11:34:37.928824 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
[0m11:34:37.929564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cbdf5e0e-1a71-40a5-95a0-97b293f8edc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f279e8213a0>]}
[0m11:34:37.932449 [info ] [MainThread]: 
[0m11:34:37.936659 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:34:37.939428 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:34:37.978837 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:34:37.979465 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:34:37.979987 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:34:40.826047 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m11:34:40.828604 [debug] [ThreadPool]: On list_GP: Close
[0m11:34:41.928076 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- check if the target schema is different to dev to use itstaging'
[0m11:34:41.929203 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- check if the target schema is different to dev to use itstaging'
[0m11:34:41.929667 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- check if the target schema is different to dev to use itstaging', identifier=None)"
[0m11:34:41.938176 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- check if the target schema is different to dev to use itstaging"
[0m11:34:41.938591 [debug] [ThreadPool]: On create_GP_-- check if the target schema is different to dev to use itstaging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- check if the target schema is different to dev to use itstaging"} */
create schema if not exists GP.-- check if the target schema is different to dev to use itstaging
[0m11:34:41.938917 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:34:44.477158 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c06276-0000-a67d-0000-eb0d0001c69a
[0m11:34:44.477616 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 97 unexpected '<EOF>'.
[0m11:34:44.478160 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro create_schema
[0m11:34:44.478459 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m11:34:44.478800 [debug] [ThreadPool]: On create_GP_-- check if the target schema is different to dev to use itstaging: Close
[0m11:34:45.318038 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:34:45.318517 [debug] [MainThread]: Connection 'create_GP_-- check if the target schema is different to dev to use itstaging' was properly closed.
[0m11:34:45.318912 [info ] [MainThread]: 
[0m11:34:45.319334 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 7.39 seconds (7.39s).
[0m11:34:45.320019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2773c5f110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2770fc3530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2770fc3b60>]}
[0m11:34:45.320493 [debug] [MainThread]: Flushing usage events
[0m11:34:46.173452 [error] [MainThread]: Encountered an error:
Database Error
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 97 unexpected '<EOF>'.


============================== 2025-11-14 11:38:35.635073 | 6c5974e9-29e3-414d-84d3-b89173ed454b ==============================
[0m11:38:35.635073 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:38:35.637630 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:38:35.637966 [debug] [MainThread]: Tracking: tracking
[0m11:38:35.638321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4079552570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4079550200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4079551cd0>]}
[0m11:38:35.689642 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 0 files changed.
[0m11:38:35.690201 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://macros/generate_alias_name.sql
[0m11:38:35.691064 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m11:38:36.396470 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m11:38:36.411139 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:38:36.414280 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:38:36.417273 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m11:38:36.422271 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m11:38:36.423835 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m11:38:36.472728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6c5974e9-29e3-414d-84d3-b89173ed454b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40792e1550>]}
[0m11:38:36.481464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6c5974e9-29e3-414d-84d3-b89173ed454b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40795a7e90>]}
[0m11:38:36.481912 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 305 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
[0m11:38:36.482250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c5974e9-29e3-414d-84d3-b89173ed454b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40799874a0>]}
[0m11:38:36.483717 [info ] [MainThread]: 
[0m11:38:36.486190 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:38:36.487706 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:38:36.513983 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:38:36.514578 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:38:36.514978 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:38:38.607234 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m11:38:38.610510 [debug] [ThreadPool]: On list_GP: Close
[0m11:38:40.266249 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- check if the target schema is different to dev to use itstaging'
[0m11:38:40.267385 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- check if the target schema is different to dev to use itstaging'
[0m11:38:40.267866 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- check if the target schema is different to dev to use itstaging', identifier=None)"
[0m11:38:40.277126 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- check if the target schema is different to dev to use itstaging"
[0m11:38:40.277510 [debug] [ThreadPool]: On create_GP_-- check if the target schema is different to dev to use itstaging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- check if the target schema is different to dev to use itstaging"} */
create schema if not exists GP.-- check if the target schema is different to dev to use itstaging
[0m11:38:40.277797 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:38:41.519224 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c0627a-0000-a67e-0000-eb0d0001f086
[0m11:38:41.519845 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 97 unexpected '<EOF>'.
[0m11:38:41.520529 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro create_schema
[0m11:38:41.521020 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m11:38:41.521363 [debug] [ThreadPool]: On create_GP_-- check if the target schema is different to dev to use itstaging: Close
[0m11:38:42.036968 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:38:42.037292 [debug] [MainThread]: Connection 'create_GP_-- check if the target schema is different to dev to use itstaging' was properly closed.
[0m11:38:42.037526 [info ] [MainThread]: 
[0m11:38:42.037846 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 5.55 seconds (5.55s).
[0m11:38:42.038273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f406b1a6a80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f406b1a71a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f406b1a71d0>]}
[0m11:38:42.038600 [debug] [MainThread]: Flushing usage events
[0m11:38:43.206885 [error] [MainThread]: Encountered an error:
Database Error
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 97 unexpected '<EOF>'.


============================== 2025-11-14 11:39:02.571458 | 33bcef9e-8d29-4403-84cc-f5e9f93a556c ==============================
[0m11:39:02.571458 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:39:02.574285 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:39:02.574660 [debug] [MainThread]: Tracking: tracking
[0m11:39:02.575052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cd9af8650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cd808b920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cb08305c0>]}
[0m11:39:02.628045 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:39:02.628895 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/generate_schema_name.sql
[0m11:39:02.632994 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m11:39:03.501915 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m11:39:03.519869 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:39:03.523817 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:39:03.527620 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m11:39:03.533257 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m11:39:03.535159 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m11:39:03.611252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '33bcef9e-8d29-4403-84cc-f5e9f93a556c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cb0862480>]}
[0m11:39:03.622178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '33bcef9e-8d29-4403-84cc-f5e9f93a556c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cb06d3fb0>]}
[0m11:39:03.622833 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 305 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
[0m11:39:03.623344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '33bcef9e-8d29-4403-84cc-f5e9f93a556c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cb135b470>]}
[0m11:39:03.625765 [info ] [MainThread]: 
[0m11:39:03.629584 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:39:03.631679 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:39:03.664671 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:39:03.665251 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:39:03.665623 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:39:06.497615 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m11:39:06.500762 [debug] [ThreadPool]: On list_GP: Close
[0m11:39:07.265556 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_mart'
[0m11:39:07.274427 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m11:39:07.280191 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_mart"
[0m11:39:07.282976 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m11:39:07.283809 [debug] [ThreadPool]: On list_GP_test_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_mart"} */
show terse objects in GP.test_mart
[0m11:39:07.284318 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m11:39:07.284843 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:39:07.285278 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:39:08.795703 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c0627b-0000-a67d-0000-eb0d0001c6ae
[0m11:39:08.796215 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m11:39:08.796799 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m11:39:08.797122 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m11:39:08.797500 [debug] [ThreadPool]: On list_GP_test_mart: Close
[0m11:39:09.062523 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m11:39:09.065787 [debug] [ThreadPool]: On list_GP_test: Close
[0m11:39:09.943009 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test_staging'
[0m11:39:09.946471 [debug] [ThreadPool]: Using snowflake connection "list_GP_test_staging"
[0m11:39:09.946920 [debug] [ThreadPool]: On list_GP_test_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test_staging"} */
show terse objects in GP.test_staging
[0m11:39:09.947337 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:39:11.484216 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m11:39:11.487627 [debug] [ThreadPool]: On list_GP_test_staging: Close
[0m11:39:12.368024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '33bcef9e-8d29-4403-84cc-f5e9f93a556c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cb1062f60>]}
[0m11:39:12.369178 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:39:12.369633 [info ] [MainThread]: 
[0m11:39:12.415992 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m11:39:12.416866 [info ] [Thread-1 (]: 1 of 1 START sql view model test_staging.stg_customers ......................... [RUN]
[0m11:39:12.418168 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m11:39:12.418591 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m11:39:12.422845 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m11:39:12.423611 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-14 11:39:12.418868 => 2025-11-14 11:39:12.423495
[0m11:39:12.424208 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m11:39:12.511357 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m11:39:12.513770 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m11:39:12.514608 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.test_staging.stg_customers
  
   as (
    select * from GP.test.customers
  );
[0m11:39:12.515243 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:39:14.208217 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m11:39:14.239539 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-14 11:39:12.424533 => 2025-11-14 11:39:14.239453
[0m11:39:14.239914 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m11:39:14.981701 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33bcef9e-8d29-4403-84cc-f5e9f93a556c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cb05fb080>]}
[0m11:39:14.983472 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test_staging.stg_customers .................... [[32mSUCCESS 1[0m in 2.56s]
[0m11:39:14.989612 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m11:39:14.995714 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:39:14.998024 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:39:14.998808 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m11:39:14.999378 [debug] [MainThread]: Connection 'list_GP_test' was properly closed.
[0m11:39:15.000213 [info ] [MainThread]: 
[0m11:39:15.001444 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 11.37 seconds (11.37s).
[0m11:39:15.003057 [debug] [MainThread]: Command end result
[0m11:39:15.027615 [info ] [MainThread]: 
[0m11:39:15.029551 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:39:15.030960 [info ] [MainThread]: 
[0m11:39:15.032208 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:39:15.033610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cb1062f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cb0830e00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cb05734d0>]}
[0m11:39:15.034732 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 11:42:16.689412 | 4d596be3-62f1-4dc1-8f03-1d472a7532b3 ==============================
[0m11:42:16.689412 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:42:16.691538 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:42:16.691819 [debug] [MainThread]: Tracking: tracking
[0m11:42:16.692110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ab13e8080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ab13eae70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ab13ea4b0>]}
[0m11:42:16.749449 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:42:16.750417 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/generate_schema_name.sql
[0m11:42:16.754679 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m11:42:17.489627 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m11:42:17.502924 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:42:17.505827 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:42:17.508562 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m11:42:17.512819 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m11:42:17.514265 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m11:42:17.571909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4d596be3-62f1-4dc1-8f03-1d472a7532b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ab215a540>]}
[0m11:42:17.582406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4d596be3-62f1-4dc1-8f03-1d472a7532b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ab1313f80>]}
[0m11:42:17.582966 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 305 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
[0m11:42:17.583367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4d596be3-62f1-4dc1-8f03-1d472a7532b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ad1dc16a0>]}
[0m11:42:17.585064 [info ] [MainThread]: 
[0m11:42:17.587931 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:42:17.589439 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:42:17.618615 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:42:17.619191 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:42:17.619551 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:42:19.370127 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m11:42:19.377020 [debug] [ThreadPool]: On list_GP: Close
[0m11:42:20.054730 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_mart'
[0m11:42:20.064385 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_staging'
[0m11:42:20.079705 [debug] [ThreadPool]: Using snowflake connection "list_GP_staging"
[0m11:42:20.080217 [debug] [ThreadPool]: On list_GP_staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_staging"} */
show terse objects in GP.staging
[0m11:42:20.080550 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:42:20.083528 [debug] [ThreadPool]: Using snowflake connection "list_GP_mart"
[0m11:42:20.084015 [debug] [ThreadPool]: On list_GP_mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_mart"} */
show terse objects in GP.mart
[0m11:42:20.084328 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:42:21.337400 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1 seconds
[0m11:42:21.340726 [debug] [ThreadPool]: On list_GP_mart: Close
[0m11:42:22.090745 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_test'
[0m11:42:22.094965 [debug] [ThreadPool]: Using snowflake connection "list_GP_test"
[0m11:42:22.095456 [debug] [ThreadPool]: On list_GP_test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_test"} */
show terse objects in GP.test
[0m11:42:22.095786 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:42:22.886936 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 3 seconds
[0m11:42:22.890099 [debug] [ThreadPool]: On list_GP_staging: Close
[0m11:42:24.794323 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 3 seconds
[0m11:42:24.797593 [debug] [ThreadPool]: On list_GP_test: Close
[0m11:42:25.503997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4d596be3-62f1-4dc1-8f03-1d472a7532b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ad9566960>]}
[0m11:42:25.505154 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:42:25.505619 [info ] [MainThread]: 
[0m11:42:25.550009 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m11:42:25.550819 [info ] [Thread-1 (]: 1 of 1 START sql view model staging.stg_customers .............................. [RUN]
[0m11:42:25.552116 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m11:42:25.552596 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m11:42:25.557168 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m11:42:25.557874 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-14 11:42:25.552924 => 2025-11-14 11:42:25.557767
[0m11:42:25.558248 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m11:42:25.659965 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m11:42:25.661793 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m11:42:25.662316 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.staging.stg_customers
  
   as (
    select * from GP.test.customers
  );
[0m11:42:25.662755 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:42:27.025880 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:42:27.053754 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-14 11:42:25.558472 => 2025-11-14 11:42:27.053642
[0m11:42:27.054160 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m11:42:27.807451 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d596be3-62f1-4dc1-8f03-1d472a7532b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5aab99ec00>]}
[0m11:42:27.808310 [info ] [Thread-1 (]: 1 of 1 OK created sql view model staging.stg_customers ......................... [[32mSUCCESS 1[0m in 2.26s]
[0m11:42:27.811462 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m11:42:27.814479 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:42:27.815561 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:42:27.815959 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m11:42:27.816285 [debug] [MainThread]: Connection 'list_GP_staging' was properly closed.
[0m11:42:27.816667 [info ] [MainThread]: 
[0m11:42:27.817165 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 10.23 seconds (10.23s).
[0m11:42:27.817810 [debug] [MainThread]: Command end result
[0m11:42:27.828834 [info ] [MainThread]: 
[0m11:42:27.829529 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:42:27.830047 [info ] [MainThread]: 
[0m11:42:27.830514 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:42:27.831639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ab37a48f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ab1358950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ad9566960>]}
[0m11:42:27.832412 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 11:48:52.203938 | e7fa7c5a-7ff6-4ca5-8370-83fefc496e5e ==============================
[0m11:48:52.203938 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:48:52.206660 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:48:52.207032 [debug] [MainThread]: Tracking: tracking
[0m11:48:52.207408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f21ab96a750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f21b0ee31a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f21ab10a030>]}
[0m11:48:52.257192 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m11:48:52.257918 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/sources.yml
[0m11:48:52.258409 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m11:48:52.258815 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/generate_schema_name.sql
[0m11:48:52.262552 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m11:48:52.986595 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m11:48:53.000169 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m11:48:53.003284 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m11:48:53.006654 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m11:48:53.011698 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m11:48:53.013455 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m11:48:53.061986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e7fa7c5a-7ff6-4ca5-8370-83fefc496e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f21abb14620>]}
[0m11:48:53.070120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e7fa7c5a-7ff6-4ca5-8370-83fefc496e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f21ab14fda0>]}
[0m11:48:53.070558 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 305 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
[0m11:48:53.070886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e7fa7c5a-7ff6-4ca5-8370-83fefc496e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f21d83bc5f0>]}
[0m11:48:53.072314 [info ] [MainThread]: 
[0m11:48:53.074794 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:48:53.076332 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:48:53.106115 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:48:53.106624 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:48:53.106996 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:48:55.308291 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m11:48:55.311690 [debug] [ThreadPool]: On list_GP: Close
[0m11:48:55.926469 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m11:48:55.927460 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m11:48:55.927904 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart', identifier=None)"
[0m11:48:55.937156 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m11:48:55.937527 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m11:48:55.937808 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:49:04.319897 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 8 seconds
[0m11:49:04.321757 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m11:49:05.006949 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m11:49:05.018856 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m11:49:05.019267 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m11:49:05.020247 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m11:49:05.020715 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:49:05.023875 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m11:49:05.025459 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m11:49:05.026560 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:49:06.945116 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2 seconds
[0m11:49:06.947714 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m11:49:08.414573 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 3 seconds
[0m11:49:08.418264 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m11:49:09.090773 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m11:49:09.094080 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m11:49:09.094527 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m11:49:09.094919 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:49:17.098561 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 8 seconds
[0m11:49:17.106970 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m11:49:19.401704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e7fa7c5a-7ff6-4ca5-8370-83fefc496e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f21a8f9bcb0>]}
[0m11:49:19.404534 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:49:19.405463 [info ] [MainThread]: 
[0m11:49:19.482572 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_customers
[0m11:49:19.484588 [info ] [Thread-1 (]: 1 of 1 START sql table model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  [RUN]
[0m11:49:19.487957 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_customers'
[0m11:49:19.489086 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_customers
[0m11:49:19.501755 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_customers"
[0m11:49:19.503840 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (compile): 2025-11-14 11:49:19.489736 => 2025-11-14 11:49:19.503427
[0m11:49:19.505255 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_customers
[0m11:49:19.669465 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_customers"
[0m11:49:19.672087 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_customers"
[0m11:49:19.673005 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_customers"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  as
        (select * 
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where  signup_date> (select max('date') from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers )
        );
[0m11:49:19.673554 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:49:21.238757 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c06285-0000-a67e-0000-eb0d0001f11e
[0m11:49:21.239267 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'GP.MART.DIM_CUSTOMERS' does not exist or not authorized.
[0m11:49:21.239862 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (execute): 2025-11-14 11:49:19.506095 => 2025-11-14 11:49:21.239748
[0m11:49:21.240196 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: Close
[0m11:49:22.042202 [debug] [Thread-1 (]: Database Error in model dim_customers (models/marts/core/dim_customers.sql)
  002003 (42S02): SQL compilation error:
  Object 'GP.MART.DIM_CUSTOMERS' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/marts/core/dim_customers.sql
[0m11:49:22.043098 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7fa7c5a-7ff6-4ca5-8370-83fefc496e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f21aafdbc20>]}
[0m11:49:22.044022 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  [[31mERROR[0m in 2.56s]
[0m11:49:22.047800 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_customers
[0m11:49:22.051313 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:49:22.052536 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:49:22.053007 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_customers' was properly closed.
[0m11:49:22.053335 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test' was properly closed.
[0m11:49:22.053753 [info ] [MainThread]: 
[0m11:49:22.054272 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 28.98 seconds (28.98s).
[0m11:49:22.055061 [debug] [MainThread]: Command end result
[0m11:49:22.069743 [info ] [MainThread]: 
[0m11:49:22.070743 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:49:22.071461 [info ] [MainThread]: 
[0m11:49:22.072153 [error] [MainThread]: [33mDatabase Error in model dim_customers (models/marts/core/dim_customers.sql)[0m
[0m11:49:22.072863 [error] [MainThread]:   002003 (42S02): SQL compilation error:
[0m11:49:22.073552 [error] [MainThread]:   Object 'GP.MART.DIM_CUSTOMERS' does not exist or not authorized.
[0m11:49:22.074141 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/marts/core/dim_customers.sql
[0m11:49:22.074851 [info ] [MainThread]: 
[0m11:49:22.075516 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m11:49:22.076434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f21aae48470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f21aae48530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f21a8f9bda0>]}
[0m11:49:22.077193 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 12:19:48.821467 | 987ed2df-2c39-47da-bdf1-c44aa16b5799 ==============================
[0m12:19:48.821467 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:19:48.823434 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m12:19:48.823670 [debug] [MainThread]: Tracking: tracking
[0m12:19:48.823941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f99e091f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f9a254f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f99b469c0>]}
[0m12:19:48.873227 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m12:19:48.873941 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/core/sources.yml
[0m12:19:48.874436 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m12:19:48.892432 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m12:19:48.919565 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m12:19:48.953607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '987ed2df-2c39-47da-bdf1-c44aa16b5799', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f9996a450>]}
[0m12:19:48.963254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '987ed2df-2c39-47da-bdf1-c44aa16b5799', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f99b99c10>]}
[0m12:19:48.963779 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 305 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m12:19:48.964166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '987ed2df-2c39-47da-bdf1-c44aa16b5799', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f99edd580>]}
[0m12:19:48.965825 [info ] [MainThread]: 
[0m12:19:48.968673 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:19:48.970575 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m12:19:49.010573 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m12:19:49.011186 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m12:19:49.011650 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:19:50.698023 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m12:19:50.703818 [debug] [ThreadPool]: On list_GP: Close
[0m12:19:51.158027 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:19:51.159123 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:19:51.159764 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart', identifier=None)"
[0m12:19:51.170822 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m12:19:51.171387 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m12:19:51.171793 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:19:52.093402 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:19:52.096047 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m12:19:52.582856 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:19:52.584582 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m12:19:52.602798 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:19:52.606571 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m12:19:52.607242 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:19:52.607933 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m12:19:52.608548 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:19:52.609224 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:19:53.700674 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:19:53.703979 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:19:54.076485 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:19:54.079878 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m12:19:54.080361 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m12:19:54.084004 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:19:55.029195 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:19:55.032103 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m12:20:13.378142 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 21 seconds
[0m12:20:13.380701 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m12:20:13.809923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '987ed2df-2c39-47da-bdf1-c44aa16b5799', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f99b79250>]}
[0m12:20:13.811220 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:20:13.811708 [info ] [MainThread]: 
[0m12:20:13.853395 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_customers
[0m12:20:13.854421 [info ] [Thread-1 (]: 1 of 1 START sql table model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  [RUN]
[0m12:20:13.856421 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_customers'
[0m12:20:13.857188 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_customers
[0m12:20:13.864224 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_customers"
[0m12:20:13.865157 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (compile): 2025-11-14 12:20:13.857600 => 2025-11-14 12:20:13.865009
[0m12:20:13.865597 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_customers
[0m12:20:13.923132 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_customers"
[0m12:20:13.924724 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_customers"
[0m12:20:13.925052 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_customers"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  as
        (with staging as(
    select *
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
    
)
merge into GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers as target 
using staging source using
ON target.emp_id = source.emp_id
WHEN MATCHED AND (target.email <> source.email OR target.phone <> source.phone) THEN
    UPDATE SET target.phone = source.phone,
               target.email = source.email;
[0m12:20:13.925275 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:20:19.215855 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c062a4-0000-a67e-0000-eb0d0001f3ee
[0m12:20:19.216335 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 11 at position 0 unexpected 'merge'.
syntax error line 15 at position 3 unexpected 'target'.
[0m12:20:19.216880 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (execute): 2025-11-14 12:20:13.865881 => 2025-11-14 12:20:19.216778
[0m12:20:19.217190 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: Close
[0m12:20:19.836049 [debug] [Thread-1 (]: Database Error in model dim_customers (models/marts/core/dim_customers.sql)
  001003 (42000): SQL compilation error:
  syntax error line 11 at position 0 unexpected 'merge'.
  syntax error line 15 at position 3 unexpected 'target'.
  compiled Code at target/run/airflow_dbt_project/models/marts/core/dim_customers.sql
[0m12:20:19.836761 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '987ed2df-2c39-47da-bdf1-c44aa16b5799', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f99016d50>]}
[0m12:20:19.837509 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  [[31mERROR[0m in 5.98s]
[0m12:20:19.840499 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_customers
[0m12:20:19.843177 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:20:19.844113 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:20:19.844434 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart' was properly closed.
[0m12:20:19.844680 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_customers' was properly closed.
[0m12:20:19.845010 [info ] [MainThread]: 
[0m12:20:19.845421 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 30.88 seconds (30.88s).
[0m12:20:19.845997 [debug] [MainThread]: Command end result
[0m12:20:19.857578 [info ] [MainThread]: 
[0m12:20:19.858354 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m12:20:19.858928 [info ] [MainThread]: 
[0m12:20:19.859419 [error] [MainThread]: [33mDatabase Error in model dim_customers (models/marts/core/dim_customers.sql)[0m
[0m12:20:19.859922 [error] [MainThread]:   001003 (42000): SQL compilation error:
[0m12:20:19.860312 [error] [MainThread]:   syntax error line 11 at position 0 unexpected 'merge'.
[0m12:20:19.860679 [error] [MainThread]:   syntax error line 15 at position 3 unexpected 'target'.
[0m12:20:19.861141 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/marts/core/dim_customers.sql
[0m12:20:19.861530 [info ] [MainThread]: 
[0m12:20:19.861950 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m12:20:19.862511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f99844770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f99847ec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f99b79250>]}
[0m12:20:19.862999 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 12:21:08.389079 | 97ca4b60-9110-4aa6-aba4-30fcd69fca0d ==============================
[0m12:21:08.389079 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:21:08.391285 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m12:21:08.391725 [debug] [MainThread]: Tracking: tracking
[0m12:21:08.392124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc873aa3200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc873ad38f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc873e8b890>]}
[0m12:21:08.438663 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:21:08.439454 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m12:21:08.457569 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m12:21:08.486523 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m12:21:08.502465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97ca4b60-9110-4aa6-aba4-30fcd69fca0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc873786600>]}
[0m12:21:08.512122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '97ca4b60-9110-4aa6-aba4-30fcd69fca0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8739a6990>]}
[0m12:21:08.512648 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 305 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m12:21:08.513056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '97ca4b60-9110-4aa6-aba4-30fcd69fca0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc879c156d0>]}
[0m12:21:08.514747 [info ] [MainThread]: 
[0m12:21:08.517608 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:21:08.519351 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m12:21:08.553288 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m12:21:08.554057 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m12:21:08.554555 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:21:10.961311 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m12:21:10.964627 [debug] [ThreadPool]: On list_GP: Close
[0m12:21:12.426535 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:21:12.427454 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:21:12.427898 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart', identifier=None)"
[0m12:21:12.435544 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m12:21:12.435962 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m12:21:12.436295 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:21:13.352777 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:21:13.355176 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m12:21:13.757454 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m12:21:13.767101 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:21:13.786418 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m12:21:13.788186 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:21:13.788913 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m12:21:13.789606 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:21:13.790485 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:21:13.791162 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:21:14.848005 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1 seconds
[0m12:21:14.851760 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m12:21:14.903550 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:21:14.906113 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:21:15.336933 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:21:15.342722 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m12:21:15.344838 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m12:21:15.345307 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:21:16.410886 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:21:16.413317 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m12:21:16.836912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '97ca4b60-9110-4aa6-aba4-30fcd69fca0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc87374d4f0>]}
[0m12:21:16.838054 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:21:16.838500 [info ] [MainThread]: 
[0m12:21:16.886013 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_customers
[0m12:21:16.886996 [info ] [Thread-1 (]: 1 of 1 START sql table model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  [RUN]
[0m12:21:16.888617 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_customers'
[0m12:21:16.889332 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_customers
[0m12:21:16.897007 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_customers"
[0m12:21:16.898203 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (compile): 2025-11-14 12:21:16.889783 => 2025-11-14 12:21:16.898023
[0m12:21:16.898959 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_customers
[0m12:21:16.960080 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_customers"
[0m12:21:16.961354 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_customers"
[0m12:21:16.961630 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_customers"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  as
        (with staging as(
    select *
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
    
)
merge into GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers as target 
using staging AS source using
ON target.emp_id = source.emp_id
WHEN MATCHED AND (target.email <> source.email OR target.phone <> source.phone) THEN
    UPDATE SET target.phone = source.phone,
               target.email = source.email;
[0m12:21:16.961834 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:21:18.080948 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c062a5-0000-a67e-0000-eb0d0001f3fe
[0m12:21:18.081441 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 11 at position 0 unexpected 'merge'.
syntax error line 15 at position 3 unexpected 'target'.
[0m12:21:18.081978 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (execute): 2025-11-14 12:21:16.899420 => 2025-11-14 12:21:18.081874
[0m12:21:18.082290 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: Close
[0m12:21:18.534976 [debug] [Thread-1 (]: Database Error in model dim_customers (models/marts/core/dim_customers.sql)
  001003 (42000): SQL compilation error:
  syntax error line 11 at position 0 unexpected 'merge'.
  syntax error line 15 at position 3 unexpected 'target'.
  compiled Code at target/run/airflow_dbt_project/models/marts/core/dim_customers.sql
[0m12:21:18.535554 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97ca4b60-9110-4aa6-aba4-30fcd69fca0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc872df1b20>]}
[0m12:21:18.536115 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  [[31mERROR[0m in 1.65s]
[0m12:21:18.538372 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_customers
[0m12:21:18.540659 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:21:18.541585 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:21:18.541956 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_customers' was properly closed.
[0m12:21:18.542251 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m12:21:18.542662 [info ] [MainThread]: 
[0m12:21:18.543257 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 10.03 seconds (10.03s).
[0m12:21:18.543923 [debug] [MainThread]: Command end result
[0m12:21:18.556222 [info ] [MainThread]: 
[0m12:21:18.556935 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m12:21:18.557396 [info ] [MainThread]: 
[0m12:21:18.557877 [error] [MainThread]: [33mDatabase Error in model dim_customers (models/marts/core/dim_customers.sql)[0m
[0m12:21:18.558330 [error] [MainThread]:   001003 (42000): SQL compilation error:
[0m12:21:18.558773 [error] [MainThread]:   syntax error line 11 at position 0 unexpected 'merge'.
[0m12:21:18.559222 [error] [MainThread]:   syntax error line 15 at position 3 unexpected 'target'.
[0m12:21:18.559667 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/marts/core/dim_customers.sql
[0m12:21:18.560162 [info ] [MainThread]: 
[0m12:21:18.560640 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m12:21:18.561377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc87374d4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc87374d2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc872e544a0>]}
[0m12:21:18.562029 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 12:27:44.662235 | e2fe9f0b-17f1-4d52-b065-c5462815a9f5 ==============================
[0m12:27:44.662235 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:27:44.664954 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m12:27:44.665441 [debug] [MainThread]: Tracking: tracking
[0m12:27:44.665922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb310d171d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e9602360>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e9600a10>]}
[0m12:27:44.719373 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m12:27:44.720215 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/generate_schema_name.sql
[0m12:27:44.720802 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m12:27:44.724732 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m12:27:45.515520 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m12:27:45.529407 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m12:27:45.532482 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m12:27:45.535519 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m12:27:45.545729 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m12:27:45.547343 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m12:27:45.601578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e2fe9f0b-17f1-4d52-b065-c5462815a9f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e936bfe0>]}
[0m12:27:45.613264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e2fe9f0b-17f1-4d52-b065-c5462815a9f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e938ab40>]}
[0m12:27:45.614021 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 305 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m12:27:45.614628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e2fe9f0b-17f1-4d52-b065-c5462815a9f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2ea09a8a0>]}
[0m12:27:45.618404 [info ] [MainThread]: 
[0m12:27:45.624966 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:27:45.628276 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m12:27:45.663203 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m12:27:45.663662 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m12:27:45.664040 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:27:48.165717 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 3 seconds
[0m12:27:48.169037 [debug] [ThreadPool]: On list_GP: Close
[0m12:27:48.711585 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:27:48.712739 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:27:48.713244 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart', identifier=None)"
[0m12:27:48.721630 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m12:27:48.722056 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m12:27:48.722420 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:28:02.826571 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 14 seconds
[0m12:28:02.827818 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m12:28:03.454301 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:28:03.461617 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:28:03.464411 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m12:28:03.467345 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:28:03.467899 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m12:28:03.468406 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:28:03.468859 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:28:03.469388 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:04.763359 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:28:04.765750 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:28:05.328504 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m12:28:05.330868 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m12:28:05.331231 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m12:28:05.331529 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:28:06.170847 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 3 seconds
[0m12:28:06.173664 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m12:28:06.414243 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1 seconds
[0m12:28:06.416297 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m12:28:06.834277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e2fe9f0b-17f1-4d52-b065-c5462815a9f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e9345eb0>]}
[0m12:28:06.835495 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:28:06.836122 [info ] [MainThread]: 
[0m12:28:06.897259 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_customers
[0m12:28:06.898579 [info ] [Thread-1 (]: 1 of 1 START sql table model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  [RUN]
[0m12:28:06.900664 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_customers'
[0m12:28:06.901450 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_customers
[0m12:28:06.911796 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_customers"
[0m12:28:06.913337 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (compile): 2025-11-14 12:28:06.901935 => 2025-11-14 12:28:06.913099
[0m12:28:06.914224 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_customers
[0m12:28:06.997437 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_customers"
[0m12:28:06.999607 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_customers"
[0m12:28:07.000091 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_customers"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  as
        (with staging as(
    select *
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
    
)
merge into GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers as target 
using staging AS source 
ON target.emp_id = source.emp_id
WHEN MATCHED AND (target.email <> source.email OR target.phone <> source.phone) THEN
    UPDATE SET target.phone = source.phone,
               target.email = source.email;
[0m12:28:07.000418 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:28:08.245390 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c062ac-0000-a67d-0000-eb0d0001ca62
[0m12:28:08.245869 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 11 at position 0 unexpected 'merge'.
syntax error line 15 at position 3 unexpected 'target'.
[0m12:28:08.246406 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (execute): 2025-11-14 12:28:06.914817 => 2025-11-14 12:28:08.246304
[0m12:28:08.246732 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: Close
[0m12:28:08.828088 [debug] [Thread-1 (]: Database Error in model dim_customers (models/marts/core/dim_customers.sql)
  001003 (42000): SQL compilation error:
  syntax error line 11 at position 0 unexpected 'merge'.
  syntax error line 15 at position 3 unexpected 'target'.
  compiled Code at target/run/airflow_dbt_project/models/marts/core/dim_customers.sql
[0m12:28:08.829767 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e2fe9f0b-17f1-4d52-b065-c5462815a9f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e80e9be0>]}
[0m12:28:08.832049 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  [[31mERROR[0m in 1.93s]
[0m12:28:08.837453 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_customers
[0m12:28:08.842799 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:28:08.845585 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:28:08.846511 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart' was properly closed.
[0m12:28:08.847280 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_customers' was properly closed.
[0m12:28:08.848142 [info ] [MainThread]: 
[0m12:28:08.849114 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 23.23 seconds (23.23s).
[0m12:28:08.851596 [debug] [MainThread]: Command end result
[0m12:28:08.886315 [info ] [MainThread]: 
[0m12:28:08.887254 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m12:28:08.888146 [info ] [MainThread]: 
[0m12:28:08.888921 [error] [MainThread]: [33mDatabase Error in model dim_customers (models/marts/core/dim_customers.sql)[0m
[0m12:28:08.889753 [error] [MainThread]:   001003 (42000): SQL compilation error:
[0m12:28:08.890668 [error] [MainThread]:   syntax error line 11 at position 0 unexpected 'merge'.
[0m12:28:08.891417 [error] [MainThread]:   syntax error line 15 at position 3 unexpected 'target'.
[0m12:28:08.892243 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/marts/core/dim_customers.sql
[0m12:28:08.893213 [info ] [MainThread]: 
[0m12:28:08.894432 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m12:28:08.896135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e99f7650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2ca939e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2ca93b1d0>]}
[0m12:28:08.897153 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 12:29:29.234157 | 5dfffb27-be60-4c14-8dc4-cc86c75d50cb ==============================
[0m12:29:29.234157 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:29:29.236162 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m12:29:29.236399 [debug] [MainThread]: Tracking: tracking
[0m12:29:29.236664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06725ee7b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06725edd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06725ef8c0>]}
[0m12:29:29.284171 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:29:29.284962 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m12:29:29.302558 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m12:29:29.330606 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m12:29:29.346568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5dfffb27-be60-4c14-8dc4-cc86c75d50cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06724a6e70>]}
[0m12:29:29.357313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5dfffb27-be60-4c14-8dc4-cc86c75d50cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0672642360>]}
[0m12:29:29.357884 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 305 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m12:29:29.358323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5dfffb27-be60-4c14-8dc4-cc86c75d50cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0672b192e0>]}
[0m12:29:29.360215 [info ] [MainThread]: 
[0m12:29:29.363657 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:29:29.365634 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m12:29:29.396586 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m12:29:29.397147 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m12:29:29.397514 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:29:32.598557 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 3 seconds
[0m12:29:32.600769 [debug] [ThreadPool]: On list_GP: Close
[0m12:29:33.237621 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:29:33.238664 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:29:33.239149 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart', identifier=None)"
[0m12:29:33.248253 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m12:29:33.248758 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m12:29:33.249103 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:29:36.947163 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 4 seconds
[0m12:29:36.949803 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m12:29:37.677639 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:29:37.688356 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m12:29:37.688761 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m12:29:37.689804 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:29:37.690217 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:29:37.693169 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:29:37.694710 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:29:37.695014 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:29:38.700758 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:29:38.704175 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:29:38.795675 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:29:38.799088 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m12:29:39.142199 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m12:29:39.145256 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m12:29:39.145665 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m12:29:39.145982 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:29:42.877994 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 4 seconds
[0m12:29:42.884636 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m12:29:45.477928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5dfffb27-be60-4c14-8dc4-cc86c75d50cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06726b94c0>]}
[0m12:29:45.481028 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:29:45.482583 [info ] [MainThread]: 
[0m12:29:45.554388 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_customers
[0m12:29:45.555935 [info ] [Thread-1 (]: 1 of 1 START sql table model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  [RUN]
[0m12:29:45.558763 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_customers'
[0m12:29:45.559967 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_customers
[0m12:29:45.569047 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_customers"
[0m12:29:45.570530 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (compile): 2025-11-14 12:29:45.560552 => 2025-11-14 12:29:45.570241
[0m12:29:45.571410 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_customers
[0m12:29:45.673887 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_customers"
[0m12:29:45.676050 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_customers"
[0m12:29:45.676706 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_customers"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  as
        (-- with staging as(
--     select *
--     from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
--     
-- )
merge into GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers as target 
using GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers AS source 
ON target.CUSTOMER_ID = source.CUSTOMER_ID
WHEN MATCHED AND (target.email <> source.email OR target.phone <> source.phone) THEN
    UPDATE SET target.phone = source.phone,
               target.email = source.email;
[0m12:29:45.677206 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:29:50.706411 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c062ad-0000-a67e-0000-eb0d0001f446
[0m12:29:50.706781 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 8 at position 8 unexpected 'staging'.
syntax error line 17 at position 3 unexpected 'target'.
[0m12:29:50.707225 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (execute): 2025-11-14 12:29:45.572063 => 2025-11-14 12:29:50.707138
[0m12:29:50.707471 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: Close
[0m12:29:51.575665 [debug] [Thread-1 (]: Database Error in model dim_customers (models/marts/core/dim_customers.sql)
  001003 (42000): SQL compilation error:
  syntax error line 8 at position 8 unexpected 'staging'.
  syntax error line 17 at position 3 unexpected 'target'.
  compiled Code at target/run/airflow_dbt_project/models/marts/core/dim_customers.sql
[0m12:29:51.576578 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5dfffb27-be60-4c14-8dc4-cc86c75d50cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0671a7dd00>]}
[0m12:29:51.577526 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  [[31mERROR[0m in 6.02s]
[0m12:29:51.582100 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_customers
[0m12:29:51.585638 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:29:51.586921 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:29:51.587389 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart' was properly closed.
[0m12:29:51.587801 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_customers' was properly closed.
[0m12:29:51.588342 [info ] [MainThread]: 
[0m12:29:51.588975 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 22.23 seconds (22.23s).
[0m12:29:51.589841 [debug] [MainThread]: Command end result
[0m12:29:51.601795 [info ] [MainThread]: 
[0m12:29:51.602788 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m12:29:51.603517 [info ] [MainThread]: 
[0m12:29:51.604534 [error] [MainThread]: [33mDatabase Error in model dim_customers (models/marts/core/dim_customers.sql)[0m
[0m12:29:51.605632 [error] [MainThread]:   001003 (42000): SQL compilation error:
[0m12:29:51.606241 [error] [MainThread]:   syntax error line 8 at position 8 unexpected 'staging'.
[0m12:29:51.606787 [error] [MainThread]:   syntax error line 17 at position 3 unexpected 'target'.
[0m12:29:51.607305 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/marts/core/dim_customers.sql
[0m12:29:51.608379 [info ] [MainThread]: 
[0m12:29:51.609617 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m12:29:51.611147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06723a4950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0696ff4320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06729f24b0>]}
[0m12:29:51.612004 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 12:35:01.569697 | 180de385-3081-453c-bc1e-02d1ae4f5c95 ==============================
[0m12:35:01.569697 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:35:01.572629 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'macro': 'merge_dim_customers', 'args': '{}', 'which': 'run-operation', 'rpc_method': 'run-operation', 'indirect_selection': 'eager'}
[0m12:35:01.573025 [debug] [MainThread]: Tracking: tracking
[0m12:35:01.573390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd87bf49fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd87a12fe90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd879c132f0>]}
[0m12:35:01.607130 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m12:35:01.608407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '180de385-3081-453c-bc1e-02d1ae4f5c95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd879a9da60>]}
[0m12:35:02.418636 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m12:35:02.432920 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m12:35:02.435765 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m12:35:02.438593 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m12:35:02.443408 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m12:35:02.444879 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m12:35:02.494863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '180de385-3081-453c-bc1e-02d1ae4f5c95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd879de67e0>]}
[0m12:35:02.502306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '180de385-3081-453c-bc1e-02d1ae4f5c95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd879e5db20>]}
[0m12:35:02.505430 [debug] [MainThread]: Acquiring new snowflake connection 'macro_merge_dim_customers'
[0m12:35:02.509941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd879a627b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd879a62780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd879a60800>]}
[0m12:35:02.510350 [debug] [MainThread]: Flushing usage events
[0m12:35:03.701506 [debug] [MainThread]: Connection 'macro_merge_dim_customers' was properly closed.


============================== 2025-11-14 12:38:47.863515 | da6c5f6a-08b2-4abe-998f-377e8c9fbea2 ==============================
[0m12:38:47.863515 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:38:47.866157 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'macro': 'merge_dim_customers', 'args': '{}', 'which': 'run-operation', 'rpc_method': 'run-operation', 'indirect_selection': 'eager'}
[0m12:38:47.866466 [debug] [MainThread]: Tracking: tracking
[0m12:38:47.866921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a8d022090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a8d022bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a8d0204a0>]}
[0m12:38:47.898172 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m12:38:47.898949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'da6c5f6a-08b2-4abe-998f-377e8c9fbea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab4709b20>]}
[0m12:38:48.850215 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m12:38:48.872876 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m12:38:48.877779 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m12:38:48.881997 [debug] [MainThread]: 1603: static parser failed on marts/core/dim_customers.sql
[0m12:38:48.888828 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/core/dim_customers.sql
[0m12:38:48.890787 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m12:38:48.963767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'da6c5f6a-08b2-4abe-998f-377e8c9fbea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a8cf7a2d0>]}
[0m12:38:48.972466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da6c5f6a-08b2-4abe-998f-377e8c9fbea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a8cfa02c0>]}
[0m12:38:48.975622 [debug] [MainThread]: Acquiring new snowflake connection 'macro_merge_dim_customers'
[0m12:38:48.980448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a8cee06b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a8cee0620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a8cee0c50>]}
[0m12:38:48.980911 [debug] [MainThread]: Flushing usage events
[0m12:38:50.636555 [debug] [MainThread]: Connection 'macro_merge_dim_customers' was properly closed.


============================== 2025-11-14 12:47:14.149029 | 3abef1da-bdb0-400a-aa80-e43d03c1c1d1 ==============================
[0m12:47:14.149029 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:47:14.151081 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'macro': 'merge_dim_customers', 'args': '{}', 'which': 'run-operation', 'rpc_method': 'run-operation', 'indirect_selection': 'eager'}
[0m12:47:14.151328 [debug] [MainThread]: Tracking: tracking
[0m12:47:14.151618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f304d46c1a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f304dd8ee70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f304d81ec30>]}
[0m12:47:14.205149 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m12:47:14.206061 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/core/sources.yml
[0m12:47:14.206626 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m12:47:14.227472 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/dim_customers.sql
[0m12:47:14.271515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f304cb245f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f304cb24500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f304cb24950>]}
[0m12:47:14.272159 [debug] [MainThread]: Flushing usage events
[0m12:47:19.726842 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.airflow_dbt_project.dim_customers' (models/marts/core/dim_customers.sql) depends on a source named 'my_mart.dim_cusomters' which was not found


============================== 2025-11-14 12:48:02.050946 | f33dea78-d8fa-48e0-9d4f-b92864e19225 ==============================
[0m12:48:02.050946 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:48:02.053569 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'macro': 'merge_dim_customers', 'args': '{}', 'which': 'run-operation', 'rpc_method': 'run-operation', 'indirect_selection': 'eager'}
[0m12:48:02.053893 [debug] [MainThread]: Tracking: tracking
[0m12:48:02.054224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de3ab84a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de9967230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de36c2120>]}
[0m12:48:02.108740 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m12:48:02.109630 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/core/sources.yml
[0m12:48:02.110218 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m12:48:02.131135 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/dim_customers.sql
[0m12:48:02.190029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f33dea78-d8fa-48e0-9d4f-b92864e19225', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de3677f50>]}
[0m12:48:02.198639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f33dea78-d8fa-48e0-9d4f-b92864e19225', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de9967c50>]}
[0m12:48:02.201776 [debug] [MainThread]: Acquiring new snowflake connection 'macro_merge_dim_customers'
[0m12:48:02.206565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de366ae70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de366aed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de366aa20>]}
[0m12:48:02.207027 [debug] [MainThread]: Flushing usage events
[0m12:48:10.036521 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m12:48:10.037040 [debug] [MainThread]: Connection 'macro_merge_dim_customers' was properly closed.


============================== 2025-11-14 12:53:23.610031 | 75b7f7be-d101-471b-940e-e41944e33ab7 ==============================
[0m12:53:23.610031 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:53:23.616133 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m12:53:23.617238 [debug] [MainThread]: Tracking: tracking
[0m12:53:23.617977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd13b54ee70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd13b54f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd13bd24fe0>]}
[0m12:53:23.687299 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:53:23.688090 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m12:53:23.710382 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/dim_customers.sql
[0m12:53:23.749155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '75b7f7be-d101-471b-940e-e41944e33ab7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd13ac65670>]}
[0m12:53:23.759761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '75b7f7be-d101-471b-940e-e41944e33ab7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd13adf6270>]}
[0m12:53:23.760372 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m12:53:23.760879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '75b7f7be-d101-471b-940e-e41944e33ab7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd13ad87560>]}
[0m12:53:23.762850 [info ] [MainThread]: 
[0m12:53:23.766330 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:53:23.768587 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m12:53:23.807152 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m12:53:23.807654 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m12:53:23.808019 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:53:27.342929 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 4 seconds
[0m12:53:27.346277 [debug] [ThreadPool]: On list_GP: Close
[0m12:53:28.013620 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:53:28.014845 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:53:28.015395 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging', identifier=None)"
[0m12:53:28.024044 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:53:28.024555 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:53:28.025006 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:53:29.129189 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:53:29.131732 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:53:29.585067 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:53:29.596577 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:53:29.611451 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m12:53:29.617515 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m12:53:29.623628 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:53:29.622998 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:53:29.627418 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:53:29.628249 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:53:30.670822 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:53:30.678876 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:53:31.137363 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m12:53:31.147001 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m12:53:31.328078 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m12:53:31.334012 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m12:53:31.334395 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m12:53:31.334695 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:53:32.583952 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1 seconds
[0m12:53:32.589944 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m12:53:33.074747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '75b7f7be-d101-471b-940e-e41944e33ab7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd138a14770>]}
[0m12:53:33.076104 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:53:33.076712 [info ] [MainThread]: 
[0m12:53:33.118805 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m12:53:33.119480 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers  [RUN]
[0m12:53:33.120558 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m12:53:33.120950 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m12:53:33.125414 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m12:53:33.126347 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-14 12:53:33.121182 => 2025-11-14 12:53:33.126208
[0m12:53:33.126812 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m12:53:33.183441 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_customers"
[0m12:53:33.184466 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_customers"
[0m12:53:33.184825 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_customers"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
  
   as (
    select * from GP.test.customers
  );
[0m12:53:33.185083 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:53:34.581434 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:53:34.604590 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-14 12:53:33.127072 => 2025-11-14 12:53:34.604496
[0m12:53:34.604982 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_customers: Close
[0m12:53:35.170027 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75b7f7be-d101-471b-940e-e41944e33ab7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd138a782f0>]}
[0m12:53:35.170883 [info ] [Thread-1 (]: 1 of 1 OK created sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers  [[32mSUCCESS 1[0m in 2.05s]
[0m12:53:35.174650 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m12:53:35.177471 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:53:35.178461 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:53:35.178819 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart' was properly closed.
[0m12:53:35.179077 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m12:53:35.179435 [info ] [MainThread]: 
[0m12:53:35.179915 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 11.42 seconds (11.42s).
[0m12:53:35.180501 [debug] [MainThread]: Command end result
[0m12:53:35.192201 [info ] [MainThread]: 
[0m12:53:35.193072 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:53:35.193538 [info ] [MainThread]: 
[0m12:53:35.194108 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m12:53:35.194837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd13adb0470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd13adf6690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd13adf6210>]}
[0m12:53:35.195260 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 12:54:03.136828 | afb0f571-8b20-41a2-b33c-8b90dd87d43c ==============================
[0m12:54:03.136828 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:54:03.140183 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m12:54:03.140583 [debug] [MainThread]: Tracking: tracking
[0m12:54:03.141027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd23278bb00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd206efcbf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd206efeea0>]}
[0m12:54:03.203285 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:54:03.203773 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:54:03.215656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'afb0f571-8b20-41a2-b33c-8b90dd87d43c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd206efc740>]}
[0m12:54:03.227346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'afb0f571-8b20-41a2-b33c-8b90dd87d43c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd22afd04d0>]}
[0m12:54:03.227984 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m12:54:03.228465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'afb0f571-8b20-41a2-b33c-8b90dd87d43c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd20cbc3a70>]}
[0m12:54:03.230551 [info ] [MainThread]: 
[0m12:54:03.234166 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:54:03.236498 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m12:54:03.273920 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m12:54:03.274475 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m12:54:03.274871 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:54:05.841634 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 3 seconds
[0m12:54:05.844869 [debug] [ThreadPool]: On list_GP: Close
[0m12:54:06.465580 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:54:06.466429 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:54:06.466857 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart', identifier=None)"
[0m12:54:06.474592 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m12:54:06.475025 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m12:54:06.475325 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:54:07.631375 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:54:07.634380 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m12:54:08.152380 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m12:54:08.158442 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:54:08.176119 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m12:54:08.176702 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m12:54:08.177560 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:54:08.182579 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:54:08.183213 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:54:08.185438 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:54:09.405446 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:54:09.408518 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:54:09.522713 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:54:09.525947 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m12:54:09.952584 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m12:54:09.962033 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m12:54:09.962576 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m12:54:09.962986 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:54:11.114838 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1 seconds
[0m12:54:11.118953 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m12:54:11.595558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'afb0f571-8b20-41a2-b33c-8b90dd87d43c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd20640dbb0>]}
[0m12:54:11.596555 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:54:11.596990 [info ] [MainThread]: 
[0m12:54:11.638502 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_customers
[0m12:54:11.639217 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  [RUN]
[0m12:54:11.640301 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_customers'
[0m12:54:11.640700 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_customers
[0m12:54:11.644925 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_customers"
[0m12:54:11.645637 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (compile): 2025-11-14 12:54:11.640944 => 2025-11-14 12:54:11.645525
[0m12:54:11.646047 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_customers
[0m12:54:11.746476 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_customers"
[0m12:54:11.747506 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_customers"
[0m12:54:11.747820 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_customers"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  as
        (SELECT
    CUSTOMER_ID,
    email,
    phone,
    signup_date
FROM GP.mart.DIM_CUSTOMERS
        );
[0m12:54:11.748053 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:54:16.643357 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 5 seconds
[0m12:54:16.656256 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_customers"
[0m12:54:16.656615 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_customers"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers__dbt_tmp cascade
[0m12:54:17.037729 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m12:54:17.106735 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (execute): 2025-11-14 12:54:11.646294 => 2025-11-14 12:54:17.106533
[0m12:54:17.107351 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: Close
[0m12:54:17.550924 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'afb0f571-8b20-41a2-b33c-8b90dd87d43c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd206365730>]}
[0m12:54:17.552562 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  [[32mSUCCESS 1[0m in 5.91s]
[0m12:54:17.557303 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_customers
[0m12:54:17.560651 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:54:17.562119 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:54:17.562621 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart' was properly closed.
[0m12:54:17.563062 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_customers' was properly closed.
[0m12:54:17.563551 [info ] [MainThread]: 
[0m12:54:17.564304 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 14.33 seconds (14.33s).
[0m12:54:17.565838 [debug] [MainThread]: Command end result
[0m12:54:17.590036 [info ] [MainThread]: 
[0m12:54:17.591738 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:54:17.593310 [info ] [MainThread]: 
[0m12:54:17.594397 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m12:54:17.595451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2072baf00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd206f92330>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2063dccb0>]}
[0m12:54:17.596354 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 12:54:55.832938 | 2b47774c-7d0b-4844-a0f5-342d5825bd88 ==============================
[0m12:54:55.832938 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:54:55.836929 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'macro': 'merge_dim_customers', 'args': '{}', 'which': 'run-operation', 'rpc_method': 'run-operation', 'indirect_selection': 'eager'}
[0m12:54:55.837510 [debug] [MainThread]: Tracking: tracking
[0m12:54:55.838210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8161811670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8162263f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f816035a480>]}
[0m12:54:55.956314 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:54:55.957299 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:54:55.983500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2b47774c-7d0b-4844-a0f5-342d5825bd88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f816010cb00>]}
[0m12:54:56.006221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2b47774c-7d0b-4844-a0f5-342d5825bd88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81603da420>]}
[0m12:54:56.017339 [debug] [MainThread]: Acquiring new snowflake connection 'macro_merge_dim_customers'
[0m12:54:56.032523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8161c82900>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815bc87680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815bc87770>]}
[0m12:54:56.033759 [debug] [MainThread]: Flushing usage events
[0m12:54:57.194293 [debug] [MainThread]: Connection 'macro_merge_dim_customers' was properly closed.


============================== 2025-11-14 17:19:33.451070 | 3e2b32ae-c31c-40aa-9447-39565bdb51c7 ==============================
[0m17:19:33.451070 [info ] [MainThread]: Running with dbt=1.4.0
[0m17:19:33.453989 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'macro': 'merge_dim_customers', 'args': '{}', 'which': 'run-operation', 'rpc_method': 'run-operation', 'indirect_selection': 'eager'}
[0m17:19:33.454371 [debug] [MainThread]: Tracking: tracking
[0m17:19:33.454759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd80db2450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd8135e270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd80b17740>]}
[0m17:19:33.525962 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:19:33.526533 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:19:33.542080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3e2b32ae-c31c-40aa-9447-39565bdb51c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd812fbd70>]}
[0m17:19:33.552660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e2b32ae-c31c-40aa-9447-39565bdb51c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd9a3cb830>]}
[0m17:19:33.556717 [debug] [MainThread]: Acquiring new snowflake connection 'macro_merge_dim_customers'
[0m17:19:33.564040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd809f3170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd809f3410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd809f3590>]}
[0m17:19:33.564740 [debug] [MainThread]: Flushing usage events
[0m17:19:40.270572 [debug] [MainThread]: Connection 'macro_merge_dim_customers' was properly closed.


============================== 2025-11-14 17:38:30.402621 | 97737830-ef55-4b98-aa29-d2276d066562 ==============================
[0m17:38:30.402621 [info ] [MainThread]: Running with dbt=1.4.0
[0m17:38:30.405949 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'macro': 'merge_dim_customers', 'args': '{}', 'which': 'run-operation', 'rpc_method': 'run-operation', 'indirect_selection': 'eager'}
[0m17:38:30.406394 [debug] [MainThread]: Tracking: tracking
[0m17:38:30.406828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb8392a750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb5c2c8980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb5c2c9fa0>]}
[0m17:38:30.466935 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:38:30.467947 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/merge_dim_customers.sql
[0m17:38:30.494170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97737830-ef55-4b98-aa29-d2276d066562', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb839297f0>]}
[0m17:38:30.507616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '97737830-ef55-4b98-aa29-d2276d066562', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb83934950>]}
[0m17:38:30.511686 [debug] [MainThread]: Acquiring new snowflake connection 'macro_merge_dim_customers'
[0m17:38:30.534919 [debug] [MainThread]: Using snowflake connection "macro_merge_dim_customers"
[0m17:38:30.535423 [debug] [MainThread]: On macro_merge_dim_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "macro_merge_dim_customers"} */
MERGE INTO GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers AS target
        USING GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers AS source
        ON target.CUSTOMER_ID = source.CUSTOMER_ID
        WHEN MATCHED AND (
            target.email <> source.email
            OR target.phone <> source.phone
        ) THEN
            UPDATE SET
                phone = source.phone,
                email = source.email
        WHEN NOT MATCHED THEN
            INSERT (CUSTOMER_ID, email, phone, signup_date)
            VALUES (source.CUSTOMER_ID, source.email, source.phone, source.signup_date)
[0m17:38:30.535800 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:38:39.809652 [debug] [MainThread]: SQL status: SUCCESS 5 in 9 seconds
[0m17:38:39.812412 [debug] [MainThread]: On macro_merge_dim_customers: Close
[0m17:38:40.558767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb5c18f020>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb5c18f500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb5c18f4d0>]}
[0m17:38:40.559470 [debug] [MainThread]: Flushing usage events
[0m17:38:44.563525 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m17:38:44.564008 [debug] [MainThread]: Connection 'macro_merge_dim_customers' was properly closed.


============================== 2025-11-14 17:50:51.899065 | 654c5e33-39a6-43f1-9ef4-59d5d687a7bd ==============================
[0m17:50:51.899065 [info ] [MainThread]: Running with dbt=1.4.0
[0m17:50:51.901646 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'macro': 'merge_dim_customers', 'args': '{}', 'which': 'run-operation', 'rpc_method': 'run-operation', 'indirect_selection': 'eager'}
[0m17:50:51.902037 [debug] [MainThread]: Tracking: tracking
[0m17:50:51.902420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabab1ab8c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab7fbecb60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab7f983050>]}
[0m17:50:51.959159 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m17:50:51.960043 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/merge_dim_customers.sql
[0m17:50:51.960593 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m17:50:51.987414 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/dim_customers.sql
[0m17:50:52.021400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '654c5e33-39a6-43f1-9ef4-59d5d687a7bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab85d83ad0>]}
[0m17:50:52.030116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '654c5e33-39a6-43f1-9ef4-59d5d687a7bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabab037b30>]}
[0m17:50:52.033257 [debug] [MainThread]: Acquiring new snowflake connection 'macro_merge_dim_customers'
[0m17:50:52.050881 [debug] [MainThread]: Using snowflake connection "macro_merge_dim_customers"
[0m17:50:52.051339 [debug] [MainThread]: On macro_merge_dim_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "macro_merge_dim_customers"} */
MERGE INTO GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers AS target
        USING GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers AS source
        ON target.CUSTOMER_ID = source.CUSTOMER_ID
        WHEN MATCHED AND (
            target.email <> source.email
            OR target.phone <> source.phone
        ) THEN
            UPDATE SET
                phone = source.phone,
                email = source.email
        WHEN NOT MATCHED THEN
            INSERT (CUSTOMER_ID, email, phone, signup_date)
            VALUES (source.CUSTOMER_ID, source.email, source.phone, source.signup_date)
[0m17:50:52.051641 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:50:57.624859 [debug] [MainThread]: SQL status: SUCCESS 0 in 6 seconds
[0m17:50:57.628375 [debug] [MainThread]: On macro_merge_dim_customers: Close
[0m17:50:58.174205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab7f84b2c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab7f84a0c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab7f84ae40>]}
[0m17:50:58.174661 [debug] [MainThread]: Flushing usage events
[0m17:50:59.933851 [debug] [MainThread]: Connection 'macro_merge_dim_customers' was properly closed.


============================== 2025-11-14 18:12:07.698413 | 91ba00f6-e637-42c9-a0b0-710575014c6b ==============================
[0m18:12:07.698413 [info ] [MainThread]: Running with dbt=1.4.0
[0m18:12:07.700561 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'port': 8080, 'open_browser': True, 'which': 'serve', 'indirect_selection': 'eager'}
[0m18:12:07.700859 [debug] [MainThread]: Tracking: tracking
[0m18:12:07.701163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa336378fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa336899370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa35a7c9550>]}
[0m18:12:07.704170 [info ] [MainThread]: Serving docs at 0.0.0.0:8080
[0m18:12:07.704620 [info ] [MainThread]: To access from your browser, navigate to:  http://localhost:8080
[0m18:12:07.704931 [info ] [MainThread]: 
[0m18:12:07.705325 [info ] [MainThread]: 
[0m18:12:07.705746 [info ] [MainThread]: Press Ctrl+C to exit.
[0m18:12:31.768106 [debug] [MainThread]: Flushing usage events
[0m18:12:32.599143 [info ] [MainThread]: ctrl-c


============================== 2025-11-14 18:13:10.168521 | 9a16db40-ca22-4a12-ba2c-0b1e0f5a8312 ==============================
[0m18:13:10.168521 [info ] [MainThread]: Running with dbt=1.4.0
[0m18:13:10.171328 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'port': 3333, 'open_browser': True, 'which': 'serve', 'indirect_selection': 'eager'}
[0m18:13:10.171678 [debug] [MainThread]: Tracking: tracking
[0m18:13:10.172031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0d5b7dfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0cf8d35c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0cf94fad0>]}
[0m18:13:10.181994 [info ] [MainThread]: Serving docs at 0.0.0.0:3333
[0m18:13:10.182619 [info ] [MainThread]: To access from your browser, navigate to:  http://localhost:3333
[0m18:13:10.183047 [info ] [MainThread]: 
[0m18:13:10.183432 [info ] [MainThread]: 
[0m18:13:10.183780 [info ] [MainThread]: Press Ctrl+C to exit.
[0m18:15:26.767706 [debug] [MainThread]: Flushing usage events
[0m18:15:27.203955 [info ] [MainThread]: ctrl-c


============================== 2025-11-14 18:23:33.957488 | 164a2175-5433-413e-875e-4e779a589c95 ==============================
[0m18:23:33.957488 [info ] [MainThread]: Running with dbt=1.4.0
[0m18:23:33.959935 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'port': 3333, 'open_browser': False, 'which': 'serve', 'indirect_selection': 'eager'}
[0m18:23:33.960316 [debug] [MainThread]: Tracking: tracking
[0m18:23:33.960689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383b597d70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383b5952b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f382c633650>]}
[0m18:23:33.968973 [info ] [MainThread]: Serving docs at 0.0.0.0:3333
[0m18:23:33.969686 [info ] [MainThread]: To access from your browser, navigate to:  http://localhost:3333
[0m18:23:33.970144 [info ] [MainThread]: 
[0m18:23:33.970590 [info ] [MainThread]: 
[0m18:23:33.970982 [info ] [MainThread]: Press Ctrl+C to exit.


============================== 2025-11-14 18:39:04.130685 | 7be4e673-aa47-4ddc-9ded-c59c653ffb95 ==============================
[0m18:39:04.130685 [info ] [MainThread]: Running with dbt=1.4.0
[0m18:39:04.133730 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_customers'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m18:39:04.134222 [debug] [MainThread]: Tracking: tracking
[0m18:39:04.134693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc50cd0bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc50cd2ae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc50cd2930>]}
[0m18:39:04.203520 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:39:04.204370 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m18:39:04.226909 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/dim_customers.sql
[0m18:39:04.264528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7be4e673-aa47-4ddc-9ded-c59c653ffb95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc516afb00>]}
[0m18:39:04.275767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7be4e673-aa47-4ddc-9ded-c59c653ffb95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc50d164b0>]}
[0m18:39:04.276430 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m18:39:04.276928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7be4e673-aa47-4ddc-9ded-c59c653ffb95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc65dd54f0>]}
[0m18:39:04.279045 [info ] [MainThread]: 
[0m18:39:04.282749 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m18:39:04.284994 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m18:39:04.323535 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m18:39:04.324042 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m18:39:04.324410 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:39:16.625066 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 12 seconds
[0m18:39:16.628308 [debug] [ThreadPool]: On list_GP: Close
[0m18:39:17.936220 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m18:39:17.937021 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m18:39:17.937391 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart', identifier=None)"
[0m18:39:17.943689 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m18:39:17.944057 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m18:39:17.944329 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:39:20.532575 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 3 seconds
[0m18:39:20.535032 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m18:39:21.338304 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m18:39:21.350774 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m18:39:21.353533 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m18:39:21.354171 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m18:39:21.354474 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:39:21.356155 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m18:39:21.356547 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m18:39:21.356798 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:39:23.168047 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m18:39:23.173147 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m18:39:23.675083 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m18:39:23.677732 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m18:39:25.185674 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m18:39:25.201479 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m18:39:25.202521 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m18:39:25.203272 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:39:30.741603 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 6 seconds
[0m18:39:30.744569 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m18:39:31.592825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7be4e673-aa47-4ddc-9ded-c59c653ffb95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc50b933e0>]}
[0m18:39:31.594427 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m18:39:31.595047 [info ] [MainThread]: 
[0m18:39:31.650358 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_customers
[0m18:39:31.651085 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  [RUN]
[0m18:39:31.652317 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_customers'
[0m18:39:31.652774 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_customers
[0m18:39:31.656941 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_customers"
[0m18:39:31.657677 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (compile): 2025-11-14 18:39:31.653083 => 2025-11-14 18:39:31.657564
[0m18:39:31.658062 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_customers
[0m18:39:31.743491 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_customers"
[0m18:39:31.744309 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_customers"
[0m18:39:31.744558 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_customers"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  as
        (SELECT
    CUSTOMER_ID,
    email,
    phone,
    signup_date
FROM GP.mart.DIM_CUSTOMERS
        );
[0m18:39:31.744736 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:39:35.298261 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 4 seconds
[0m18:39:35.311467 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_customers"
[0m18:39:35.311820 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_customers"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers__dbt_tmp cascade
[0m18:39:35.750475 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m18:39:35.783145 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (execute): 2025-11-14 18:39:31.658310 => 2025-11-14 18:39:35.783052
[0m18:39:35.783567 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_customers: Close
[0m18:39:36.466605 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7be4e673-aa47-4ddc-9ded-c59c653ffb95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc50d17890>]}
[0m18:39:36.467682 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers  [[32mSUCCESS 1[0m in 4.81s]
[0m18:39:36.471905 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_customers
[0m18:39:36.477695 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m18:39:36.479855 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:39:36.480403 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_customers' was properly closed.
[0m18:39:36.480747 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart' was properly closed.
[0m18:39:36.481313 [info ] [MainThread]: 
[0m18:39:36.481837 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 32.20 seconds (32.20s).
[0m18:39:36.482582 [debug] [MainThread]: Command end result
[0m18:39:36.500667 [info ] [MainThread]: 
[0m18:39:36.501514 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:39:36.502039 [info ] [MainThread]: 
[0m18:39:36.502508 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:39:36.503174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc50b71670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc42b8bfe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc50d669f0>]}
[0m18:39:36.503782 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 18:50:45.601384 | ff1e463e-3602-4656-876d-e61585728bde ==============================
[0m18:50:45.601384 [info ] [MainThread]: Running with dbt=1.4.0
[0m18:50:45.603812 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'port': 8080, 'open_browser': True, 'which': 'serve', 'indirect_selection': 'eager'}
[0m18:50:45.604356 [debug] [MainThread]: Tracking: tracking
[0m18:50:45.604785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f5612f830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f5c3aa9f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f562cc9b0>]}
[0m18:50:45.613499 [info ] [MainThread]: Serving docs at 0.0.0.0:8080
[0m18:50:45.614297 [info ] [MainThread]: To access from your browser, navigate to:  http://localhost:8080
[0m18:50:45.614873 [info ] [MainThread]: 
[0m18:50:45.615571 [info ] [MainThread]: 
[0m18:50:45.616036 [info ] [MainThread]: Press Ctrl+C to exit.
[0m18:56:13.496040 [debug] [MainThread]: Flushing usage events
[0m18:56:14.044872 [info ] [MainThread]: ctrl-c


============================== 2025-11-14 18:56:24.799562 | 239453bb-6220-49a6-a599-d2c0b051aca0 ==============================
[0m18:56:24.799562 [info ] [MainThread]: Running with dbt=1.4.0
[0m18:56:24.803442 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m18:56:24.804379 [debug] [MainThread]: Tracking: tracking
[0m18:56:24.805104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f059dd651f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f059de93530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a8d2d070>]}
[0m18:56:24.885446 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:56:24.885930 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:56:24.897481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '239453bb-6220-49a6-a599-d2c0b051aca0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f059e4cc890>]}
[0m18:56:24.908654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '239453bb-6220-49a6-a599-d2c0b051aca0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f059dcc7080>]}
[0m18:56:24.909283 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m18:56:24.909729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '239453bb-6220-49a6-a599-d2c0b051aca0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05bfbc1010>]}
[0m18:56:24.912275 [info ] [MainThread]: 
[0m18:56:24.915943 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m18:56:24.918198 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m18:56:24.933067 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m18:56:24.963927 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m18:56:24.964464 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m18:56:24.964809 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:56:24.971364 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m18:56:24.971821 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m18:56:24.972136 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:56:45.414477 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 20 seconds
[0m18:56:45.417249 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m18:56:46.146951 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m18:56:46.153443 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m18:56:46.153831 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m18:56:46.154125 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:56:48.204251 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m18:56:48.207192 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m18:57:00.143104 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 35 seconds
[0m18:57:00.145530 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m18:57:00.888166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '239453bb-6220-49a6-a599-d2c0b051aca0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f059e5af230>]}
[0m18:57:00.890590 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m18:57:00.891482 [info ] [MainThread]: 
[0m18:57:00.974532 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.cus_orders
[0m18:57:00.975767 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.dim_customers
[0m18:57:00.977644 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m18:57:00.979874 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_customers'
[0m18:57:00.980822 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m18:57:00.981767 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.dim_customers
[0m18:57:00.985840 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m18:57:00.994214 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_customers"
[0m18:57:00.995868 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-14 18:57:00.982370 => 2025-11-14 18:57:00.995646
[0m18:57:00.996621 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.dim_customers (compile): 2025-11-14 18:57:00.986823 => 2025-11-14 18:57:00.996438
[0m18:57:00.997365 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m18:57:00.998086 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.dim_customers
[0m18:57:00.998761 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-14 18:57:00.998585 => 2025-11-14 18:57:00.998629
[0m18:57:00.999444 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.dim_customers (execute): 2025-11-14 18:57:00.999245 => 2025-11-14 18:57:00.999292
[0m18:57:01.005943 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m18:57:01.009072 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.dim_customers
[0m18:57:01.010482 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.ord
[0m18:57:01.011921 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.stg_customers
[0m18:57:01.014416 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.ord'
[0m18:57:01.016528 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m18:57:01.017366 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.ord
[0m18:57:01.018292 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m18:57:01.023159 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.ord"
[0m18:57:01.030825 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m18:57:01.032425 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.ord (compile): 2025-11-14 18:57:01.019098 => 2025-11-14 18:57:01.032086
[0m18:57:01.033177 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.ord
[0m18:57:01.033825 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.ord (execute): 2025-11-14 18:57:01.033671 => 2025-11-14 18:57:01.033699
[0m18:57:01.035593 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.ord
[0m18:57:01.036478 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.test_model
[0m18:57:01.038078 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.test_model'
[0m18:57:01.038741 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.test_model
[0m18:57:01.045103 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-14 18:57:01.023956 => 2025-11-14 18:57:01.044829
[0m18:57:01.049175 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.test_model"
[0m18:57:01.050580 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m18:57:01.052141 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-14 18:57:01.051876 => 2025-11-14 18:57:01.051926
[0m18:57:01.054702 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m18:57:01.056462 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.test_model (compile): 2025-11-14 18:57:01.039654 => 2025-11-14 18:57:01.056095
[0m18:57:01.057796 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.test_model
[0m18:57:01.058710 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.test_model (execute): 2025-11-14 18:57:01.058522 => 2025-11-14 18:57:01.058553
[0m18:57:01.060808 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.test_model
[0m18:57:01.064684 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:57:01.065446 [debug] [MainThread]: Connection 'model.airflow_dbt_project.test_model' was properly closed.
[0m18:57:01.066031 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_customers' was properly closed.
[0m18:57:01.067331 [debug] [MainThread]: Command end result
[0m18:57:01.090172 [info ] [MainThread]: Done.
[0m18:57:01.117626 [debug] [MainThread]: Acquiring new snowflake connection 'generate_catalog'
[0m18:57:01.118607 [info ] [MainThread]: Building catalog
[0m18:57:01.126014 [debug] [ThreadPool]: Acquiring new snowflake connection 'GP.information_schema'
[0m18:57:01.162501 [debug] [ThreadPool]: Using snowflake connection "GP.information_schema"
[0m18:57:01.164012 [debug] [ThreadPool]: On GP.information_schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "GP.information_schema"} */
with tables as (

          select
              table_catalog as "table_database",
              table_schema as "table_schema",
              table_name as "table_name",
              table_type as "table_type",
              comment as "table_comment",

              -- note: this is the _role_ that owns the table
              table_owner as "table_owner",

              'Clustering Key' as "stats:clustering_key:label",
              clustering_key as "stats:clustering_key:value",
              'The key used to cluster this table' as "stats:clustering_key:description",
              (clustering_key is not null) as "stats:clustering_key:include",

              'Row Count' as "stats:row_count:label",
              row_count as "stats:row_count:value",
              'An approximate count of rows in this table' as "stats:row_count:description",
              (row_count is not null) as "stats:row_count:include",

              'Approximate Size' as "stats:bytes:label",
              bytes as "stats:bytes:value",
              'Approximate size of the table as reported by Snowflake' as "stats:bytes:description",
              (bytes is not null) as "stats:bytes:include",

              'Last Modified' as "stats:last_modified:label",
              to_varchar(convert_timezone('UTC', last_altered), 'yyyy-mm-dd HH24:MI'||'UTC') as "stats:last_modified:value",
              'The timestamp for last update/change' as "stats:last_modified:description",
              (last_altered is not null and table_type='BASE TABLE') as "stats:last_modified:include"

          from GP.INFORMATION_SCHEMA.tables

      ),

      columns as (

          select
              table_catalog as "table_database",
              table_schema as "table_schema",
              table_name as "table_name",

              column_name as "column_name",
              ordinal_position as "column_index",
              data_type as "column_type",
              comment as "column_comment"

          from GP.INFORMATION_SCHEMA.columns
      )

      select *
      from tables
      join columns using ("table_database", "table_schema", "table_name")
      where (upper("table_schema") = upper('-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart') or upper("table_schema") = upper('test') or upper("table_schema") = upper('mart') or upper("table_schema") = upper('-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test') or upper("table_schema") = upper('-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'))
      order by "column_index"
[0m18:57:01.165824 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:57:06.912952 [debug] [ThreadPool]: SQL status: SUCCESS 34 in 6 seconds
[0m18:57:06.932134 [debug] [ThreadPool]: On GP.information_schema: Close
[0m18:57:07.833338 [info ] [MainThread]: Catalog written to /opt/airflow/dbt/target/catalog.json
[0m18:57:07.834043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f059c7af800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f059c7ad340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f059c7af980>]}
[0m18:57:07.834475 [debug] [MainThread]: Flushing usage events
[0m18:57:08.647979 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m18:57:08.648856 [debug] [MainThread]: Connection 'GP.information_schema' was properly closed.


============================== 2025-11-14 18:58:16.649898 | 77e0147e-a6a4-4c49-8db3-abe26bcaa6e2 ==============================
[0m18:58:16.649898 [info ] [MainThread]: Running with dbt=1.4.0
[0m18:58:16.653197 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'port': 8080, 'open_browser': True, 'which': 'serve', 'indirect_selection': 'eager'}
[0m18:58:16.653716 [debug] [MainThread]: Tracking: tracking
[0m18:58:16.654197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59e0eb0800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a082256d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59e14f7710>]}
[0m18:58:16.662961 [info ] [MainThread]: Serving docs at 0.0.0.0:8080
[0m18:58:16.663717 [info ] [MainThread]: To access from your browser, navigate to:  http://localhost:8080
[0m18:58:16.664331 [info ] [MainThread]: 
[0m18:58:16.664760 [info ] [MainThread]: 
[0m18:58:16.665143 [info ] [MainThread]: Press Ctrl+C to exit.


============================== 2025-11-14 19:39:32.440987 | 93686c55-9ede-40c4-9091-ad908e158ce0 ==============================
[0m19:39:32.440987 [info ] [MainThread]: Running with dbt=1.4.0
[0m19:39:32.443985 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['cus_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m19:39:32.444375 [debug] [MainThread]: Tracking: tracking
[0m19:39:32.444747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5db1cb680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5bda55c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5be335d60>]}
[0m19:39:32.520602 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:39:32.521772 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/cus_orders.sql
[0m19:39:32.555374 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m19:39:32.611485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '93686c55-9ede-40c4-9091-ad908e158ce0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5bdea3bc0>]}
[0m19:39:32.623213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '93686c55-9ede-40c4-9091-ad908e158ce0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5bc8c13a0>]}
[0m19:39:32.623857 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m19:39:32.624462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '93686c55-9ede-40c4-9091-ad908e158ce0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5bc3c14c0>]}
[0m19:39:32.626604 [info ] [MainThread]: 
[0m19:39:32.630364 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:39:32.632892 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m19:39:32.672633 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m19:39:32.673287 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m19:39:32.673712 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:39:36.693477 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 4 seconds
[0m19:39:36.700563 [debug] [ThreadPool]: On list_GP: Close
[0m19:39:37.748395 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m19:39:37.750842 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m19:39:37.752075 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test', identifier=None)"
[0m19:39:37.779528 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m19:39:37.780760 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m19:39:37.781719 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:39:39.523635 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m19:39:39.526346 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m19:39:40.905786 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m19:39:40.927083 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m19:39:41.013145 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m19:39:41.020577 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m19:39:41.024352 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m19:39:41.026544 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:39:41.029523 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m19:39:41.039094 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:39:42.575072 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m19:39:42.578173 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m19:39:43.200528 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m19:39:43.213122 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m19:39:43.214052 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m19:39:43.214806 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:39:44.566689 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 4 seconds
[0m19:39:44.572906 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m19:39:47.839375 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 5 seconds
[0m19:39:47.841768 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m19:39:48.530323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '93686c55-9ede-40c4-9091-ad908e158ce0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5b7f3e1e0>]}
[0m19:39:48.531897 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m19:39:48.532783 [info ] [MainThread]: 
[0m19:39:48.593008 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.cus_orders
[0m19:39:48.593889 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders  [RUN]
[0m19:39:48.595132 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m19:39:48.595628 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m19:39:48.600226 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m19:39:48.601342 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-14 19:39:48.595906 => 2025-11-14 19:39:48.601160
[0m19:39:48.601815 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m19:39:48.678925 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.cus_orders"
[0m19:39:48.680874 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.cus_orders"
[0m19:39:48.681353 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.cus_orders"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders
  
   as (
    with cus as(
    select customer_id,first_name,last_name, email 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers 
    where status = 'active'
),
alls as(
    select 
    email,
    concat(first_name,' ',last_name),
    order_id,
    order_date,
    total_amount,
    shipping_address
    from ORDERS o join cus c on
    o.customer_id = c.customer_id 
)
select * from alls
  );
[0m19:39:48.681715 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:40:00.187849 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 12 seconds
[0m19:40:00.218947 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-14 19:39:48.602076 => 2025-11-14 19:40:00.218831
[0m19:40:00.219414 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: Close
[0m19:40:00.913746 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '93686c55-9ede-40c4-9091-ad908e158ce0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5b5f1bfe0>]}
[0m19:40:00.914513 [info ] [Thread-1 (]: 1 of 1 OK created sql view model -- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders  [[32mSUCCESS 1[0m in 12.32s]
[0m19:40:00.918266 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m19:40:00.920762 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:40:00.921778 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:40:00.922224 [debug] [MainThread]: Connection 'model.airflow_dbt_project.cus_orders' was properly closed.
[0m19:40:00.922645 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m19:40:00.923129 [info ] [MainThread]: 
[0m19:40:00.923716 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 28.30 seconds (28.30s).
[0m19:40:00.924488 [debug] [MainThread]: Command end result
[0m19:40:00.936795 [info ] [MainThread]: 
[0m19:40:00.938313 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:40:00.939652 [info ] [MainThread]: 
[0m19:40:00.940850 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:40:00.942700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5b6868b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5bc14fb30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5bc14c1d0>]}
[0m19:40:00.944111 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 19:43:26.605595 | b2067e39-2820-44cd-b107-28bad29d53b1 ==============================
[0m19:43:26.605595 [info ] [MainThread]: Running with dbt=1.4.0
[0m19:43:26.609894 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['cus_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m19:43:26.610365 [debug] [MainThread]: Tracking: tracking
[0m19:43:26.610862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4452e3ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe446c7b290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe446c7ae10>]}
[0m19:43:26.698064 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:43:26.699897 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/cus_orders.sql
[0m19:43:26.741495 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m19:43:26.791214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b2067e39-2820-44cd-b107-28bad29d53b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4447c8680>]}
[0m19:43:26.809970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b2067e39-2820-44cd-b107-28bad29d53b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe444956330>]}
[0m19:43:26.810938 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m19:43:26.811896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b2067e39-2820-44cd-b107-28bad29d53b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe444a81d00>]}
[0m19:43:26.815089 [info ] [MainThread]: 
[0m19:43:26.820881 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:43:26.824276 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m19:43:26.863576 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m19:43:26.864311 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m19:43:26.864774 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:43:35.602823 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 9 seconds
[0m19:43:35.605664 [debug] [ThreadPool]: On list_GP: Close
[0m19:43:36.538923 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m19:43:36.540004 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m19:43:36.540523 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test', identifier=None)"
[0m19:43:36.548377 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m19:43:36.548745 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m19:43:36.549032 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:43:40.911439 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 4 seconds
[0m19:43:40.913430 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m19:43:41.748596 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m19:43:41.750679 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m19:43:41.769433 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m19:43:41.769992 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m19:43:41.770653 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:43:41.774720 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m19:43:41.775121 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m19:43:41.775567 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:43:45.438139 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 4 seconds
[0m19:43:45.442166 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m19:43:49.231416 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m19:43:49.234570 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m19:43:49.234942 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m19:43:49.239460 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:43:50.575703 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 9 seconds
[0m19:43:50.578388 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m19:43:56.730890 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 7 seconds
[0m19:43:56.733057 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m19:43:58.721337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b2067e39-2820-44cd-b107-28bad29d53b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe445132b10>]}
[0m19:43:58.723293 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m19:43:58.723976 [info ] [MainThread]: 
[0m19:43:58.770802 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.cus_orders
[0m19:43:58.771707 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders  [RUN]
[0m19:43:58.773366 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m19:43:58.773971 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m19:43:58.779492 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m19:43:58.780847 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-14 19:43:58.774359 => 2025-11-14 19:43:58.780652
[0m19:43:58.781490 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m19:43:58.851630 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.cus_orders"
[0m19:43:58.853099 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.cus_orders"
[0m19:43:58.853431 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.cus_orders"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders
  
   as (
    with cus as(
    select customer_id,first_name,last_name, email 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers 
    where status = 'active'
),
alls as(
    select 
    email,
    concat(first_name,' ',last_name) as fullName,
    order_id,
    order_date,
    total_amount,
    shipping_address
    from ORDERS o join cus c on
    o.customer_id = c.customer_id 
)
select * from alls
  );
[0m19:43:58.853684 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:44:19.153141 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c06460-0000-a5e0-0000-eb0d0002130e
[0m19:44:19.153727 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 7 at position 23
invalid identifier 'FIRST_NAME'
[0m19:44:19.154401 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-14 19:43:58.781871 => 2025-11-14 19:44:19.154257
[0m19:44:19.154775 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: Close
[0m19:44:24.415986 [debug] [Thread-1 (]: Database Error in model cus_orders (models/cus_orders.sql)
  000904 (42000): SQL compilation error: error line 7 at position 23
  invalid identifier 'FIRST_NAME'
  compiled Code at target/run/airflow_dbt_project/models/cus_orders.sql
[0m19:44:24.416728 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2067e39-2820-44cd-b107-28bad29d53b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4365bc410>]}
[0m19:44:24.417439 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model -- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders  [[31mERROR[0m in 25.64s]
[0m19:44:24.420118 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m19:44:24.422618 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:44:24.423495 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:44:24.423794 [debug] [MainThread]: Connection 'model.airflow_dbt_project.cus_orders' was properly closed.
[0m19:44:24.424034 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart' was properly closed.
[0m19:44:24.424347 [info ] [MainThread]: 
[0m19:44:24.424709 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 57.61 seconds (57.61s).
[0m19:44:24.425186 [debug] [MainThread]: Command end result
[0m19:44:24.435984 [info ] [MainThread]: 
[0m19:44:24.436993 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:44:24.437788 [info ] [MainThread]: 
[0m19:44:24.438528 [error] [MainThread]: [33mDatabase Error in model cus_orders (models/cus_orders.sql)[0m
[0m19:44:24.438968 [error] [MainThread]:   000904 (42000): SQL compilation error: error line 7 at position 23
[0m19:44:24.439352 [error] [MainThread]:   invalid identifier 'FIRST_NAME'
[0m19:44:24.439723 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/cus_orders.sql
[0m19:44:24.440172 [info ] [MainThread]: 
[0m19:44:24.440663 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m19:44:24.441357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe46c012db0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe446c84260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe445132b10>]}
[0m19:44:24.441974 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 19:45:33.567892 | 5d327489-68a9-436f-be80-2d7e73fc2c0f ==============================
[0m19:45:33.567892 [info ] [MainThread]: Running with dbt=1.4.0
[0m19:45:33.570395 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['cus_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m19:45:33.570721 [debug] [MainThread]: Tracking: tracking
[0m19:45:33.571167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f432000f350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42f8a6d9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42f9ccee10>]}
[0m19:45:33.626054 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:45:33.626912 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/cus_orders.sql
[0m19:45:33.648781 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m19:45:33.689734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5d327489-68a9-436f-be80-2d7e73fc2c0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42f8869e80>]}
[0m19:45:33.700689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d327489-68a9-436f-be80-2d7e73fc2c0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42f89e6390>]}
[0m19:45:33.701297 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m19:45:33.701788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5d327489-68a9-436f-be80-2d7e73fc2c0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43141e40b0>]}
[0m19:45:33.704066 [info ] [MainThread]: 
[0m19:45:33.707278 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:45:33.709081 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m19:45:33.742811 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m19:45:33.743341 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m19:45:33.743764 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:45:51.418007 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 18 seconds
[0m19:45:51.420332 [debug] [ThreadPool]: On list_GP: Close
[0m19:45:52.666278 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m19:45:52.667257 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m19:45:52.667748 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test', identifier=None)"
[0m19:45:52.676978 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m19:45:52.677549 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m19:45:52.677914 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:46:05.958561 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 13 seconds
[0m19:46:05.960181 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m19:46:07.409258 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m19:46:07.413813 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m19:46:07.424054 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m19:46:07.427135 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m19:46:07.427716 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m19:46:07.428205 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m19:46:07.428942 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:46:07.429434 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:46:09.976933 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 3 seconds
[0m19:46:09.979788 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m19:46:10.231434 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 3 seconds
[0m19:46:10.234790 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m19:46:10.965870 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m19:46:10.975085 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m19:46:10.975834 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m19:46:10.976396 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:46:24.290421 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 13 seconds
[0m19:46:24.293592 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m19:46:25.409425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5d327489-68a9-436f-be80-2d7e73fc2c0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42f8185370>]}
[0m19:46:25.410576 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m19:46:25.411097 [info ] [MainThread]: 
[0m19:46:25.453821 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.cus_orders
[0m19:46:25.454807 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders  [RUN]
[0m19:46:25.456221 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m19:46:25.456779 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m19:46:25.461833 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m19:46:25.462693 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-14 19:46:25.457097 => 2025-11-14 19:46:25.462554
[0m19:46:25.463129 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m19:46:25.525439 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.cus_orders"
[0m19:46:25.526810 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.cus_orders"
[0m19:46:25.527126 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.cus_orders"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders
  
   as (
    with cus as(
    select customer_id, email,phone,signup_date 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers 
    where status = 'active'
),
alls as(
    select 
    email,
    order_id,
    order_date,
    total_amount,
    shipping_address
    from ORDERS o join cus c on
    o.customer_id = c.customer_id 
)
select * from alls
  );
[0m19:46:25.527385 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:46:33.752715 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c06462-0000-a68c-0000-eb0d000222ca
[0m19:46:33.753152 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 11 at position 10
invalid identifier 'STATUS'
[0m19:46:33.753642 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-14 19:46:25.463386 => 2025-11-14 19:46:33.753547
[0m19:46:33.753926 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: Close
[0m19:46:34.780016 [debug] [Thread-1 (]: Database Error in model cus_orders (models/cus_orders.sql)
  000904 (42000): SQL compilation error: error line 11 at position 10
  invalid identifier 'STATUS'
  compiled Code at target/run/airflow_dbt_project/models/cus_orders.sql
[0m19:46:34.780660 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d327489-68a9-436f-be80-2d7e73fc2c0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42f2592ba0>]}
[0m19:46:34.781337 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model -- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders  [[31mERROR[0m in 9.33s]
[0m19:46:34.784011 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m19:46:34.786883 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:46:34.787698 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:46:34.787974 [debug] [MainThread]: Connection 'model.airflow_dbt_project.cus_orders' was properly closed.
[0m19:46:34.788201 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m19:46:34.788507 [info ] [MainThread]: 
[0m19:46:34.788861 [info ] [MainThread]: Finished running 1 view model in 0 hours 1 minutes and 1.08 seconds (61.08s).
[0m19:46:34.789335 [debug] [MainThread]: Command end result
[0m19:46:34.799868 [info ] [MainThread]: 
[0m19:46:34.800833 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:46:34.801444 [info ] [MainThread]: 
[0m19:46:34.801952 [error] [MainThread]: [33mDatabase Error in model cus_orders (models/cus_orders.sql)[0m
[0m19:46:34.802436 [error] [MainThread]:   000904 (42000): SQL compilation error: error line 11 at position 10
[0m19:46:34.802878 [error] [MainThread]:   invalid identifier 'STATUS'
[0m19:46:34.803336 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/cus_orders.sql
[0m19:46:34.803811 [info ] [MainThread]: 
[0m19:46:34.804329 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m19:46:34.805092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42f8878a40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42f9cce6f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42f94b3290>]}
[0m19:46:34.805826 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 19:46:51.857059 | 8d1b2de9-79d8-4f52-84b1-a1f995a28e16 ==============================
[0m19:46:51.857059 [info ] [MainThread]: Running with dbt=1.4.0
[0m19:46:51.859818 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['cus_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m19:46:51.860167 [debug] [MainThread]: Tracking: tracking
[0m19:46:51.860542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14146e0e00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1416876e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f141581e660>]}
[0m19:46:51.920298 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:46:51.921197 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/cus_orders.sql
[0m19:46:51.942583 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m19:46:51.980028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8d1b2de9-79d8-4f52-84b1-a1f995a28e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14143cb200>]}
[0m19:46:51.990573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8d1b2de9-79d8-4f52-84b1-a1f995a28e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14144da150>]}
[0m19:46:51.991153 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m19:46:51.991619 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d1b2de9-79d8-4f52-84b1-a1f995a28e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1414d38470>]}
[0m19:46:51.993514 [info ] [MainThread]: 
[0m19:46:51.996880 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:46:51.999139 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m19:46:52.041906 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m19:46:52.042779 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m19:46:52.043353 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:46:56.996078 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 5 seconds
[0m19:46:56.998760 [debug] [ThreadPool]: On list_GP: Close
[0m19:46:58.457062 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m19:46:58.457931 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m19:46:58.458329 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test', identifier=None)"
[0m19:46:58.466435 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m19:46:58.466852 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m19:46:58.467167 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:47:18.916590 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 20 seconds
[0m19:47:18.919184 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m19:47:20.670859 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m19:47:20.679442 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m19:47:20.684742 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m19:47:20.688238 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m19:47:20.688764 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m19:47:20.689382 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m19:47:20.689918 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:47:20.690443 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:47:22.878867 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m19:47:22.882362 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m19:47:23.647002 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m19:47:23.652042 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m19:47:23.652471 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m19:47:23.652758 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:47:25.912321 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m19:47:25.916007 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m19:47:27.667583 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 7 seconds
[0m19:47:27.670494 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m19:47:28.423689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d1b2de9-79d8-4f52-84b1-a1f995a28e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f141685f1a0>]}
[0m19:47:28.424583 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m19:47:28.424966 [info ] [MainThread]: 
[0m19:47:28.470221 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.cus_orders
[0m19:47:28.471098 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders  [RUN]
[0m19:47:28.472223 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m19:47:28.472667 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m19:47:28.477100 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m19:47:28.477897 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-14 19:47:28.472917 => 2025-11-14 19:47:28.477778
[0m19:47:28.478326 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m19:47:28.542187 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.cus_orders"
[0m19:47:28.543686 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.cus_orders"
[0m19:47:28.544033 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.cus_orders"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders
  
   as (
    with cus as(
    select customer_id, email,phone,signup_date 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers 
),
alls as(
    select 
    email,
    order_id,
    order_date,
    total_amount,
    shipping_address
    from ORDERS o join cus c on
    o.customer_id = c.customer_id 
)
select * from alls
  );
[0m19:47:28.544309 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:47:30.243500 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m19:47:30.268283 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-14 19:47:28.478617 => 2025-11-14 19:47:30.268173
[0m19:47:30.268671 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: Close
[0m19:47:33.057944 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d1b2de9-79d8-4f52-84b1-a1f995a28e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f140e5e41a0>]}
[0m19:47:33.058627 [info ] [Thread-1 (]: 1 of 1 OK created sql view model -- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders  [[32mSUCCESS 1[0m in 4.59s]
[0m19:47:33.061778 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m19:47:33.064131 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:47:33.064963 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:47:33.065307 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test' was properly closed.
[0m19:47:33.065534 [debug] [MainThread]: Connection 'model.airflow_dbt_project.cus_orders' was properly closed.
[0m19:47:33.065845 [info ] [MainThread]: 
[0m19:47:33.066300 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 41.07 seconds (41.07s).
[0m19:47:33.066868 [debug] [MainThread]: Command end result
[0m19:47:33.077866 [info ] [MainThread]: 
[0m19:47:33.078611 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:47:33.079332 [info ] [MainThread]: 
[0m19:47:33.079860 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:47:33.080555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1414f66f00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f141685f1a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14144b5460>]}
[0m19:47:33.081127 [debug] [MainThread]: Flushing usage events


============================== 2025-11-14 19:55:20.116551 | 7d774028-a2c5-490b-aff5-3f58fcf2f8fd ==============================
[0m19:55:20.116551 [info ] [MainThread]: Running with dbt=1.4.0
[0m19:55:20.118957 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m19:55:20.119272 [debug] [MainThread]: Tracking: tracking
[0m19:55:20.119609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39e307b4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39e3dc4800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39e32132f0>]}
[0m19:55:20.176130 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:55:20.176675 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:55:20.188725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7d774028-a2c5-490b-aff5-3f58fcf2f8fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39e2e486b0>]}
[0m19:55:20.203796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7d774028-a2c5-490b-aff5-3f58fcf2f8fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39e334fdd0>]}
[0m19:55:20.204749 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m19:55:20.205871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d774028-a2c5-490b-aff5-3f58fcf2f8fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39e3afae70>]}
[0m19:55:20.210608 [info ] [MainThread]: 
[0m19:55:20.218506 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:55:20.222912 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m19:55:20.231424 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m19:55:20.345356 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m19:55:20.346999 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m19:55:20.347719 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m19:55:20.348605 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m19:55:20.349449 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:55:20.350095 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:55:27.562880 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 7 seconds
[0m19:55:27.566088 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m19:55:29.204720 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m19:55:29.212855 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m19:55:29.213392 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m19:55:29.213753 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:55:31.112761 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 11 seconds
[0m19:55:31.115716 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m19:55:33.547710 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 4 seconds
[0m19:55:33.549746 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m19:55:35.522270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d774028-a2c5-490b-aff5-3f58fcf2f8fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39e3f7ccb0>]}
[0m19:55:35.523427 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m19:55:35.523968 [info ] [MainThread]: 
[0m19:55:35.565535 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_customers
[0m19:55:35.566221 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.ord
[0m19:55:35.567419 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_customers'
[0m19:55:35.568651 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.ord'
[0m19:55:35.569449 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_customers
[0m19:55:35.569934 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.ord
[0m19:55:35.574225 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_customers"
[0m19:55:35.576245 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.ord"
[0m19:55:35.577025 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (compile): 2025-11-14 19:55:35.570389 => 2025-11-14 19:55:35.576917
[0m19:55:35.577394 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_customers
[0m19:55:35.577676 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (execute): 2025-11-14 19:55:35.577594 => 2025-11-14 19:55:35.577616
[0m19:55:35.580393 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_customers
[0m19:55:35.580866 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m19:55:35.581347 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.ord (compile): 2025-11-14 19:55:35.574681 => 2025-11-14 19:55:35.581247
[0m19:55:35.582249 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m19:55:35.583060 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.ord
[0m19:55:35.583483 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m19:55:35.583950 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.ord (execute): 2025-11-14 19:55:35.583851 => 2025-11-14 19:55:35.583870
[0m19:55:35.588581 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m19:55:35.590002 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.ord
[0m19:55:35.590862 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.test_model
[0m19:55:35.592082 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.test_model'
[0m19:55:35.592531 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.test_model
[0m19:55:35.592903 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-14 19:55:35.584220 => 2025-11-14 19:55:35.592780
[0m19:55:35.597488 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.test_model"
[0m19:55:35.598208 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m19:55:35.599076 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-14 19:55:35.598872 => 2025-11-14 19:55:35.598910
[0m19:55:35.600982 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m19:55:35.601714 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.cus_orders
[0m19:55:35.602376 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.test_model (compile): 2025-11-14 19:55:35.593222 => 2025-11-14 19:55:35.602175
[0m19:55:35.603420 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m19:55:35.603928 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.test_model
[0m19:55:35.604561 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m19:55:35.605063 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.test_model (execute): 2025-11-14 19:55:35.604961 => 2025-11-14 19:55:35.604980
[0m19:55:35.609924 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m19:55:35.611369 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.test_model
[0m19:55:35.612219 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-14 19:55:35.605516 => 2025-11-14 19:55:35.612121
[0m19:55:35.612620 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m19:55:35.612930 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-14 19:55:35.612853 => 2025-11-14 19:55:35.612869
[0m19:55:35.613914 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m19:55:35.615681 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:55:35.616122 [debug] [MainThread]: Connection 'model.airflow_dbt_project.test_model' was properly closed.
[0m19:55:35.616439 [debug] [MainThread]: Connection 'model.airflow_dbt_project.cus_orders' was properly closed.
[0m19:55:35.617068 [debug] [MainThread]: Command end result
[0m19:55:35.626911 [info ] [MainThread]: Done.
[0m19:55:35.639588 [debug] [MainThread]: Acquiring new snowflake connection 'generate_catalog'
[0m19:55:35.640056 [info ] [MainThread]: Building catalog
[0m19:55:35.644056 [debug] [ThreadPool]: Acquiring new snowflake connection 'GP.information_schema'
[0m19:55:35.668056 [debug] [ThreadPool]: Using snowflake connection "GP.information_schema"
[0m19:55:35.668922 [debug] [ThreadPool]: On GP.information_schema: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "GP.information_schema"} */
with tables as (

          select
              table_catalog as "table_database",
              table_schema as "table_schema",
              table_name as "table_name",
              table_type as "table_type",
              comment as "table_comment",

              -- note: this is the _role_ that owns the table
              table_owner as "table_owner",

              'Clustering Key' as "stats:clustering_key:label",
              clustering_key as "stats:clustering_key:value",
              'The key used to cluster this table' as "stats:clustering_key:description",
              (clustering_key is not null) as "stats:clustering_key:include",

              'Row Count' as "stats:row_count:label",
              row_count as "stats:row_count:value",
              'An approximate count of rows in this table' as "stats:row_count:description",
              (row_count is not null) as "stats:row_count:include",

              'Approximate Size' as "stats:bytes:label",
              bytes as "stats:bytes:value",
              'Approximate size of the table as reported by Snowflake' as "stats:bytes:description",
              (bytes is not null) as "stats:bytes:include",

              'Last Modified' as "stats:last_modified:label",
              to_varchar(convert_timezone('UTC', last_altered), 'yyyy-mm-dd HH24:MI'||'UTC') as "stats:last_modified:value",
              'The timestamp for last update/change' as "stats:last_modified:description",
              (last_altered is not null and table_type='BASE TABLE') as "stats:last_modified:include"

          from GP.INFORMATION_SCHEMA.tables

      ),

      columns as (

          select
              table_catalog as "table_database",
              table_schema as "table_schema",
              table_name as "table_name",

              column_name as "column_name",
              ordinal_position as "column_index",
              data_type as "column_type",
              comment as "column_comment"

          from GP.INFORMATION_SCHEMA.columns
      )

      select *
      from tables
      join columns using ("table_database", "table_schema", "table_name")
      where (upper("table_schema") = upper('-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart') or upper("table_schema") = upper('-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging') or upper("table_schema") = upper('test') or upper("table_schema") = upper('mart') or upper("table_schema") = upper('-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'))
      order by "column_index"
[0m19:55:35.669614 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:55:40.436158 [debug] [ThreadPool]: SQL status: SUCCESS 39 in 5 seconds
[0m19:55:40.452928 [debug] [ThreadPool]: On GP.information_schema: Close
[0m19:55:41.328592 [info ] [MainThread]: Catalog written to /opt/airflow/dbt/target/catalog.json
[0m19:55:41.329437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39e1afb200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39e1afbf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39e1af81d0>]}
[0m19:55:41.329908 [debug] [MainThread]: Flushing usage events
[0m19:55:42.417671 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m19:55:42.418084 [debug] [MainThread]: Connection 'GP.information_schema' was properly closed.


============================== 2025-11-14 19:56:04.168344 | cec156de-d41e-4989-8cc2-8372caf7bb79 ==============================
[0m19:56:04.168344 [info ] [MainThread]: Running with dbt=1.4.0
[0m19:56:04.171050 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'port': 8080, 'open_browser': True, 'which': 'serve', 'indirect_selection': 'eager'}
[0m19:56:04.171468 [debug] [MainThread]: Tracking: tracking
[0m19:56:04.171857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f543e721100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54133cba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5412ef4200>]}
[0m19:56:04.179656 [info ] [MainThread]: Serving docs at 0.0.0.0:8080
[0m19:56:04.180305 [info ] [MainThread]: To access from your browser, navigate to:  http://localhost:8080
[0m19:56:04.180812 [info ] [MainThread]: 
[0m19:56:04.181388 [info ] [MainThread]: 
[0m19:56:04.182089 [info ] [MainThread]: Press Ctrl+C to exit.
[0m19:56:04.183020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5433fe1820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5412ef4200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5412ef6840>]}
[0m19:56:04.183512 [debug] [MainThread]: Flushing usage events
[0m19:56:04.962408 [error] [MainThread]: Encountered an error:
[Errno 98] Address already in use
[0m19:56:04.973313 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/main.py", line 135, in main
    results, succeeded = handle_and_check(args)
                         ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/main.py", line 198, in handle_and_check
    task, res = run_from_args(parsed)
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/main.py", line 245, in run_from_args
    results = task.run()
              ^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/serve.py", line 30, in run
    httpd = TCPServer(  # type: ignore
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socketserver.py", line 457, in __init__
    self.server_bind()
  File "/usr/local/lib/python3.12/socketserver.py", line 478, in server_bind
    self.socket.bind(self.server_address)
OSError: [Errno 98] Address already in use



============================== 2025-11-16 13:51:47.566028 | d9f8944d-4708-4f5b-9a90-5161311e5933 ==============================
[0m13:51:47.566028 [info ] [MainThread]: Running with dbt=1.4.0
[0m13:51:47.570355 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:51:47.570843 [debug] [MainThread]: Tracking: tracking
[0m13:51:47.571367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f789a9ddd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f789028f590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7890ccf920>]}
[0m13:51:47.665300 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m13:51:47.666410 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/staging/schema.yml
[0m13:51:47.666967 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/staging/stg_orders.sql
[0m13:51:47.692342 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m13:51:47.749759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f788afaa960>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f788afab770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f788afab8c0>]}
[0m13:51:47.750550 [debug] [MainThread]: Flushing usage events
[0m13:51:49.354020 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two schema.yml entries for the same resource named stg_customers. Resources and their associated columns may only be described a single time. To fix this, remove one of the resource entries for stg_customers in this file:
   - models/staging/schema.yml
  


============================== 2025-11-16 13:52:22.966069 | ed9fbb19-0184-4feb-880e-6fc6e0854014 ==============================
[0m13:52:22.966069 [info ] [MainThread]: Running with dbt=1.4.0
[0m13:52:22.968130 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:52:22.968414 [debug] [MainThread]: Tracking: tracking
[0m13:52:22.968722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f976548b3b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97853e20f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97653177a0>]}
[0m13:52:23.018515 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m13:52:23.019255 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/staging/schema.yml
[0m13:52:23.019678 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/staging/stg_orders.sql
[0m13:52:23.038493 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m13:52:23.106017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97651e3350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f978caaf680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97651d0350>]}
[0m13:52:23.106541 [debug] [MainThread]: Flushing usage events
[0m13:52:25.025551 [error] [MainThread]: Encountered an error:
Compilation Error in test relationships_stg_customers_ref_customers___id__customer_id (models/staging/schema.yml)
  macro 'dbt_macro__test_relationships' takes no keyword argument 'arguments'


============================== 2025-11-16 13:53:52.120731 | 3f7f3752-a104-464d-8c8e-8281db373ba5 ==============================
[0m13:53:52.120731 [info ] [MainThread]: Running with dbt=1.4.0
[0m13:53:52.123892 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:53:52.124332 [debug] [MainThread]: Tracking: tracking
[0m13:53:52.124784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a6fb3ee10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a6de14590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a6dbd3380>]}
[0m13:53:52.206943 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m13:53:52.208371 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/staging/schema.yml
[0m13:53:52.209300 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/staging/stg_orders.sql
[0m13:53:52.243352 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m13:53:52.336051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a6e5eec60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a6da865d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a6d795e50>]}
[0m13:53:52.336952 [debug] [MainThread]: Flushing usage events
[0m13:53:53.597392 [error] [MainThread]: Encountered an error:
Compilation Error in test relationships_stg_customers_ref_stg_customers___customer_id__customer_id (models/staging/schema.yml)
  macro 'dbt_macro__test_relationships' takes no keyword argument 'arguments'


============================== 2025-11-16 13:54:54.540331 | 48ff1b2c-76e1-440b-b9e4-d1bd3e92c289 ==============================
[0m13:54:54.540331 [info ] [MainThread]: Running with dbt=1.4.0
[0m13:54:54.542780 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:54:54.543190 [debug] [MainThread]: Tracking: tracking
[0m13:54:54.543550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ce1c068a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ce1c04bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ce1c07b60>]}
[0m13:54:54.598203 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m13:54:54.599010 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/staging/schema.yml
[0m13:54:54.599499 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/staging/stg_orders.sql
[0m13:54:54.617727 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m13:54:54.678017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ce1ab1af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ce1ab18e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ce1ab3ec0>]}
[0m13:54:54.678579 [debug] [MainThread]: Flushing usage events
[0m13:54:55.526355 [error] [MainThread]: Encountered an error:
Compilation Error in test relationships_stg_orders_ref_stg_customers___customer_id__customer_id (models/staging/schema.yml)
  macro 'dbt_macro__test_relationships' takes no keyword argument 'arguments'


============================== 2025-11-16 13:56:24.453990 | 8f53495c-fbb8-4af9-a76f-87141e9b1878 ==============================
[0m13:56:24.453990 [info ] [MainThread]: Running with dbt=1.4.0
[0m13:56:24.456002 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['stg_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:56:24.456267 [debug] [MainThread]: Tracking: tracking
[0m13:56:24.456541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3955f78c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa395b10e60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3be8cae10>]}
[0m13:56:24.505747 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m13:56:24.506437 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/staging/stg_orders.sql
[0m13:56:24.506943 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/staging/schema.yml
[0m13:56:24.526030 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m13:56:24.610792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8f53495c-fbb8-4af9-a76f-87141e9b1878', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3954cde50>]}
[0m13:56:24.620850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8f53495c-fbb8-4af9-a76f-87141e9b1878', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa395665790>]}
[0m13:56:24.621378 [info ] [MainThread]: Found 6 models, 5 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m13:56:24.621770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8f53495c-fbb8-4af9-a76f-87141e9b1878', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa39705b050>]}
[0m13:56:24.623655 [info ] [MainThread]: 
[0m13:56:24.626544 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:56:24.628157 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m13:56:24.659672 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m13:56:24.660205 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m13:56:24.660537 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:56:29.350263 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 5 seconds
[0m13:56:29.353338 [debug] [ThreadPool]: On list_GP: Close
[0m13:56:30.181578 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m13:56:30.182722 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m13:56:30.183288 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging', identifier=None)"
[0m13:56:30.191607 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m13:56:30.192139 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m13:56:30.192577 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:56:31.264204 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m13:56:31.267050 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m13:56:31.938110 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m13:56:31.945708 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m13:56:31.955544 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m13:56:31.962613 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m13:56:31.964317 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m13:56:31.964788 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:56:31.965227 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m13:56:31.967143 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:56:33.608553 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m13:56:33.611459 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m13:56:33.630243 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m13:56:33.633723 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m13:56:34.377590 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m13:56:34.380686 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m13:56:34.382372 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m13:56:34.382703 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:56:35.295312 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m13:56:35.298678 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m13:56:35.880598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8f53495c-fbb8-4af9-a76f-87141e9b1878', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa395b4b710>]}
[0m13:56:35.882072 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m13:56:35.882555 [info ] [MainThread]: 
[0m13:56:35.934377 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_orders
[0m13:56:35.935118 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders  [RUN]
[0m13:56:35.936970 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_orders'
[0m13:56:35.937376 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_orders
[0m13:56:35.941218 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_orders"
[0m13:56:35.942047 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_orders (compile): 2025-11-16 13:56:35.937606 => 2025-11-16 13:56:35.941928
[0m13:56:35.942409 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_orders
[0m13:56:35.997722 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_orders"
[0m13:56:35.998730 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_orders"
[0m13:56:35.999058 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_orders: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_orders"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
  
   as (
    select * from GP.test.orders
  );
[0m13:56:35.999280 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:56:37.616685 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m13:56:37.642682 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_orders (execute): 2025-11-16 13:56:35.942616 => 2025-11-16 13:56:37.642577
[0m13:56:37.643115 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_orders: Close
[0m13:56:38.202632 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f53495c-fbb8-4af9-a76f-87141e9b1878', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa387bd6570>]}
[0m13:56:38.203382 [info ] [Thread-1 (]: 1 of 1 OK created sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders  [[32mSUCCESS 1[0m in 2.27s]
[0m13:56:38.206155 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_orders
[0m13:56:38.208938 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:56:38.210041 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:56:38.210474 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test' was properly closed.
[0m13:56:38.210827 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_orders' was properly closed.
[0m13:56:38.211267 [info ] [MainThread]: 
[0m13:56:38.211845 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 13.59 seconds (13.59s).
[0m13:56:38.212682 [debug] [MainThread]: Command end result
[0m13:56:38.231595 [info ] [MainThread]: 
[0m13:56:38.232510 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:56:38.233078 [info ] [MainThread]: 
[0m13:56:38.233563 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:56:38.234226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa395620a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa387196a20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa387196300>]}
[0m13:56:38.234818 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 13:59:37.453428 | 7ddb84ee-dd81-46ed-b12f-4ddcb055a060 ==============================
[0m13:59:37.453428 [info ] [MainThread]: Running with dbt=1.4.0
[0m13:59:37.459966 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m13:59:37.461199 [debug] [MainThread]: Tracking: tracking
[0m13:59:37.462431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c24dcf110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c1fc24b60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c25637d70>]}
[0m13:59:37.570860 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:59:37.571466 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:59:37.589755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7ddb84ee-dd81-46ed-b12f-4ddcb055a060', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c1f4ac680>]}
[0m13:59:37.611566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7ddb84ee-dd81-46ed-b12f-4ddcb055a060', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c1f3aeab0>]}
[0m13:59:37.612862 [info ] [MainThread]: Found 6 models, 5 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m13:59:37.613759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7ddb84ee-dd81-46ed-b12f-4ddcb055a060', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c1f83f560>]}
[0m13:59:37.618267 [info ] [MainThread]: 
[0m13:59:37.623690 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:59:37.628213 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m13:59:37.631663 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m13:59:37.772504 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m13:59:37.799244 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m13:59:37.801798 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m13:59:37.788810 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m13:59:37.803753 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:59:37.805745 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:59:43.549350 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 6 seconds
[0m13:59:43.552012 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 6 seconds
[0m13:59:43.559673 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m13:59:43.564576 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m13:59:44.759818 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m13:59:44.767963 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m13:59:44.768552 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m13:59:44.768970 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:59:50.365358 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 6 seconds
[0m13:59:50.367678 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m13:59:51.765205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7ddb84ee-dd81-46ed-b12f-4ddcb055a060', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c1f793aa0>]}
[0m13:59:51.766753 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m13:59:51.767413 [info ] [MainThread]: 
[0m13:59:51.824840 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_customers_order_id.7cef17ca3c
[0m13:59:51.825845 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m13:59:51.826700 [info ] [Thread-1 (]: 1 of 5 START test not_null_stg_customers_order_id .............................. [RUN]
[0m13:59:51.827460 [info ] [Thread-2 (]: 2 of 5 START test not_null_stg_orders_order_id ................................. [RUN]
[0m13:59:51.829409 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_customers_order_id.7cef17ca3c'
[0m13:59:51.831047 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m13:59:51.831933 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_customers_order_id.7cef17ca3c
[0m13:59:51.832727 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m13:59:51.936136 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_customers_order_id.7cef17ca3c"
[0m13:59:51.937050 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m13:59:51.939228 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_order_id.7cef17ca3c (compile): 2025-11-16 13:59:51.833388 => 2025-11-16 13:59:51.938924
[0m13:59:51.940204 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 13:59:51.850012 => 2025-11-16 13:59:51.939985
[0m13:59:51.941092 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_customers_order_id.7cef17ca3c
[0m13:59:51.942006 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m13:59:52.053495 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_customers_order_id.7cef17ca3c"
[0m13:59:52.054984 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m13:59:52.056752 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_customers_order_id.7cef17ca3c"
[0m13:59:52.057268 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_order_id.7cef17ca3c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_customers_order_id.7cef17ca3c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where order_id is null



      
    ) dbt_internal_test
[0m13:59:52.057620 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:59:52.058613 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m13:59:52.060583 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m13:59:52.062388 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:59:54.495941 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c06e47-0000-a6ae-0000-eb0d00028416
[0m13:59:54.497454 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 12 at position 7
invalid identifier 'ORDER_ID'
[0m13:59:54.499510 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_order_id.7cef17ca3c (execute): 2025-11-16 13:59:51.942604 => 2025-11-16 13:59:54.499178
[0m13:59:54.500767 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_order_id.7cef17ca3c: Close
[0m13:59:54.911262 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 3 seconds
[0m13:59:54.979468 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 13:59:51.959612 => 2025-11-16 13:59:54.978944
[0m13:59:54.982457 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m13:59:55.467430 [debug] [Thread-1 (]: Database Error in test not_null_stg_customers_order_id (models/staging/schema.yml)
  000904 (42000): SQL compilation error: error line 12 at position 7
  invalid identifier 'ORDER_ID'
  compiled Code at target/run/airflow_dbt_project/models/staging/schema.yml/not_null_stg_customers_order_id.sql
[0m13:59:55.468940 [error] [Thread-1 (]: 1 of 5 ERROR not_null_stg_customers_order_id ................................... [[31mERROR[0m in 3.64s]
[0m13:59:55.476012 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_customers_order_id.7cef17ca3c
[0m13:59:55.477404 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m13:59:55.479185 [info ] [Thread-1 (]: 3 of 5 START test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [RUN]
[0m13:59:55.482747 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500'
[0m13:59:55.483997 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m13:59:55.540412 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m13:59:55.542032 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (compile): 2025-11-16 13:59:55.484774 => 2025-11-16 13:59:55.541768
[0m13:59:55.543014 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m13:59:55.557799 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m13:59:55.560741 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m13:59:55.561290 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select customer_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where customer_id is not null
),

parent as (
    select customer_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:59:55.561763 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:59:55.955798 [info ] [Thread-2 (]: 2 of 5 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 4.13s]
[0m13:59:55.956541 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m13:59:55.957084 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_customers_order_id.c6a1813fa7
[0m13:59:55.957440 [info ] [Thread-2 (]: 4 of 5 START test unique_stg_customers_order_id ................................ [RUN]
[0m13:59:55.958417 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_customers_order_id.c6a1813fa7'
[0m13:59:55.958764 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_customers_order_id.c6a1813fa7
[0m13:59:55.972509 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_customers_order_id.c6a1813fa7"
[0m13:59:55.973517 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_order_id.c6a1813fa7 (compile): 2025-11-16 13:59:55.959027 => 2025-11-16 13:59:55.973359
[0m13:59:55.974038 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_customers_order_id.c6a1813fa7
[0m13:59:55.979257 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_customers_order_id.c6a1813fa7"
[0m13:59:55.981733 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_customers_order_id.c6a1813fa7"
[0m13:59:55.982520 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_customers_order_id.c6a1813fa7: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_customers_order_id.c6a1813fa7"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:59:55.983074 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:00:03.074832 [debug] [Thread-2 (]: Snowflake adapter: Snowflake query id: 01c06e48-0000-a6d0-0000-eb0d0002b106
[0m14:00:03.075456 [debug] [Thread-2 (]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 11 at position 4
invalid identifier 'ORDER_ID'
[0m14:00:03.076094 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_order_id.c6a1813fa7 (execute): 2025-11-16 13:59:55.974318 => 2025-11-16 14:00:03.075971
[0m14:00:03.076485 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_customers_order_id.c6a1813fa7: Close
[0m14:00:03.921616 [debug] [Thread-2 (]: Database Error in test unique_stg_customers_order_id (models/staging/schema.yml)
  000904 (42000): SQL compilation error: error line 11 at position 4
  invalid identifier 'ORDER_ID'
  compiled Code at target/run/airflow_dbt_project/models/staging/schema.yml/unique_stg_customers_order_id.sql
[0m14:00:03.922263 [error] [Thread-2 (]: 4 of 5 ERROR unique_stg_customers_order_id ..................................... [[31mERROR[0m in 7.96s]
[0m14:00:03.922867 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_customers_order_id.c6a1813fa7
[0m14:00:03.923362 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:00:03.923992 [info ] [Thread-2 (]: 5 of 5 START test unique_stg_orders_order_id ................................... [RUN]
[0m14:00:03.925020 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m14:00:03.925394 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:00:03.932070 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:00:03.932863 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 14:00:03.925621 => 2025-11-16 14:00:03.932747
[0m14:00:03.933266 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:00:03.936896 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:00:03.938247 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:00:03.938590 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:00:03.938864 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:00:05.297537 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 10 seconds
[0m14:00:05.302210 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (execute): 2025-11-16 13:59:55.543575 => 2025-11-16 14:00:05.302053
[0m14:00:05.302736 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: Close
[0m14:00:05.510500 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:00:05.513138 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 14:00:03.933495 => 2025-11-16 14:00:05.513036
[0m14:00:05.513472 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m14:00:05.963403 [error] [Thread-1 (]: 3 of 5 FAIL 5 relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [[31mFAIL 5[0m in 10.48s]
[0m14:00:05.966046 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:00:06.263953 [info ] [Thread-2 (]: 5 of 5 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 2.34s]
[0m14:00:06.264685 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:00:06.267437 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:00:06.268490 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:00:06.268845 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500' was properly closed.
[0m14:00:06.269159 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m14:00:06.269495 [info ] [MainThread]: 
[0m14:00:06.269940 [info ] [MainThread]: Finished running 5 tests in 0 hours 0 minutes and 28.65 seconds (28.65s).
[0m14:00:06.270730 [debug] [MainThread]: Command end result
[0m14:00:06.286542 [info ] [MainThread]: 
[0m14:00:06.287895 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m14:00:06.289086 [info ] [MainThread]: 
[0m14:00:06.290180 [error] [MainThread]: [33mDatabase Error in test not_null_stg_customers_order_id (models/staging/schema.yml)[0m
[0m14:00:06.291638 [error] [MainThread]:   000904 (42000): SQL compilation error: error line 12 at position 7
[0m14:00:06.292584 [error] [MainThread]:   invalid identifier 'ORDER_ID'
[0m14:00:06.294177 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/schema.yml/not_null_stg_customers_order_id.sql
[0m14:00:06.295431 [info ] [MainThread]: 
[0m14:00:06.296624 [error] [MainThread]: [33mDatabase Error in test unique_stg_customers_order_id (models/staging/schema.yml)[0m
[0m14:00:06.297662 [error] [MainThread]:   000904 (42000): SQL compilation error: error line 11 at position 4
[0m14:00:06.298692 [error] [MainThread]:   invalid identifier 'ORDER_ID'
[0m14:00:06.299697 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/schema.yml/unique_stg_customers_order_id.sql
[0m14:00:06.300972 [info ] [MainThread]: 
[0m14:00:06.302488 [error] [MainThread]: [31mFailure in test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_ (models/staging/schema.yml)[0m
[0m14:00:06.303509 [error] [MainThread]:   Got 5 results, configured to fail if != 0
[0m14:00:06.304226 [info ] [MainThread]: 
[0m14:00:06.304855 [info ] [MainThread]:   compiled Code at target/compiled/airflow_dbt_project/models/staging/schema.yml/relationships_stg_orders_96411fe0c89b49c3f4da955dfd358ba0.sql
[0m14:00:06.305493 [info ] [MainThread]: 
[0m14:00:06.306618 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=3 SKIP=0 TOTAL=5
[0m14:00:06.308135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c1f8bfec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c1de4f380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c1f3aff20>]}
[0m14:00:06.309043 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:04:30.631420 | 0eda1993-be76-4c91-bd54-bad5bb407b23 ==============================
[0m14:04:30.631420 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:04:30.634540 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m14:04:30.634964 [debug] [MainThread]: Tracking: tracking
[0m14:04:30.635392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb1f2814380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb1f218f110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb1f1d6a660>]}
[0m14:04:30.706061 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:04:30.707376 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/schema.yml
[0m14:04:30.733125 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:04:30.817574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0eda1993-be76-4c91-bd54-bad5bb407b23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb1f1d90410>]}
[0m14:04:30.832236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0eda1993-be76-4c91-bd54-bad5bb407b23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb1f1dae9f0>]}
[0m14:04:30.833012 [info ] [MainThread]: Found 6 models, 5 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:04:30.833731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0eda1993-be76-4c91-bd54-bad5bb407b23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb1f25c0470>]}
[0m14:04:30.837098 [info ] [MainThread]: 
[0m14:04:30.841358 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:04:30.844475 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m14:04:30.851693 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:04:30.908294 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m14:04:30.909480 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:04:30.910049 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m14:04:30.910538 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:04:30.910990 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:04:30.911425 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:04:33.069685 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m14:04:33.077314 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:04:33.220438 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m14:04:33.227085 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m14:04:33.611593 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m14:04:33.639437 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m14:04:33.641844 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m14:04:33.643067 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:04:35.205649 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 2 seconds
[0m14:04:35.208445 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m14:04:36.472614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0eda1993-be76-4c91-bd54-bad5bb407b23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb1f81c4590>]}
[0m14:04:36.473851 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:04:36.474360 [info ] [MainThread]: 
[0m14:04:36.519535 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:04:36.520407 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:04:36.520952 [info ] [Thread-1 (]: 1 of 5 START test not_null_stg_customers_customer_id ........................... [RUN]
[0m14:04:36.521762 [info ] [Thread-2 (]: 2 of 5 START test not_null_stg_orders_order_id ................................. [RUN]
[0m14:04:36.523286 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa'
[0m14:04:36.524462 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m14:04:36.525121 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:04:36.525613 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:04:36.575282 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:04:36.576238 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:04:36.576994 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 14:04:36.536356 => 2025-11-16 14:04:36.576864
[0m14:04:36.577433 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (compile): 2025-11-16 14:04:36.525969 => 2025-11-16 14:04:36.577300
[0m14:04:36.577915 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:04:36.578290 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:04:36.677860 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:04:36.683088 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:04:36.686957 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:04:36.688091 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m14:04:36.690255 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:04:36.691374 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:04:36.692473 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where customer_id is null



      
    ) dbt_internal_test
[0m14:04:36.700504 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:04:38.873659 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:04:38.902426 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 14:04:36.578568 => 2025-11-16 14:04:38.902148
[0m14:04:38.903445 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m14:04:39.867808 [info ] [Thread-2 (]: 2 of 5 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 3.34s]
[0m14:04:39.871114 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:04:39.871703 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:04:39.872046 [info ] [Thread-2 (]: 3 of 5 START test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [RUN]
[0m14:04:39.872993 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500'
[0m14:04:39.873486 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:04:39.890000 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:04:39.891188 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (compile): 2025-11-16 14:04:39.873686 => 2025-11-16 14:04:39.890978
[0m14:04:39.891797 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:04:39.897373 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:04:39.900124 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:04:39.900848 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select customer_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where customer_id is not null
),

parent as (
    select customer_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m14:04:39.901393 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:04:41.697750 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 5 seconds
[0m14:04:41.706370 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (execute): 2025-11-16 14:04:36.589125 => 2025-11-16 14:04:41.706089
[0m14:04:41.707371 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa: Close
[0m14:04:42.410495 [info ] [Thread-1 (]: 1 of 5 PASS not_null_stg_customers_customer_id ................................. [[32mPASS[0m in 5.89s]
[0m14:04:42.411366 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:04:42.412292 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:04:42.413069 [info ] [Thread-1 (]: 4 of 5 START test unique_stg_customers_customer_id ............................. [RUN]
[0m14:04:42.414128 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada'
[0m14:04:42.414469 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:04:42.427202 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:04:42.428188 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (compile): 2025-11-16 14:04:42.414680 => 2025-11-16 14:04:42.428043
[0m14:04:42.428735 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:04:42.434066 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:04:42.437111 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:04:42.438011 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:04:42.438647 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:04:44.053426 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:04:44.056545 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (execute): 2025-11-16 14:04:42.429045 => 2025-11-16 14:04:44.056436
[0m14:04:44.056922 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada: Close
[0m14:04:44.686534 [info ] [Thread-1 (]: 4 of 5 PASS unique_stg_customers_customer_id ................................... [[32mPASS[0m in 2.27s]
[0m14:04:44.687388 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:04:44.688103 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:04:44.688518 [info ] [Thread-1 (]: 5 of 5 START test unique_stg_orders_order_id ................................... [RUN]
[0m14:04:44.689732 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m14:04:44.690107 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:04:44.696328 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:04:44.697074 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 14:04:44.690325 => 2025-11-16 14:04:44.696959
[0m14:04:44.697554 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:04:44.701835 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:04:44.703409 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:04:44.703814 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:04:44.704144 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:04:46.226403 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:04:46.230330 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 14:04:44.697818 => 2025-11-16 14:04:46.230213
[0m14:04:46.230737 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m14:04:47.498714 [info ] [Thread-1 (]: 5 of 5 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 2.81s]
[0m14:04:47.499660 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:04:47.749469 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 8 seconds
[0m14:04:47.753087 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (execute): 2025-11-16 14:04:39.892154 => 2025-11-16 14:04:47.752969
[0m14:04:47.753486 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: Close
[0m14:04:48.852252 [error] [Thread-2 (]: 3 of 5 FAIL 5 relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [[31mFAIL 5[0m in 8.98s]
[0m14:04:48.853001 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:04:48.855417 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:04:48.856294 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:04:48.856575 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500' was properly closed.
[0m14:04:48.856795 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m14:04:48.857071 [info ] [MainThread]: 
[0m14:04:48.857444 [info ] [MainThread]: Finished running 5 tests in 0 hours 0 minutes and 18.02 seconds (18.02s).
[0m14:04:48.858137 [debug] [MainThread]: Command end result
[0m14:04:48.873361 [info ] [MainThread]: 
[0m14:04:48.874527 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:04:48.875450 [info ] [MainThread]: 
[0m14:04:48.876326 [error] [MainThread]: [31mFailure in test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_ (models/staging/schema.yml)[0m
[0m14:04:48.877103 [error] [MainThread]:   Got 5 results, configured to fail if != 0
[0m14:04:48.877861 [info ] [MainThread]: 
[0m14:04:48.878682 [info ] [MainThread]:   compiled Code at target/compiled/airflow_dbt_project/models/staging/schema.yml/relationships_stg_orders_96411fe0c89b49c3f4da955dfd358ba0.sql
[0m14:04:48.879441 [info ] [MainThread]: 
[0m14:04:48.880108 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m14:04:48.880991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb1f1ca7260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb1f1ca7680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb1f1ca76e0>]}
[0m14:04:48.881638 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:06:41.118433 | 921e0ae1-9f2b-4d8e-9799-5a490c9698f6 ==============================
[0m14:06:41.118433 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:06:41.121477 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m14:06:41.121798 [debug] [MainThread]: Tracking: tracking
[0m14:06:41.122159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01406dc1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0140c75b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01406deab0>]}
[0m14:06:41.179942 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:06:41.180372 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:06:41.191137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '921e0ae1-9f2b-4d8e-9799-5a490c9698f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0142060fe0>]}
[0m14:06:41.202554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '921e0ae1-9f2b-4d8e-9799-5a490c9698f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01407323c0>]}
[0m14:06:41.203123 [info ] [MainThread]: Found 6 models, 5 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:06:41.203542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '921e0ae1-9f2b-4d8e-9799-5a490c9698f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0140974d70>]}
[0m14:06:41.205983 [info ] [MainThread]: 
[0m14:06:41.209010 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:06:41.211060 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m14:06:41.218126 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m14:06:41.266647 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m14:06:41.267574 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m14:06:41.268036 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m14:06:41.268623 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m14:06:41.269209 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:06:41.269730 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:06:44.667806 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 3 seconds
[0m14:06:44.669062 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 3 seconds
[0m14:06:44.672066 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m14:06:44.674945 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m14:06:45.327562 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:06:45.334452 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:06:45.334834 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:06:45.335137 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:06:46.956531 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m14:06:46.960169 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:06:48.324294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '921e0ae1-9f2b-4d8e-9799-5a490c9698f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0140733b00>]}
[0m14:06:48.325682 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:06:48.326309 [info ] [MainThread]: 
[0m14:06:48.373664 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:06:48.374709 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:06:48.375451 [info ] [Thread-1 (]: 1 of 5 START test not_null_stg_customers_customer_id ........................... [RUN]
[0m14:06:48.376526 [info ] [Thread-2 (]: 2 of 5 START test not_null_stg_orders_order_id ................................. [RUN]
[0m14:06:48.378373 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa'
[0m14:06:48.379655 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m14:06:48.380338 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:06:48.380894 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:06:48.431043 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:06:48.429413 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:06:48.432173 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (compile): 2025-11-16 14:06:48.381275 => 2025-11-16 14:06:48.432060
[0m14:06:48.432517 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:06:48.432862 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 14:06:48.392102 => 2025-11-16 14:06:48.432741
[0m14:06:48.444513 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:06:48.471998 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:06:48.473050 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:06:48.473897 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:06:48.474141 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m14:06:48.474324 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:06:48.474980 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:06:48.475255 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where customer_id is null



      
    ) dbt_internal_test
[0m14:06:48.475488 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:06:49.978723 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:06:49.980359 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:06:49.993256 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (execute): 2025-11-16 14:06:48.433165 => 2025-11-16 14:06:49.993159
[0m14:06:49.993589 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa: Close
[0m14:06:49.995353 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 14:06:48.450038 => 2025-11-16 14:06:49.995257
[0m14:06:49.996753 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m14:06:50.986270 [info ] [Thread-2 (]: 2 of 5 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 2.61s]
[0m14:06:50.988193 [info ] [Thread-1 (]: 1 of 5 PASS not_null_stg_customers_customer_id ................................. [[32mPASS[0m in 2.61s]
[0m14:06:50.991340 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:06:50.991971 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:06:50.992579 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:06:50.993389 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:06:50.993931 [info ] [Thread-2 (]: 3 of 5 START test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [RUN]
[0m14:06:50.994566 [info ] [Thread-1 (]: 4 of 5 START test unique_stg_customers_customer_id ............................. [RUN]
[0m14:06:50.995686 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500'
[0m14:06:50.996651 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada'
[0m14:06:50.997117 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:06:50.997538 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:06:51.034386 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:06:51.044677 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:06:51.045765 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (compile): 2025-11-16 14:06:50.998576 => 2025-11-16 14:06:51.045591
[0m14:06:51.046296 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (compile): 2025-11-16 14:06:50.997846 => 2025-11-16 14:06:51.046175
[0m14:06:51.047021 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:06:51.047652 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:06:51.058263 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:06:51.062049 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:06:51.063895 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:06:51.064377 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:06:51.064674 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:06:51.067499 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:06:51.067907 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select customer_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where customer_id is not null
),

parent as (
    select customer_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m14:06:51.068215 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:06:52.603395 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:06:52.607624 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (execute): 2025-11-16 14:06:51.048075 => 2025-11-16 14:06:52.607506
[0m14:06:52.608036 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada: Close
[0m14:06:52.689481 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:06:52.692780 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (execute): 2025-11-16 14:06:51.058786 => 2025-11-16 14:06:52.692658
[0m14:06:52.693211 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: Close
[0m14:06:53.308263 [info ] [Thread-1 (]: 4 of 5 PASS unique_stg_customers_customer_id ................................... [[32mPASS[0m in 2.31s]
[0m14:06:53.309077 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:06:53.309697 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:06:53.310088 [info ] [Thread-1 (]: 5 of 5 START test unique_stg_orders_order_id ................................... [RUN]
[0m14:06:53.311350 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m14:06:53.312981 [error] [Thread-2 (]: 3 of 5 FAIL 5 relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [[31mFAIL 5[0m in 2.32s]
[0m14:06:53.313577 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:06:53.314208 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:06:53.321750 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:06:53.323020 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 14:06:53.314665 => 2025-11-16 14:06:53.322840
[0m14:06:53.323570 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:06:53.329396 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:06:53.331121 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:06:53.331589 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:06:53.331944 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:06:55.021077 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:06:55.025215 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 14:06:53.323938 => 2025-11-16 14:06:55.025087
[0m14:06:55.025642 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m14:06:55.936203 [info ] [Thread-1 (]: 5 of 5 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 2.63s]
[0m14:06:55.937024 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:06:55.939848 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:06:55.940894 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:06:55.941232 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500' was properly closed.
[0m14:06:55.941486 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m14:06:55.941794 [info ] [MainThread]: 
[0m14:06:55.942262 [info ] [MainThread]: Finished running 5 tests in 0 hours 0 minutes and 14.74 seconds (14.74s).
[0m14:06:55.943042 [debug] [MainThread]: Command end result
[0m14:06:55.957223 [info ] [MainThread]: 
[0m14:06:55.958433 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:06:55.959657 [info ] [MainThread]: 
[0m14:06:55.960501 [error] [MainThread]: [31mFailure in test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_ (models/staging/schema.yml)[0m
[0m14:06:55.961172 [error] [MainThread]:   Got 5 results, configured to fail if != 0
[0m14:06:55.961753 [info ] [MainThread]: 
[0m14:06:55.962496 [info ] [MainThread]:   compiled Code at target/compiled/airflow_dbt_project/models/staging/schema.yml/relationships_stg_orders_96411fe0c89b49c3f4da955dfd358ba0.sql
[0m14:06:55.963259 [info ] [MainThread]: 
[0m14:06:55.964079 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m14:06:55.965623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01405090d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01413d3920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f014020bd40>]}
[0m14:06:55.966937 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:08:13.742579 | 28fb961c-51f9-4c0f-8cf2-01d2ac21f795 ==============================
[0m14:08:13.742579 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:08:13.744554 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m14:08:13.744790 [debug] [MainThread]: Tracking: tracking
[0m14:08:13.745055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8def29d220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8def4df6b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8df4a99790>]}
[0m14:08:13.799144 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:08:13.799609 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:08:13.811212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '28fb961c-51f9-4c0f-8cf2-01d2ac21f795', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8defbc7950>]}
[0m14:08:13.822445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '28fb961c-51f9-4c0f-8cf2-01d2ac21f795', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8df42725a0>]}
[0m14:08:13.823039 [info ] [MainThread]: Found 6 models, 5 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:08:13.823463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '28fb961c-51f9-4c0f-8cf2-01d2ac21f795', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8defb43830>]}
[0m14:08:13.826011 [info ] [MainThread]: 
[0m14:08:13.829322 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:08:13.831671 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m14:08:13.839176 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:08:13.884286 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:08:13.884720 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:08:13.891690 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:08:13.892512 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m14:08:13.894898 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m14:08:13.895276 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:08:15.741066 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 2 seconds
[0m14:08:15.746130 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m14:08:16.045063 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m14:08:16.047480 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:08:16.227906 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m14:08:16.234817 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m14:08:16.235248 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m14:08:16.235555 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:08:18.019121 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m14:08:18.022568 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m14:08:18.537939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '28fb961c-51f9-4c0f-8cf2-01d2ac21f795', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfe9fba70>]}
[0m14:08:18.539221 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:08:18.539807 [info ] [MainThread]: 
[0m14:08:18.593235 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:08:18.594034 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:08:18.594667 [info ] [Thread-1 (]: 1 of 5 START test not_null_stg_customers_customer_id ........................... [RUN]
[0m14:08:18.595474 [info ] [Thread-2 (]: 2 of 5 START test not_null_stg_orders_order_id ................................. [RUN]
[0m14:08:18.597001 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa'
[0m14:08:18.598449 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m14:08:18.599121 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:08:18.599755 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:08:18.658251 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:08:18.657610 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:08:18.659380 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (compile): 2025-11-16 14:08:18.600222 => 2025-11-16 14:08:18.659187
[0m14:08:18.659905 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:08:18.671514 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 14:08:18.610647 => 2025-11-16 14:08:18.671339
[0m14:08:18.677361 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:08:18.721206 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:08:18.725238 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:08:18.726755 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:08:18.727228 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m14:08:18.727546 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:08:18.728360 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:08:18.728798 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where customer_id is null



      
    ) dbt_internal_test
[0m14:08:18.730180 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:08:20.053999 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:08:20.067720 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 14:08:18.683009 => 2025-11-16 14:08:20.067565
[0m14:08:20.068255 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m14:08:20.623137 [info ] [Thread-2 (]: 2 of 5 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 2.03s]
[0m14:08:20.625427 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:08:20.625935 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:08:20.626486 [info ] [Thread-2 (]: 3 of 5 START test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [RUN]
[0m14:08:20.627415 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500'
[0m14:08:20.627741 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:08:20.644107 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:08:20.645229 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (compile): 2025-11-16 14:08:20.627991 => 2025-11-16 14:08:20.645061
[0m14:08:20.645822 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:08:20.656073 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:08:20.658682 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:08:20.659264 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select customer_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where customer_id is not null
),

parent as (
    select customer_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m14:08:20.659610 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:08:22.072272 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:08:22.075007 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (execute): 2025-11-16 14:08:20.646255 => 2025-11-16 14:08:22.074907
[0m14:08:22.075387 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: Close
[0m14:08:22.698671 [error] [Thread-2 (]: 3 of 5 FAIL 5 relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [[31mFAIL 5[0m in 2.07s]
[0m14:08:22.699591 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:08:22.700323 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:08:22.700923 [info ] [Thread-2 (]: 4 of 5 START test unique_stg_customers_customer_id ............................. [RUN]
[0m14:08:22.702052 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada'
[0m14:08:22.702442 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:08:22.715693 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:08:22.716627 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (compile): 2025-11-16 14:08:22.702667 => 2025-11-16 14:08:22.716472
[0m14:08:22.717143 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:08:22.721894 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:08:22.723990 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:08:22.724963 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:08:22.725405 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:08:24.100270 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:08:24.104008 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (execute): 2025-11-16 14:08:22.717442 => 2025-11-16 14:08:24.103886
[0m14:08:24.104419 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada: Close
[0m14:08:24.596491 [info ] [Thread-2 (]: 4 of 5 PASS unique_stg_customers_customer_id ................................... [[32mPASS[0m in 1.89s]
[0m14:08:24.597525 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:08:24.598274 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:08:24.598850 [info ] [Thread-2 (]: 5 of 5 START test unique_stg_orders_order_id ................................... [RUN]
[0m14:08:24.599912 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m14:08:24.600292 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:08:24.608517 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:08:24.609449 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 14:08:24.600521 => 2025-11-16 14:08:24.609297
[0m14:08:24.609955 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:08:24.614483 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:08:24.616033 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:08:24.616434 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:08:24.616709 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:08:25.722023 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:08:25.725351 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 14:08:24.610242 => 2025-11-16 14:08:25.725232
[0m14:08:25.725771 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m14:08:26.262435 [info ] [Thread-2 (]: 5 of 5 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 1.66s]
[0m14:08:26.263361 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:08:28.556815 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 10 seconds
[0m14:08:28.559519 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (execute): 2025-11-16 14:08:18.660183 => 2025-11-16 14:08:28.559421
[0m14:08:28.559880 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa: Close
[0m14:08:29.733018 [info ] [Thread-1 (]: 1 of 5 PASS not_null_stg_customers_customer_id ................................. [[32mPASS[0m in 11.14s]
[0m14:08:29.733695 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:08:29.736446 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:08:29.737425 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:08:29.737767 [debug] [MainThread]: Connection 'test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa' was properly closed.
[0m14:08:29.738063 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m14:08:29.738405 [info ] [MainThread]: 
[0m14:08:29.738832 [info ] [MainThread]: Finished running 5 tests in 0 hours 0 minutes and 15.91 seconds (15.91s).
[0m14:08:29.739720 [debug] [MainThread]: Command end result
[0m14:08:29.753859 [info ] [MainThread]: 
[0m14:08:29.754964 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:08:29.755599 [info ] [MainThread]: 
[0m14:08:29.756170 [error] [MainThread]: [31mFailure in test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_ (models/staging/schema.yml)[0m
[0m14:08:29.756724 [error] [MainThread]:   Got 5 results, configured to fail if != 0
[0m14:08:29.757241 [info ] [MainThread]: 
[0m14:08:29.757800 [info ] [MainThread]:   compiled Code at target/compiled/airflow_dbt_project/models/staging/schema.yml/relationships_stg_orders_96411fe0c89b49c3f4da955dfd358ba0.sql
[0m14:08:29.758276 [info ] [MainThread]: 
[0m14:08:29.758663 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m14:08:29.759350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8def239430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8deefe4c20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfe9b3ad0>]}
[0m14:08:29.759958 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:11:07.787203 | bd962ab6-659a-49c7-8935-f96956e66461 ==============================
[0m14:11:07.787203 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:11:07.789519 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m14:11:07.789784 [debug] [MainThread]: Tracking: tracking
[0m14:11:07.790086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe536163050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe536125220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe535f0b620>]}
[0m14:11:07.842147 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:11:07.842601 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:11:07.854318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bd962ab6-659a-49c7-8935-f96956e66461', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe536c31d90>]}
[0m14:11:07.867606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bd962ab6-659a-49c7-8935-f96956e66461', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe536163050>]}
[0m14:11:07.868308 [info ] [MainThread]: Found 6 models, 5 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:11:07.868794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bd962ab6-659a-49c7-8935-f96956e66461', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe535fc9fa0>]}
[0m14:11:07.871359 [info ] [MainThread]: 
[0m14:11:07.875022 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:11:07.877949 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:11:07.885121 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m14:11:07.939495 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:11:07.940628 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m14:11:07.941124 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:11:07.941574 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m14:11:07.941994 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:11:07.942463 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:11:09.686719 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 2 seconds
[0m14:11:09.692059 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m14:11:09.698947 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m14:11:09.704521 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:11:10.191966 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m14:11:10.197840 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m14:11:10.198226 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m14:11:10.198508 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:11:11.683740 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m14:11:11.687237 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m14:11:12.190574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bd962ab6-659a-49c7-8935-f96956e66461', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe534d24dd0>]}
[0m14:11:12.191978 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:11:12.192534 [info ] [MainThread]: 
[0m14:11:12.237272 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:11:12.237980 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:11:12.238461 [info ] [Thread-1 (]: 1 of 3 START test not_null_stg_orders_order_id ................................. [RUN]
[0m14:11:12.239237 [info ] [Thread-2 (]: 2 of 3 START test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [RUN]
[0m14:11:12.240647 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m14:11:12.241774 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500'
[0m14:11:12.242323 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:11:12.242802 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:11:12.288824 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:11:12.289561 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:11:12.290359 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (compile): 2025-11-16 14:11:12.254334 => 2025-11-16 14:11:12.290240
[0m14:11:12.290749 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:11:12.301482 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 14:11:12.243118 => 2025-11-16 14:11:12.301366
[0m14:11:12.307089 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:11:12.321179 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:11:12.323904 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:11:12.325211 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:11:12.325507 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select customer_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where customer_id is not null
),

parent as (
    select customer_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m14:11:12.325720 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:11:12.327380 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:11:12.327660 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m14:11:12.329105 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:11:13.356329 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:11:13.371036 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 14:11:12.312584 => 2025-11-16 14:11:13.370891
[0m14:11:13.371535 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m14:11:13.559241 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:11:13.561815 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (execute): 2025-11-16 14:11:12.291023 => 2025-11-16 14:11:13.561718
[0m14:11:13.562156 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: Close
[0m14:11:13.881734 [info ] [Thread-1 (]: 1 of 3 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 1.64s]
[0m14:11:13.884614 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:11:13.885230 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:11:13.885619 [info ] [Thread-1 (]: 3 of 3 START test unique_stg_orders_order_id ................................... [RUN]
[0m14:11:13.886844 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m14:11:13.887255 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:11:13.901862 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:11:13.903221 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 14:11:13.887557 => 2025-11-16 14:11:13.903007
[0m14:11:13.903977 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:11:13.914272 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:11:13.916222 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:11:13.916893 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:11:13.917369 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:11:14.072312 [error] [Thread-2 (]: 2 of 3 FAIL 5 relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [[31mFAIL 5[0m in 1.83s]
[0m14:11:14.073620 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:11:15.067210 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:11:15.072259 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 14:11:13.904770 => 2025-11-16 14:11:15.072075
[0m14:11:15.072900 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m14:11:15.784000 [info ] [Thread-1 (]: 3 of 3 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 1.90s]
[0m14:11:15.784828 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:11:15.787685 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:11:15.788599 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:11:15.788970 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500' was properly closed.
[0m14:11:15.789255 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m14:11:15.789566 [info ] [MainThread]: 
[0m14:11:15.789966 [info ] [MainThread]: Finished running 3 tests in 0 hours 0 minutes and 7.92 seconds (7.92s).
[0m14:11:15.790579 [debug] [MainThread]: Command end result
[0m14:11:15.801725 [info ] [MainThread]: 
[0m14:11:15.802419 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:11:15.802939 [info ] [MainThread]: 
[0m14:11:15.803443 [error] [MainThread]: [31mFailure in test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_ (models/staging/schema.yml)[0m
[0m14:11:15.803904 [error] [MainThread]:   Got 5 results, configured to fail if != 0
[0m14:11:15.804366 [info ] [MainThread]: 
[0m14:11:15.804818 [info ] [MainThread]:   compiled Code at target/compiled/airflow_dbt_project/models/staging/schema.yml/relationships_stg_orders_96411fe0c89b49c3f4da955dfd358ba0.sql
[0m14:11:15.805347 [info ] [MainThread]: 
[0m14:11:15.806134 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m14:11:15.807339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5360a3560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe534c7a1b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe535ffde20>]}
[0m14:11:15.808210 [debug] [MainThread]: Flushing usage events
[0m14:11:19.821274 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.


============================== 2025-11-16 14:11:34.694096 | 2b0aadef-ee05-48d4-a03f-21cf19ba6ea8 ==============================
[0m14:11:34.694096 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:11:34.696091 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_customers'], 'which': 'test', 'rpc_method': 'test'}
[0m14:11:34.696359 [debug] [MainThread]: Tracking: tracking
[0m14:11:34.696623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8be1d15df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8be17dbe60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8be16636e0>]}
[0m14:11:34.746437 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:11:34.746855 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:11:34.757321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2b0aadef-ee05-48d4-a03f-21cf19ba6ea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8be1ecfd40>]}
[0m14:11:34.768313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2b0aadef-ee05-48d4-a03f-21cf19ba6ea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8be18b2ea0>]}
[0m14:11:34.768861 [info ] [MainThread]: Found 6 models, 5 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:11:34.769313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2b0aadef-ee05-48d4-a03f-21cf19ba6ea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8be1766cc0>]}
[0m14:11:34.771527 [info ] [MainThread]: 
[0m14:11:34.775340 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:11:34.778599 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:11:34.780190 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m14:11:34.833665 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m14:11:34.834201 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m14:11:34.834559 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:11:34.837220 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:11:34.837756 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:11:34.840785 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:11:36.476703 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m14:11:36.480172 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:11:36.506920 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m14:11:36.509204 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m14:11:37.190192 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m14:11:37.196620 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m14:11:37.197021 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m14:11:37.197303 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:11:38.983741 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 2 seconds
[0m14:11:38.990061 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m14:11:41.068579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2b0aadef-ee05-48d4-a03f-21cf19ba6ea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8be1534650>]}
[0m14:11:41.069964 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:11:41.070444 [info ] [MainThread]: 
[0m14:11:41.107006 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:11:41.107563 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:11:41.108038 [info ] [Thread-1 (]: 1 of 3 START test not_null_stg_customers_customer_id ........................... [RUN]
[0m14:11:41.108596 [info ] [Thread-2 (]: 2 of 3 START test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [RUN]
[0m14:11:41.109720 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa'
[0m14:11:41.110673 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500'
[0m14:11:41.111197 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:11:41.111614 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:11:41.160250 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:11:41.161020 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:11:41.162162 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (compile): 2025-11-16 14:11:41.117281 => 2025-11-16 14:11:41.161980
[0m14:11:41.162720 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:11:41.173700 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (compile): 2025-11-16 14:11:41.112009 => 2025-11-16 14:11:41.173444
[0m14:11:41.180975 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:11:41.242073 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:11:41.243117 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:11:41.244758 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:11:41.245229 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select customer_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where customer_id is not null
),

parent as (
    select customer_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m14:11:41.245518 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:11:41.246512 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:11:41.246959 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where customer_id is null



      
    ) dbt_internal_test
[0m14:11:41.247267 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:11:42.453135 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:11:42.480570 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (execute): 2025-11-16 14:11:41.186722 => 2025-11-16 14:11:42.480190
[0m14:11:42.481684 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa: Close
[0m14:11:42.786264 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:11:42.793852 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (execute): 2025-11-16 14:11:41.163036 => 2025-11-16 14:11:42.793597
[0m14:11:42.794787 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: Close
[0m14:11:43.308808 [info ] [Thread-1 (]: 1 of 3 PASS not_null_stg_customers_customer_id ................................. [[32mPASS[0m in 2.20s]
[0m14:11:43.313618 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:11:43.314940 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:11:43.316101 [info ] [Thread-1 (]: 3 of 3 START test unique_stg_customers_customer_id ............................. [RUN]
[0m14:11:43.317956 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada'
[0m14:11:43.318635 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:11:43.339934 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:11:43.341732 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (compile): 2025-11-16 14:11:43.319025 => 2025-11-16 14:11:43.341407
[0m14:11:43.342959 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:11:43.357840 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:11:43.361962 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:11:43.363276 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:11:43.364161 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:11:43.566148 [error] [Thread-2 (]: 2 of 3 FAIL 5 relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [[31mFAIL 5[0m in 2.46s]
[0m14:11:43.569432 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:11:46.315809 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m14:11:46.325647 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (execute): 2025-11-16 14:11:43.343557 => 2025-11-16 14:11:46.325351
[0m14:11:46.326761 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada: Close
[0m14:11:47.212507 [info ] [Thread-1 (]: 3 of 3 PASS unique_stg_customers_customer_id ................................... [[32mPASS[0m in 3.90s]
[0m14:11:47.214571 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:11:47.222062 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:11:47.225381 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:11:47.226656 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada' was properly closed.
[0m14:11:47.227753 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500' was properly closed.
[0m14:11:47.228692 [info ] [MainThread]: 
[0m14:11:47.230316 [info ] [MainThread]: Finished running 3 tests in 0 hours 0 minutes and 12.46 seconds (12.46s).
[0m14:11:47.232590 [debug] [MainThread]: Command end result
[0m14:11:47.262610 [info ] [MainThread]: 
[0m14:11:47.264559 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:11:47.266438 [info ] [MainThread]: 
[0m14:11:47.268214 [error] [MainThread]: [31mFailure in test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_ (models/staging/schema.yml)[0m
[0m14:11:47.269837 [error] [MainThread]:   Got 5 results, configured to fail if != 0
[0m14:11:47.271272 [info ] [MainThread]: 
[0m14:11:47.272670 [info ] [MainThread]:   compiled Code at target/compiled/airflow_dbt_project/models/staging/schema.yml/relationships_stg_orders_96411fe0c89b49c3f4da955dfd358ba0.sql
[0m14:11:47.274863 [info ] [MainThread]: 
[0m14:11:47.276699 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m14:11:47.278780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8be1d123f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8c01de8800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8be1d16b10>]}
[0m14:11:47.280702 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:16:33.088497 | 7fa92faf-dec8-402a-bda9-d3ee7643ca72 ==============================
[0m14:16:33.088497 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:16:33.091446 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_customers'], 'which': 'test', 'rpc_method': 'test'}
[0m14:16:33.091797 [debug] [MainThread]: Tracking: tracking
[0m14:16:33.092189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4087441f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4087443890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4087443ad0>]}
[0m14:16:33.109640 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:16:33.110402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7fa92faf-dec8-402a-bda9-d3ee7643ca72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f408d759190>]}
[0m14:16:33.846032 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m14:16:33.859890 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m14:16:33.863136 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:16:33.866328 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m14:16:33.869747 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/dim_customers.sql
[0m14:16:33.872614 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m14:16:33.955266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f408738b410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f408738b7a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f408738b770>]}
[0m14:16:33.955666 [debug] [MainThread]: Flushing usage events
[0m14:16:35.106073 [error] [MainThread]: Encountered an error:
[Errno 13] Permission denied: '/opt/airflow/dbt/target/partial_parse.msgpack'
[0m14:16:35.110113 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/main.py", line 135, in main
    results, succeeded = handle_and_check(args)
                         ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/main.py", line 198, in handle_and_check
    task, res = run_from_args(parsed)
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/main.py", line 245, in run_from_args
    results = task.run()
              ^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/runnable.py", line 454, in run
    self._runtime_initialize()
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/runnable.py", line 165, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/runnable.py", line 94, in _runtime_initialize
    self.load_manifest()
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/runnable.py", line 81, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/parser/manifest.py", line 203, in get_full_manifest
    manifest = loader.load()
               ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/parser/manifest.py", line 398, in load
    self.write_manifest_for_partial_parse()
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/parser/manifest.py", line 549, in write_manifest_for_partial_parse
    with open(path, "wb") as fp:
         ^^^^^^^^^^^^^^^^
PermissionError: [Errno 13] Permission denied: '/opt/airflow/dbt/target/partial_parse.msgpack'



============================== 2025-11-16 14:17:15.912277 | 2c7e8dde-88b8-47d7-a9f9-879bd130b831 ==============================
[0m14:17:15.912277 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:17:15.914575 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m14:17:15.914878 [debug] [MainThread]: Tracking: tracking
[0m14:17:15.915188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedbc41b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedbcb34680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedbcb34260>]}
[0m14:17:15.929521 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:17:15.930134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2c7e8dde-88b8-47d7-a9f9-879bd130b831', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedbc95b6b0>]}
[0m14:17:16.747639 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m14:17:16.764839 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m14:17:16.768485 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:17:16.772015 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m14:17:16.776008 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/dim_customers.sql
[0m14:17:16.779658 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m14:17:16.874338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedb7f579e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedb7f57350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedb7f57740>]}
[0m14:17:16.874769 [debug] [MainThread]: Flushing usage events
[0m14:17:20.882459 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m14:17:20.883599 [error] [MainThread]: Encountered an error:
[Errno 13] Permission denied: '/opt/airflow/dbt/target/partial_parse.msgpack'
[0m14:17:20.887991 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/main.py", line 135, in main
    results, succeeded = handle_and_check(args)
                         ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/main.py", line 198, in handle_and_check
    task, res = run_from_args(parsed)
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/main.py", line 245, in run_from_args
    results = task.run()
              ^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/runnable.py", line 454, in run
    self._runtime_initialize()
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/runnable.py", line 165, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/runnable.py", line 94, in _runtime_initialize
    self.load_manifest()
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/runnable.py", line 81, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/parser/manifest.py", line 203, in get_full_manifest
    manifest = loader.load()
               ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/parser/manifest.py", line 398, in load
    self.write_manifest_for_partial_parse()
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/parser/manifest.py", line 549, in write_manifest_for_partial_parse
    with open(path, "wb") as fp:
         ^^^^^^^^^^^^^^^^
PermissionError: [Errno 13] Permission denied: '/opt/airflow/dbt/target/partial_parse.msgpack'



============================== 2025-11-16 14:22:44.350754 | 79854641-279f-40bd-8031-425f91828fe7 ==============================
[0m14:22:44.350754 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:22:44.352813 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m14:22:44.353137 [debug] [MainThread]: Tracking: tracking
[0m14:22:44.353442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7fd24c320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7ff589790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7fd48ee70>]}
[0m14:22:44.367125 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:22:44.367675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '79854641-279f-40bd-8031-425f91828fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7fda31af0>]}
[0m14:22:45.124794 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m14:22:45.138695 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m14:22:45.141876 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:22:45.144923 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m14:22:45.148103 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/dim_customers.sql
[0m14:22:45.150937 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m14:22:45.241975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '79854641-279f-40bd-8031-425f91828fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7fd159460>]}
[0m14:22:45.249938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '79854641-279f-40bd-8031-425f91828fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7fd15a990>]}
[0m14:22:45.250431 [info ] [MainThread]: Found 6 models, 5 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:22:45.250847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79854641-279f-40bd-8031-425f91828fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7fd1c7fe0>]}
[0m14:22:45.253266 [info ] [MainThread]: 
[0m14:22:45.256274 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:22:45.258570 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:22:45.265353 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m14:22:45.304174 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:22:45.304621 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:22:45.305305 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m14:22:45.305736 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:22:45.306110 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m14:22:45.308073 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:22:47.124950 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m14:22:47.129104 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:22:47.133239 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m14:22:47.135783 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m14:22:47.570096 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m14:22:47.575983 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m14:22:47.576348 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m14:22:47.576612 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:22:49.392252 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 2 seconds
[0m14:22:49.394407 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m14:22:49.908089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79854641-279f-40bd-8031-425f91828fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7fd159460>]}
[0m14:22:49.909636 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:22:49.910253 [info ] [MainThread]: 
[0m14:22:49.973425 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:22:49.974634 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:22:49.975496 [info ] [Thread-1 (]: 1 of 5 START test not_null_stg_customers_customer_id ........................... [RUN]
[0m14:22:49.976769 [info ] [Thread-2 (]: 2 of 5 START test not_null_stg_orders_order_id ................................. [RUN]
[0m14:22:49.979077 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa'
[0m14:22:49.981092 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m14:22:49.982130 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:22:49.983170 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:22:50.044146 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:22:50.045508 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:22:50.047200 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (compile): 2025-11-16 14:22:49.983867 => 2025-11-16 14:22:50.047004
[0m14:22:50.047911 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:22:50.053665 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 14:22:49.994362 => 2025-11-16 14:22:50.053435
[0m14:22:50.059773 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:22:50.102436 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:22:50.103174 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:22:50.104438 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:22:50.105133 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:22:50.105525 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where customer_id is null



      
    ) dbt_internal_test
[0m14:22:50.105860 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m14:22:50.106144 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:22:50.106386 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:22:51.271533 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:22:51.284211 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 14:22:50.065816 => 2025-11-16 14:22:51.284103
[0m14:22:51.284606 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m14:22:51.786289 [info ] [Thread-2 (]: 2 of 5 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 1.81s]
[0m14:22:51.788660 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:22:51.789161 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:22:51.789590 [info ] [Thread-2 (]: 3 of 5 START test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [RUN]
[0m14:22:51.790443 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500'
[0m14:22:51.790721 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:22:51.801475 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:22:51.802581 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (compile): 2025-11-16 14:22:51.790915 => 2025-11-16 14:22:51.802393
[0m14:22:51.803200 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:22:51.808621 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:22:51.811239 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:22:51.811730 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select customer_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where customer_id is not null
),

parent as (
    select customer_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m14:22:51.812064 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:22:53.744576 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:22:53.747128 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (execute): 2025-11-16 14:22:51.803549 => 2025-11-16 14:22:53.747028
[0m14:22:53.747451 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: Close
[0m14:22:54.089220 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 4 seconds
[0m14:22:54.092404 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (execute): 2025-11-16 14:22:50.048279 => 2025-11-16 14:22:54.092291
[0m14:22:54.092842 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa: Close
[0m14:22:54.391352 [error] [Thread-2 (]: 3 of 5 FAIL 5 relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [[31mFAIL 5[0m in 2.60s]
[0m14:22:54.392289 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:22:54.393017 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:22:54.393626 [info ] [Thread-2 (]: 4 of 5 START test unique_stg_customers_customer_id ............................. [RUN]
[0m14:22:54.394997 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada'
[0m14:22:54.395547 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:22:54.420919 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:22:54.422413 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (compile): 2025-11-16 14:22:54.395942 => 2025-11-16 14:22:54.422210
[0m14:22:54.423125 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:22:54.428280 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:22:54.430517 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:22:54.431193 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:22:54.431782 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:22:54.654510 [info ] [Thread-1 (]: 1 of 5 PASS not_null_stg_customers_customer_id ................................. [[32mPASS[0m in 4.68s]
[0m14:22:54.655318 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:22:54.655828 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:22:54.656341 [info ] [Thread-1 (]: 5 of 5 START test unique_stg_orders_order_id ................................... [RUN]
[0m14:22:54.657358 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m14:22:54.657717 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:22:54.665019 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:22:54.665775 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 14:22:54.657963 => 2025-11-16 14:22:54.665672
[0m14:22:54.666204 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:22:54.670214 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:22:54.671506 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:22:54.671837 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:22:54.672136 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:22:55.658008 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:22:55.663243 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (execute): 2025-11-16 14:22:54.423473 => 2025-11-16 14:22:55.663074
[0m14:22:55.663954 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada: Close
[0m14:22:55.999642 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:22:56.004066 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 14:22:54.666440 => 2025-11-16 14:22:56.003935
[0m14:22:56.004524 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m14:22:56.600821 [info ] [Thread-1 (]: 5 of 5 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 1.94s]
[0m14:22:56.601681 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:22:58.649867 [info ] [Thread-2 (]: 4 of 5 PASS unique_stg_customers_customer_id ................................... [[32mPASS[0m in 4.26s]
[0m14:22:58.650415 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:22:58.652529 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:22:58.653298 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:22:58.653563 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada' was properly closed.
[0m14:22:58.653760 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m14:22:58.654011 [info ] [MainThread]: 
[0m14:22:58.654358 [info ] [MainThread]: Finished running 5 tests in 0 hours 0 minutes and 13.40 seconds (13.40s).
[0m14:22:58.654992 [debug] [MainThread]: Command end result
[0m14:22:58.667349 [info ] [MainThread]: 
[0m14:22:58.668555 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:22:58.669450 [info ] [MainThread]: 
[0m14:22:58.670331 [error] [MainThread]: [31mFailure in test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_ (models/staging/schema.yml)[0m
[0m14:22:58.670937 [error] [MainThread]:   Got 5 results, configured to fail if != 0
[0m14:22:58.671501 [info ] [MainThread]: 
[0m14:22:58.672230 [info ] [MainThread]:   compiled Code at target/compiled/airflow_dbt_project/models/staging/schema.yml/relationships_stg_orders_96411fe0c89b49c3f4da955dfd358ba0.sql
[0m14:22:58.672946 [info ] [MainThread]: 
[0m14:22:58.673704 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m14:22:58.675380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7fd15b830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7fd15bb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7fd4f06e0>]}
[0m14:22:58.676539 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:24:23.894674 | 56c18721-4d67-45dd-8dfa-d36fcb7d2ea4 ==============================
[0m14:24:23.894674 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:24:23.896913 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'parse_only': False, 'which': 'compile', 'rpc_method': 'compile', 'indirect_selection': 'eager'}
[0m14:24:23.897185 [debug] [MainThread]: Tracking: tracking
[0m14:24:23.897555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2cd5618b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2cd5dbb30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2be4fc590>]}
[0m14:24:23.911944 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:24:23.912802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '56c18721-4d67-45dd-8dfa-d36fcb7d2ea4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2be2dfc80>]}
[0m14:24:24.661556 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m14:24:24.674754 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m14:24:24.677644 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:24:24.680408 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m14:24:24.683497 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/dim_customers.sql
[0m14:24:24.686110 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m14:24:24.779357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '56c18721-4d67-45dd-8dfa-d36fcb7d2ea4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2be125e20>]}
[0m14:24:24.785613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '56c18721-4d67-45dd-8dfa-d36fcb7d2ea4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2be124cb0>]}
[0m14:24:24.786016 [info ] [MainThread]: Found 6 models, 5 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:24:24.786322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '56c18721-4d67-45dd-8dfa-d36fcb7d2ea4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e4bf9730>]}
[0m14:24:24.788250 [info ] [MainThread]: 
[0m14:24:24.790535 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:24:24.792182 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:24:24.798617 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m14:24:24.839602 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:24:24.839984 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m14:24:24.840397 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:24:24.840776 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m14:24:24.841189 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:24.841511 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:26.509503 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m14:24:26.516762 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:24:27.348693 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m14:24:27.365619 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m14:24:27.366642 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m14:24:27.367369 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:24:28.235951 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 3 seconds
[0m14:24:28.241242 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m14:24:29.234300 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 2 seconds
[0m14:24:29.241026 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m14:24:30.012311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '56c18721-4d67-45dd-8dfa-d36fcb7d2ea4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2be1196a0>]}
[0m14:24:30.013648 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:24:30.014184 [info ] [MainThread]: 
[0m14:24:30.057803 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_customers
[0m14:24:30.058574 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.ord
[0m14:24:30.059646 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_customers'
[0m14:24:30.060592 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.ord'
[0m14:24:30.061139 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_customers
[0m14:24:30.061537 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.ord
[0m14:24:30.065418 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_customers"
[0m14:24:30.067530 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.ord"
[0m14:24:30.068762 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.ord (compile): 2025-11-16 14:24:30.065895 => 2025-11-16 14:24:30.068636
[0m14:24:30.069187 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (compile): 2025-11-16 14:24:30.061853 => 2025-11-16 14:24:30.069084
[0m14:24:30.069558 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.ord
[0m14:24:30.069992 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_customers
[0m14:24:30.070467 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.ord (execute): 2025-11-16 14:24:30.070330 => 2025-11-16 14:24:30.070367
[0m14:24:30.070859 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (execute): 2025-11-16 14:24:30.070787 => 2025-11-16 14:24:30.070802
[0m14:24:30.074417 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.ord
[0m14:24:30.075670 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_customers
[0m14:24:30.076374 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.stg_customers
[0m14:24:30.076984 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_orders
[0m14:24:30.078046 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m14:24:30.078951 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_orders'
[0m14:24:30.079586 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m14:24:30.080175 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_orders
[0m14:24:30.083505 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m14:24:30.087400 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_orders"
[0m14:24:30.088376 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-16 14:24:30.080495 => 2025-11-16 14:24:30.088277
[0m14:24:30.088763 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m14:24:30.089120 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_orders (compile): 2025-11-16 14:24:30.083921 => 2025-11-16 14:24:30.089008
[0m14:24:30.089626 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-16 14:24:30.089499 => 2025-11-16 14:24:30.089521
[0m14:24:30.090093 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_orders
[0m14:24:30.091021 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m14:24:30.091526 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_orders (execute): 2025-11-16 14:24:30.091408 => 2025-11-16 14:24:30.091429
[0m14:24:30.092010 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.test_model
[0m14:24:30.093018 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_orders
[0m14:24:30.094027 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.test_model'
[0m14:24:30.094604 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.cus_orders
[0m14:24:30.095059 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.test_model
[0m14:24:30.095833 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m14:24:30.099147 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.test_model"
[0m14:24:30.099691 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m14:24:30.103479 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m14:24:30.104100 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.test_model (compile): 2025-11-16 14:24:30.096110 => 2025-11-16 14:24:30.103997
[0m14:24:30.104478 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.test_model
[0m14:24:30.104779 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-16 14:24:30.100332 => 2025-11-16 14:24:30.104680
[0m14:24:30.105222 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.test_model (execute): 2025-11-16 14:24:30.105112 => 2025-11-16 14:24:30.105133
[0m14:24:30.105602 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m14:24:30.106471 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.test_model
[0m14:24:30.106866 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-16 14:24:30.106771 => 2025-11-16 14:24:30.106788
[0m14:24:30.107286 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:24:30.108252 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m14:24:30.109449 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa'
[0m14:24:30.110046 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:24:30.110425 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:24:30.111306 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada'
[0m14:24:30.122205 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:24:30.130748 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:24:30.135225 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:24:30.136176 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (compile): 2025-11-16 14:24:30.111617 => 2025-11-16 14:24:30.135982
[0m14:24:30.136506 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:24:30.136736 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (execute): 2025-11-16 14:24:30.136677 => 2025-11-16 14:24:30.136690
[0m14:24:30.137444 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:24:30.137796 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:24:30.138355 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m14:24:30.138648 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (compile): 2025-11-16 14:24:30.122502 => 2025-11-16 14:24:30.138561
[0m14:24:30.139072 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:24:30.139724 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:24:30.144797 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:24:30.145330 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (execute): 2025-11-16 14:24:30.145215 => 2025-11-16 14:24:30.145238
[0m14:24:30.146462 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:24:30.146891 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:24:30.147554 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500'
[0m14:24:30.147849 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:24:30.156155 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:24:30.156839 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 14:24:30.140086 => 2025-11-16 14:24:30.156709
[0m14:24:30.157324 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:24:30.157697 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 14:24:30.157605 => 2025-11-16 14:24:30.157625
[0m14:24:30.158155 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (compile): 2025-11-16 14:24:30.148700 => 2025-11-16 14:24:30.158044
[0m14:24:30.159307 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:24:30.159773 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:24:30.160293 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:24:30.160939 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (execute): 2025-11-16 14:24:30.160814 => 2025-11-16 14:24:30.160834
[0m14:24:30.161813 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m14:24:30.163396 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:24:30.163948 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:24:30.169242 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:24:30.169807 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 14:24:30.164409 => 2025-11-16 14:24:30.169731
[0m14:24:30.170113 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:24:30.170338 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 14:24:30.170282 => 2025-11-16 14:24:30.170293
[0m14:24:30.171054 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:24:30.172504 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:24:30.172764 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500' was properly closed.
[0m14:24:30.172959 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m14:24:30.173607 [debug] [MainThread]: Command end result
[0m14:24:30.181576 [info ] [MainThread]: Done.
[0m14:24:30.182088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2be10d1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2be10ee40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2be44daf0>]}
[0m14:24:30.182412 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:24:45.521996 | 857d6a65-29f0-4465-875b-4f394c354924 ==============================
[0m14:24:45.521996 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:24:45.526688 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m14:24:45.527124 [debug] [MainThread]: Tracking: tracking
[0m14:24:45.527542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a5a6be210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a5a6bc1a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a5a6bfbf0>]}
[0m14:24:45.586066 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:24:45.586552 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:24:45.598704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '857d6a65-29f0-4465-875b-4f394c354924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a5b0c4bf0>]}
[0m14:24:45.612359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '857d6a65-29f0-4465-875b-4f394c354924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a5a702ea0>]}
[0m14:24:45.613022 [info ] [MainThread]: Found 6 models, 5 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:24:45.613496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '857d6a65-29f0-4465-875b-4f394c354924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a5aecb9b0>]}
[0m14:24:45.616332 [info ] [MainThread]: 
[0m14:24:45.619862 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:24:45.622366 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m14:24:45.629442 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:24:45.674706 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m14:24:45.679705 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:24:45.680191 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m14:24:45.680632 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:24:45.681046 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:45.681430 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:47.713861 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m14:24:47.722695 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m14:24:47.735709 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m14:24:47.743735 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:24:48.153267 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m14:24:48.177499 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m14:24:48.178632 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m14:24:48.179705 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:24:49.076364 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 1 seconds
[0m14:24:49.079241 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m14:24:49.518084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '857d6a65-29f0-4465-875b-4f394c354924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a5aa4ecc0>]}
[0m14:24:49.518946 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:24:49.519309 [info ] [MainThread]: 
[0m14:24:49.559838 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:24:49.560563 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:24:49.561042 [info ] [Thread-1 (]: 1 of 5 START test not_null_stg_customers_customer_id ........................... [RUN]
[0m14:24:49.561883 [info ] [Thread-2 (]: 2 of 5 START test not_null_stg_orders_order_id ................................. [RUN]
[0m14:24:49.563243 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa'
[0m14:24:49.564384 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m14:24:49.565079 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:24:49.565615 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:24:49.613181 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:24:49.614091 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:24:49.615080 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (compile): 2025-11-16 14:24:49.566036 => 2025-11-16 14:24:49.614944
[0m14:24:49.615524 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 14:24:49.571313 => 2025-11-16 14:24:49.615401
[0m14:24:49.615968 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:24:49.616367 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:24:49.667339 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:24:49.669122 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:24:49.670471 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:24:49.671327 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:24:49.671626 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m14:24:49.671951 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where customer_id is null



      
    ) dbt_internal_test
[0m14:24:49.672256 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:24:49.672510 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:24:50.663317 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:24:50.675431 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 14:24:49.632202 => 2025-11-16 14:24:50.675303
[0m14:24:50.675862 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m14:24:50.713613 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:24:50.715968 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (execute): 2025-11-16 14:24:49.616661 => 2025-11-16 14:24:50.715885
[0m14:24:50.716258 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa: Close
[0m14:24:51.111789 [info ] [Thread-2 (]: 2 of 5 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 1.55s]
[0m14:24:51.119299 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:24:51.120945 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:24:51.122220 [info ] [Thread-2 (]: 3 of 5 START test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [RUN]
[0m14:24:51.124699 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500'
[0m14:24:51.125648 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:24:51.174857 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:24:51.177008 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (compile): 2025-11-16 14:24:51.126327 => 2025-11-16 14:24:51.176673
[0m14:24:51.178116 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:24:51.191649 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:24:51.187481 [info ] [Thread-1 (]: 1 of 5 PASS not_null_stg_customers_customer_id ................................. [[32mPASS[0m in 1.62s]
[0m14:24:51.194146 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:24:51.198514 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:24:51.200560 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:24:51.202028 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select customer_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where customer_id is not null
),

parent as (
    select customer_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m14:24:51.203418 [info ] [Thread-1 (]: 4 of 5 START test unique_stg_customers_customer_id ............................. [RUN]
[0m14:24:51.205139 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:24:51.207371 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada'
[0m14:24:51.211301 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:24:51.249943 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:24:51.251952 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (compile): 2025-11-16 14:24:51.214626 => 2025-11-16 14:24:51.251610
[0m14:24:51.253139 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:24:51.261938 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:24:51.265092 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:24:51.266378 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:24:51.267055 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:24:53.466829 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:24:53.476150 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (execute): 2025-11-16 14:24:51.253748 => 2025-11-16 14:24:53.475748
[0m14:24:53.477674 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada: Close
[0m14:24:53.498732 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:24:53.506687 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (execute): 2025-11-16 14:24:51.178747 => 2025-11-16 14:24:53.506380
[0m14:24:53.507720 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500: Close
[0m14:24:54.511361 [info ] [Thread-1 (]: 4 of 5 PASS unique_stg_customers_customer_id ................................... [[32mPASS[0m in 3.31s]
[0m14:24:54.512129 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:24:54.512690 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:24:54.513337 [info ] [Thread-1 (]: 5 of 5 START test unique_stg_orders_order_id ................................... [RUN]
[0m14:24:54.514447 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m14:24:54.514889 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:24:54.521643 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:24:54.523536 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 14:24:54.515124 => 2025-11-16 14:24:54.523390
[0m14:24:54.524062 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:24:54.525979 [error] [Thread-2 (]: 3 of 5 FAIL 5 relationships_stg_orders_customer_id__customer_id__ref_stg_customers_  [[31mFAIL 5[0m in 3.40s]
[0m14:24:54.526729 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:24:54.531655 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:24:54.534262 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:24:54.534903 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:24:54.535390 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:24:56.205695 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:24:56.209096 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 14:24:54.524326 => 2025-11-16 14:24:56.208973
[0m14:24:56.209554 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m14:24:56.745779 [info ] [Thread-1 (]: 5 of 5 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 2.23s]
[0m14:24:56.746682 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:24:56.749447 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:24:56.750356 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:24:56.750671 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500' was properly closed.
[0m14:24:56.750931 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m14:24:56.751229 [info ] [MainThread]: 
[0m14:24:56.751610 [info ] [MainThread]: Finished running 5 tests in 0 hours 0 minutes and 11.13 seconds (11.13s).
[0m14:24:56.752395 [debug] [MainThread]: Command end result
[0m14:24:56.767619 [info ] [MainThread]: 
[0m14:24:56.768796 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:24:56.769530 [info ] [MainThread]: 
[0m14:24:56.770139 [error] [MainThread]: [31mFailure in test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_ (models/staging/schema.yml)[0m
[0m14:24:56.770705 [error] [MainThread]:   Got 5 results, configured to fail if != 0
[0m14:24:56.771497 [info ] [MainThread]: 
[0m14:24:56.772740 [info ] [MainThread]:   compiled Code at target/compiled/airflow_dbt_project/models/staging/schema.yml/relationships_stg_orders_96411fe0c89b49c3f4da955dfd358ba0.sql
[0m14:24:56.773559 [info ] [MainThread]: 
[0m14:24:56.774424 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m14:24:56.775639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a603bf980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a5a8dc680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a59400110>]}
[0m14:24:56.776679 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:27:25.103823 | b8ff07bd-a1ba-4393-b4dd-11e0e918d672 ==============================
[0m14:27:25.103823 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:27:25.107349 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'deps', 'rpc_method': 'deps', 'indirect_selection': 'eager'}
[0m14:27:25.107720 [debug] [MainThread]: Tracking: tracking
[0m14:27:25.110325 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f76c3037e00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f76c3034500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f76c3037e90>]}
[0m14:27:25.110906 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m14:27:25.111457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f76c32d3cb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f76c3037c20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f76c3034500>]}
[0m14:27:25.111889 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:27:44.804325 | 19651c58-c603-4a4f-8d45-02c9809ae89e ==============================
[0m14:27:44.804325 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:27:44.806697 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'parse_only': False, 'which': 'compile', 'rpc_method': 'compile', 'indirect_selection': 'eager'}
[0m14:27:44.807094 [debug] [MainThread]: Tracking: tracking
[0m14:27:44.807459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85693941a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f856b53caa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8569394b00>]}
[0m14:27:44.866966 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:27:44.867942 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/schema.yml
[0m14:27:44.896885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '19651c58-c603-4a4f-8d45-02c9809ae89e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f856ada3d70>]}
[0m14:27:44.909536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '19651c58-c603-4a4f-8d45-02c9809ae89e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8569dccc50>]}
[0m14:27:44.910193 [info ] [MainThread]: Found 6 models, 5 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:27:44.910682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '19651c58-c603-4a4f-8d45-02c9809ae89e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f856acc8ad0>]}
[0m14:27:44.913714 [info ] [MainThread]: 
[0m14:27:44.917302 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:27:44.919768 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m14:27:44.932048 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:27:44.981428 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m14:27:44.982423 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:27:44.982834 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m14:27:44.983248 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:27:44.983605 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:27:44.983994 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:27:47.247264 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m14:27:47.251035 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m14:27:47.306539 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m14:27:47.312182 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:27:48.142312 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m14:27:48.145094 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m14:27:48.145444 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m14:27:48.145698 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:27:52.128477 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 4 seconds
[0m14:27:52.132198 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m14:27:54.558765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '19651c58-c603-4a4f-8d45-02c9809ae89e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8569462090>]}
[0m14:27:54.559530 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:27:54.559889 [info ] [MainThread]: 
[0m14:27:54.599053 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_customers
[0m14:27:54.599986 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.ord
[0m14:27:54.601367 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_customers'
[0m14:27:54.602706 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.ord'
[0m14:27:54.603375 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_customers
[0m14:27:54.603963 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.ord
[0m14:27:54.609158 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_customers"
[0m14:27:54.611696 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.ord"
[0m14:27:54.612651 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (compile): 2025-11-16 14:27:54.604341 => 2025-11-16 14:27:54.612500
[0m14:27:54.613135 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.ord (compile): 2025-11-16 14:27:54.609645 => 2025-11-16 14:27:54.613024
[0m14:27:54.613521 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_customers
[0m14:27:54.613974 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.ord
[0m14:27:54.614389 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (execute): 2025-11-16 14:27:54.614283 => 2025-11-16 14:27:54.614312
[0m14:27:54.614943 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.ord (execute): 2025-11-16 14:27:54.614748 => 2025-11-16 14:27:54.614782
[0m14:27:54.618848 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_customers
[0m14:27:54.620447 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.ord
[0m14:27:54.621291 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m14:27:54.622282 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.stg_orders
[0m14:27:54.623798 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m14:27:54.625011 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_orders'
[0m14:27:54.625629 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m14:27:54.626235 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.stg_orders
[0m14:27:54.630863 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m14:27:54.635692 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_orders"
[0m14:27:54.636678 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-16 14:27:54.626638 => 2025-11-16 14:27:54.636549
[0m14:27:54.637119 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m14:27:54.637424 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-16 14:27:54.637352 => 2025-11-16 14:27:54.637366
[0m14:27:54.637743 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.stg_orders (compile): 2025-11-16 14:27:54.631361 => 2025-11-16 14:27:54.637627
[0m14:27:54.638915 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m14:27:54.639349 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.stg_orders
[0m14:27:54.639957 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.test_model
[0m14:27:54.640513 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.stg_orders (execute): 2025-11-16 14:27:54.640428 => 2025-11-16 14:27:54.640443
[0m14:27:54.641507 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.test_model'
[0m14:27:54.642743 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.stg_orders
[0m14:27:54.643208 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.test_model
[0m14:27:54.643808 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.cus_orders
[0m14:27:54.649585 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.test_model"
[0m14:27:54.650809 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m14:27:54.651674 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m14:27:54.652146 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.test_model (compile): 2025-11-16 14:27:54.644137 => 2025-11-16 14:27:54.652045
[0m14:27:54.656058 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m14:27:54.656650 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.test_model
[0m14:27:54.657350 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.test_model (execute): 2025-11-16 14:27:54.657235 => 2025-11-16 14:27:54.657255
[0m14:27:54.658271 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.test_model
[0m14:27:54.658685 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:27:54.659367 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa'
[0m14:27:54.659645 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:27:54.679990 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:27:54.680613 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-16 14:27:54.652466 => 2025-11-16 14:27:54.680468
[0m14:27:54.681130 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m14:27:54.681481 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-16 14:27:54.681394 => 2025-11-16 14:27:54.681409
[0m14:27:54.682324 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m14:27:54.682706 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:27:54.683363 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada'
[0m14:27:54.683650 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:27:54.693665 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:27:54.694617 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (compile): 2025-11-16 14:27:54.659830 => 2025-11-16 14:27:54.694495
[0m14:27:54.695044 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (compile): 2025-11-16 14:27:54.683835 => 2025-11-16 14:27:54.694963
[0m14:27:54.695530 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:27:54.695948 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:27:54.696393 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (execute): 2025-11-16 14:27:54.696275 => 2025-11-16 14:27:54.696295
[0m14:27:54.696767 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (execute): 2025-11-16 14:27:54.696695 => 2025-11-16 14:27:54.696709
[0m14:27:54.697674 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:27:54.698671 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:27:54.699160 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:27:54.699700 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:27:54.700452 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m14:27:54.701188 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500'
[0m14:27:54.701937 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:27:54.702495 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:27:54.709180 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:27:54.722475 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500"
[0m14:27:54.723123 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 14:27:54.702887 => 2025-11-16 14:27:54.723009
[0m14:27:54.723508 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:27:54.723779 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 14:27:54.723713 => 2025-11-16 14:27:54.723727
[0m14:27:54.724612 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:27:54.724966 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (compile): 2025-11-16 14:27:54.709584 => 2025-11-16 14:27:54.724848
[0m14:27:54.725581 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:27:54.726008 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:27:54.727024 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m14:27:54.727567 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500 (execute): 2025-11-16 14:27:54.727455 => 2025-11-16 14:27:54.727474
[0m14:27:54.728015 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:27:54.729126 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500
[0m14:27:54.734433 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:27:54.735290 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 14:27:54.729420 => 2025-11-16 14:27:54.735205
[0m14:27:54.735611 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:27:54.735865 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 14:27:54.735806 => 2025-11-16 14:27:54.735818
[0m14:27:54.736670 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:27:54.738090 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:27:54.738411 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m14:27:54.738635 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_.430bf21500' was properly closed.
[0m14:27:54.739386 [debug] [MainThread]: Command end result
[0m14:27:54.748716 [info ] [MainThread]: Done.
[0m14:27:54.749310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8569462090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8568184bc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8568184ec0>]}
[0m14:27:54.749684 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:30:52.948794 | 63e5a29c-99d1-4b43-ae1c-59b2424d5035 ==============================
[0m14:30:52.948794 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:30:52.954263 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'parse_only': False, 'which': 'compile', 'rpc_method': 'compile', 'indirect_selection': 'eager'}
[0m14:30:52.955080 [debug] [MainThread]: Tracking: tracking
[0m14:30:52.956047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7e622db50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7e6831fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8079f9520>]}
[0m14:30:53.054472 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:30:53.056725 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/schema.yml
[0m14:30:53.105902 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m14:30:53.225913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '63e5a29c-99d1-4b43-ae1c-59b2424d5035', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7e56310a0>]}
[0m14:30:53.241264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '63e5a29c-99d1-4b43-ae1c-59b2424d5035', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7e586e900>]}
[0m14:30:53.241992 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:30:53.242607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '63e5a29c-99d1-4b43-ae1c-59b2424d5035', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa80cf25580>]}
[0m14:30:53.245961 [info ] [MainThread]: 
[0m14:30:53.249890 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:30:53.252438 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m14:30:53.260238 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:30:53.312025 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m14:30:53.316312 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:30:53.316899 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m14:30:53.317675 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:30:53.318376 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:53.319094 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:54.666271 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 1 seconds
[0m14:30:54.672026 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m14:30:54.743199 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m14:30:54.747705 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:30:55.197990 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m14:30:55.207515 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m14:30:55.208289 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m14:30:55.208911 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:30:56.319765 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m14:30:56.322156 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m14:30:56.913608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '63e5a29c-99d1-4b43-ae1c-59b2424d5035', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7e56e70e0>]}
[0m14:30:56.914659 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:30:56.915180 [info ] [MainThread]: 
[0m14:30:56.960532 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_customers
[0m14:30:56.961339 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.ord
[0m14:30:56.962604 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_customers'
[0m14:30:56.964244 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.ord'
[0m14:30:56.965100 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_customers
[0m14:30:56.965795 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.ord
[0m14:30:56.971092 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_customers"
[0m14:30:56.973631 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.ord"
[0m14:30:56.974593 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (compile): 2025-11-16 14:30:56.966235 => 2025-11-16 14:30:56.974457
[0m14:30:56.975063 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_customers
[0m14:30:56.975509 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (execute): 2025-11-16 14:30:56.975392 => 2025-11-16 14:30:56.975424
[0m14:30:56.979198 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_customers
[0m14:30:56.979768 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.ord (compile): 2025-11-16 14:30:56.971597 => 2025-11-16 14:30:56.979595
[0m14:30:56.980725 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_customers
[0m14:30:56.981642 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.ord
[0m14:30:56.983156 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m14:30:56.983827 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.ord (execute): 2025-11-16 14:30:56.983649 => 2025-11-16 14:30:56.983683
[0m14:30:56.984506 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m14:30:56.986183 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.ord
[0m14:30:56.991665 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m14:30:56.992593 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.stg_orders
[0m14:30:56.994276 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_orders'
[0m14:30:56.994681 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.stg_orders
[0m14:30:56.999373 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_orders"
[0m14:30:57.000373 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-16 14:30:56.986713 => 2025-11-16 14:30:57.000186
[0m14:30:57.001059 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m14:30:57.001583 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.stg_orders (compile): 2025-11-16 14:30:56.994938 => 2025-11-16 14:30:57.001466
[0m14:30:57.002240 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-16 14:30:57.002049 => 2025-11-16 14:30:57.002083
[0m14:30:57.002860 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.stg_orders
[0m14:30:57.004530 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m14:30:57.005382 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.stg_orders (execute): 2025-11-16 14:30:57.005184 => 2025-11-16 14:30:57.005217
[0m14:30:57.006518 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.test_model
[0m14:30:57.008510 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.stg_orders
[0m14:30:57.010413 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.test_model'
[0m14:30:57.011464 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.cus_orders
[0m14:30:57.012416 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.test_model
[0m14:30:57.014535 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m14:30:57.021383 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.test_model"
[0m14:30:57.022219 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m14:30:57.026803 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m14:30:57.027530 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-16 14:30:57.022864 => 2025-11-16 14:30:57.027419
[0m14:30:57.027945 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m14:30:57.028261 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-16 14:30:57.028183 => 2025-11-16 14:30:57.028199
[0m14:30:57.029275 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m14:30:57.029738 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:30:57.030564 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa'
[0m14:30:57.030947 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:30:57.041680 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.test_model (compile): 2025-11-16 14:30:57.015148 => 2025-11-16 14:30:57.041521
[0m14:30:57.047488 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.test_model
[0m14:30:57.053311 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.test_model (execute): 2025-11-16 14:30:57.053126 => 2025-11-16 14:30:57.053159
[0m14:30:57.056524 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:30:57.057999 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.test_model
[0m14:30:57.059012 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:30:57.060083 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada'
[0m14:30:57.060547 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:30:57.072326 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (compile): 2025-11-16 14:30:57.031770 => 2025-11-16 14:30:57.072187
[0m14:30:57.073048 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:30:57.073475 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:30:57.074007 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (execute): 2025-11-16 14:30:57.073896 => 2025-11-16 14:30:57.073918
[0m14:30:57.075013 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:30:57.075512 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:30:57.076310 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m14:30:57.076673 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:30:57.083571 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:30:57.084075 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (compile): 2025-11-16 14:30:57.061107 => 2025-11-16 14:30:57.083960
[0m14:30:57.084615 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:30:57.085056 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (execute): 2025-11-16 14:30:57.084963 => 2025-11-16 14:30:57.084979
[0m14:30:57.086084 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:30:57.086454 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 14:30:57.076917 => 2025-11-16 14:30:57.086371
[0m14:30:57.086924 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:30:57.087363 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:30:57.088198 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m14:30:57.088560 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 14:30:57.088476 => 2025-11-16 14:30:57.088492
[0m14:30:57.088909 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:30:57.089914 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:30:57.096154 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:30:57.097059 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 14:30:57.090200 => 2025-11-16 14:30:57.096949
[0m14:30:57.097494 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:30:57.097828 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 14:30:57.097744 => 2025-11-16 14:30:57.097761
[0m14:30:57.098858 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:30:57.100911 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:30:57.101432 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m14:30:57.101849 [debug] [MainThread]: Connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64' was properly closed.
[0m14:30:57.103182 [debug] [MainThread]: Command end result
[0m14:30:57.116963 [info ] [MainThread]: Done.
[0m14:30:57.117698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7e56e70e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7e413aba0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7e561c710>]}
[0m14:30:57.118162 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:31:22.308565 | 358d3083-10e1-480e-9d0f-c1fc348537bc ==============================
[0m14:31:22.308565 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:31:22.315515 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'parse_only': False, 'which': 'compile', 'rpc_method': 'compile', 'indirect_selection': 'eager'}
[0m14:31:22.316338 [debug] [MainThread]: Tracking: tracking
[0m14:31:22.317184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cafd1880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cae62780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cae61d30>]}
[0m14:31:22.350442 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:31:22.351765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '358d3083-10e1-480e-9d0f-c1fc348537bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cafd3830>]}
[0m14:31:23.639811 [debug] [MainThread]: 1699: static parser successfully parsed test_model.sql
[0m14:31:23.655317 [debug] [MainThread]: 1699: static parser successfully parsed cus_orders.sql
[0m14:31:23.658659 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_customers.sql
[0m14:31:23.662017 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m14:31:23.665702 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/dim_customers.sql
[0m14:31:23.669068 [debug] [MainThread]: 1699: static parser successfully parsed marts/core/ord.sql
[0m14:31:23.763071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '358d3083-10e1-480e-9d0f-c1fc348537bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0d08d54f0>]}
[0m14:31:23.770376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '358d3083-10e1-480e-9d0f-c1fc348537bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cacbcb00>]}
[0m14:31:23.770834 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:31:23.771187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '358d3083-10e1-480e-9d0f-c1fc348537bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cad1a8a0>]}
[0m14:31:23.773509 [info ] [MainThread]: 
[0m14:31:23.776535 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:31:23.778609 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m14:31:23.790941 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:31:23.834788 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m14:31:23.838429 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:31:23.838987 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m14:31:23.839514 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:31:23.840103 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:31:23.840569 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:31:26.355185 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 3 seconds
[0m14:31:26.357661 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m14:31:26.381711 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 3 seconds
[0m14:31:26.383818 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:31:27.164185 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m14:31:27.166628 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m14:31:27.166988 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m14:31:27.167250 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:31:28.415602 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 1 seconds
[0m14:31:28.418034 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m14:31:29.100538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '358d3083-10e1-480e-9d0f-c1fc348537bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cad1b290>]}
[0m14:31:29.102516 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:31:29.103293 [info ] [MainThread]: 
[0m14:31:29.155189 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_customers
[0m14:31:29.156067 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.ord
[0m14:31:29.157353 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_customers'
[0m14:31:29.158658 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.ord'
[0m14:31:29.159301 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_customers
[0m14:31:29.160057 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.ord
[0m14:31:29.166258 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_customers"
[0m14:31:29.168983 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.ord"
[0m14:31:29.170450 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.ord (compile): 2025-11-16 14:31:29.166740 => 2025-11-16 14:31:29.170316
[0m14:31:29.171009 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.ord
[0m14:31:29.171390 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.ord (execute): 2025-11-16 14:31:29.171278 => 2025-11-16 14:31:29.171311
[0m14:31:29.171851 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (compile): 2025-11-16 14:31:29.160638 => 2025-11-16 14:31:29.171684
[0m14:31:29.176132 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.ord
[0m14:31:29.176942 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_customers
[0m14:31:29.177951 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.stg_customers
[0m14:31:29.178999 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_customers (execute): 2025-11-16 14:31:29.178751 => 2025-11-16 14:31:29.178792
[0m14:31:29.180165 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_customers'
[0m14:31:29.181534 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_customers
[0m14:31:29.182041 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.stg_customers
[0m14:31:29.182636 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_orders
[0m14:31:29.187767 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_customers"
[0m14:31:29.189590 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_orders'
[0m14:31:29.190542 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_orders
[0m14:31:29.197563 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_orders"
[0m14:31:29.198323 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.stg_customers (compile): 2025-11-16 14:31:29.183183 => 2025-11-16 14:31:29.198151
[0m14:31:29.199083 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.stg_customers
[0m14:31:29.199597 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.stg_customers (execute): 2025-11-16 14:31:29.199487 => 2025-11-16 14:31:29.199508
[0m14:31:29.200847 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.stg_customers
[0m14:31:29.201401 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_orders (compile): 2025-11-16 14:31:29.191042 => 2025-11-16 14:31:29.201207
[0m14:31:29.202152 [debug] [Thread-2 (]: Began running node model.airflow_dbt_project.test_model
[0m14:31:29.202905 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_orders
[0m14:31:29.204307 [debug] [Thread-2 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.test_model'
[0m14:31:29.205016 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_orders (execute): 2025-11-16 14:31:29.204782 => 2025-11-16 14:31:29.204820
[0m14:31:29.205664 [debug] [Thread-2 (]: Began compiling node model.airflow_dbt_project.test_model
[0m14:31:29.207244 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_orders
[0m14:31:29.213195 [debug] [Thread-2 (]: Writing injected SQL for node "model.airflow_dbt_project.test_model"
[0m14:31:29.214163 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.cus_orders
[0m14:31:29.216290 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m14:31:29.217061 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m14:31:29.217945 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.test_model (compile): 2025-11-16 14:31:29.207735 => 2025-11-16 14:31:29.217711
[0m14:31:29.225764 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m14:31:29.226653 [debug] [Thread-2 (]: Began executing node model.airflow_dbt_project.test_model
[0m14:31:29.227967 [debug] [Thread-2 (]: Timing info for model.airflow_dbt_project.test_model (execute): 2025-11-16 14:31:29.227680 => 2025-11-16 14:31:29.227728
[0m14:31:29.229996 [debug] [Thread-2 (]: Finished running node model.airflow_dbt_project.test_model
[0m14:31:29.230898 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:31:29.231467 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-16 14:31:29.218488 => 2025-11-16 14:31:29.231315
[0m14:31:29.233266 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa'
[0m14:31:29.234200 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m14:31:29.234924 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:31:29.235617 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-16 14:31:29.235444 => 2025-11-16 14:31:29.235476
[0m14:31:29.247984 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m14:31:29.254263 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:31:29.266045 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada'
[0m14:31:29.272055 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:31:29.273108 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:31:29.289366 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:31:29.290364 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (compile): 2025-11-16 14:31:29.273637 => 2025-11-16 14:31:29.290227
[0m14:31:29.291020 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:31:29.291581 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (compile): 2025-11-16 14:31:29.236174 => 2025-11-16 14:31:29.291407
[0m14:31:29.292299 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (execute): 2025-11-16 14:31:29.292113 => 2025-11-16 14:31:29.292148
[0m14:31:29.292950 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:31:29.294386 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:31:29.295131 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (execute): 2025-11-16 14:31:29.294937 => 2025-11-16 14:31:29.294973
[0m14:31:29.295900 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:31:29.297705 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:31:29.298907 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m14:31:29.299799 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:31:29.300628 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:31:29.302025 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m14:31:29.311516 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:31:29.312245 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:31:29.323843 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 14:31:29.302519 => 2025-11-16 14:31:29.323574
[0m14:31:29.325155 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:31:29.325972 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:31:29.327035 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 14:31:29.326817 => 2025-11-16 14:31:29.326854
[0m14:31:29.329060 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:31:29.329765 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 14:31:29.313164 => 2025-11-16 14:31:29.329576
[0m14:31:29.330740 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:31:29.331363 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 14:31:29.331215 => 2025-11-16 14:31:29.331243
[0m14:31:29.332791 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:31:29.335020 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:31:29.335582 [debug] [MainThread]: Connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64' was properly closed.
[0m14:31:29.336024 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m14:31:29.337394 [debug] [MainThread]: Command end result
[0m14:31:29.355738 [info ] [MainThread]: Done.
[0m14:31:29.356815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cb8812e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cacc1dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cb682b70>]}
[0m14:31:29.357654 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:32:10.818953 | 75eb65e4-fcc0-4dc0-9ba2-e72591b5ae45 ==============================
[0m14:32:10.818953 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:32:10.822657 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m14:32:10.823036 [debug] [MainThread]: Tracking: tracking
[0m14:32:10.823426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa48f9782f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4940a8e00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa48f7dba70>]}
[0m14:32:10.877928 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:32:10.878383 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:32:10.890393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '75eb65e4-fcc0-4dc0-9ba2-e72591b5ae45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa48fb6cb60>]}
[0m14:32:10.902626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '75eb65e4-fcc0-4dc0-9ba2-e72591b5ae45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa48f851c40>]}
[0m14:32:10.903277 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:32:10.903775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '75eb65e4-fcc0-4dc0-9ba2-e72591b5ae45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa49419bd70>]}
[0m14:32:10.906140 [info ] [MainThread]: 
[0m14:32:10.909650 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:32:10.912242 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m14:32:10.919093 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:32:10.980345 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m14:32:10.980844 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m14:32:10.981201 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:32:10.984149 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:32:10.984588 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:32:10.984893 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:32:14.568838 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 4 seconds
[0m14:32:14.571797 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:32:15.274484 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 4 seconds
[0m14:32:15.277685 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m14:32:16.458128 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m14:32:16.461218 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m14:32:16.462159 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m14:32:16.462498 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:32:22.897214 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 6 seconds
[0m14:32:22.900886 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m14:32:23.847201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '75eb65e4-fcc0-4dc0-9ba2-e72591b5ae45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a3fec3b0>]}
[0m14:32:23.848413 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:32:23.848933 [info ] [MainThread]: 
[0m14:32:23.889517 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:32:23.890475 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:32:23.891258 [info ] [Thread-1 (]: 1 of 2 START test not_null_stg_orders_order_id ................................. [RUN]
[0m14:32:23.892574 [info ] [Thread-2 (]: 2 of 2 START test unique_stg_orders_order_id ................................... [RUN]
[0m14:32:23.895413 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m14:32:23.897464 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m14:32:23.898837 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:32:23.899980 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:32:23.936850 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:32:23.944263 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:32:23.944995 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 14:32:23.911400 => 2025-11-16 14:32:23.944850
[0m14:32:23.945397 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 14:32:23.900622 => 2025-11-16 14:32:23.945314
[0m14:32:23.945732 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:32:23.946150 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:32:23.988166 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:32:23.988990 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:32:23.990312 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:32:23.991113 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:32:23.991350 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m14:32:23.991586 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:32:23.991804 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:32:23.992029 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:32:25.628278 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:32:25.649127 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 14:32:23.957224 => 2025-11-16 14:32:25.648924
[0m14:32:25.649727 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m14:32:25.702347 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m14:32:25.709909 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 14:32:23.946378 => 2025-11-16 14:32:25.709554
[0m14:32:25.711023 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m14:32:26.249678 [info ] [Thread-2 (]: 2 of 2 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 2.35s]
[0m14:32:26.253390 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:32:26.300299 [info ] [Thread-1 (]: 1 of 2 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 2.41s]
[0m14:32:26.301076 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:32:26.304029 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:32:26.305396 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:32:26.305976 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m14:32:26.306394 [debug] [MainThread]: Connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64' was properly closed.
[0m14:32:26.306941 [info ] [MainThread]: 
[0m14:32:26.307639 [info ] [MainThread]: Finished running 2 tests in 0 hours 0 minutes and 15.40 seconds (15.40s).
[0m14:32:26.308600 [debug] [MainThread]: Command end result
[0m14:32:26.322444 [info ] [MainThread]: 
[0m14:32:26.323225 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:32:26.323761 [info ] [MainThread]: 
[0m14:32:26.324360 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m14:32:26.325312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa48e2c5d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4959b4170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4959b4140>]}
[0m14:32:26.326236 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:33:47.112341 | 90421253-e867-487c-bc36-bca337544c53 ==============================
[0m14:33:47.112341 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:33:47.114300 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m14:33:47.114557 [debug] [MainThread]: Tracking: tracking
[0m14:33:47.114830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b1793a40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b1793a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b1793d40>]}
[0m14:33:47.164169 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:33:47.164645 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:33:47.176053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '90421253-e867-487c-bc36-bca337544c53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b19030e0>]}
[0m14:33:47.187361 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '90421253-e867-487c-bc36-bca337544c53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b17e6cf0>]}
[0m14:33:47.187889 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:33:47.188311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '90421253-e867-487c-bc36-bca337544c53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b18b6270>]}
[0m14:33:47.190398 [info ] [MainThread]: 
[0m14:33:47.193525 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:33:47.196080 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m14:33:47.202842 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:33:47.255517 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:33:47.255942 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:33:47.256235 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:33:47.251950 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m14:33:47.257084 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m14:33:47.257427 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:33:48.664421 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m14:33:48.666943 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:33:49.194051 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 2 seconds
[0m14:33:49.198627 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m14:33:49.203214 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m14:33:49.206400 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m14:33:49.206770 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m14:33:49.209550 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:33:50.380817 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m14:33:50.383801 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m14:33:50.948865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '90421253-e867-487c-bc36-bca337544c53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b2198080>]}
[0m14:33:50.950247 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:33:50.950863 [info ] [MainThread]: 
[0m14:33:51.000211 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:33:51.001123 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:33:51.001788 [info ] [Thread-1 (]: 1 of 4 START test not_null_stg_customers_customer_id ........................... [RUN]
[0m14:33:51.002718 [info ] [Thread-2 (]: 2 of 4 START test not_null_stg_orders_order_id ................................. [RUN]
[0m14:33:51.004126 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa'
[0m14:33:51.005380 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m14:33:51.006105 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:33:51.006775 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:33:51.077995 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:33:51.083157 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:33:51.085000 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 14:33:51.018148 => 2025-11-16 14:33:51.084658
[0m14:33:51.086160 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:33:51.092367 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (compile): 2025-11-16 14:33:51.007214 => 2025-11-16 14:33:51.092057
[0m14:33:51.098904 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:33:51.208217 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:33:51.204367 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:33:51.209979 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"
[0m14:33:51.210397 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where customer_id is null



      
    ) dbt_internal_test
[0m14:33:51.211231 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m14:33:51.211617 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:33:51.211972 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m14:33:51.213639 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:33:52.630217 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:33:52.640032 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa (execute): 2025-11-16 14:33:51.104891 => 2025-11-16 14:33:52.639918
[0m14:33:52.640411 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa: Close
[0m14:33:54.025855 [info ] [Thread-1 (]: 1 of 4 PASS not_null_stg_customers_customer_id ................................. [[32mPASS[0m in 3.02s]
[0m14:33:54.028298 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_customers_customer_id.e2cfb1f9aa
[0m14:33:54.028802 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:33:54.029098 [info ] [Thread-1 (]: 3 of 4 START test unique_stg_customers_customer_id ............................. [RUN]
[0m14:33:54.030016 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada'
[0m14:33:54.030315 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:33:54.042259 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:33:54.043094 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (compile): 2025-11-16 14:33:54.030500 => 2025-11-16 14:33:54.042964
[0m14:33:54.043547 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:33:54.053126 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:33:54.055957 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"
[0m14:33:54.056751 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:33:54.057289 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:33:54.472354 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 3 seconds
[0m14:33:54.475997 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 14:33:51.086862 => 2025-11-16 14:33:54.475834
[0m14:33:54.476510 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m14:33:55.146591 [info ] [Thread-2 (]: 2 of 4 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 4.14s]
[0m14:33:55.147210 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m14:33:55.147620 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:33:55.148152 [info ] [Thread-2 (]: 4 of 4 START test unique_stg_orders_order_id ................................... [RUN]
[0m14:33:55.149084 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m14:33:55.149392 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:33:55.155152 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:33:55.155782 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 14:33:55.149583 => 2025-11-16 14:33:55.155683
[0m14:33:55.156148 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:33:55.159912 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:33:55.161174 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m14:33:55.161516 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m14:33:55.161773 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:33:55.235546 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:33:55.238096 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada (execute): 2025-11-16 14:33:54.043815 => 2025-11-16 14:33:55.237999
[0m14:33:55.238422 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada: Close
[0m14:33:55.796587 [info ] [Thread-1 (]: 3 of 4 PASS unique_stg_customers_customer_id ................................... [[32mPASS[0m in 1.77s]
[0m14:33:55.797312 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada
[0m14:33:57.883132 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 3 seconds
[0m14:33:57.886897 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 14:33:55.156367 => 2025-11-16 14:33:57.886741
[0m14:33:57.887391 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m14:33:59.106180 [info ] [Thread-2 (]: 4 of 4 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 3.96s]
[0m14:33:59.106988 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m14:33:59.109849 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:33:59.111074 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:33:59.111516 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m14:33:59.111905 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_customers_customer_id.c7614daada' was properly closed.
[0m14:33:59.112360 [info ] [MainThread]: 
[0m14:33:59.113009 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 11.92 seconds (11.92s).
[0m14:33:59.114120 [debug] [MainThread]: Command end result
[0m14:33:59.130582 [info ] [MainThread]: 
[0m14:33:59.131787 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:33:59.132740 [info ] [MainThread]: 
[0m14:33:59.133666 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m14:33:59.135616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b1b77b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74c1fcdaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74b2198080>]}
[0m14:33:59.137164 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:44:23.796430 | c2b11e4f-9b70-49e3-93df-ab51b0b047ef ==============================
[0m14:44:23.796430 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:44:23.799097 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['cus_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:44:23.799445 [debug] [MainThread]: Tracking: tracking
[0m14:44:23.799800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb52328800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb53f6c5f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb2c28e390>]}
[0m14:44:23.863673 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:44:23.864522 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:44:23.886472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c2b11e4f-9b70-49e3-93df-ab51b0b047ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb271dcb60>]}
[0m14:44:23.909820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c2b11e4f-9b70-49e3-93df-ab51b0b047ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb279dc800>]}
[0m14:44:23.910986 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 306 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:44:23.911922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c2b11e4f-9b70-49e3-93df-ab51b0b047ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb523ab860>]}
[0m14:44:23.916040 [info ] [MainThread]: 
[0m14:44:23.922446 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:44:23.926595 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m14:44:23.982898 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m14:44:23.983463 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m14:44:23.983860 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:44:25.378254 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m14:44:25.381888 [debug] [ThreadPool]: On list_GP: Close
[0m14:44:25.783921 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:44:25.784822 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:44:25.785382 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test', identifier=None)"
[0m14:44:25.795683 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:44:25.796188 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:44:25.796505 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:44:26.718487 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m14:44:26.720040 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:44:27.618334 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m14:44:27.628543 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m14:44:27.629583 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m14:44:27.630109 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m14:44:27.633782 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m14:44:27.634303 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:44:27.634788 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m14:44:27.636225 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:44:28.613041 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m14:44:28.615031 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m14:44:28.654340 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 1 seconds
[0m14:44:28.656203 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m14:44:29.007069 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m14:44:29.012978 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m14:44:29.013319 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m14:44:29.013579 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:44:29.845413 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m14:44:29.847713 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m14:44:30.368603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c2b11e4f-9b70-49e3-93df-ab51b0b047ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb2753ca70>]}
[0m14:44:30.369699 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m14:44:30.370181 [info ] [MainThread]: 
[0m14:44:30.411726 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.cus_orders
[0m14:44:30.412957 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders  [RUN]
[0m14:44:30.414910 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.cus_orders'
[0m14:44:30.415507 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.cus_orders
[0m14:44:30.420284 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.cus_orders"
[0m14:44:30.421050 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (compile): 2025-11-16 14:44:30.415823 => 2025-11-16 14:44:30.420918
[0m14:44:30.421496 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.cus_orders
[0m14:44:30.481551 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.cus_orders"
[0m14:44:30.482902 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.cus_orders"
[0m14:44:30.483234 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.cus_orders"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders
  
   as (
    with cus as(
    select customer_id, email,phone,signup_date 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers 
),
alls as(
    select 
    email,
    order_id,
    order_date,
    total_amount,
    shipping_address
    from ORDERS o join cus c on
    o.customer_id = c.customer_id 
)
select * from alls
  );
[0m14:44:30.483489 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:44:31.533371 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m14:44:31.556233 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.cus_orders (execute): 2025-11-16 14:44:30.421767 => 2025-11-16 14:44:31.556145
[0m14:44:31.556599 [debug] [Thread-1 (]: On model.airflow_dbt_project.cus_orders: Close
[0m14:44:31.954441 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2b11e4f-9b70-49e3-93df-ab51b0b047ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb26161a60>]}
[0m14:44:31.955006 [info ] [Thread-1 (]: 1 of 1 OK created sql view model -- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test.cus_orders  [[32mSUCCESS 1[0m in 1.54s]
[0m14:44:31.957169 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.cus_orders
[0m14:44:31.959182 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m14:44:31.959888 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:44:31.960125 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m14:44:31.960308 [debug] [MainThread]: Connection 'model.airflow_dbt_project.cus_orders' was properly closed.
[0m14:44:31.960590 [info ] [MainThread]: 
[0m14:44:31.960929 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 8.04 seconds (8.04s).
[0m14:44:31.961430 [debug] [MainThread]: Command end result
[0m14:44:31.971188 [info ] [MainThread]: 
[0m14:44:31.972008 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:44:31.972516 [info ] [MainThread]: 
[0m14:44:31.973010 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:44:31.973763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb26d94680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb4b5dd100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb261df2f0>]}
[0m14:44:31.974473 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 14:48:07.815507 | a5a0dc2d-d2ba-4fae-9622-b7e97470df12 ==============================
[0m14:48:07.815507 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:48:07.819334 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'macro': 'merge_dim_customers', 'args': '{}', 'which': 'run-operation', 'rpc_method': 'run-operation', 'indirect_selection': 'eager'}
[0m14:48:07.819883 [debug] [MainThread]: Tracking: tracking
[0m14:48:07.820453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae65d9ec30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae653cb230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae66cac080>]}
[0m14:48:07.922793 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:48:07.923965 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:48:07.950185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a5a0dc2d-d2ba-4fae-9622-b7e97470df12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae65c6bd40>]}
[0m14:48:07.969541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5a0dc2d-d2ba-4fae-9622-b7e97470df12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae6589bd70>]}
[0m14:48:07.975481 [debug] [MainThread]: Acquiring new snowflake connection 'macro_merge_dim_customers'
[0m14:48:08.003737 [debug] [MainThread]: Using snowflake connection "macro_merge_dim_customers"
[0m14:48:08.004426 [debug] [MainThread]: On macro_merge_dim_customers: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "macro_merge_dim_customers"} */
MERGE INTO GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_customers AS target
        USING GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_customers AS source
        ON target.CUSTOMER_ID = source.CUSTOMER_ID
        WHEN MATCHED AND (
            target.email <> source.email
            OR target.phone <> source.phone
        ) THEN
            UPDATE SET
                phone = source.phone,
                email = source.email
        WHEN NOT MATCHED THEN
            INSERT (CUSTOMER_ID, email, phone, signup_date)
            VALUES (source.CUSTOMER_ID, source.email, source.phone, source.signup_date)
[0m14:48:08.005020 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:48:11.324808 [debug] [MainThread]: SQL status: SUCCESS 0 in 3 seconds
[0m14:48:11.329326 [debug] [MainThread]: On macro_merge_dim_customers: Close
[0m14:48:11.709822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae65d9ec30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae650a2b40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae650a0d40>]}
[0m14:48:11.710505 [debug] [MainThread]: Flushing usage events
[0m14:48:12.591144 [debug] [MainThread]: Connection 'macro_merge_dim_customers' was properly closed.


============================== 2025-11-16 15:59:48.359912 | d8f0554f-bd58-46c2-bbed-c6f6afe0147f ==============================
[0m15:59:48.359912 [info ] [MainThread]: Running with dbt=1.4.0
[0m15:59:48.362730 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m15:59:48.363078 [debug] [MainThread]: Tracking: tracking
[0m15:59:48.363404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7f3a69c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7f3a687a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7f3a6b650>]}
[0m15:59:48.416773 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m15:59:48.417476 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/order_amount.sql
[0m15:59:48.418140 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/schema.yml
[0m15:59:48.439615 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m15:59:48.492550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7f392aa20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7f392b440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7f392a6c0>]}
[0m15:59:48.493163 [debug] [MainThread]: Flushing usage events
[0m15:59:49.907920 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two tests with the name "unique_stg_orders_order_id" defined on column "order_id" in "models.stg_orders".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when running tests.
  
  To fix this, change the name of one of these resources:
  - test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (models/staging/schema.yml)
  - test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (models/staging/schema.yml)


============================== 2025-11-16 16:00:11.472209 | 5232b9a4-0192-4b3f-9858-20e69a36fbc0 ==============================
[0m16:00:11.472209 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:00:11.475598 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:00:11.476026 [debug] [MainThread]: Tracking: tracking
[0m16:00:11.476502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe697d67e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe69c236ff0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe697e589b0>]}
[0m16:00:11.548253 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m16:00:11.549139 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/order_amount.sql
[0m16:00:11.549961 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/schema.yml
[0m16:00:11.573385 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m16:00:11.639313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe69dd2d460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe697972e70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe69c23d5e0>]}
[0m16:00:11.639940 [debug] [MainThread]: Flushing usage events
[0m16:00:12.530468 [error] [MainThread]: Encountered an error:
Compilation Error in test check_amount_stg_orders_total_amount (models/staging/schema.yml)
  macro 'dbt_macro__test_check_amount' takes no keyword argument 'column_name'


============================== 2025-11-16 16:01:05.471111 | afbac4dd-1198-4e36-8117-a9be417aecdc ==============================
[0m16:01:05.471111 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:01:05.473431 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:01:05.473713 [debug] [MainThread]: Tracking: tracking
[0m16:01:05.474043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbeca0c0770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbeca0c2ae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbeca0c0140>]}
[0m16:01:05.529947 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m16:01:05.530779 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/order_amount.sql
[0m16:01:05.531578 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/schema.yml
[0m16:01:05.559677 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m16:01:05.640825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'afbac4dd-1198-4e36-8117-a9be417aecdc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbec9fc9a90>]}
[0m16:01:05.651052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'afbac4dd-1198-4e36-8117-a9be417aecdc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbeca106840>]}
[0m16:01:05.651541 [info ] [MainThread]: Found 6 models, 5 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m16:01:05.651952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'afbac4dd-1198-4e36-8117-a9be417aecdc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbef1d8e420>]}
[0m16:01:05.653952 [info ] [MainThread]: 
[0m16:01:05.656991 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:01:05.659098 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m16:01:05.665617 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m16:01:05.711060 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m16:01:05.711518 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m16:01:05.711966 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m16:01:05.712486 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:01:05.712977 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m16:01:05.715216 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:01:15.715386 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 10 seconds
[0m16:01:15.718503 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m16:01:15.719421 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 10 seconds
[0m16:01:15.723527 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m16:01:16.141858 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m16:01:16.145671 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m16:01:16.146068 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m16:01:16.146361 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:01:17.352387 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m16:01:17.354771 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m16:01:18.055046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'afbac4dd-1198-4e36-8117-a9be417aecdc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbeca1047d0>]}
[0m16:01:18.056299 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:01:18.056749 [info ] [MainThread]: 
[0m16:01:18.111683 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:01:18.112373 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:01:18.112822 [info ] [Thread-2 (]: 2 of 3 START test not_null_stg_orders_order_id ................................. [RUN]
[0m16:01:18.113354 [info ] [Thread-1 (]: 1 of 3 START test check_amount_stg_orders_total_amount ......................... [RUN]
[0m16:01:18.114429 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m16:01:18.115325 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c'
[0m16:01:18.115796 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:01:18.116203 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:01:18.139155 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:01:18.144279 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:01:18.145839 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (compile): 2025-11-16 16:01:18.126779 => 2025-11-16 16:01:18.145612
[0m16:01:18.146913 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:01:18.152719 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 16:01:18.116481 => 2025-11-16 16:01:18.152556
[0m16:01:18.153209 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:01:18.208144 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:01:18.208843 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:01:18.210007 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:01:18.210911 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:01:18.211370 [debug] [Thread-1 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where <class 'dbt.adapters.snowflake.column.SnowflakeColumn'> <0

      
    ) dbt_internal_test
[0m16:01:18.211809 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m16:01:18.212188 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:01:18.212505 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:01:19.622045 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:01:19.634310 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 16:01:18.153454 => 2025-11-16 16:01:19.634194
[0m16:01:19.634701 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m16:01:20.132177 [info ] [Thread-2 (]: 2 of 3 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 2.02s]
[0m16:01:20.135201 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:01:20.135790 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:01:20.136157 [info ] [Thread-2 (]: 3 of 3 START test unique_stg_orders_order_id ................................... [RUN]
[0m16:01:20.137585 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m16:01:20.137957 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:01:20.149750 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:01:20.150604 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 16:01:20.138174 => 2025-11-16 16:01:20.150478
[0m16:01:20.151072 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:01:20.156110 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:01:20.158112 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:01:20.158586 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m16:01:20.158976 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:01:20.403716 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c06ec1-0000-a6d0-0000-eb0d0002b3f6
[0m16:01:20.404373 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 10 at position 10 unexpected '<'.
[0m16:01:20.405296 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (execute): 2025-11-16 16:01:18.147434 => 2025-11-16 16:01:20.404974
[0m16:01:20.405860 [debug] [Thread-1 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: Close
[0m16:01:22.390119 [debug] [Thread-1 (]: Database Error in test check_amount_stg_orders_total_amount (models/staging/schema.yml)
  001003 (42000): SQL compilation error:
  syntax error line 10 at position 10 unexpected '<'.
  compiled Code at target/run/airflow_dbt_project/models/staging/schema.yml/check_amount_stg_orders_total_amount.sql
[0m16:01:22.390747 [error] [Thread-1 (]: 1 of 3 ERROR check_amount_stg_orders_total_amount .............................. [[31mERROR[0m in 4.28s]
[0m16:01:22.391307 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:01:25.252353 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 5 seconds
[0m16:01:25.254942 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 16:01:20.151364 => 2025-11-16 16:01:25.254826
[0m16:01:25.255274 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m16:01:25.864676 [info ] [Thread-2 (]: 3 of 3 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 5.73s]
[0m16:01:25.865331 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:01:25.867749 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:01:25.868805 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:01:25.869187 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m16:01:25.869496 [debug] [MainThread]: Connection 'test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c' was properly closed.
[0m16:01:25.869880 [info ] [MainThread]: 
[0m16:01:25.870380 [info ] [MainThread]: Finished running 3 tests in 0 hours 0 minutes and 20.22 seconds (20.22s).
[0m16:01:25.871233 [debug] [MainThread]: Command end result
[0m16:01:25.884503 [info ] [MainThread]: 
[0m16:01:25.885523 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:01:25.886307 [info ] [MainThread]: 
[0m16:01:25.886829 [error] [MainThread]: [33mDatabase Error in test check_amount_stg_orders_total_amount (models/staging/schema.yml)[0m
[0m16:01:25.887372 [error] [MainThread]:   001003 (42000): SQL compilation error:
[0m16:01:25.887864 [error] [MainThread]:   syntax error line 10 at position 10 unexpected '<'.
[0m16:01:25.888349 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/staging/schema.yml/check_amount_stg_orders_total_amount.sql
[0m16:01:25.888827 [info ] [MainThread]: 
[0m16:01:25.889335 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m16:01:25.890075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbecba76ea0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbecba86bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbec87dee40>]}
[0m16:01:25.890867 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 16:01:49.145668 | 9e54beb0-44a1-42a8-883b-f531434ff041 ==============================
[0m16:01:49.145668 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:01:49.148386 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:01:49.148722 [debug] [MainThread]: Tracking: tracking
[0m16:01:49.149089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a4af52960>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a4af509b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a4af52270>]}
[0m16:01:49.206399 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:01:49.207344 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/order_amount.sql
[0m16:01:49.226594 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m16:01:49.298979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9e54beb0-44a1-42a8-883b-f531434ff041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a4969a9f0>]}
[0m16:01:49.310775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9e54beb0-44a1-42a8-883b-f531434ff041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a4afa6780>]}
[0m16:01:49.311386 [info ] [MainThread]: Found 6 models, 5 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m16:01:49.311894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e54beb0-44a1-42a8-883b-f531434ff041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a50978bf0>]}
[0m16:01:49.314231 [info ] [MainThread]: 
[0m16:01:49.317794 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:01:49.320698 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m16:01:49.328156 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m16:01:49.381463 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m16:01:49.382110 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m16:01:49.382481 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m16:01:49.382857 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m16:01:49.383243 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:01:49.383563 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:01:52.431059 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 3 seconds
[0m16:01:52.434031 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m16:01:52.949661 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m16:01:52.956532 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m16:01:52.956935 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m16:01:52.957358 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:01:54.452366 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 5 seconds
[0m16:01:54.455824 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m16:01:56.311610 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 3 seconds
[0m16:01:56.315117 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m16:01:57.550343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e54beb0-44a1-42a8-883b-f531434ff041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a4afc0320>]}
[0m16:01:57.552223 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:01:57.552949 [info ] [MainThread]: 
[0m16:01:57.597047 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:01:57.597804 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:01:57.598605 [info ] [Thread-1 (]: 1 of 3 START test check_amount_stg_orders_total_amount ......................... [RUN]
[0m16:01:57.599445 [info ] [Thread-2 (]: 2 of 3 START test not_null_stg_orders_order_id ................................. [RUN]
[0m16:01:57.600713 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c'
[0m16:01:57.601770 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m16:01:57.602293 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:01:57.602744 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:01:57.609727 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:01:57.636096 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:01:57.637217 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (compile): 2025-11-16 16:01:57.603058 => 2025-11-16 16:01:57.637009
[0m16:01:57.637925 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:01:57.644129 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 16:01:57.610229 => 2025-11-16 16:01:57.643959
[0m16:01:57.644613 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:01:57.701044 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:01:57.701858 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:01:57.702901 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:01:57.703255 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m16:01:57.703537 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:01:57.704288 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:01:57.705795 [debug] [Thread-1 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where total_amount< 0

      
    ) dbt_internal_test
[0m16:01:57.706996 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:02:00.187841 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m16:02:00.198727 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 16:01:57.650193 => 2025-11-16 16:02:00.198597
[0m16:02:00.199229 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m16:02:00.391855 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m16:02:00.395739 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (execute): 2025-11-16 16:01:57.638270 => 2025-11-16 16:02:00.395622
[0m16:02:00.396196 [debug] [Thread-1 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: Close
[0m16:02:00.685790 [info ] [Thread-2 (]: 2 of 3 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 3.08s]
[0m16:02:00.687913 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:02:00.688363 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:02:00.688619 [info ] [Thread-2 (]: 3 of 3 START test unique_stg_orders_order_id ................................... [RUN]
[0m16:02:00.689346 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m16:02:00.689599 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:02:00.700395 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:02:00.701217 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 16:02:00.689964 => 2025-11-16 16:02:00.701095
[0m16:02:00.701624 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:02:00.705722 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:02:00.707284 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:02:00.707701 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m16:02:00.708033 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:02:01.021815 [error] [Thread-1 (]: 1 of 3 FAIL 1 check_amount_stg_orders_total_amount ............................. [[31mFAIL 1[0m in 3.42s]
[0m16:02:01.022451 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:02:01.852774 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:02:01.855100 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 16:02:00.701855 => 2025-11-16 16:02:01.855013
[0m16:02:01.855399 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m16:02:02.288815 [info ] [Thread-2 (]: 3 of 3 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 1.60s]
[0m16:02:02.289278 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:02:02.291462 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:02:02.292247 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:02:02.292554 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m16:02:02.292819 [debug] [MainThread]: Connection 'test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c' was properly closed.
[0m16:02:02.293142 [info ] [MainThread]: 
[0m16:02:02.293573 [info ] [MainThread]: Finished running 3 tests in 0 hours 0 minutes and 12.98 seconds (12.98s).
[0m16:02:02.294262 [debug] [MainThread]: Command end result
[0m16:02:02.310167 [info ] [MainThread]: 
[0m16:02:02.310915 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:02:02.311427 [info ] [MainThread]: 
[0m16:02:02.311938 [error] [MainThread]: [31mFailure in test check_amount_stg_orders_total_amount (models/staging/schema.yml)[0m
[0m16:02:02.312424 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m16:02:02.313060 [info ] [MainThread]: 
[0m16:02:02.313557 [info ] [MainThread]:   compiled Code at target/compiled/airflow_dbt_project/models/staging/schema.yml/check_amount_stg_orders_total_amount.sql
[0m16:02:02.313991 [info ] [MainThread]: 
[0m16:02:02.314456 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m16:02:02.315121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a4b7568a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a4ae1f530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a4afc0320>]}
[0m16:02:02.315634 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 16:08:36.271815 | c052c6c7-dddf-48b7-9ac7-42905a160f9b ==============================
[0m16:08:36.271815 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:08:36.274904 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:08:36.275417 [debug] [MainThread]: Tracking: tracking
[0m16:08:36.275925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8bcab632c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8bcab62ae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8bcab62b10>]}
[0m16:08:36.341520 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m16:08:36.342405 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://tests/amount_validation.sql
[0m16:08:36.343225 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/order_amount.sql
[0m16:08:36.368315 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m16:08:36.481498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c052c6c7-dddf-48b7-9ac7-42905a160f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8bc937fd10>]}
[0m16:08:36.496709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c052c6c7-dddf-48b7-9ac7-42905a160f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8bc9311760>]}
[0m16:08:36.497467 [info ] [MainThread]: Found 6 models, 6 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m16:08:36.498006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c052c6c7-dddf-48b7-9ac7-42905a160f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8bcacae5a0>]}
[0m16:08:36.500614 [info ] [MainThread]: 
[0m16:08:36.504338 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:08:36.507092 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m16:08:36.519681 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m16:08:36.569061 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m16:08:36.569564 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m16:08:36.570027 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m16:08:36.570423 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:08:36.570796 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m16:08:36.573390 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:08:38.362493 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m16:08:38.367443 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m16:08:38.725896 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m16:08:38.728798 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m16:08:38.956901 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m16:08:38.960809 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m16:08:38.961218 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m16:08:38.964121 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:08:43.189523 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 4 seconds
[0m16:08:43.193023 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m16:08:45.148547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c052c6c7-dddf-48b7-9ac7-42905a160f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8bcb460260>]}
[0m16:08:45.150128 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:08:45.150700 [info ] [MainThread]: 
[0m16:08:45.207817 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.amount_validation
[0m16:08:45.208654 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:08:45.209223 [info ] [Thread-1 (]: 1 of 4 START test amount_validation ............................................ [RUN]
[0m16:08:45.210054 [info ] [Thread-2 (]: 2 of 4 START test check_amount_stg_orders_total_amount ......................... [RUN]
[0m16:08:45.211582 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.amount_validation'
[0m16:08:45.212929 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c'
[0m16:08:45.213690 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.amount_validation
[0m16:08:45.214321 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:08:45.219613 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.amount_validation"
[0m16:08:45.229278 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:08:45.231253 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.amount_validation (compile): 2025-11-16 16:08:45.214889 => 2025-11-16 16:08:45.231000
[0m16:08:45.232150 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.amount_validation
[0m16:08:45.238297 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (compile): 2025-11-16 16:08:45.220229 => 2025-11-16 16:08:45.237997
[0m16:08:45.244677 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:08:45.305727 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:08:45.306618 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.amount_validation"
[0m16:08:45.307718 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:08:45.308079 [debug] [Thread-2 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where total_amount< 0

      
    ) dbt_internal_test
[0m16:08:45.308320 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:08:45.310112 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.amount_validation"
[0m16:08:45.310436 [debug] [Thread-1 (]: On test.airflow_dbt_project.amount_validation: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.amount_validation"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT * 
FROM GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
WHERE total_amount < 0
      
    ) dbt_internal_test
[0m16:08:45.311597 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:08:47.790867 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m16:08:47.801220 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (execute): 2025-11-16 16:08:45.245316 => 2025-11-16 16:08:47.801103
[0m16:08:47.801602 [debug] [Thread-2 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: Close
[0m16:08:48.959168 [error] [Thread-2 (]: 2 of 4 FAIL 1 check_amount_stg_orders_total_amount ............................. [[31mFAIL 1[0m in 3.75s]
[0m16:08:48.961813 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:08:48.962360 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:08:48.962842 [info ] [Thread-2 (]: 3 of 4 START test not_null_stg_orders_order_id ................................. [RUN]
[0m16:08:48.963741 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m16:08:48.964056 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:08:48.983276 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:08:48.984267 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 16:08:48.964251 => 2025-11-16 16:08:48.984111
[0m16:08:48.984793 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:08:48.989647 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:08:48.991611 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:08:48.992247 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m16:08:48.992729 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:08:49.207280 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 4 seconds
[0m16:08:49.210238 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.amount_validation (execute): 2025-11-16 16:08:45.232724 => 2025-11-16 16:08:49.210130
[0m16:08:49.210608 [debug] [Thread-1 (]: On test.airflow_dbt_project.amount_validation: Close
[0m16:08:50.832134 [info ] [Thread-1 (]: 1 of 4 PASS amount_validation .................................................. [[32mPASS[0m in 5.62s]
[0m16:08:50.833015 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.amount_validation
[0m16:08:50.833633 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:08:50.834060 [info ] [Thread-1 (]: 4 of 4 START test unique_stg_orders_order_id ................................... [RUN]
[0m16:08:50.835253 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m16:08:50.835698 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:08:50.850311 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:08:50.851221 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 16:08:50.836002 => 2025-11-16 16:08:50.851079
[0m16:08:50.851722 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:08:50.857120 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:08:50.859663 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:08:50.860193 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m16:08:50.860556 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:08:51.657667 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 3 seconds
[0m16:08:51.661718 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 16:08:48.985109 => 2025-11-16 16:08:51.661601
[0m16:08:51.662128 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m16:08:53.407008 [info ] [Thread-2 (]: 3 of 4 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 4.44s]
[0m16:08:53.407744 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:09:04.000546 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 13 seconds
[0m16:09:04.004950 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 16:08:50.852028 => 2025-11-16 16:09:04.004810
[0m16:09:04.005375 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m16:09:06.094025 [info ] [Thread-1 (]: 4 of 4 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 15.26s]
[0m16:09:06.094584 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:09:06.097067 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:09:06.097896 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:09:06.098191 [debug] [MainThread]: Connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64' was properly closed.
[0m16:09:06.098395 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m16:09:06.098648 [info ] [MainThread]: 
[0m16:09:06.099018 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 29.60 seconds (29.60s).
[0m16:09:06.099662 [debug] [MainThread]: Command end result
[0m16:09:06.112929 [info ] [MainThread]: 
[0m16:09:06.114333 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:09:06.115275 [info ] [MainThread]: 
[0m16:09:06.116134 [error] [MainThread]: [31mFailure in test check_amount_stg_orders_total_amount (models/staging/schema.yml)[0m
[0m16:09:06.116835 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m16:09:06.117556 [info ] [MainThread]: 
[0m16:09:06.118518 [info ] [MainThread]:   compiled Code at target/compiled/airflow_dbt_project/models/staging/schema.yml/check_amount_stg_orders_total_amount.sql
[0m16:09:06.119196 [info ] [MainThread]: 
[0m16:09:06.119755 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m16:09:06.120555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8bc9311610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8bc93111c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8bc8157fb0>]}
[0m16:09:06.121214 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 16:15:27.364791 | 822c15ea-7831-4572-b473-49f6d2cce36d ==============================
[0m16:15:27.364791 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:15:27.366776 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:15:27.367047 [debug] [MainThread]: Tracking: tracking
[0m16:15:27.367324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f951941b2f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95193cf980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95424ec590>]}
[0m16:15:27.416194 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:15:27.417166 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/schema.yml
[0m16:15:27.435165 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m16:15:27.479948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9519163bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9519163740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95191637d0>]}
[0m16:15:27.480444 [debug] [MainThread]: Flushing usage events
[0m16:15:29.120428 [error] [MainThread]: Encountered an error:
Compilation Error
  Invalid generic test configuration given in models/staging/schema.yml: 
  Test arguments include "model", which is a reserved argument
  	@: UnparsedNodeUpdate(original_file_path='model...ne)


============================== 2025-11-16 16:16:13.714283 | 3e2f5a2b-9f74-4f70-85fb-1857178f5293 ==============================
[0m16:16:13.714283 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:16:13.716984 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:16:13.717350 [debug] [MainThread]: Tracking: tracking
[0m16:16:13.717828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4829356780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48293556d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4829356480>]}
[0m16:16:13.774388 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:16:13.775454 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/schema.yml
[0m16:16:13.795908 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m16:16:13.848549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f482920fce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f482920fbc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f482920fd40>]}
[0m16:16:13.849189 [debug] [MainThread]: Flushing usage events
[0m16:16:17.027330 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid test config given in models/staging/schema.yml:
  	test definition dictionary must have exactly one key, got [('check_amount', {'model': "ref('stg_orders')"}), ('column_name', 'total_amount')] instead (2 keys)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)


============================== 2025-11-16 16:16:25.623240 | ed3e8030-5aed-453f-9d0f-7d3615eb294f ==============================
[0m16:16:25.623240 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:16:25.626322 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:16:25.626697 [debug] [MainThread]: Tracking: tracking
[0m16:16:25.627167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12316c6e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1258b029c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1231edf260>]}
[0m16:16:25.692009 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:16:25.693156 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/schema.yml
[0m16:16:25.714790 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m16:16:25.767138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f123129fec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f123129f9b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f123129f560>]}
[0m16:16:25.767774 [debug] [MainThread]: Flushing usage events
[0m16:16:27.071509 [error] [MainThread]: Encountered an error:
Compilation Error
  Invalid generic test configuration given in models/staging/schema.yml: 
  Test arguments include "model", which is a reserved argument
  	@: UnparsedNodeUpdate(original_file_path='model...ne)


============================== 2025-11-16 16:17:09.596260 | 98146408-7711-47b7-8678-4c384908d829 ==============================
[0m16:17:09.596260 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:17:09.598283 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:17:09.598536 [debug] [MainThread]: Tracking: tracking
[0m16:17:09.598823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54170e0770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5443ce4110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5417073cb0>]}
[0m16:17:09.650792 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:17:09.651792 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/schema.yml
[0m16:17:09.671146 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m16:17:09.744011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '98146408-7711-47b7-8678-4c384908d829', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f541c10ae10>]}
[0m16:17:09.754308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '98146408-7711-47b7-8678-4c384908d829', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5416676780>]}
[0m16:17:09.754798 [info ] [MainThread]: Found 6 models, 6 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m16:17:09.755238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '98146408-7711-47b7-8678-4c384908d829', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5416bc81a0>]}
[0m16:17:09.757295 [info ] [MainThread]: 
[0m16:17:09.760149 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:17:09.762536 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m16:17:09.769455 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m16:17:09.814525 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m16:17:09.814973 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m16:17:09.815268 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:17:09.816172 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m16:17:09.816589 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m16:17:09.817013 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:17:12.096422 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 2 seconds
[0m16:17:12.099439 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m16:17:12.135005 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m16:17:12.138488 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m16:17:12.548225 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m16:17:12.551304 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m16:17:12.555935 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m16:17:12.556354 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:17:13.699081 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m16:17:13.703235 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m16:17:14.240594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '98146408-7711-47b7-8678-4c384908d829', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5414e1a000>]}
[0m16:17:14.241831 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:17:14.242313 [info ] [MainThread]: 
[0m16:17:14.283043 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.amount_validation
[0m16:17:14.283905 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:17:14.284674 [info ] [Thread-1 (]: 1 of 4 START test amount_validation ............................................ [RUN]
[0m16:17:14.285245 [info ] [Thread-2 (]: 2 of 4 START test check_amount_stg_orders_total_amount ......................... [RUN]
[0m16:17:14.286865 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.amount_validation'
[0m16:17:14.288155 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c'
[0m16:17:14.288664 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.amount_validation
[0m16:17:14.289121 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:17:14.293723 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.amount_validation"
[0m16:17:14.300464 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:17:14.301369 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.amount_validation (compile): 2025-11-16 16:17:14.289443 => 2025-11-16 16:17:14.301194
[0m16:17:14.301957 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.amount_validation
[0m16:17:14.325720 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (compile): 2025-11-16 16:17:14.294217 => 2025-11-16 16:17:14.325527
[0m16:17:14.326562 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:17:14.361310 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.amount_validation"
[0m16:17:14.362795 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:17:14.363892 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.amount_validation"
[0m16:17:14.364208 [debug] [Thread-1 (]: On test.airflow_dbt_project.amount_validation: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.amount_validation"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT * 
FROM GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
WHERE total_amount < 0
      
    ) dbt_internal_test
[0m16:17:14.364437 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:17:14.365061 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:17:14.366401 [debug] [Thread-2 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where total_amount< 0

      
    ) dbt_internal_test
[0m16:17:14.367381 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:17:15.645377 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:17:15.657864 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.amount_validation (execute): 2025-11-16 16:17:14.302437 => 2025-11-16 16:17:15.657725
[0m16:17:15.658361 [debug] [Thread-1 (]: On test.airflow_dbt_project.amount_validation: Close
[0m16:17:16.150274 [info ] [Thread-1 (]: 1 of 4 PASS amount_validation .................................................. [[32mPASS[0m in 1.86s]
[0m16:17:16.153652 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.amount_validation
[0m16:17:16.154241 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:17:16.154583 [info ] [Thread-1 (]: 3 of 4 START test not_null_stg_orders_order_id ................................. [RUN]
[0m16:17:16.155992 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m16:17:16.156379 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:17:16.169848 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:17:16.170904 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 16:17:16.156608 => 2025-11-16 16:17:16.170713
[0m16:17:16.171443 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:17:16.176683 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:17:16.178281 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:17:16.178803 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m16:17:16.179285 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:17:16.974883 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 3 seconds
[0m16:17:16.981126 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (execute): 2025-11-16 16:17:14.332058 => 2025-11-16 16:17:16.980905
[0m16:17:16.981997 [debug] [Thread-2 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: Close
[0m16:17:17.520665 [error] [Thread-2 (]: 2 of 4 FAIL 1 check_amount_stg_orders_total_amount ............................. [[31mFAIL 1[0m in 3.23s]
[0m16:17:17.521435 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:17:17.521969 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:17:17.522603 [info ] [Thread-2 (]: 4 of 4 START test unique_stg_orders_order_id ................................... [RUN]
[0m16:17:17.523773 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m16:17:17.524190 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:17:17.537200 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:17:17.538379 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 16:17:17.524427 => 2025-11-16 16:17:17.538129
[0m16:17:17.539081 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:17:17.544733 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:17:17.546986 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:17:17.547594 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m16:17:17.548100 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:17:18.845736 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:17:18.849824 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 16:17:17.539691 => 2025-11-16 16:17:18.849699
[0m16:17:18.850258 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m16:17:18.855454 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m16:17:18.858250 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 16:17:16.171749 => 2025-11-16 16:17:18.858158
[0m16:17:18.858579 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m16:17:19.289081 [info ] [Thread-2 (]: 4 of 4 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 1.77s]
[0m16:17:19.289960 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:17:19.402383 [info ] [Thread-1 (]: 3 of 4 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 3.25s]
[0m16:17:19.403267 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:17:19.406069 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:17:19.407008 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:17:19.407314 [debug] [MainThread]: Connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64' was properly closed.
[0m16:17:19.407539 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m16:17:19.407824 [info ] [MainThread]: 
[0m16:17:19.408224 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 9.65 seconds (9.65s).
[0m16:17:19.408922 [debug] [MainThread]: Command end result
[0m16:17:19.423069 [info ] [MainThread]: 
[0m16:17:19.423782 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:17:19.424245 [info ] [MainThread]: 
[0m16:17:19.424678 [error] [MainThread]: [31mFailure in test check_amount_stg_orders_total_amount (models/staging/schema.yml)[0m
[0m16:17:19.425101 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m16:17:19.425491 [info ] [MainThread]: 
[0m16:17:19.425911 [info ] [MainThread]:   compiled Code at target/compiled/airflow_dbt_project/models/staging/schema.yml/check_amount_stg_orders_total_amount.sql
[0m16:17:19.426374 [info ] [MainThread]: 
[0m16:17:19.426827 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m16:17:19.427543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f541c974d70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5434fa0bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54144dbdd0>]}
[0m16:17:19.428118 [debug] [MainThread]: Flushing usage events
[0m16:17:23.438997 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.


============================== 2025-11-16 16:17:34.836429 | 261e7919-b3c8-412b-9a4b-1eefd8b7c6ed ==============================
[0m16:17:34.836429 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:17:34.839118 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:17:34.839544 [debug] [MainThread]: Tracking: tracking
[0m16:17:34.839965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda1cfe82f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9fe1e2c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9f7fab800>]}
[0m16:17:34.901427 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:17:34.904216 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/schema.yml
[0m16:17:34.929388 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m16:17:34.981341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9f7d3bd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9f7d3bc80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9f7d3bb60>]}
[0m16:17:34.982107 [debug] [MainThread]: Flushing usage events
[0m16:17:35.847523 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid test config given in models/staging/schema.yml:
  	test arguments must be a dict, got <class 'NoneType'> (value None)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)


============================== 2025-11-16 16:17:56.615452 | a7416f5d-9951-4393-8dab-ffca6452d4cb ==============================
[0m16:17:56.615452 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:17:56.621432 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:17:56.622247 [debug] [MainThread]: Tracking: tracking
[0m16:17:56.623045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e56c8f980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e55bf7a40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e553bfa10>]}
[0m16:17:56.714158 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:17:56.715923 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/schema.yml
[0m16:17:56.747803 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m16:17:56.832840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e55c134d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e55107b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e55107e00>]}
[0m16:17:56.833962 [debug] [MainThread]: Flushing usage events
[0m16:17:57.980950 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid test config given in models/staging/schema.yml:
  	test arguments must be a dict, got <class 'NoneType'> (value None)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)


============================== 2025-11-16 16:18:13.760329 | 7eb95dcd-929c-4f4d-bae7-155668ece7b4 ==============================
[0m16:18:13.760329 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:18:13.763139 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:18:13.763501 [debug] [MainThread]: Tracking: tracking
[0m16:18:13.764034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0af1f7a300>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0af1f7a2a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0af1f7a330>]}
[0m16:18:13.838913 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:18:13.840440 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/schema.yml
[0m16:18:13.863942 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m16:18:13.956459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7eb95dcd-929c-4f4d-bae7-155668ece7b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0af1db4560>]}
[0m16:18:13.969487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7eb95dcd-929c-4f4d-bae7-155668ece7b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0af1fbe9f0>]}
[0m16:18:13.970151 [info ] [MainThread]: Found 6 models, 6 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m16:18:13.970634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7eb95dcd-929c-4f4d-bae7-155668ece7b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0af211e930>]}
[0m16:18:13.973224 [info ] [MainThread]: 
[0m16:18:13.976716 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:18:13.979828 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m16:18:13.986833 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m16:18:14.035013 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m16:18:14.035482 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m16:18:14.036107 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m16:18:14.036628 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:18:14.037136 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m16:18:14.039615 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:18:16.448971 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m16:18:16.451692 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m16:18:16.956619 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m16:18:16.962996 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m16:18:16.963462 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m16:18:16.963770 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:18:18.022394 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 1 seconds
[0m16:18:18.034970 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m16:18:18.115709 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 4 seconds
[0m16:18:18.120494 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m16:18:18.750991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7eb95dcd-929c-4f4d-bae7-155668ece7b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0af8253b30>]}
[0m16:18:18.752231 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:18:18.752735 [info ] [MainThread]: 
[0m16:18:18.799066 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.amount_validation
[0m16:18:18.800320 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:18:18.800954 [info ] [Thread-1 (]: 1 of 4 START test amount_validation ............................................ [RUN]
[0m16:18:18.802037 [info ] [Thread-2 (]: 2 of 4 START test check_amount_stg_orders_total_amount ......................... [RUN]
[0m16:18:18.804392 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.amount_validation'
[0m16:18:18.806352 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c'
[0m16:18:18.807333 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.amount_validation
[0m16:18:18.808084 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:18:18.815701 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.amount_validation"
[0m16:18:18.827199 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:18:18.828986 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (compile): 2025-11-16 16:18:18.816293 => 2025-11-16 16:18:18.828698
[0m16:18:18.830037 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.amount_validation (compile): 2025-11-16 16:18:18.808589 => 2025-11-16 16:18:18.829656
[0m16:18:18.831079 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:18:18.832202 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.amount_validation
[0m16:18:19.001497 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.amount_validation"
[0m16:18:19.008622 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:18:19.011755 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.amount_validation"
[0m16:18:19.014705 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:18:19.015768 [debug] [Thread-1 (]: On test.airflow_dbt_project.amount_validation: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.amount_validation"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT * 
FROM GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
WHERE total_amount < 0
      
    ) dbt_internal_test
[0m16:18:19.016737 [debug] [Thread-2 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where total_amount< 0

      
    ) dbt_internal_test
[0m16:18:19.017559 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:18:19.018313 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:18:20.064735 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:18:20.094284 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.amount_validation (execute): 2025-11-16 16:18:18.843566 => 2025-11-16 16:18:20.094007
[0m16:18:20.095286 [debug] [Thread-1 (]: On test.airflow_dbt_project.amount_validation: Close
[0m16:18:20.107561 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:18:20.114780 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (execute): 2025-11-16 16:18:18.833046 => 2025-11-16 16:18:20.114547
[0m16:18:20.115701 [debug] [Thread-2 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: Close
[0m16:18:20.702251 [error] [Thread-2 (]: 2 of 4 FAIL 1 check_amount_stg_orders_total_amount ............................. [[31mFAIL 1[0m in 1.90s]
[0m16:18:20.709298 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:18:20.711073 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:18:20.712612 [info ] [Thread-2 (]: 3 of 4 START test not_null_stg_orders_order_id ................................. [RUN]
[0m16:18:20.717455 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m16:18:20.718536 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:18:20.729796 [info ] [Thread-1 (]: 1 of 4 PASS amount_validation .................................................. [[32mPASS[0m in 1.93s]
[0m16:18:20.742240 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.amount_validation
[0m16:18:20.749988 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:18:20.759701 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:18:20.761117 [info ] [Thread-1 (]: 4 of 4 START test unique_stg_orders_order_id ................................... [RUN]
[0m16:18:20.763595 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m16:18:20.764347 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:18:20.775864 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 16:18:20.719300 => 2025-11-16 16:18:20.775478
[0m16:18:20.782800 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:18:20.815599 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:18:20.817276 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:18:20.819442 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:18:20.820111 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m16:18:20.820662 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:18:20.825321 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 16:18:20.764933 => 2025-11-16 16:18:20.825096
[0m16:18:20.826084 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:18:20.833188 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:18:20.836343 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:18:20.837223 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m16:18:20.837663 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:18:21.868238 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:18:21.872559 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 16:18:20.826450 => 2025-11-16 16:18:21.872439
[0m16:18:21.872986 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m16:18:22.130743 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:18:22.134463 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 16:18:20.789370 => 2025-11-16 16:18:22.134356
[0m16:18:22.134844 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m16:18:22.516379 [info ] [Thread-1 (]: 4 of 4 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 1.75s]
[0m16:18:22.517524 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:18:22.572982 [info ] [Thread-2 (]: 3 of 4 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 1.86s]
[0m16:18:22.573814 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:18:22.576893 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:18:22.578112 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:18:22.578542 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m16:18:22.578939 [debug] [MainThread]: Connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64' was properly closed.
[0m16:18:22.579390 [info ] [MainThread]: 
[0m16:18:22.580036 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 8.61 seconds (8.61s).
[0m16:18:22.581138 [debug] [MainThread]: Command end result
[0m16:18:22.596693 [info ] [MainThread]: 
[0m16:18:22.597686 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:18:22.598274 [info ] [MainThread]: 
[0m16:18:22.598964 [error] [MainThread]: [31mFailure in test check_amount_stg_orders_total_amount (models/staging/schema.yml)[0m
[0m16:18:22.599549 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m16:18:22.600120 [info ] [MainThread]: 
[0m16:18:22.600692 [info ] [MainThread]:   compiled Code at target/compiled/airflow_dbt_project/models/staging/schema.yml/check_amount_stg_orders_total_amount.sql
[0m16:18:22.601313 [info ] [MainThread]: 
[0m16:18:22.602008 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m16:18:22.603025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0af29ab680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0af2476870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0af06bc9e0>]}
[0m16:18:22.603813 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 16:26:52.597088 | 2a273723-d75f-4a6c-a450-448b060303a0 ==============================
[0m16:26:52.597088 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:26:52.599920 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:26:52.600282 [debug] [MainThread]: Tracking: tracking
[0m16:26:52.600637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90464ba030>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90466bea50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f904667f7d0>]}
[0m16:26:52.659286 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:26:52.659775 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:26:52.671939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2a273723-d75f-4a6c-a450-448b060303a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9046785160>]}
[0m16:26:52.685031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2a273723-d75f-4a6c-a450-448b060303a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90464ba030>]}
[0m16:26:52.685889 [info ] [MainThread]: Found 6 models, 6 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m16:26:52.686644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a273723-d75f-4a6c-a450-448b060303a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90464e77a0>]}
[0m16:26:52.690174 [info ] [MainThread]: 
[0m16:26:52.694165 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:26:52.696674 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m16:26:52.703391 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m16:26:52.760276 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m16:26:52.761018 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m16:26:52.761631 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m16:26:52.762161 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m16:26:52.762682 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:26:52.763162 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:26:54.819347 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m16:26:54.822371 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m16:26:54.828016 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m16:26:54.830911 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m16:26:55.279072 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m16:26:55.282178 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m16:26:55.282544 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m16:26:55.282810 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:26:56.565569 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 1 seconds
[0m16:26:56.568045 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m16:26:57.155221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a273723-d75f-4a6c-a450-448b060303a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9047ea7b60>]}
[0m16:26:57.156399 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:26:57.156846 [info ] [MainThread]: 
[0m16:26:57.201538 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.amount_validation
[0m16:26:57.202377 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:26:57.202939 [info ] [Thread-1 (]: 1 of 4 START test amount_validation ............................................ [RUN]
[0m16:26:57.203629 [info ] [Thread-2 (]: 2 of 4 START test check_amount_stg_orders_total_amount ......................... [RUN]
[0m16:26:57.204923 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.amount_validation'
[0m16:26:57.206068 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c'
[0m16:26:57.206557 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.amount_validation
[0m16:26:57.207049 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:26:57.211865 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.amount_validation"
[0m16:26:57.228154 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:26:57.229501 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.amount_validation (compile): 2025-11-16 16:26:57.207343 => 2025-11-16 16:26:57.229260
[0m16:26:57.230311 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.amount_validation
[0m16:26:57.256841 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (compile): 2025-11-16 16:26:57.212365 => 2025-11-16 16:26:57.256693
[0m16:26:57.262503 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:26:57.275170 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.amount_validation"
[0m16:26:57.275609 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:26:57.276529 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:26:57.276769 [debug] [Thread-2 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where total_amount< 0

      
    ) dbt_internal_test
[0m16:26:57.277357 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.amount_validation"
[0m16:26:57.277766 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:26:57.278109 [debug] [Thread-1 (]: On test.airflow_dbt_project.amount_validation: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.amount_validation"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT * 
FROM GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
WHERE total_amount < 0
      
    ) dbt_internal_test
[0m16:26:57.279389 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:26:58.422010 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:26:58.434012 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (execute): 2025-11-16 16:26:57.268006 => 2025-11-16 16:26:58.433905
[0m16:26:58.434373 [debug] [Thread-2 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: Close
[0m16:26:58.478027 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:26:58.481863 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.amount_validation (execute): 2025-11-16 16:26:57.230738 => 2025-11-16 16:26:58.481753
[0m16:26:58.482252 [debug] [Thread-1 (]: On test.airflow_dbt_project.amount_validation: Close
[0m16:26:58.860543 [error] [Thread-2 (]: 2 of 4 FAIL 1 check_amount_stg_orders_total_amount ............................. [[31mFAIL 1[0m in 1.65s]
[0m16:26:58.863699 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:26:58.864438 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:26:58.865281 [info ] [Thread-2 (]: 3 of 4 START test not_null_stg_orders_order_id ................................. [RUN]
[0m16:26:58.867219 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m16:26:58.867981 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:26:58.887183 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:26:58.888775 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 16:26:58.868485 => 2025-11-16 16:26:58.888522
[0m16:26:58.889562 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:26:58.895318 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:26:58.896800 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:26:58.897263 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m16:26:58.897587 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:26:59.008386 [info ] [Thread-1 (]: 1 of 4 PASS amount_validation .................................................. [[32mPASS[0m in 1.80s]
[0m16:26:59.009023 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.amount_validation
[0m16:26:59.009446 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:26:59.009866 [info ] [Thread-1 (]: 4 of 4 START test unique_stg_orders_order_id ................................... [RUN]
[0m16:26:59.010747 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m16:26:59.011072 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:26:59.025265 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:26:59.026563 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 16:26:59.011277 => 2025-11-16 16:26:59.026405
[0m16:26:59.027100 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:26:59.032480 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:26:59.035541 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:26:59.036353 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m16:26:59.036783 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:26:59.901465 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:26:59.906586 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 16:26:58.889975 => 2025-11-16 16:26:59.906397
[0m16:26:59.907194 [debug] [Thread-2 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m16:27:00.005103 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:27:00.008816 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 16:26:59.027380 => 2025-11-16 16:27:00.008671
[0m16:27:00.009323 [debug] [Thread-1 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m16:27:00.413071 [info ] [Thread-2 (]: 3 of 4 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 1.55s]
[0m16:27:00.413762 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:27:00.434306 [info ] [Thread-1 (]: 4 of 4 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 1.42s]
[0m16:27:00.435548 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:27:00.440368 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:27:00.441953 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:27:00.442461 [debug] [MainThread]: Connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64' was properly closed.
[0m16:27:00.442831 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m16:27:00.443294 [info ] [MainThread]: 
[0m16:27:00.443833 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 7.75 seconds (7.75s).
[0m16:27:00.444757 [debug] [MainThread]: Command end result
[0m16:27:00.462248 [info ] [MainThread]: 
[0m16:27:00.462998 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:27:00.463461 [info ] [MainThread]: 
[0m16:27:00.463951 [error] [MainThread]: [31mFailure in test check_amount_stg_orders_total_amount (models/staging/schema.yml)[0m
[0m16:27:00.464407 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m16:27:00.464848 [info ] [MainThread]: 
[0m16:27:00.465327 [info ] [MainThread]:   compiled Code at target/compiled/airflow_dbt_project/models/staging/schema.yml/check_amount_stg_orders_total_amount.sql
[0m16:27:00.465763 [info ] [MainThread]: 
[0m16:27:00.466352 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m16:27:00.467066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f904512d640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f904512f6b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f904512d2e0>]}
[0m16:27:00.467612 [debug] [MainThread]: Flushing usage events
[0m16:27:04.479898 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.


============================== 2025-11-16 16:29:35.726125 | 735403ef-0cbe-4e30-9db3-36607fe7b4aa ==============================
[0m16:29:35.726125 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:29:35.731084 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:29:35.731713 [debug] [MainThread]: Tracking: tracking
[0m16:29:35.732304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd262444e00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd262446840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd26263fa10>]}
[0m16:29:35.797509 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:29:35.798795 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/order_amount.sql
[0m16:29:35.825307 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m16:29:35.936847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '735403ef-0cbe-4e30-9db3-36607fe7b4aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd262f1ba10>]}
[0m16:29:35.950905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '735403ef-0cbe-4e30-9db3-36607fe7b4aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd26248ad80>]}
[0m16:29:35.951736 [info ] [MainThread]: Found 6 models, 6 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m16:29:35.952526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '735403ef-0cbe-4e30-9db3-36607fe7b4aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd28db21f40>]}
[0m16:29:35.956105 [info ] [MainThread]: 
[0m16:29:35.960134 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:29:35.962771 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m16:29:35.970101 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m16:29:36.026772 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m16:29:36.027266 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m16:29:36.027598 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:29:36.030426 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m16:29:36.030831 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m16:29:36.032834 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:29:39.136919 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 3 seconds
[0m16:29:39.140080 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m16:29:39.189835 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 3 seconds
[0m16:29:39.193082 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m16:29:39.662694 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m16:29:39.666310 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m16:29:39.666681 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m16:29:39.666967 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:29:41.712291 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m16:29:41.715550 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m16:29:42.593749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '735403ef-0cbe-4e30-9db3-36607fe7b4aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2603a6330>]}
[0m16:29:42.595005 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:29:42.595475 [info ] [MainThread]: 
[0m16:29:42.640929 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.amount_validation
[0m16:29:42.641774 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:29:42.642534 [info ] [Thread-1 (]: 1 of 4 START test amount_validation ............................................ [RUN]
[0m16:29:42.643341 [info ] [Thread-2 (]: 2 of 4 START test check_amount_stg_orders_total_amount ......................... [RUN]
[0m16:29:42.644588 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.amount_validation'
[0m16:29:42.645622 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c'
[0m16:29:42.646151 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.amount_validation
[0m16:29:42.646598 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:29:42.650820 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.amount_validation"
[0m16:29:42.657508 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:29:42.658457 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.amount_validation (compile): 2025-11-16 16:29:42.646925 => 2025-11-16 16:29:42.658325
[0m16:29:42.658935 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.amount_validation
[0m16:29:42.665555 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (compile): 2025-11-16 16:29:42.651256 => 2025-11-16 16:29:42.665330
[0m16:29:42.671494 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:29:42.729344 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.amount_validation"
[0m16:29:42.731442 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:29:42.732582 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.amount_validation"
[0m16:29:42.732910 [debug] [Thread-1 (]: On test.airflow_dbt_project.amount_validation: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.amount_validation"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT * 
FROM GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
WHERE total_amount < 0
      
    ) dbt_internal_test
[0m16:29:42.733146 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:29:42.734932 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:29:42.735254 [debug] [Thread-2 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where total_amount< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m16:29:42.735482 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:29:44.631194 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m16:29:44.642991 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.amount_validation (execute): 2025-11-16 16:29:42.659230 => 2025-11-16 16:29:44.642856
[0m16:29:44.643380 [debug] [Thread-1 (]: On test.airflow_dbt_project.amount_validation: Close
[0m16:29:45.433242 [info ] [Thread-1 (]: 1 of 4 PASS amount_validation .................................................. [[32mPASS[0m in 2.79s]
[0m16:29:45.436552 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.amount_validation
[0m16:29:45.437611 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 3 seconds
[0m16:29:45.438366 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:29:45.441597 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (execute): 2025-11-16 16:29:42.677740 => 2025-11-16 16:29:45.441490
[0m16:29:45.442434 [info ] [Thread-1 (]: 3 of 4 START test not_null_stg_orders_order_id ................................. [RUN]
[0m16:29:45.443047 [debug] [Thread-2 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: Close
[0m16:29:45.444071 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m16:29:45.446546 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:29:45.465679 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:29:45.467173 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 16:29:45.448646 => 2025-11-16 16:29:45.466961
[0m16:29:45.467906 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:29:45.475443 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:29:45.477976 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:29:45.478595 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m16:29:45.479035 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:29:46.123430 [info ] [Thread-2 (]: 2 of 4 PASS check_amount_stg_orders_total_amount ............................... [[32mPASS[0m in 3.48s]
[0m16:29:46.124054 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:29:46.124512 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:29:46.124923 [info ] [Thread-2 (]: 4 of 4 START test unique_stg_orders_order_id ................................... [RUN]
[0m16:29:46.125693 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m16:29:46.126008 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:29:46.137059 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:29:46.137929 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 16:29:46.126215 => 2025-11-16 16:29:46.137777
[0m16:29:46.138429 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:29:46.148275 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:29:46.150611 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:29:46.151169 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m16:29:46.151537 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:29:47.001222 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m16:29:47.005909 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 16:29:45.468375 => 2025-11-16 16:29:47.005780
[0m16:29:47.006315 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m16:29:47.647757 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m16:29:47.651683 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 16:29:46.138704 => 2025-11-16 16:29:47.651543
[0m16:29:47.652200 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m16:29:47.972310 [info ] [Thread-1 (]: 3 of 4 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 2.53s]
[0m16:29:47.972913 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:29:48.985378 [info ] [Thread-2 (]: 4 of 4 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 2.86s]
[0m16:29:48.985974 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:29:48.988192 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:29:48.988958 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:29:48.989234 [debug] [MainThread]: Connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64' was properly closed.
[0m16:29:48.989438 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m16:29:48.989682 [info ] [MainThread]: 
[0m16:29:48.990017 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 13.03 seconds (13.03s).
[0m16:29:48.990712 [debug] [MainThread]: Command end result
[0m16:29:49.006902 [info ] [MainThread]: 
[0m16:29:49.008784 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:29:49.011886 [info ] [MainThread]: 
[0m16:29:49.013131 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m16:29:49.014435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2745cdf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd263d7f4a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2602249e0>]}
[0m16:29:49.015626 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 16:31:22.667820 | 87c105b7-a2c7-47cf-be38-bf8a58def380 ==============================
[0m16:31:22.667820 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:31:22.670170 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:31:22.670451 [debug] [MainThread]: Tracking: tracking
[0m16:31:22.670758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4cd6769c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4cd55b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4cde00260>]}
[0m16:31:22.721097 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:31:22.722106 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/order_amount.sql
[0m16:31:22.742239 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m16:31:22.827493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '87c105b7-a2c7-47cf-be38-bf8a58def380', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4ecd99f70>]}
[0m16:31:22.837858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '87c105b7-a2c7-47cf-be38-bf8a58def380', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4cd3a68a0>]}
[0m16:31:22.838371 [info ] [MainThread]: Found 6 models, 6 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m16:31:22.838769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '87c105b7-a2c7-47cf-be38-bf8a58def380', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4cdfc7e90>]}
[0m16:31:22.840911 [info ] [MainThread]: 
[0m16:31:22.843908 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:31:22.846026 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m16:31:22.852596 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m16:31:22.901705 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m16:31:22.902188 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m16:31:22.902477 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:31:22.903246 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m16:31:22.903945 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m16:31:22.906514 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:31:26.752140 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 4 seconds
[0m16:31:26.755430 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m16:31:28.657021 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m16:31:28.662773 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m16:31:28.663189 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m16:31:28.663477 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:31:29.924160 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 7 seconds
[0m16:31:29.929686 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m16:31:31.027551 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m16:31:31.030892 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m16:31:31.861103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '87c105b7-a2c7-47cf-be38-bf8a58def380', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4cd319760>]}
[0m16:31:31.862464 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:31:31.863015 [info ] [MainThread]: 
[0m16:31:31.908425 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.amount_validation
[0m16:31:31.909092 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:31:31.909730 [info ] [Thread-1 (]: 1 of 4 START test amount_validation ............................................ [RUN]
[0m16:31:31.910426 [info ] [Thread-2 (]: 2 of 4 START test check_amount_stg_orders_total_amount ......................... [RUN]
[0m16:31:31.911592 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.amount_validation'
[0m16:31:31.912580 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c'
[0m16:31:31.913077 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.amount_validation
[0m16:31:31.913498 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:31:31.917914 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.amount_validation"
[0m16:31:31.924245 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:31:31.925238 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.amount_validation (compile): 2025-11-16 16:31:31.913775 => 2025-11-16 16:31:31.925094
[0m16:31:31.925662 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (compile): 2025-11-16 16:31:31.918398 => 2025-11-16 16:31:31.925557
[0m16:31:31.926192 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.amount_validation
[0m16:31:31.926668 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:31:31.991321 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.amount_validation"
[0m16:31:31.994215 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:31:31.995226 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:31:31.995498 [debug] [Thread-2 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where total_amount< 0
    -- having count(*)>0

      
    ) dbt_internal_test
[0m16:31:31.995733 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:31:31.997225 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.amount_validation"
[0m16:31:31.997505 [debug] [Thread-1 (]: On test.airflow_dbt_project.amount_validation: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.amount_validation"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT * 
FROM GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
WHERE total_amount < 0
      
    ) dbt_internal_test
[0m16:31:31.998493 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:31:34.282827 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m16:31:34.295155 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (execute): 2025-11-16 16:31:31.937705 => 2025-11-16 16:31:34.295052
[0m16:31:34.295520 [debug] [Thread-2 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: Close
[0m16:31:34.315703 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m16:31:34.320029 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.amount_validation (execute): 2025-11-16 16:31:31.926965 => 2025-11-16 16:31:34.319914
[0m16:31:34.320446 [debug] [Thread-1 (]: On test.airflow_dbt_project.amount_validation: Close
[0m16:31:34.816636 [info ] [Thread-1 (]: 1 of 4 PASS amount_validation .................................................. [[32mPASS[0m in 2.91s]
[0m16:31:34.819657 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.amount_validation
[0m16:31:34.820306 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:31:34.820664 [info ] [Thread-1 (]: 3 of 4 START test not_null_stg_orders_order_id ................................. [RUN]
[0m16:31:34.821644 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m16:31:34.822192 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:31:34.840552 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:31:34.844601 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 16:31:34.822427 => 2025-11-16 16:31:34.844382
[0m16:31:34.845312 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:31:34.852530 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:31:34.854685 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:31:34.855368 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m16:31:34.855922 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:31:35.735444 [error] [Thread-2 (]: 2 of 4 FAIL 1 check_amount_stg_orders_total_amount ............................. [[31mFAIL 1[0m in 3.82s]
[0m16:31:35.736495 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:31:35.737273 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:31:35.737947 [info ] [Thread-2 (]: 4 of 4 START test unique_stg_orders_order_id ................................... [RUN]
[0m16:31:35.739409 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m16:31:35.739940 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:31:35.755526 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:31:35.756467 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 16:31:35.740270 => 2025-11-16 16:31:35.756319
[0m16:31:35.757030 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:31:35.762069 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:31:35.764452 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:31:35.765111 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m16:31:35.765537 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:31:37.780626 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m16:31:37.785006 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 16:31:34.845653 => 2025-11-16 16:31:37.784884
[0m16:31:37.785428 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m16:31:39.042278 [info ] [Thread-1 (]: 3 of 4 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 4.22s]
[0m16:31:39.043176 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:31:40.569447 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 5 seconds
[0m16:31:40.572215 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 16:31:35.757447 => 2025-11-16 16:31:40.572112
[0m16:31:40.572571 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m16:31:41.224278 [info ] [Thread-2 (]: 4 of 4 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 5.49s]
[0m16:31:41.225236 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:31:41.228668 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:31:41.229833 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:31:41.230259 [debug] [MainThread]: Connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64' was properly closed.
[0m16:31:41.230536 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m16:31:41.230910 [info ] [MainThread]: 
[0m16:31:41.231494 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 18.39 seconds (18.39s).
[0m16:31:41.232406 [debug] [MainThread]: Command end result
[0m16:31:41.246768 [info ] [MainThread]: 
[0m16:31:41.247965 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:31:41.248678 [info ] [MainThread]: 
[0m16:31:41.249246 [error] [MainThread]: [31mFailure in test check_amount_stg_orders_total_amount (models/staging/schema.yml)[0m
[0m16:31:41.250193 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m16:31:41.250967 [info ] [MainThread]: 
[0m16:31:41.252392 [info ] [MainThread]:   compiled Code at target/compiled/airflow_dbt_project/models/staging/schema.yml/check_amount_stg_orders_total_amount.sql
[0m16:31:41.253675 [info ] [MainThread]: 
[0m16:31:41.254907 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m16:31:41.256584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4f54f31a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4cd975d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4cd78abd0>]}
[0m16:31:41.257827 [debug] [MainThread]: Flushing usage events


============================== 2025-11-16 16:34:41.398565 | fde21a81-fefa-4368-8717-042bcc634b37 ==============================
[0m16:34:41.398565 [info ] [MainThread]: Running with dbt=1.4.0
[0m16:34:41.402036 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['stg_orders'], 'which': 'test', 'rpc_method': 'test'}
[0m16:34:41.402473 [debug] [MainThread]: Tracking: tracking
[0m16:34:41.402943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4bfb54cb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4cb9cd070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4bdbbdf70>]}
[0m16:34:41.472637 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:34:41.473823 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://macros/order_amount.sql
[0m16:34:41.498321 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_orders.sql
[0m16:34:41.582885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fde21a81-fefa-4368-8717-042bcc634b37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4bd71a690>]}
[0m16:34:41.595100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fde21a81-fefa-4368-8717-042bcc634b37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4bd7ce7b0>]}
[0m16:34:41.595691 [info ] [MainThread]: Found 6 models, 6 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m16:34:41.596166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fde21a81-fefa-4368-8717-042bcc634b37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4bda6c9e0>]}
[0m16:34:41.598650 [info ] [MainThread]: 
[0m16:34:41.601944 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:34:41.604501 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m16:34:41.611487 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test'
[0m16:34:41.662921 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m16:34:41.664075 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test"
[0m16:34:41.664551 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m16:34:41.664995 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema \n\n        test"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test
[0m16:34:41.665400 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:34:41.665773 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:34:44.373987 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 3 seconds
[0m16:34:44.377424 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- if no customized the schema in  or project.yml, which is none, enter and use the defualt schema 

        test: Close
[0m16:34:45.569972 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m16:34:45.578461 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m16:34:45.578983 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m16:34:45.579323 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:34:45.636357 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 4 seconds
[0m16:34:45.639395 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m16:34:54.681898 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 9 seconds
[0m16:34:54.685171 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m16:34:55.800803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fde21a81-fefa-4368-8717-042bcc634b37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4bd715c70>]}
[0m16:34:55.802395 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m16:34:55.803142 [info ] [MainThread]: 
[0m16:34:55.851213 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.amount_validation
[0m16:34:55.852186 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:34:55.852839 [info ] [Thread-1 (]: 1 of 4 START test amount_validation ............................................ [RUN]
[0m16:34:55.853785 [info ] [Thread-2 (]: 2 of 4 START test check_amount_stg_orders_total_amount ......................... [RUN]
[0m16:34:55.855567 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.amount_validation'
[0m16:34:55.857067 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c'
[0m16:34:55.857776 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.amount_validation
[0m16:34:55.858396 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:34:55.863325 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.amount_validation"
[0m16:34:55.870538 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:34:55.871520 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.amount_validation (compile): 2025-11-16 16:34:55.858743 => 2025-11-16 16:34:55.871353
[0m16:34:55.872104 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.amount_validation
[0m16:34:55.878688 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (compile): 2025-11-16 16:34:55.863851 => 2025-11-16 16:34:55.878474
[0m16:34:55.884866 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:34:55.946100 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:34:55.948778 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.amount_validation"
[0m16:34:55.949982 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"
[0m16:34:55.950307 [debug] [Thread-2 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
    where total_amount< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m16:34:55.950563 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:34:55.951298 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.amount_validation"
[0m16:34:55.952807 [debug] [Thread-1 (]: On test.airflow_dbt_project.amount_validation: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.amount_validation"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT * 
FROM GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
WHERE total_amount < 0
      
    ) dbt_internal_test
[0m16:34:55.953938 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:34:58.137352 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m16:34:58.149370 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.amount_validation (execute): 2025-11-16 16:34:55.872411 => 2025-11-16 16:34:58.149254
[0m16:34:58.149795 [debug] [Thread-1 (]: On test.airflow_dbt_project.amount_validation: Close
[0m16:34:58.181211 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m16:34:58.185070 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c (execute): 2025-11-16 16:34:55.890920 => 2025-11-16 16:34:58.184954
[0m16:34:58.185463 [debug] [Thread-2 (]: On test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c: Close
[0m16:34:58.643092 [info ] [Thread-1 (]: 1 of 4 PASS amount_validation .................................................. [[32mPASS[0m in 2.79s]
[0m16:34:58.646701 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.amount_validation
[0m16:34:58.647483 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:34:58.648082 [info ] [Thread-1 (]: 3 of 4 START test not_null_stg_orders_order_id ................................. [RUN]
[0m16:34:58.649195 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64'
[0m16:34:58.649607 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:34:58.665650 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:34:58.667166 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (compile): 2025-11-16 16:34:58.649858 => 2025-11-16 16:34:58.666793
[0m16:34:58.667994 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:34:58.673712 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:34:58.675457 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"
[0m16:34:58.676042 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is null



      
    ) dbt_internal_test
[0m16:34:58.677037 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:34:58.701823 [info ] [Thread-2 (]: 2 of 4 PASS check_amount_stg_orders_total_amount ............................... [[32mPASS[0m in 2.85s]
[0m16:34:58.702767 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.check_amount_stg_orders_total_amount.67db8be88c
[0m16:34:58.703508 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:34:58.704233 [info ] [Thread-2 (]: 4 of 4 START test unique_stg_orders_order_id ................................... [RUN]
[0m16:34:58.705536 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a'
[0m16:34:58.706088 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:34:58.722558 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:34:58.723509 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (compile): 2025-11-16 16:34:58.706423 => 2025-11-16 16:34:58.723363
[0m16:34:58.724099 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:34:58.730683 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:34:58.732362 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"
[0m16:34:58.732930 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m16:34:58.733272 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:35:01.144561 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m16:35:01.148546 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a (execute): 2025-11-16 16:34:58.724447 => 2025-11-16 16:35:01.148414
[0m16:35:01.149059 [debug] [Thread-2 (]: On test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a: Close
[0m16:35:01.427160 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m16:35:01.432071 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64 (execute): 2025-11-16 16:34:58.668410 => 2025-11-16 16:35:01.431799
[0m16:35:01.432628 [debug] [Thread-1 (]: On test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64: Close
[0m16:35:01.569204 [info ] [Thread-2 (]: 4 of 4 PASS unique_stg_orders_order_id ......................................... [[32mPASS[0m in 2.86s]
[0m16:35:01.569773 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a
[0m16:35:01.929939 [info ] [Thread-1 (]: 3 of 4 PASS not_null_stg_orders_order_id ....................................... [[32mPASS[0m in 3.28s]
[0m16:35:01.930728 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64
[0m16:35:01.933634 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m16:35:01.934642 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:35:01.934997 [debug] [MainThread]: Connection 'test.airflow_dbt_project.unique_stg_orders_order_id.e3b841c71a' was properly closed.
[0m16:35:01.935255 [debug] [MainThread]: Connection 'test.airflow_dbt_project.not_null_stg_orders_order_id.81cfe2fe64' was properly closed.
[0m16:35:01.935561 [info ] [MainThread]: 
[0m16:35:01.936003 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 20.34 seconds (20.34s).
[0m16:35:01.937003 [debug] [MainThread]: Command end result
[0m16:35:01.949231 [info ] [MainThread]: 
[0m16:35:01.950122 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:35:01.951025 [info ] [MainThread]: 
[0m16:35:01.951676 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m16:35:01.952507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4bda27e60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4bf150a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa49eb6adb0>]}
[0m16:35:01.953189 [debug] [MainThread]: Flushing usage events


============================== 2025-11-19 14:44:51.571160 | 86587e81-e144-43bf-a381-29c69bb65167 ==============================
[0m14:44:51.571160 [info ] [MainThread]: Running with dbt=1.4.0
[0m14:44:51.581624 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['fact_orders'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:44:51.582003 [debug] [MainThread]: Tracking: tracking
[0m14:44:51.582331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff41cfbe540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3fe484aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3fe484b90>]}
[0m14:44:51.663979 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:44:51.664891 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:44:51.682658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '86587e81-e144-43bf-a381-29c69bb65167', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3ff4e41d0>]}
[0m14:44:51.700003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '86587e81-e144-43bf-a381-29c69bb65167', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4001635c0>]}
[0m14:44:51.700795 [info ] [MainThread]: Found 6 models, 6 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics
[0m14:44:51.701375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '86587e81-e144-43bf-a381-29c69bb65167', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3fe525d00>]}
[0m14:44:51.702545 [warn ] [MainThread]: The selection criterion 'fact_orders' does not match any nodes
[0m14:44:51.704775 [info ] [MainThread]: 
[0m14:44:51.706459 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:44:51.707623 [debug] [MainThread]: Command end result
[0m14:44:51.724267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3fe56f2c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3fe9684d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3fe968050>]}
[0m14:44:51.725835 [debug] [MainThread]: Flushing usage events


============================== 2025-11-25 21:51:32.118176 | 3438ad8b-3ae0-43e5-8efe-9a45fbc28a02 ==============================
[0m21:51:32.118176 [info ] [MainThread]: Running with dbt=1.4.0
[0m21:51:32.120710 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m21:51:32.121040 [debug] [MainThread]: Tracking: tracking
[0m21:51:32.121429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c6188f1a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c6188d220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c61d2aea0>]}
[0m21:51:32.201880 [debug] [MainThread]: Partial parsing enabled: 9 files deleted, 13 files added, 2 files changed.
[0m21:51:32.202734 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/new_origin_dest.sql
[0m21:51:32.203216 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/num_to_text.sql
[0m21:51:32.203745 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/schema.yml
[0m21:51:32.204121 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/opeartion_type.sql
[0m21:51:32.204484 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/cancellation_code.sql
[0m21:51:32.204798 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/dim_date.sql
[0m21:51:32.205110 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/dim_origin.sql
[0m21:51:32.205472 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/fact_flights.sql
[0m21:51:32.205817 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/dim_flight_status.sql
[0m21:51:32.206130 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/lower_case.sql
[0m21:51:32.206439 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/staging/stg_flight_status.sql
[0m21:51:32.206748 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/dim_destination.sql
[0m21:51:32.207052 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/dim_time.sql
[0m21:51:32.207830 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/schema.yml
[0m21:51:32.208404 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/sources.yml
[0m21:51:32.208768 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://models/test_model.sql
[0m21:51:32.209048 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://macros/order_amount.sql
[0m21:51:32.209294 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m21:51:32.209678 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://models/staging/stg_orders.sql
[0m21:51:32.209918 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://models/marts/core/ord.sql
[0m21:51:32.210150 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://models/staging/stg_customers.sql
[0m21:51:32.210411 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://models/cus_orders.sql
[0m21:51:32.210696 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://macros/merge_dim_customers.sql
[0m21:51:32.243105 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_date.sql
[0m21:51:32.265627 [debug] [MainThread]: 1603: static parser failed on marts/dim_origin.sql
[0m21:51:32.277301 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_origin.sql
[0m21:51:32.280434 [debug] [MainThread]: 1699: static parser successfully parsed marts/fact_flights.sql
[0m21:51:32.286636 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_flight_status.sql
[0m21:51:32.291979 [debug] [MainThread]: 1603: static parser failed on staging/stg_flight_status.sql
[0m21:51:32.314469 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_flight_status.sql
[0m21:51:32.317196 [debug] [MainThread]: 1603: static parser failed on marts/dim_destination.sql
[0m21:51:32.324800 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_destination.sql
[0m21:51:32.327279 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_time.sql
[0m21:51:32.367973 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_order_items' in the 'models' section of file 'models/marts/schema.yml'
[0m21:51:32.438277 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_orders' in the 'models' section of file 'models/staging/schema.yml'
[0m21:51:32.441977 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_customers' in the 'models' section of file 'models/staging/schema.yml'
[0m21:51:32.448708 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_order_items' in the 'models' section of file 'models/staging/schema.yml'
[0m21:51:32.453281 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_products' in the 'models' section of file 'models/staging/schema.yml'
[0m21:51:32.539250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c61601e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c61602ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c6161a270>]}
[0m21:51:32.539938 [debug] [MainThread]: Flushing usage events
[0m21:51:33.638243 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two tests with the name "relationships_stg_order_items_product_id__category_id__ref_stg_products_" defined on column "product_id" in "models.stg_order_items".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when running tests.
  
  To fix this, change the name of one of these resources:
  - test.airflow_dbt_project.relationships_stg_order_items_product_id__category_id__ref_stg_products_.fff7c9a732 (models/staging/schema.yml)
  - test.airflow_dbt_project.relationships_stg_order_items_product_id__category_id__ref_stg_products_.fff7c9a732 (models/marts/schema.yml)


============================== 2025-11-25 21:52:44.740412 | 220d5164-3a3b-41b2-8edd-8eeef7721ae4 ==============================
[0m21:52:44.740412 [info ] [MainThread]: Running with dbt=1.4.0
[0m21:52:44.742875 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m21:52:44.743154 [debug] [MainThread]: Tracking: tracking
[0m21:52:44.743497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be7d949b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be7d949e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be7d94b30>]}
[0m21:52:44.806506 [debug] [MainThread]: Partial parsing enabled: 10 files deleted, 13 files added, 1 files changed.
[0m21:52:44.807420 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/fact_flights.sql
[0m21:52:44.807916 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/new_origin_dest.sql
[0m21:52:44.808325 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/dim_date.sql
[0m21:52:44.808809 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/schema.yml
[0m21:52:44.809205 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/staging/stg_flight_status.sql
[0m21:52:44.809599 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/opeartion_type.sql
[0m21:52:44.809936 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/dim_time.sql
[0m21:52:44.810276 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/num_to_text.sql
[0m21:52:44.810616 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/dim_destination.sql
[0m21:52:44.810934 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/dim_flight_status.sql
[0m21:52:44.811266 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://models/marts/dim_origin.sql
[0m21:52:44.811628 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/cancellation_code.sql
[0m21:52:44.811986 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/lower_case.sql
[0m21:52:44.812577 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/sources.yml
[0m21:52:44.813182 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://models/marts/core/dim_customers.sql
[0m21:52:44.813610 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://models/marts/core/ord.sql
[0m21:52:44.813943 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://models/cus_orders.sql
[0m21:52:44.814246 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://models/test_model.sql
[0m21:52:44.814595 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://models/staging/stg_customers.sql
[0m21:52:44.814929 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://macros/merge_dim_customers.sql
[0m21:52:44.815244 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://macros/order_amount.sql
[0m21:52:44.815790 [debug] [MainThread]: Partial parsing: deleted file: airflow_dbt_project://models/staging/stg_orders.sql
[0m21:52:44.868093 [debug] [MainThread]: 1699: static parser successfully parsed marts/fact_flights.sql
[0m21:52:44.909184 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_date.sql
[0m21:52:44.914281 [debug] [MainThread]: 1603: static parser failed on staging/stg_flight_status.sql
[0m21:52:44.937473 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_flight_status.sql
[0m21:52:44.939640 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_time.sql
[0m21:52:44.943922 [debug] [MainThread]: 1603: static parser failed on marts/dim_destination.sql
[0m21:52:44.952830 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_destination.sql
[0m21:52:44.955335 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_flight_status.sql
[0m21:52:44.959559 [debug] [MainThread]: 1603: static parser failed on marts/dim_origin.sql
[0m21:52:44.966026 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_origin.sql
[0m21:52:44.996823 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_order_items' in the 'models' section of file 'models/marts/schema.yml'
[0m21:52:45.075934 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.airflow_dbt_project.amount_validation' (tests/amount_validation.sql) depends on a node named 'stg_orders' in package '' which was not found
[0m21:52:45.076648 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.airflow_dbt_project.relationships_stg_order_items_product_id__category_id__ref_stg_products_.fff7c9a732' (models/marts/schema.yml) depends on a node named 'stg_products' in package '' which was not found
[0m21:52:45.077173 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.airflow_dbt_project.relationships_stg_order_items_product_id__category_id__ref_stg_products_.fff7c9a732' (models/marts/schema.yml) depends on a node named 'stg_order_items' in package '' which was not found
[0m21:52:45.077660 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.airflow_dbt_project.check_amount_stg_order_items_revenue.f0054d1f83' (models/marts/schema.yml) depends on a node named 'stg_order_items' in package '' which was not found
[0m21:52:45.096953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '220d5164-3a3b-41b2-8edd-8eeef7721ae4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be7ae1be0>]}
[0m21:52:45.116131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '220d5164-3a3b-41b2-8edd-8eeef7721ae4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be7c5c0e0>]}
[0m21:52:45.116798 [info ] [MainThread]: Found 7 models, 1 test, 0 snapshots, 0 analyses, 310 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:52:45.117290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '220d5164-3a3b-41b2-8edd-8eeef7721ae4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be7eb7ad0>]}
[0m21:52:45.119434 [info ] [MainThread]: 
[0m21:52:45.123057 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:52:45.125858 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m21:52:45.138339 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m21:52:45.183204 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m21:52:45.183782 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m21:52:45.184253 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m21:52:45.184705 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m21:52:45.185145 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:52:45.185512 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:52:46.924638 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m21:52:46.927653 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m21:52:46.996033 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m21:52:46.999036 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m21:52:47.599516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '220d5164-3a3b-41b2-8edd-8eeef7721ae4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be7c4fc20>]}
[0m21:52:47.601244 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m21:52:47.602015 [info ] [MainThread]: 
[0m21:52:47.677145 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5
[0m21:52:47.678253 [info ] [Thread-1 (]: 1 of 1 START test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_  [RUN]
[0m21:52:47.680702 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5'
[0m21:52:47.681812 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5
[0m21:52:47.703836 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5"
[0m21:52:47.706061 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5 (compile): 2025-11-25 21:52:47.682484 => 2025-11-25 21:52:47.705786
[0m21:52:47.707098 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5
[0m21:52:47.783873 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5"
[0m21:52:47.785750 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5"
[0m21:52:47.786117 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.fact_flights
    where Actual_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_date
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m21:52:47.786399 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:52:48.895580 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c0a2c0-0000-a90d-0000-eb0d000602de
[0m21:52:48.896685 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'GP.MART.FACT_FLIGHTS' does not exist or not authorized.
[0m21:52:48.898762 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5 (execute): 2025-11-25 21:52:47.707693 => 2025-11-25 21:52:48.898363
[0m21:52:48.899959 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5: Close
[0m21:52:49.405128 [debug] [Thread-1 (]: Database Error in test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_ (models/marts/schema.yml)
  002003 (42S02): SQL compilation error:
  Object 'GP.MART.FACT_FLIGHTS' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/marts/schema.yml/relationships_fact_flights_d7a905de0066e188c347308ca9428d11.sql
[0m21:52:49.405751 [error] [Thread-1 (]: 1 of 1 ERROR relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_  [[31mERROR[0m in 1.73s]
[0m21:52:49.408257 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5
[0m21:52:49.410900 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:52:49.411846 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:52:49.412184 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5' was properly closed.
[0m21:52:49.412512 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m21:52:49.412882 [info ] [MainThread]: 
[0m21:52:49.413390 [info ] [MainThread]: Finished running 1 test in 0 hours 0 minutes and 4.29 seconds (4.29s).
[0m21:52:49.414210 [debug] [MainThread]: Command end result
[0m21:52:49.429017 [info ] [MainThread]: 
[0m21:52:49.430056 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:52:49.430832 [info ] [MainThread]: 
[0m21:52:49.431827 [error] [MainThread]: [33mDatabase Error in test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_ (models/marts/schema.yml)[0m
[0m21:52:49.432432 [error] [MainThread]:   002003 (42S02): SQL compilation error:
[0m21:52:49.433262 [error] [MainThread]:   Object 'GP.MART.FACT_FLIGHTS' does not exist or not authorized.
[0m21:52:49.433975 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/marts/schema.yml/relationships_fact_flights_d7a905de0066e188c347308ca9428d11.sql
[0m21:52:49.434782 [info ] [MainThread]: 
[0m21:52:49.435740 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m21:52:49.436835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bece23f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be7fc8a40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be7ab7560>]}
[0m21:52:49.437503 [debug] [MainThread]: Flushing usage events


============================== 2025-11-25 21:53:24.695923 | f6c7de30-39f8-4ca6-8a23-89953b75d0b1 ==============================
[0m21:53:24.695923 [info ] [MainThread]: Running with dbt=1.4.0
[0m21:53:24.703611 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m21:53:24.704771 [debug] [MainThread]: Tracking: tracking
[0m21:53:24.705983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc375a04170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc37468e2a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc37468e690>]}
[0m21:53:24.831962 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:53:24.833048 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/schema.yml
[0m21:53:24.868437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f6c7de30-39f8-4ca6-8a23-89953b75d0b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc37476ed20>]}
[0m21:53:24.881672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f6c7de30-39f8-4ca6-8a23-89953b75d0b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3762cd640>]}
[0m21:53:24.882362 [info ] [MainThread]: Found 7 models, 1 test, 0 snapshots, 0 analyses, 310 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:53:24.882936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f6c7de30-39f8-4ca6-8a23-89953b75d0b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3762f8ce0>]}
[0m21:53:24.885508 [info ] [MainThread]: 
[0m21:53:24.889011 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:53:24.891555 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m21:53:24.898507 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m21:53:24.945399 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m21:53:24.946458 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m21:53:24.946943 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m21:53:24.947528 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m21:53:24.948036 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:53:24.948551 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:53:27.549040 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 3 seconds
[0m21:53:27.551958 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m21:53:27.555603 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 3 seconds
[0m21:53:27.558197 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m21:53:28.001731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f6c7de30-39f8-4ca6-8a23-89953b75d0b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3743f44a0>]}
[0m21:53:28.002884 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m21:53:28.003388 [info ] [MainThread]: 
[0m21:53:28.052455 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5
[0m21:53:28.053475 [info ] [Thread-1 (]: 1 of 1 START test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_  [RUN]
[0m21:53:28.056177 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5'
[0m21:53:28.057304 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5
[0m21:53:28.096973 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5"
[0m21:53:28.098671 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5 (compile): 2025-11-25 21:53:28.058051 => 2025-11-25 21:53:28.098290
[0m21:53:28.099941 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5
[0m21:53:28.171128 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5"
[0m21:53:28.174411 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5"
[0m21:53:28.175022 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.fact_flights
    where Actual_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_date
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m21:53:28.175432 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:53:29.262951 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c0a2c1-0000-a90d-0000-eb0d000602e6
[0m21:53:29.264472 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'GP.MART.FACT_FLIGHTS' does not exist or not authorized.
[0m21:53:29.266465 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5 (execute): 2025-11-25 21:53:28.100938 => 2025-11-25 21:53:29.266073
[0m21:53:29.267710 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5: Close
[0m21:53:29.932898 [debug] [Thread-1 (]: Database Error in test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_ (models/marts/schema.yml)
  002003 (42S02): SQL compilation error:
  Object 'GP.MART.FACT_FLIGHTS' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/marts/schema.yml/relationships_fact_flights_d7a905de0066e188c347308ca9428d11.sql
[0m21:53:29.933554 [error] [Thread-1 (]: 1 of 1 ERROR relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_  [[31mERROR[0m in 1.88s]
[0m21:53:29.936328 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5
[0m21:53:29.938982 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:53:29.939830 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:53:29.940128 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5' was properly closed.
[0m21:53:29.940373 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart' was properly closed.
[0m21:53:29.940653 [info ] [MainThread]: 
[0m21:53:29.941040 [info ] [MainThread]: Finished running 1 test in 0 hours 0 minutes and 5.05 seconds (5.05s).
[0m21:53:29.941673 [debug] [MainThread]: Command end result
[0m21:53:29.953508 [info ] [MainThread]: 
[0m21:53:29.954184 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:53:29.954797 [info ] [MainThread]: 
[0m21:53:29.955362 [error] [MainThread]: [33mDatabase Error in test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_ (models/marts/schema.yml)[0m
[0m21:53:29.955851 [error] [MainThread]:   002003 (42S02): SQL compilation error:
[0m21:53:29.956237 [error] [MainThread]:   Object 'GP.MART.FACT_FLIGHTS' does not exist or not authorized.
[0m21:53:29.956683 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/marts/schema.yml/relationships_fact_flights_d7a905de0066e188c347308ca9428d11.sql
[0m21:53:29.957732 [info ] [MainThread]: 
[0m21:53:29.958293 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m21:53:29.959083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3751ff290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3744cf260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3762cdcd0>]}
[0m21:53:29.959769 [debug] [MainThread]: Flushing usage events


============================== 2025-11-25 21:54:59.889007 | 23b6d6e2-c695-4baf-8e94-e7d8b9ef364a ==============================
[0m21:54:59.889007 [info ] [MainThread]: Running with dbt=1.4.0
[0m21:54:59.892642 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m21:54:59.893125 [debug] [MainThread]: Tracking: tracking
[0m21:54:59.894083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec27844d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec0fc8530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec0fc87d0>]}
[0m21:54:59.949996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec1ee34d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec091bb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec091bef0>]}
[0m21:54:59.951414 [debug] [MainThread]: Flushing usage events
[0m21:55:00.879529 [error] [MainThread]: Encountered an error:
Parsing Error
  The schema file at models/marts/schema.yml is invalid because a list element for 'models' does not have a name attribute.


============================== 2025-11-25 21:55:18.182483 | 22da47a4-0954-4ba2-8534-e4f4321203dc ==============================
[0m21:55:18.182483 [info ] [MainThread]: Running with dbt=1.4.0
[0m21:55:18.184573 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m21:55:18.184839 [debug] [MainThread]: Tracking: tracking
[0m21:55:18.185138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9ceb5d340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b3c0af30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b3e03dd0>]}
[0m21:55:18.242549 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:55:18.243838 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/schema.yml
[0m21:55:18.275148 [debug] [MainThread]: 1699: static parser successfully parsed marts/fact_flights.sql
[0m21:55:18.384720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '22da47a4-0954-4ba2-8534-e4f4321203dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b39512b0>]}
[0m21:55:18.395664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '22da47a4-0954-4ba2-8534-e4f4321203dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b3aca060>]}
[0m21:55:18.396229 [info ] [MainThread]: Found 7 models, 1 test, 0 snapshots, 0 analyses, 310 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:55:18.396699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22da47a4-0954-4ba2-8534-e4f4321203dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9c2df5be0>]}
[0m21:55:18.398551 [info ] [MainThread]: 
[0m21:55:18.401575 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:55:18.403808 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m21:55:18.410677 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart'
[0m21:55:18.460158 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m21:55:18.461296 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart"
[0m21:55:18.461799 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m21:55:18.462330 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart
[0m21:55:18.462797 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:55:18.463216 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:55:19.965844 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m21:55:19.968746 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart: Close
[0m21:55:20.041849 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m21:55:20.044368 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m21:55:20.439904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22da47a4-0954-4ba2-8534-e4f4321203dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b379a720>]}
[0m21:55:20.441304 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m21:55:20.441990 [info ] [MainThread]: 
[0m21:55:20.498871 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5
[0m21:55:20.499854 [info ] [Thread-1 (]: 1 of 1 START test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_  [RUN]
[0m21:55:20.501930 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5'
[0m21:55:20.502831 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5
[0m21:55:20.526930 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5"
[0m21:55:20.528278 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5 (compile): 2025-11-25 21:55:20.503433 => 2025-11-25 21:55:20.528061
[0m21:55:20.529169 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5
[0m21:55:20.609456 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5"
[0m21:55:20.612217 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5"
[0m21:55:20.613424 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.fact_flights
    where Actual_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart.dim_date
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m21:55:20.614052 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:55:21.564792 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c0a2c3-0000-a81d-0000-eb0d00061172
[0m21:55:21.565579 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'GP.MART.FACT_FLIGHTS' does not exist or not authorized.
[0m21:55:21.566386 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5 (execute): 2025-11-25 21:55:20.529938 => 2025-11-25 21:55:21.566216
[0m21:55:21.566795 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5: Close
[0m21:55:21.954758 [debug] [Thread-1 (]: Database Error in test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_ (models/marts/schema.yml)
  002003 (42S02): SQL compilation error:
  Object 'GP.MART.FACT_FLIGHTS' does not exist or not authorized.
  compiled Code at target/run/airflow_dbt_project/models/marts/schema.yml/relationships_fact_flights_d7a905de0066e188c347308ca9428d11.sql
[0m21:55:21.955462 [error] [Thread-1 (]: 1 of 1 ERROR relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_  [[31mERROR[0m in 1.45s]
[0m21:55:21.958429 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5
[0m21:55:21.961598 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:55:21.962780 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:55:21.963156 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_.0a373d49c5' was properly closed.
[0m21:55:21.963449 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart' was properly closed.
[0m21:55:21.963755 [info ] [MainThread]: 
[0m21:55:21.964212 [info ] [MainThread]: Finished running 1 test in 0 hours 0 minutes and 3.56 seconds (3.56s).
[0m21:55:21.964793 [debug] [MainThread]: Command end result
[0m21:55:21.982568 [info ] [MainThread]: 
[0m21:55:21.983548 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:55:21.984167 [info ] [MainThread]: 
[0m21:55:21.984892 [error] [MainThread]: [33mDatabase Error in test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_date_ (models/marts/schema.yml)[0m
[0m21:55:21.985736 [error] [MainThread]:   002003 (42S02): SQL compilation error:
[0m21:55:21.986894 [error] [MainThread]:   Object 'GP.MART.FACT_FLIGHTS' does not exist or not authorized.
[0m21:55:21.988142 [error] [MainThread]:   compiled Code at target/run/airflow_dbt_project/models/marts/schema.yml/relationships_fact_flights_d7a905de0066e188c347308ca9428d11.sql
[0m21:55:21.988974 [info ] [MainThread]: 
[0m21:55:21.989871 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m21:55:21.991708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b3ce3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9dec1c740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b8526930>]}
[0m21:55:21.992661 [debug] [MainThread]: Flushing usage events


============================== 2025-11-25 22:00:41.212069 | 8e7d7e5e-6708-46a0-803f-4e4e25e28c74 ==============================
[0m22:00:41.212069 [info ] [MainThread]: Running with dbt=1.4.0
[0m22:00:41.214299 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m22:00:41.214584 [debug] [MainThread]: Tracking: tracking
[0m22:00:41.214894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff046011370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff045a5b650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff045a507d0>]}
[0m22:00:41.244437 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m22:00:41.245217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8e7d7e5e-6708-46a0-803f-4e4e25e28c74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0458c2960>]}
[0m22:00:41.255061 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0458c1f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0458c1b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0458c1a90>]}
[0m22:00:41.256043 [debug] [MainThread]: Flushing usage events
[0m22:00:42.417262 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading airflow_dbt_project: marts/schema.yml - Runtime Error
    Syntax error near line 3
    ------------------------------
    1  | version: 2
    2  | 
    3  |   models:
    4  |     - name: fact_flights # you must write mode name here
    5  |       columns:  
    6  |         - name: destination_id
    
    Raw Error:
    ------------------------------
    mapping values are not allowed in this context
      in "<unicode string>", line 3, column 9


============================== 2025-11-25 22:03:06.884400 | 05872c5c-f76a-4ff8-a8eb-5aa221844e83 ==============================
[0m22:03:06.884400 [info ] [MainThread]: Running with dbt=1.4.0
[0m22:03:06.886595 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m22:03:06.886862 [debug] [MainThread]: Tracking: tracking
[0m22:03:06.887160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f378507c4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37845a5c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f378464a750>]}
[0m22:03:06.917459 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m22:03:06.918472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '05872c5c-f76a-4ff8-a8eb-5aa221844e83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f378440eb70>]}
[0m22:03:08.288382 [debug] [MainThread]: 1603: static parser failed on marts/dim_origin.sql
[0m22:03:08.318570 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_origin.sql
[0m22:03:08.321381 [debug] [MainThread]: 1603: static parser failed on marts/dim_destination.sql
[0m22:03:08.328061 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_destination.sql
[0m22:03:08.331056 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_flight_status.sql
[0m22:03:08.335226 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_date.sql
[0m22:03:08.339003 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_time.sql
[0m22:03:08.343276 [debug] [MainThread]: 1699: static parser successfully parsed marts/fact_flights.sql
[0m22:03:08.347603 [debug] [MainThread]: 1603: static parser failed on staging/stg_flight_status.sql
[0m22:03:08.367732 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_flight_status.sql
[0m22:03:08.543291 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.airflow_dbt_project.amount_validation' (tests/amount_validation.sql) depends on a node named 'stg_orders' in package '' which was not found
[0m22:03:08.588047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '05872c5c-f76a-4ff8-a8eb-5aa221844e83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37844595b0>]}
[0m22:03:08.605078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '05872c5c-f76a-4ff8-a8eb-5aa221844e83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37840ccb00>]}
[0m22:03:08.605971 [info ] [MainThread]: Found 7 models, 10 tests, 0 snapshots, 0 analyses, 310 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m22:03:08.606604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '05872c5c-f76a-4ff8-a8eb-5aa221844e83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f378464a750>]}
[0m22:03:08.610361 [info ] [MainThread]: 
[0m22:03:08.616353 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m22:03:08.620023 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m22:03:08.628306 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m22:03:08.708473 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m22:03:08.708947 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m22:03:08.709844 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m22:03:08.710397 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:03:08.710863 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m22:03:08.715017 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:03:10.324985 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m22:03:10.328417 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m22:03:20.665513 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 12 seconds
[0m22:03:20.669127 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m22:03:21.752665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '05872c5c-f76a-4ff8-a8eb-5aa221844e83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37845ab620>]}
[0m22:03:21.753863 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m22:03:21.754392 [info ] [MainThread]: 
[0m22:03:21.811414 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m22:03:21.812298 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m22:03:21.813087 [info ] [Thread-1 (]: 1 of 10 START test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m22:03:21.813847 [info ] [Thread-2 (]: 2 of 10 START test relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m22:03:21.816501 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9'
[0m22:03:21.818718 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079'
[0m22:03:21.820261 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m22:03:21.821606 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m22:03:21.853431 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m22:03:21.864750 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m22:03:21.866355 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (compile): 2025-11-25 22:03:21.822503 => 2025-11-25 22:03:21.865965
[0m22:03:21.867757 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m22:03:21.879645 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (compile): 2025-11-25 22:03:21.833206 => 2025-11-25 22:03:21.879249
[0m22:03:21.885913 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m22:03:21.966734 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m22:03:21.967657 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m22:03:21.969489 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m22:03:21.969838 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:03:21.970199 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:03:21.971446 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m22:03:21.972838 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:03:21.974000 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:03:26.683710 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 5 seconds
[0m22:03:26.701776 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (execute): 2025-11-25 22:03:21.892050 => 2025-11-25 22:03:26.701579
[0m22:03:26.703849 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: Close
[0m22:03:26.708872 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 5 seconds
[0m22:03:26.712997 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (execute): 2025-11-25 22:03:21.868715 => 2025-11-25 22:03:26.712859
[0m22:03:26.713509 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: Close
[0m22:03:27.382541 [info ] [Thread-2 (]: 2 of 10 PASS relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 5.56s]
[0m22:03:27.386762 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m22:03:27.387682 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m22:03:27.388234 [info ] [Thread-2 (]: 3 of 10 START test relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m22:03:27.390404 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608'
[0m22:03:27.391095 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m22:03:27.413781 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m22:03:27.415400 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (compile): 2025-11-25 22:03:27.391624 => 2025-11-25 22:03:27.415101
[0m22:03:27.416292 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m22:03:27.429553 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m22:03:27.425792 [info ] [Thread-1 (]: 1 of 10 PASS relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 5.61s]
[0m22:03:27.431591 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m22:03:27.433034 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m22:03:27.436716 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m22:03:27.437614 [info ] [Thread-1 (]: 4 of 10 START test relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m22:03:27.438705 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:03:27.440764 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932'
[0m22:03:27.441540 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:03:27.442352 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m22:03:27.470635 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m22:03:27.473692 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (compile): 2025-11-25 22:03:27.445190 => 2025-11-25 22:03:27.473432
[0m22:03:27.474583 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m22:03:27.482594 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m22:03:27.485299 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m22:03:27.485909 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:03:27.486352 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:03:29.351419 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m22:03:29.354109 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (execute): 2025-11-25 22:03:27.475096 => 2025-11-25 22:03:29.354008
[0m22:03:29.354456 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: Close
[0m22:03:29.382012 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m22:03:29.384396 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (execute): 2025-11-25 22:03:27.416901 => 2025-11-25 22:03:29.384291
[0m22:03:29.384697 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: Close
[0m22:03:29.778466 [info ] [Thread-1 (]: 4 of 10 PASS relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 2.34s]
[0m22:03:29.778968 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m22:03:29.779381 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m22:03:29.779613 [info ] [Thread-1 (]: 5 of 10 START test relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [RUN]
[0m22:03:29.780290 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5'
[0m22:03:29.780537 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m22:03:29.789032 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m22:03:29.789824 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (compile): 2025-11-25 22:03:29.780793 => 2025-11-25 22:03:29.789708
[0m22:03:29.790212 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m22:03:29.793726 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m22:03:29.795733 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m22:03:29.796168 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_Off_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_Off_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:03:29.796518 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:03:29.858290 [info ] [Thread-2 (]: 3 of 10 PASS relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 2.47s]
[0m22:03:29.859457 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m22:03:29.860452 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m22:03:29.861001 [info ] [Thread-2 (]: 6 of 10 START test relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [RUN]
[0m22:03:29.863037 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850'
[0m22:03:29.864084 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m22:03:29.878708 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m22:03:29.880073 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (compile): 2025-11-25 22:03:29.864611 => 2025-11-25 22:03:29.879870
[0m22:03:29.880860 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m22:03:29.887153 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m22:03:29.889169 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m22:03:29.889689 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_On_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_On_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:03:29.890052 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:03:30.802932 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m22:03:30.807362 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (execute): 2025-11-25 22:03:29.790446 => 2025-11-25 22:03:30.807197
[0m22:03:30.808036 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: Close
[0m22:03:31.229586 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m22:03:31.234681 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (execute): 2025-11-25 22:03:29.881404 => 2025-11-25 22:03:31.234515
[0m22:03:31.235235 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: Close
[0m22:03:31.476980 [info ] [Thread-1 (]: 5 of 10 PASS relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.70s]
[0m22:03:31.477921 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m22:03:31.478511 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m22:03:31.478890 [info ] [Thread-1 (]: 7 of 10 START test relationships_fact_flights_date_id__date_id__ref_dim_date_ .. [RUN]
[0m22:03:31.480109 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9'
[0m22:03:31.480444 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m22:03:31.491126 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m22:03:31.491972 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (compile): 2025-11-25 22:03:31.480658 => 2025-11-25 22:03:31.491846
[0m22:03:31.492421 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m22:03:31.496631 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m22:03:31.498472 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m22:03:31.498922 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select date_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where date_id is not null
),

parent as (
    select date_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:03:31.499276 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:03:31.848472 [info ] [Thread-2 (]: 6 of 10 PASS relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.99s]
[0m22:03:31.849406 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m22:03:31.850120 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m22:03:31.850647 [info ] [Thread-2 (]: 8 of 10 START test relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [RUN]
[0m22:03:31.851763 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5'
[0m22:03:31.852158 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m22:03:31.862435 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m22:03:31.863303 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (compile): 2025-11-25 22:03:31.852402 => 2025-11-25 22:03:31.863149
[0m22:03:31.863923 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m22:03:31.868029 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m22:03:31.870059 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m22:03:31.870580 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select destination_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where destination_id is not null
),

parent as (
    select destination_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:03:31.871015 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:03:33.582932 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m22:03:33.587651 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (execute): 2025-11-25 22:03:31.864264 => 2025-11-25 22:03:33.587521
[0m22:03:33.588101 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: Close
[0m22:03:34.142736 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m22:03:34.147017 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (execute): 2025-11-25 22:03:31.492679 => 2025-11-25 22:03:34.146901
[0m22:03:34.147464 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: Close
[0m22:03:34.164808 [info ] [Thread-2 (]: 8 of 10 PASS relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [[32mPASS[0m in 2.31s]
[0m22:03:34.165489 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m22:03:34.165994 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m22:03:34.166324 [info ] [Thread-2 (]: 9 of 10 START test relationships_fact_flights_origin_id__origin_id__ref_dim_origin_  [RUN]
[0m22:03:34.167408 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24'
[0m22:03:34.167732 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m22:03:34.177584 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m22:03:34.178301 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (compile): 2025-11-25 22:03:34.167934 => 2025-11-25 22:03:34.178200
[0m22:03:34.178698 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m22:03:34.186500 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m22:03:34.188977 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m22:03:34.190081 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select origin_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where origin_id is not null
),

parent as (
    select origin_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:03:34.190650 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:03:35.914780 [info ] [Thread-1 (]: 7 of 10 PASS relationships_fact_flights_date_id__date_id__ref_dim_date_ ........ [[32mPASS[0m in 4.44s]
[0m22:03:35.915365 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m22:03:35.915789 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m22:03:35.916130 [info ] [Thread-1 (]: 10 of 10 START test relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [RUN]
[0m22:03:35.916897 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa'
[0m22:03:35.917161 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m22:03:35.926171 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m22:03:35.926919 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (compile): 2025-11-25 22:03:35.917354 => 2025-11-25 22:03:35.926809
[0m22:03:35.927290 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m22:03:35.931794 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m22:03:35.934345 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m22:03:35.935218 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select status_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where status_id is not null
),

parent as (
    select status_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:03:35.935700 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:03:36.405057 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m22:03:36.409348 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (execute): 2025-11-25 22:03:34.178917 => 2025-11-25 22:03:36.409217
[0m22:03:36.409763 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: Close
[0m22:03:37.051174 [info ] [Thread-2 (]: 9 of 10 PASS relationships_fact_flights_origin_id__origin_id__ref_dim_origin_ .. [[32mPASS[0m in 2.88s]
[0m22:03:37.053403 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m22:03:37.170983 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m22:03:37.176710 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (execute): 2025-11-25 22:03:35.927520 => 2025-11-25 22:03:37.176564
[0m22:03:37.178434 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: Close
[0m22:03:37.688577 [info ] [Thread-1 (]: 10 of 10 PASS relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [[32mPASS[0m in 1.77s]
[0m22:03:37.690111 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m22:03:37.695348 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m22:03:37.697622 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:03:37.698370 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa' was properly closed.
[0m22:03:37.698885 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24' was properly closed.
[0m22:03:37.699477 [info ] [MainThread]: 
[0m22:03:37.700236 [info ] [MainThread]: Finished running 10 tests in 0 hours 0 minutes and 29.09 seconds (29.09s).
[0m22:03:37.701756 [debug] [MainThread]: Command end result
[0m22:03:37.723520 [info ] [MainThread]: 
[0m22:03:37.724272 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:03:37.725029 [info ] [MainThread]: 
[0m22:03:37.725708 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=0 SKIP=0 TOTAL=10
[0m22:03:37.726621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37a41c02f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f378438c7a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f378438faa0>]}
[0m22:03:37.727367 [debug] [MainThread]: Flushing usage events


============================== 2025-11-25 22:27:39.568291 | ea384530-d9d1-4eb4-ad15-9a2c5299f0de ==============================
[0m22:27:39.568291 [info ] [MainThread]: Running with dbt=1.4.0
[0m22:27:39.570483 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m22:27:39.570734 [debug] [MainThread]: Tracking: tracking
[0m22:27:39.571031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6b03ad760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6b0c55fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6b0c2c7d0>]}
[0m22:27:39.611639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6aad38860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6aad382f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6aad38260>]}
[0m22:27:39.612661 [debug] [MainThread]: Flushing usage events
[0m22:27:40.605740 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading airflow_dbt_project: marts/schema.yml - Runtime Error
    Syntax error near line 3
    ------------------------------
    1  | version: 2
    2  | 
    3  |   models:
    4  |     - name: fact_flights
    5  |       columns:  
    6  |         - name: destination_id
    
    Raw Error:
    ------------------------------
    mapping values are not allowed in this context
      in "<unicode string>", line 3, column 9


============================== 2025-11-25 22:32:56.194988 | 6b26bc04-d050-431a-be94-f6d507e983d9 ==============================
[0m22:32:56.194988 [info ] [MainThread]: Running with dbt=1.4.0
[0m22:32:56.197771 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m22:32:56.198141 [debug] [MainThread]: Tracking: tracking
[0m22:32:56.198634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb248f2cf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb25bbf7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb247c2ed0>]}
[0m22:32:56.280187 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m22:32:56.281596 [debug] [MainThread]: Partial parsing: added file: airflow_dbt_project://macros/is_positive.sql
[0m22:32:56.283734 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/schema.yml
[0m22:32:56.337088 [debug] [MainThread]: 1699: static parser successfully parsed marts/fact_flights.sql
[0m22:32:56.615585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6b26bc04-d050-431a-be94-f6d507e983d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb244aaa50>]}
[0m22:32:56.629695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6b26bc04-d050-431a-be94-f6d507e983d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24651040>]}
[0m22:32:56.630252 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m22:32:56.630688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6b26bc04-d050-431a-be94-f6d507e983d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb244c2f60>]}
[0m22:32:56.633625 [info ] [MainThread]: 
[0m22:32:56.636751 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m22:32:56.639020 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m22:32:56.646191 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m22:32:56.686525 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m22:32:56.687248 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m22:32:56.687582 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m22:32:56.687876 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m22:32:56.688155 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:32:56.688433 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:32:58.651380 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m22:32:58.655004 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m22:32:58.657776 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m22:32:58.660287 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m22:32:59.120070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6b26bc04-d050-431a-be94-f6d507e983d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb37386f00>]}
[0m22:32:59.121069 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m22:32:59.121486 [info ] [MainThread]: 
[0m22:32:59.173540 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m22:32:59.174434 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m22:32:59.175261 [info ] [Thread-1 (]: 1 of 17 START test is_positive_fact_flights_CARRIER_DELAY ...................... [RUN]
[0m22:32:59.176292 [info ] [Thread-2 (]: 2 of 17 START test is_positive_fact_flights_LATE_AIRCRAFT_DELAY ................ [RUN]
[0m22:32:59.178352 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec'
[0m22:32:59.179883 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa'
[0m22:32:59.180592 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m22:32:59.181130 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m22:32:59.189989 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m22:32:59.204062 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m22:32:59.205975 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (compile): 2025-11-25 22:32:59.181482 => 2025-11-25 22:32:59.205725
[0m22:32:59.206788 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m22:32:59.218370 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (compile): 2025-11-25 22:32:59.190696 => 2025-11-25 22:32:59.217965
[0m22:32:59.229718 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m22:32:59.317285 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m22:32:59.319851 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m22:32:59.321198 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m22:32:59.322097 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m22:32:59.322437 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where LATE_AIRCRAFT_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m22:32:59.322744 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where CARRIER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m22:32:59.323023 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:32:59.323272 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:02.424084 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m22:33:02.438725 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (execute): 2025-11-25 22:32:59.207405 => 2025-11-25 22:33:02.438589
[0m22:33:02.439169 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: Close
[0m22:33:02.441797 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 3 seconds
[0m22:33:02.444975 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (execute): 2025-11-25 22:32:59.235904 => 2025-11-25 22:33:02.444867
[0m22:33:02.445379 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: Close
[0m22:33:03.667933 [info ] [Thread-1 (]: 1 of 17 PASS is_positive_fact_flights_CARRIER_DELAY ............................ [[32mPASS[0m in 4.49s]
[0m22:33:03.671101 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m22:33:03.671704 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m22:33:03.672059 [info ] [Thread-1 (]: 3 of 17 START test is_positive_fact_flights_NAS_DELAY .......................... [RUN]
[0m22:33:03.673476 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3'
[0m22:33:03.673886 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m22:33:03.681192 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m22:33:03.682050 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (compile): 2025-11-25 22:33:03.674133 => 2025-11-25 22:33:03.681930
[0m22:33:03.682493 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m22:33:03.686570 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m22:33:03.687923 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m22:33:03.688337 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where NAS_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m22:33:03.688625 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:03.747771 [info ] [Thread-2 (]: 2 of 17 PASS is_positive_fact_flights_LATE_AIRCRAFT_DELAY ...................... [[32mPASS[0m in 4.57s]
[0m22:33:03.749207 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m22:33:03.750006 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m22:33:03.750529 [info ] [Thread-2 (]: 4 of 17 START test is_positive_fact_flights_SECURITY_DELAY ..................... [RUN]
[0m22:33:03.752335 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384'
[0m22:33:03.753025 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m22:33:03.764444 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m22:33:03.765548 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (compile): 2025-11-25 22:33:03.753438 => 2025-11-25 22:33:03.765377
[0m22:33:03.766100 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m22:33:03.772264 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m22:33:03.774850 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m22:33:03.775794 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where SECURITY_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m22:33:03.776504 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:33:04.843103 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m22:33:04.852566 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (execute): 2025-11-25 22:33:03.766460 => 2025-11-25 22:33:04.852194
[0m22:33:04.853702 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: Close
[0m22:33:05.301042 [info ] [Thread-2 (]: 4 of 17 PASS is_positive_fact_flights_SECURITY_DELAY ........................... [[32mPASS[0m in 1.55s]
[0m22:33:05.301917 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m22:33:05.302549 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m22:33:05.302965 [info ] [Thread-2 (]: 5 of 17 START test is_positive_fact_flights_TAXI_IN_TIME ....................... [RUN]
[0m22:33:05.304196 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c'
[0m22:33:05.304803 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m22:33:05.313125 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m22:33:05.314084 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (compile): 2025-11-25 22:33:05.305047 => 2025-11-25 22:33:05.313936
[0m22:33:05.314680 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m22:33:05.318997 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m22:33:05.320459 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m22:33:05.321014 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_IN_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m22:33:05.321553 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:33:06.243250 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m22:33:06.250433 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (execute): 2025-11-25 22:33:05.315020 => 2025-11-25 22:33:06.250212
[0m22:33:06.251182 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: Close
[0m22:33:06.376933 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m22:33:06.384020 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (execute): 2025-11-25 22:33:03.682735 => 2025-11-25 22:33:06.383786
[0m22:33:06.384906 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: Close
[0m22:33:06.721753 [info ] [Thread-2 (]: 5 of 17 PASS is_positive_fact_flights_TAXI_IN_TIME ............................. [[32mPASS[0m in 1.42s]
[0m22:33:06.722496 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m22:33:06.722991 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m22:33:06.723335 [info ] [Thread-2 (]: 6 of 17 START test is_positive_fact_flights_TAXI_OUT_TIME ...................... [RUN]
[0m22:33:06.724230 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da'
[0m22:33:06.724820 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m22:33:06.731816 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m22:33:06.732649 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (compile): 2025-11-25 22:33:06.725159 => 2025-11-25 22:33:06.732526
[0m22:33:06.733096 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m22:33:06.736894 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m22:33:06.738201 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m22:33:06.738568 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_OUT_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m22:33:06.738839 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:33:06.877677 [info ] [Thread-1 (]: 3 of 17 PASS is_positive_fact_flights_NAS_DELAY ................................ [[32mPASS[0m in 3.20s]
[0m22:33:06.878699 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m22:33:06.879620 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m22:33:06.880196 [info ] [Thread-1 (]: 7 of 17 START test is_positive_fact_flights_WEATHER_DELAY ...................... [RUN]
[0m22:33:06.881890 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474'
[0m22:33:06.882355 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m22:33:06.890398 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m22:33:06.891631 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (compile): 2025-11-25 22:33:06.882622 => 2025-11-25 22:33:06.891421
[0m22:33:06.892283 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m22:33:06.897634 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m22:33:06.899194 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m22:33:06.899691 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where WEATHER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m22:33:06.900017 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:07.772492 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m22:33:07.776413 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (execute): 2025-11-25 22:33:06.733380 => 2025-11-25 22:33:07.776215
[0m22:33:07.776929 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: Close
[0m22:33:08.259439 [info ] [Thread-2 (]: 6 of 17 PASS is_positive_fact_flights_TAXI_OUT_TIME ............................ [[32mPASS[0m in 1.54s]
[0m22:33:08.260501 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m22:33:08.261075 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m22:33:08.261682 [info ] [Thread-2 (]: 8 of 17 START test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m22:33:08.263174 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9'
[0m22:33:08.263768 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m22:33:08.276843 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m22:33:08.277823 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (compile): 2025-11-25 22:33:08.264187 => 2025-11-25 22:33:08.277671
[0m22:33:08.278299 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m22:33:08.284039 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m22:33:08.287150 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m22:33:08.287888 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:33:08.288489 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:33:09.250153 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m22:33:09.255831 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (execute): 2025-11-25 22:33:08.278598 => 2025-11-25 22:33:09.255606
[0m22:33:09.256775 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: Close
[0m22:33:09.340238 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m22:33:09.345522 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (execute): 2025-11-25 22:33:06.892685 => 2025-11-25 22:33:09.345336
[0m22:33:09.346086 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: Close
[0m22:33:09.719860 [info ] [Thread-2 (]: 8 of 17 PASS relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.46s]
[0m22:33:09.720723 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m22:33:09.721454 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m22:33:09.721852 [info ] [Thread-2 (]: 9 of 17 START test relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m22:33:09.723037 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079'
[0m22:33:09.723404 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m22:33:09.734902 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m22:33:09.739118 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (compile): 2025-11-25 22:33:09.723631 => 2025-11-25 22:33:09.738865
[0m22:33:09.739975 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m22:33:09.746235 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m22:33:09.749101 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m22:33:09.749790 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:33:09.750235 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:33:09.940376 [info ] [Thread-1 (]: 7 of 17 PASS is_positive_fact_flights_WEATHER_DELAY ............................ [[32mPASS[0m in 3.06s]
[0m22:33:09.941210 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m22:33:09.941768 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m22:33:09.942082 [info ] [Thread-1 (]: 10 of 17 START test relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m22:33:09.943157 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608'
[0m22:33:09.943540 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m22:33:09.953187 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m22:33:09.954047 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (compile): 2025-11-25 22:33:09.943783 => 2025-11-25 22:33:09.953921
[0m22:33:09.954529 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m22:33:09.959051 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m22:33:09.962327 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m22:33:09.963068 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:33:09.963609 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:10.765519 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m22:33:10.770827 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (execute): 2025-11-25 22:33:09.740592 => 2025-11-25 22:33:10.770636
[0m22:33:10.771541 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: Close
[0m22:33:10.911579 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m22:33:10.917258 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (execute): 2025-11-25 22:33:09.954816 => 2025-11-25 22:33:10.917118
[0m22:33:10.917804 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: Close
[0m22:33:11.369293 [info ] [Thread-2 (]: 9 of 17 PASS relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.65s]
[0m22:33:11.371250 [info ] [Thread-1 (]: 10 of 17 PASS relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.43s]
[0m22:33:11.371893 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m22:33:11.372391 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m22:33:11.372948 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m22:33:11.373537 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m22:33:11.373983 [info ] [Thread-2 (]: 11 of 17 START test relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m22:33:11.374450 [info ] [Thread-1 (]: 12 of 17 START test relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [RUN]
[0m22:33:11.375449 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932'
[0m22:33:11.376254 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5'
[0m22:33:11.376767 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m22:33:11.377215 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m22:33:11.406062 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m22:33:11.406976 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m22:33:11.408650 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (compile): 2025-11-25 22:33:11.377630 => 2025-11-25 22:33:11.408450
[0m22:33:11.410017 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m22:33:11.410628 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (compile): 2025-11-25 22:33:11.385274 => 2025-11-25 22:33:11.410477
[0m22:33:11.417234 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m22:33:11.418207 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m22:33:11.424525 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m22:33:11.427060 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m22:33:11.427895 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:33:11.428540 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:33:11.430555 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m22:33:11.432495 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_Off_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_Off_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:33:11.434129 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:12.444707 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m22:33:12.449741 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (execute): 2025-11-25 22:33:11.419183 => 2025-11-25 22:33:12.449594
[0m22:33:12.450220 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: Close
[0m22:33:12.975282 [info ] [Thread-1 (]: 12 of 17 PASS relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.60s]
[0m22:33:12.976122 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m22:33:12.976683 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m22:33:12.977171 [info ] [Thread-1 (]: 13 of 17 START test relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [RUN]
[0m22:33:12.978243 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850'
[0m22:33:12.978672 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m22:33:12.989184 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m22:33:12.990006 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (compile): 2025-11-25 22:33:12.978907 => 2025-11-25 22:33:12.989883
[0m22:33:12.990445 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m22:33:12.997018 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m22:33:12.999356 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m22:33:12.999917 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_On_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_On_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:33:13.000414 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:14.084578 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m22:33:14.091166 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (execute): 2025-11-25 22:33:12.990695 => 2025-11-25 22:33:14.090900
[0m22:33:14.092160 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: Close
[0m22:33:14.533480 [info ] [Thread-1 (]: 13 of 17 PASS relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.56s]
[0m22:33:14.534225 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m22:33:14.534767 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m22:33:14.535232 [info ] [Thread-1 (]: 14 of 17 START test relationships_fact_flights_date_id__date_id__ref_dim_date_ . [RUN]
[0m22:33:14.536359 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9'
[0m22:33:14.536748 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m22:33:14.546404 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m22:33:14.547197 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (compile): 2025-11-25 22:33:14.536991 => 2025-11-25 22:33:14.547076
[0m22:33:14.547618 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m22:33:14.552122 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m22:33:14.554035 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m22:33:14.554464 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select date_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where date_id is not null
),

parent as (
    select date_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:33:14.554780 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:15.525689 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m22:33:15.535812 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (execute): 2025-11-25 22:33:14.547862 => 2025-11-25 22:33:15.535478
[0m22:33:15.536983 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: Close
[0m22:33:15.915122 [info ] [Thread-1 (]: 14 of 17 PASS relationships_fact_flights_date_id__date_id__ref_dim_date_ ....... [[32mPASS[0m in 1.38s]
[0m22:33:15.915916 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m22:33:15.916566 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m22:33:15.917063 [info ] [Thread-1 (]: 15 of 17 START test relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [RUN]
[0m22:33:15.918226 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5'
[0m22:33:15.918653 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m22:33:15.930371 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m22:33:15.931249 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (compile): 2025-11-25 22:33:15.918903 => 2025-11-25 22:33:15.931116
[0m22:33:15.931758 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m22:33:15.937686 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m22:33:15.940486 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m22:33:15.941170 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select destination_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where destination_id is not null
),

parent as (
    select destination_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:33:15.941740 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:16.913547 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m22:33:16.920266 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (execute): 2025-11-25 22:33:15.932030 => 2025-11-25 22:33:16.920009
[0m22:33:16.921290 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: Close
[0m22:33:17.506380 [info ] [Thread-1 (]: 15 of 17 PASS relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [[32mPASS[0m in 1.59s]
[0m22:33:17.507183 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m22:33:17.507802 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m22:33:17.508231 [info ] [Thread-1 (]: 16 of 17 START test relationships_fact_flights_origin_id__origin_id__ref_dim_origin_  [RUN]
[0m22:33:17.509284 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24'
[0m22:33:17.509727 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m22:33:17.519988 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m22:33:17.520986 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (compile): 2025-11-25 22:33:17.510009 => 2025-11-25 22:33:17.520806
[0m22:33:17.521657 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m22:33:17.526266 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m22:33:17.528276 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m22:33:17.528777 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select origin_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where origin_id is not null
),

parent as (
    select origin_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:33:17.529187 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:19.306434 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m22:33:19.309689 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (execute): 2025-11-25 22:33:17.521932 => 2025-11-25 22:33:19.309570
[0m22:33:19.310130 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: Close
[0m22:33:19.680451 [info ] [Thread-1 (]: 16 of 17 PASS relationships_fact_flights_origin_id__origin_id__ref_dim_origin_ . [[32mPASS[0m in 2.17s]
[0m22:33:19.681291 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m22:33:19.681756 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m22:33:19.682027 [info ] [Thread-1 (]: 17 of 17 START test relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [RUN]
[0m22:33:19.682935 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa'
[0m22:33:19.683238 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m22:33:19.692485 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m22:33:19.693273 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (compile): 2025-11-25 22:33:19.683453 => 2025-11-25 22:33:19.693116
[0m22:33:19.694029 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m22:33:19.699364 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m22:33:19.701658 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m22:33:19.702492 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select status_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where status_id is not null
),

parent as (
    select status_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m22:33:19.703152 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:20.607092 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m22:33:20.613075 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (execute): 2025-11-25 22:33:19.694335 => 2025-11-25 22:33:20.612918
[0m22:33:20.613595 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: Close
[0m22:33:21.040621 [info ] [Thread-1 (]: 17 of 17 PASS relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [[32mPASS[0m in 1.36s]
[0m22:33:21.041660 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m22:34:14.221159 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 63 seconds
[0m22:34:14.225623 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (execute): 2025-11-25 22:33:11.410988 => 2025-11-25 22:34:14.225499
[0m22:34:14.226043 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: Close
[0m22:34:14.588307 [info ] [Thread-2 (]: 11 of 17 PASS relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 63.21s]
[0m22:34:14.589323 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m22:34:14.592598 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m22:34:14.593516 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:34:14.593832 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa' was properly closed.
[0m22:34:14.594070 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932' was properly closed.
[0m22:34:14.594387 [info ] [MainThread]: 
[0m22:34:14.594788 [info ] [MainThread]: Finished running 17 tests in 0 hours 1 minutes and 17.96 seconds (77.96s).
[0m22:34:14.596038 [debug] [MainThread]: Command end result
[0m22:34:14.614801 [info ] [MainThread]: 
[0m22:34:14.616063 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:34:14.617150 [info ] [MainThread]: 
[0m22:34:14.617930 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=0 SKIP=0 TOTAL=17
[0m22:34:14.619166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24807b60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24807d40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb24804a70>]}
[0m22:34:14.620549 [debug] [MainThread]: Flushing usage events


============================== 2025-11-25 22:54:07.847104 | 9b46fcf1-2bcd-469f-a893-28159ced4ef0 ==============================
[0m22:54:07.847104 [info ] [MainThread]: Running with dbt=1.4.0
[0m22:54:07.849463 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'source-freshness', 'rpc_method': 'source-freshness', 'indirect_selection': 'eager'}
[0m22:54:07.849754 [debug] [MainThread]: Tracking: tracking
[0m22:54:07.850056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faea39a3530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faea39a2e70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faea39a35c0>]}
[0m22:54:07.918167 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:54:07.919329 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/sources.yml
[0m22:54:07.938398 [debug] [MainThread]: 1699: static parser successfully parsed marts/fact_flights.sql
[0m22:54:07.959520 [debug] [MainThread]: 1603: static parser failed on marts/dim_destination.sql
[0m22:54:07.968977 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_destination.sql
[0m22:54:07.971477 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_flight_status.sql
[0m22:54:07.975806 [debug] [MainThread]: 1603: static parser failed on marts/dim_origin.sql
[0m22:54:07.982195 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_origin.sql
[0m22:54:07.984742 [debug] [MainThread]: 1603: static parser failed on staging/stg_flight_status.sql
[0m22:54:08.003513 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_flight_status.sql
[0m22:54:08.187336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9b46fcf1-2bcd-469f-a893-28159ced4ef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faea3778260>]}
[0m22:54:08.197010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9b46fcf1-2bcd-469f-a893-28159ced4ef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faecec2eb10>]}
[0m22:54:08.197417 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m22:54:08.197727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b46fcf1-2bcd-469f-a893-28159ced4ef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faea85397f0>]}
[0m22:54:08.199625 [info ] [MainThread]: 
[0m22:54:08.200127 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m22:54:08.208254 [info ] [MainThread]: Done.
[0m22:54:08.208796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec4b79220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faea9261310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec75e0cb0>]}
[0m22:54:08.209120 [debug] [MainThread]: Flushing usage events


============================== 2025-11-25 23:00:40.796701 | a1734056-5b86-4ad7-a78d-912420edd051 ==============================
[0m23:00:40.796701 [info ] [MainThread]: Running with dbt=1.4.0
[0m23:00:40.799398 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'source-freshness', 'rpc_method': 'source-freshness', 'indirect_selection': 'eager'}
[0m23:00:40.799749 [debug] [MainThread]: Tracking: tracking
[0m23:00:40.800143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865e02c590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865df81550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865df749b0>]}
[0m23:00:40.866083 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:00:40.867573 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/sources.yml
[0m23:00:40.888909 [debug] [MainThread]: 1699: static parser successfully parsed marts/fact_flights.sql
[0m23:00:40.911533 [debug] [MainThread]: 1603: static parser failed on marts/dim_destination.sql
[0m23:00:40.923067 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_destination.sql
[0m23:00:40.925706 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_flight_status.sql
[0m23:00:40.930506 [debug] [MainThread]: 1603: static parser failed on marts/dim_origin.sql
[0m23:00:40.937367 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_origin.sql
[0m23:00:40.939786 [debug] [MainThread]: 1603: static parser failed on staging/stg_flight_status.sql
[0m23:00:40.957483 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_flight_status.sql
[0m23:00:41.154679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a1734056-5b86-4ad7-a78d-912420edd051', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865dcdfc20>]}
[0m23:00:41.164631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a1734056-5b86-4ad7-a78d-912420edd051', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865dc5ec90>]}
[0m23:00:41.165068 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m23:00:41.165418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a1734056-5b86-4ad7-a78d-912420edd051', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865e1a7200>]}
[0m23:00:41.167526 [info ] [MainThread]: 
[0m23:00:41.169961 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:00:41.171721 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m23:00:41.172871 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:00:41.218097 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m23:00:41.218540 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m23:00:41.218845 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:00:41.219516 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:00:41.223519 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:00:41.224107 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:00:42.707070 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m23:00:42.711263 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:00:42.808598 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m23:00:42.811538 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m23:00:43.354892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a1734056-5b86-4ad7-a78d-912420edd051', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865dcfaed0>]}
[0m23:00:43.356045 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m23:00:43.356556 [info ] [MainThread]: 
[0m23:00:43.411887 [debug] [Thread-1 (]: Began running node source.airflow_dbt_project.raw_data.flights
[0m23:00:43.412480 [info ] [Thread-1 (]: 1 of 1 START freshness of raw_data.flights ..................................... [RUN]
[0m23:00:43.413768 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m23:00:43.414220 [debug] [Thread-1 (]: Began compiling node source.airflow_dbt_project.raw_data.flights
[0m23:00:43.414587 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (compile): 2025-11-25 23:00:43.414488 => 2025-11-25 23:00:43.414498
[0m23:00:43.414880 [debug] [Thread-1 (]: Began executing node source.airflow_dbt_project.raw_data.flights
[0m23:00:43.415735 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m23:00:43.428846 [debug] [Thread-1 (]: Using snowflake connection "source.airflow_dbt_project.raw_data.flights"
[0m23:00:43.429241 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "source.airflow_dbt_project.raw_data.flights"} */
select
      max(INGESTION_TIME# it is converted to >>now()-max(ingestion_time)) as max_loaded_at,
      convert_timezone('UTC', current_timestamp()) as snapshotted_at
    from GP.RAW.flights
[0m23:00:43.429502 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:00:44.613251 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c0a304-0000-a90d-0000-eb0d0006040a
[0m23:00:44.613862 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 2 at position 24 unexpected '# '.
syntax error line 2 at position 24 unexpected '# '.
[0m23:00:44.614469 [debug] [Thread-1 (]: Snowflake adapter: Error running SQL: macro collect_freshness
[0m23:00:44.614788 [debug] [Thread-1 (]: Snowflake adapter: Rolling back transaction.
[0m23:00:44.615108 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: Close
[0m23:00:45.077439 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (execute): 2025-11-25 23:00:43.415077 => 2025-11-25 23:00:45.077224
[0m23:00:45.083190 [debug] [Thread-1 (]: Database Error in source flights (models/staging/sources.yml)
  001003 (42000): SQL compilation error:
  syntax error line 2 at position 24 unexpected '# '.
  syntax error line 2 at position 24 unexpected '# '.
[0m23:00:45.083766 [error] [Thread-1 (]: 1 of 1 ERROR freshness of raw_data.flights ..................................... [[31mERROR[0m in 1.67s]
[0m23:00:45.086541 [debug] [Thread-1 (]: Finished running node source.airflow_dbt_project.raw_data.flights
[0m23:00:45.088336 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:00:45.088704 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m23:00:45.088940 [debug] [MainThread]: Connection 'source.airflow_dbt_project.raw_data.flights' was properly closed.
[0m23:00:45.100869 [info ] [MainThread]: 
[0m23:00:45.101847 [error] [MainThread]: [33mDatabase Error in source flights (models/staging/sources.yml)[0m
[0m23:00:45.102775 [error] [MainThread]:   001003 (42000): SQL compilation error:
[0m23:00:45.103286 [error] [MainThread]:   syntax error line 2 at position 24 unexpected '# '.
[0m23:00:45.103695 [error] [MainThread]:   syntax error line 2 at position 24 unexpected '# '.
[0m23:00:45.104068 [info ] [MainThread]: Done.
[0m23:00:45.104685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865c3584a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865c3a18b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865c42bda0>]}
[0m23:00:45.105172 [debug] [MainThread]: Flushing usage events


============================== 2025-11-25 23:00:57.590756 | 5de6363f-39d8-4213-8427-b794604680d9 ==============================
[0m23:00:57.590756 [info ] [MainThread]: Running with dbt=1.4.0
[0m23:00:57.592946 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'source-freshness', 'rpc_method': 'source-freshness', 'indirect_selection': 'eager'}
[0m23:00:57.593228 [debug] [MainThread]: Tracking: tracking
[0m23:00:57.593561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0df00a900>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0df76ec30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc109e6a600>]}
[0m23:00:57.649706 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:00:57.651087 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/sources.yml
[0m23:00:57.670179 [debug] [MainThread]: 1699: static parser successfully parsed marts/fact_flights.sql
[0m23:00:57.691818 [debug] [MainThread]: 1603: static parser failed on marts/dim_destination.sql
[0m23:00:57.703447 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_destination.sql
[0m23:00:57.705755 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_flight_status.sql
[0m23:00:57.709791 [debug] [MainThread]: 1603: static parser failed on marts/dim_origin.sql
[0m23:00:57.716112 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_origin.sql
[0m23:00:57.718416 [debug] [MainThread]: 1603: static parser failed on staging/stg_flight_status.sql
[0m23:00:57.735580 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_flight_status.sql
[0m23:00:57.916378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5de6363f-39d8-4213-8427-b794604680d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0de8e7620>]}
[0m23:00:57.926148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5de6363f-39d8-4213-8427-b794604680d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0dea32c00>]}
[0m23:00:57.926558 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m23:00:57.926868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5de6363f-39d8-4213-8427-b794604680d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0df00a900>]}
[0m23:00:57.928916 [info ] [MainThread]: 
[0m23:00:57.931297 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:00:57.932979 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m23:00:57.939489 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:00:58.019009 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:00:58.019969 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m23:00:58.020672 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:00:58.021484 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m23:00:58.022283 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:00:58.023035 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:00:59.609674 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2 seconds
[0m23:00:59.612325 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m23:00:59.616205 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m23:00:59.620082 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:01:01.058110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5de6363f-39d8-4213-8427-b794604680d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0dea32d20>]}
[0m23:01:01.059400 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m23:01:01.060115 [info ] [MainThread]: 
[0m23:01:01.102565 [debug] [Thread-1 (]: Began running node source.airflow_dbt_project.raw_data.flights
[0m23:01:01.103131 [info ] [Thread-1 (]: 1 of 1 START freshness of raw_data.flights ..................................... [RUN]
[0m23:01:01.104262 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m23:01:01.104679 [debug] [Thread-1 (]: Began compiling node source.airflow_dbt_project.raw_data.flights
[0m23:01:01.105018 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (compile): 2025-11-25 23:01:01.104915 => 2025-11-25 23:01:01.104926
[0m23:01:01.105363 [debug] [Thread-1 (]: Began executing node source.airflow_dbt_project.raw_data.flights
[0m23:01:01.106319 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m23:01:01.121046 [debug] [Thread-1 (]: Using snowflake connection "source.airflow_dbt_project.raw_data.flights"
[0m23:01:01.121553 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "source.airflow_dbt_project.raw_data.flights"} */
select
      max(INGESTION_TIME) as max_loaded_at,
      convert_timezone('UTC', current_timestamp()) as snapshotted_at
    from GP.RAW.flights
[0m23:01:01.121856 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:01:06.976261 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 6 seconds
[0m23:01:06.978791 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: Close
[0m23:01:07.584429 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (execute): 2025-11-25 23:01:01.105576 => 2025-11-25 23:01:07.584218
[0m23:01:07.585927 [error] [Thread-1 (]: 1 of 1 ERROR STALE freshness of raw_data.flights ............................... [[31mERROR STALE[0m in 6.48s]
[0m23:01:07.589090 [debug] [Thread-1 (]: Finished running node source.airflow_dbt_project.raw_data.flights
[0m23:01:07.591243 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:01:07.591621 [debug] [MainThread]: Connection 'source.airflow_dbt_project.raw_data.flights' was properly closed.
[0m23:01:07.591865 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m23:01:07.602848 [info ] [MainThread]: 
[0m23:01:07.603452 [info ] [MainThread]: Done.
[0m23:01:07.604508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0deb5deb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0deb5ea20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0dd19e240>]}
[0m23:01:07.605209 [debug] [MainThread]: Flushing usage events


============================== 2025-11-25 23:01:46.921122 | 205bbb83-aeca-4493-9415-43015aaa5ad3 ==============================
[0m23:01:46.921122 [info ] [MainThread]: Running with dbt=1.4.0
[0m23:01:46.923217 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'source-freshness', 'rpc_method': 'source-freshness', 'indirect_selection': 'eager'}
[0m23:01:46.923527 [debug] [MainThread]: Tracking: tracking
[0m23:01:46.923831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca2af6d550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca2157a300>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca425e3260>]}
[0m23:01:46.987090 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:01:46.989041 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/sources.yml
[0m23:01:47.025545 [debug] [MainThread]: 1699: static parser successfully parsed marts/fact_flights.sql
[0m23:01:47.079867 [debug] [MainThread]: 1603: static parser failed on marts/dim_destination.sql
[0m23:01:47.093306 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_destination.sql
[0m23:01:47.095797 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_flight_status.sql
[0m23:01:47.100844 [debug] [MainThread]: 1603: static parser failed on marts/dim_origin.sql
[0m23:01:47.107200 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_origin.sql
[0m23:01:47.109588 [debug] [MainThread]: 1603: static parser failed on staging/stg_flight_status.sql
[0m23:01:47.129168 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_flight_status.sql
[0m23:01:47.323582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '205bbb83-aeca-4493-9415-43015aaa5ad3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1be9cb90>]}
[0m23:01:47.333471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '205bbb83-aeca-4493-9415-43015aaa5ad3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1be22c00>]}
[0m23:01:47.333872 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m23:01:47.334180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '205bbb83-aeca-4493-9415-43015aaa5ad3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca20653170>]}
[0m23:01:47.336202 [info ] [MainThread]: 
[0m23:01:47.338638 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:01:47.340444 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:01:47.352225 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m23:01:47.380887 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:01:47.381329 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:01:47.381629 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:01:47.385242 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m23:01:47.386999 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m23:01:47.389474 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:01:49.960924 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 3 seconds
[0m23:01:49.966283 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m23:01:50.222246 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m23:01:50.224987 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:01:50.944123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '205bbb83-aeca-4493-9415-43015aaa5ad3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1be22960>]}
[0m23:01:50.945342 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m23:01:50.945796 [info ] [MainThread]: 
[0m23:01:50.993870 [debug] [Thread-1 (]: Began running node source.airflow_dbt_project.raw_data.flights
[0m23:01:50.994727 [info ] [Thread-1 (]: 1 of 1 START freshness of raw_data.flights ..................................... [RUN]
[0m23:01:50.996592 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m23:01:50.997494 [debug] [Thread-1 (]: Began compiling node source.airflow_dbt_project.raw_data.flights
[0m23:01:50.998168 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (compile): 2025-11-25 23:01:50.997974 => 2025-11-25 23:01:50.997994
[0m23:01:50.998790 [debug] [Thread-1 (]: Began executing node source.airflow_dbt_project.raw_data.flights
[0m23:01:51.000655 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m23:01:51.042153 [debug] [Thread-1 (]: Using snowflake connection "source.airflow_dbt_project.raw_data.flights"
[0m23:01:51.043228 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "source.airflow_dbt_project.raw_data.flights"} */
select
      max(INGESTION_TIME) as max_loaded_at,
      convert_timezone('UTC', current_timestamp()) as snapshotted_at
    from GP.RAW.flights
[0m23:01:51.044161 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:01:52.651952 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m23:01:52.655992 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: Close
[0m23:01:53.092030 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (execute): 2025-11-25 23:01:50.999225 => 2025-11-25 23:01:53.091841
[0m23:01:53.093387 [error] [Thread-1 (]: 1 of 1 ERROR STALE freshness of raw_data.flights ............................... [[31mERROR STALE[0m in 2.10s]
[0m23:01:53.096372 [debug] [Thread-1 (]: Finished running node source.airflow_dbt_project.raw_data.flights
[0m23:01:53.098687 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:01:53.099068 [debug] [MainThread]: Connection 'source.airflow_dbt_project.raw_data.flights' was properly closed.
[0m23:01:53.099335 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m23:01:53.111464 [info ] [MainThread]: 
[0m23:01:53.112140 [info ] [MainThread]: Done.
[0m23:01:53.112841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1bebaf30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1bebabd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1befc830>]}
[0m23:01:53.113411 [debug] [MainThread]: Flushing usage events


============================== 2025-11-25 23:02:30.684790 | fd61576d-8b59-4127-b862-a3cead68161e ==============================
[0m23:02:30.684790 [info ] [MainThread]: Running with dbt=1.4.0
[0m23:02:30.687033 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'source-freshness', 'rpc_method': 'source-freshness', 'indirect_selection': 'eager'}
[0m23:02:30.687346 [debug] [MainThread]: Tracking: tracking
[0m23:02:30.687692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fdff69910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fde1f0ef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fde1f12b0>]}
[0m23:02:30.743795 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:02:30.745174 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/staging/sources.yml
[0m23:02:30.765174 [debug] [MainThread]: 1699: static parser successfully parsed marts/fact_flights.sql
[0m23:02:30.785221 [debug] [MainThread]: 1603: static parser failed on marts/dim_destination.sql
[0m23:02:30.794588 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_destination.sql
[0m23:02:30.796842 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_flight_status.sql
[0m23:02:30.800897 [debug] [MainThread]: 1603: static parser failed on marts/dim_origin.sql
[0m23:02:30.807080 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_origin.sql
[0m23:02:30.809480 [debug] [MainThread]: 1603: static parser failed on staging/stg_flight_status.sql
[0m23:02:30.826293 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_flight_status.sql
[0m23:02:31.033219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fd61576d-8b59-4127-b862-a3cead68161e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fddf4ba70>]}
[0m23:02:31.045205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fd61576d-8b59-4127-b862-a3cead68161e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fde0cae70>]}
[0m23:02:31.045695 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m23:02:31.046060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fd61576d-8b59-4127-b862-a3cead68161e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fdee0bf80>]}
[0m23:02:31.048459 [info ] [MainThread]: 
[0m23:02:31.051088 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:02:31.052994 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:02:31.059489 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m23:02:31.106182 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:02:31.106962 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m23:02:31.107454 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:02:31.107991 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m23:02:31.108413 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:02:31.108793 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:02:32.433541 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m23:02:32.435877 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:02:32.445095 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1 seconds
[0m23:02:32.447128 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m23:02:32.849466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fd61576d-8b59-4127-b862-a3cead68161e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fde542660>]}
[0m23:02:32.850446 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m23:02:32.850831 [info ] [MainThread]: 
[0m23:02:32.892768 [debug] [Thread-1 (]: Began running node source.airflow_dbt_project.raw_data.flights
[0m23:02:32.893679 [info ] [Thread-1 (]: 1 of 1 START freshness of raw_data.flights ..................................... [RUN]
[0m23:02:32.895111 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m23:02:32.895622 [debug] [Thread-1 (]: Began compiling node source.airflow_dbt_project.raw_data.flights
[0m23:02:32.896038 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (compile): 2025-11-25 23:02:32.895918 => 2025-11-25 23:02:32.895931
[0m23:02:32.896407 [debug] [Thread-1 (]: Began executing node source.airflow_dbt_project.raw_data.flights
[0m23:02:32.897437 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m23:02:32.914562 [debug] [Thread-1 (]: Using snowflake connection "source.airflow_dbt_project.raw_data.flights"
[0m23:02:32.915217 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "source.airflow_dbt_project.raw_data.flights"} */
select
      max(INGESTION_TIME) as max_loaded_at,
      convert_timezone('UTC', current_timestamp()) as snapshotted_at
    from GP.RAW.flights
[0m23:02:32.915720 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:02:34.780599 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m23:02:34.784150 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: Close
[0m23:02:35.159465 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (execute): 2025-11-25 23:02:32.896657 => 2025-11-25 23:02:35.159279
[0m23:02:35.160749 [warn ] [Thread-1 (]: 1 of 1 WARN freshness of raw_data.flights ...................................... [[33mWARN[0m in 2.27s]
[0m23:02:35.163789 [debug] [Thread-1 (]: Finished running node source.airflow_dbt_project.raw_data.flights
[0m23:02:35.166250 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:02:35.166653 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m23:02:35.166908 [debug] [MainThread]: Connection 'source.airflow_dbt_project.raw_data.flights' was properly closed.
[0m23:02:35.179187 [info ] [MainThread]: Done.
[0m23:02:35.180292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fdc5c9820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fdc615af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fde0ca930>]}
[0m23:02:35.181225 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 07:52:46.350044 | 3d2bef8a-5082-473b-a178-94bca0a61790 ==============================
[0m07:52:46.350044 [info ] [MainThread]: Running with dbt=1.4.0
[0m07:52:46.352664 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['staging.*'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:52:46.352976 [debug] [MainThread]: Tracking: tracking
[0m07:52:46.353306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f386d5aca10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f386c24bcb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3867c4fe00>]}
[0m07:52:46.458848 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:52:46.459717 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:52:46.480790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3d2bef8a-5082-473b-a178-94bca0a61790', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3867c44a10>]}
[0m07:52:46.499127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3d2bef8a-5082-473b-a178-94bca0a61790', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3867662e70>]}
[0m07:52:46.499858 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m07:52:46.500890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3d2bef8a-5082-473b-a178-94bca0a61790', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3867cf3b00>]}
[0m07:52:46.504625 [info ] [MainThread]: 
[0m07:52:46.508512 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m07:52:46.510962 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m07:52:46.546829 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m07:52:46.547364 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m07:52:46.547686 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:52:47.684179 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m07:52:47.687864 [debug] [ThreadPool]: On list_GP: Close
[0m07:52:48.092096 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m07:52:48.093264 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m07:52:48.093793 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging', identifier=None)"
[0m07:52:48.102812 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m07:52:48.103346 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m07:52:48.103695 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:52:48.951872 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m07:52:48.959770 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m07:52:49.345999 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m07:52:49.359043 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m07:52:49.375818 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m07:52:49.369756 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m07:52:49.376990 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m07:52:49.377712 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m07:52:49.378492 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:52:49.379287 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:52:50.171496 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m07:52:50.178562 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m07:52:50.386833 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1 seconds
[0m07:52:50.396926 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m07:52:50.798128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3d2bef8a-5082-473b-a178-94bca0a61790', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f387e3ed9a0>]}
[0m07:52:50.803477 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m07:52:50.805359 [info ] [MainThread]: 
[0m07:52:50.923888 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_flight_status
[0m07:52:50.924869 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [RUN]
[0m07:52:50.927964 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_flight_status'
[0m07:52:50.928833 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_flight_status
[0m07:52:50.963675 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_flight_status"
[0m07:52:50.965126 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (compile): 2025-11-26 07:52:50.929390 => 2025-11-26 07:52:50.964847
[0m07:52:50.966344 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_flight_status
[0m07:52:51.039745 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_flight_status"
[0m07:52:51.043300 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_flight_status"
[0m07:52:51.043656 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_flight_status"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
  
   as (
    select 
    DATE_FROM_PARTS(year, month, day_of_month) AS flight_date,
    
    lower(op_unique_carrier)
 as Airline_Code,
    op_carrier_fl_num::INT as Flight_Number,
    
    lower(origin)
 as Origin_Airport_Code,
    
    lower(origin_city_name)
 as Origin_City,
    
    lower(origin_state_nm)
 as Origin_State,
    
    lower(dest)
 as Destination_Airport_Code,
    
    lower(dest_city_name)
 as Destination_City,
    
    lower(dest_state_nm)
 as Destination_State,
    crs_dep_time::INT as Scheduled_Departure_Time,
    dep_time::INT as Actual_Departure_Time,
    dep_delay::INT as Departure_Delay,
    taxi_out::INT as Taxi_Out_Time,
    wheels_off::INT as Wheels_Off_Time,
    wheels_on::INT as Wheels_On_Time,
    taxi_in::INT as Taxi_In_Time,
    crs_arr_time::INT as Scheduled_Arrival_Time,
    arr_time::INT as Actual_Arrival_Time,
    arr_delay::INT as Arrival_Delay,
    CASE cancelled WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_cancelled,
    CASE cancellation_code WHEN 'A' THEN 'Carrier'  WHEN 'B' THEN 'Weather'  WHEN 'C' THEN 'National Air System'  WHEN 'D' THEN 'Security'  ELSE 'still available' END as Cancellation_Reason,
    CASE diverted WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_diverted,
    crs_elapsed_time::INT as Scheduled_Flight_Duration,
    actual_elapsed_time::INT as Actual_Flight_Duration,
    air_time,
    distance,
    carrier_delay,
    weather_delay,
    nas_delay,
    security_delay,
    late_aircraft_delay,
    isDelete,
    CASE operation WHEN 'c' THEN 'Create'  WHEN 'u' THEN 'Update'  WHEN 'd' THEN 'Delete'  WHEN 'r' THEN 'Snapshot'  ELSE 'Unknown' END as operation_type,
    TO_TIMESTAMP_LTZ(event_time / 1000) as event_time,
    ingestion_time  as ingestion_datetime
from GP.RAW.flights
  );
[0m07:52:51.043959 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:52:52.069715 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m07:52:52.100184 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (execute): 2025-11-26 07:52:50.967330 => 2025-11-26 07:52:52.100080
[0m07:52:52.100588 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: Close
[0m07:52:52.527459 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d2bef8a-5082-473b-a178-94bca0a61790', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38675769f0>]}
[0m07:52:52.528408 [info ] [Thread-1 (]: 1 of 1 OK created sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [[32mSUCCESS 1[0m in 1.60s]
[0m07:52:52.531516 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_flight_status
[0m07:52:52.534351 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m07:52:52.535294 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:52:52.535677 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m07:52:52.535945 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_flight_status' was properly closed.
[0m07:52:52.536241 [info ] [MainThread]: 
[0m07:52:52.536672 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 6.03 seconds (6.03s).
[0m07:52:52.537723 [debug] [MainThread]: Command end result
[0m07:52:52.550228 [info ] [MainThread]: 
[0m07:52:52.550970 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:52:52.551492 [info ] [MainThread]: 
[0m07:52:52.552100 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m07:52:52.552920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f386778cc20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3867960920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3866aa4da0>]}
[0m07:52:52.553529 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 07:53:19.610795 | ea54573c-313f-4fa9-92b7-735e859c0b5f ==============================
[0m07:53:19.610795 [info ] [MainThread]: Running with dbt=1.4.0
[0m07:53:19.613052 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'source-freshness', 'rpc_method': 'source-freshness', 'indirect_selection': 'eager'}
[0m07:53:19.613351 [debug] [MainThread]: Tracking: tracking
[0m07:53:19.613656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30ad3984d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30a297ef30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30ad32ef00>]}
[0m07:53:19.668691 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:53:19.669152 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:53:19.680845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ea54573c-313f-4fa9-92b7-735e859c0b5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30a2b269c0>]}
[0m07:53:19.695066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ea54573c-313f-4fa9-92b7-735e859c0b5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30a254f020>]}
[0m07:53:19.695639 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m07:53:19.696078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ea54573c-313f-4fa9-92b7-735e859c0b5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30a328bf50>]}
[0m07:53:19.699237 [info ] [MainThread]: 
[0m07:53:19.702617 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m07:53:19.704992 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m07:53:19.712547 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m07:53:19.759030 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m07:53:19.759526 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m07:53:19.760207 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m07:53:19.760743 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:53:19.761362 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m07:53:19.765039 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:53:20.908897 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m07:53:20.912514 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m07:53:20.918148 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m07:53:20.921152 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m07:53:21.396857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ea54573c-313f-4fa9-92b7-735e859c0b5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30a254ef30>]}
[0m07:53:21.398030 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m07:53:21.398502 [info ] [MainThread]: 
[0m07:53:21.444589 [debug] [Thread-1 (]: Began running node source.airflow_dbt_project.raw_data.flights
[0m07:53:21.445380 [info ] [Thread-1 (]: 1 of 1 START freshness of raw_data.flights ..................................... [RUN]
[0m07:53:21.446632 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m07:53:21.447089 [debug] [Thread-1 (]: Began compiling node source.airflow_dbt_project.raw_data.flights
[0m07:53:21.447441 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (compile): 2025-11-26 07:53:21.447340 => 2025-11-26 07:53:21.447352
[0m07:53:21.447735 [debug] [Thread-1 (]: Began executing node source.airflow_dbt_project.raw_data.flights
[0m07:53:21.448638 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m07:53:21.464107 [debug] [Thread-1 (]: Using snowflake connection "source.airflow_dbt_project.raw_data.flights"
[0m07:53:21.464684 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "source.airflow_dbt_project.raw_data.flights"} */
select
      max(INGESTION_TIME) as max_loaded_at,
      convert_timezone('UTC', current_timestamp()) as snapshotted_at
    from GP.RAW.flights
[0m07:53:21.465018 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:53:22.544594 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m07:53:22.547971 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: Close
[0m07:53:23.026361 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (execute): 2025-11-26 07:53:21.447957 => 2025-11-26 07:53:23.026149
[0m07:53:23.027625 [warn ] [Thread-1 (]: 1 of 1 WARN freshness of raw_data.flights ...................................... [[33mWARN[0m in 1.58s]
[0m07:53:23.030766 [debug] [Thread-1 (]: Finished running node source.airflow_dbt_project.raw_data.flights
[0m07:53:23.032944 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:53:23.033385 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m07:53:23.033704 [debug] [MainThread]: Connection 'source.airflow_dbt_project.raw_data.flights' was properly closed.
[0m07:53:23.045886 [info ] [MainThread]: Done.
[0m07:53:23.046879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30a237c5c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30a28906b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30a33f8740>]}
[0m07:53:23.047492 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 07:55:53.517630 | 3c454b9d-f880-4eb9-9fec-d30d77c05af1 ==============================
[0m07:55:53.517630 [info ] [MainThread]: Running with dbt=1.4.0
[0m07:55:53.519777 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'source-freshness', 'rpc_method': 'source-freshness', 'indirect_selection': 'eager'}
[0m07:55:53.520064 [debug] [MainThread]: Tracking: tracking
[0m07:55:53.520369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f337e4254c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f337e8eb0b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f337e450410>]}
[0m07:55:53.570358 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:55:53.570826 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:55:53.582822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3c454b9d-f880-4eb9-9fec-d30d77c05af1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f337f2044d0>]}
[0m07:55:53.597150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3c454b9d-f880-4eb9-9fec-d30d77c05af1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f337e1026c0>]}
[0m07:55:53.597744 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m07:55:53.598215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3c454b9d-f880-4eb9-9fec-d30d77c05af1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f337e920440>]}
[0m07:55:53.601363 [info ] [MainThread]: 
[0m07:55:53.604925 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m07:55:53.607362 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m07:55:53.619481 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m07:55:53.648880 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m07:55:53.649323 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m07:55:53.649665 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:55:53.651903 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m07:55:53.652322 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m07:55:53.652609 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:55:55.768408 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m07:55:55.771734 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m07:55:55.776630 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m07:55:55.778888 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m07:55:56.565683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3c454b9d-f880-4eb9-9fec-d30d77c05af1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f337e102630>]}
[0m07:55:56.566681 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m07:55:56.567088 [info ] [MainThread]: 
[0m07:55:56.606138 [debug] [Thread-1 (]: Began running node source.airflow_dbt_project.raw_data.flights
[0m07:55:56.606697 [info ] [Thread-1 (]: 1 of 1 START freshness of raw_data.flights ..................................... [RUN]
[0m07:55:56.607849 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m07:55:56.608345 [debug] [Thread-1 (]: Began compiling node source.airflow_dbt_project.raw_data.flights
[0m07:55:56.608783 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (compile): 2025-11-26 07:55:56.608660 => 2025-11-26 07:55:56.608676
[0m07:55:56.609195 [debug] [Thread-1 (]: Began executing node source.airflow_dbt_project.raw_data.flights
[0m07:55:56.610235 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m07:55:56.623054 [debug] [Thread-1 (]: Using snowflake connection "source.airflow_dbt_project.raw_data.flights"
[0m07:55:56.623455 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "source.airflow_dbt_project.raw_data.flights"} */
select
      max(INGESTION_TIME) as max_loaded_at,
      convert_timezone('UTC', current_timestamp()) as snapshotted_at
    from GP.RAW.flights
[0m07:55:56.623699 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:55:58.099107 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m07:55:58.102507 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: Close
[0m07:55:59.959368 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (execute): 2025-11-26 07:55:56.609488 => 2025-11-26 07:55:59.959172
[0m07:55:59.960759 [warn ] [Thread-1 (]: 1 of 1 WARN freshness of raw_data.flights ...................................... [[33mWARN[0m in 3.35s]
[0m07:55:59.963863 [debug] [Thread-1 (]: Finished running node source.airflow_dbt_project.raw_data.flights
[0m07:55:59.965899 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:55:59.966307 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m07:55:59.966587 [debug] [MainThread]: Connection 'source.airflow_dbt_project.raw_data.flights' was properly closed.
[0m07:55:59.977955 [info ] [MainThread]: Done.
[0m07:55:59.978547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f337e94eb40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33842c5460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f337e18a0c0>]}
[0m07:55:59.978987 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 07:56:24.191015 | dd5bc7ac-16de-4369-aff1-6e08072396c0 ==============================
[0m07:56:24.191015 [info ] [MainThread]: Running with dbt=1.4.0
[0m07:56:24.193197 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['staging.*'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:56:24.193458 [debug] [MainThread]: Tracking: tracking
[0m07:56:24.193749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3c5b4c48f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3c2f954c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3c2f9544a0>]}
[0m07:56:24.236001 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:56:24.236378 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:56:24.245903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dd5bc7ac-16de-4369-aff1-6e08072396c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3c35180620>]}
[0m07:56:24.259471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dd5bc7ac-16de-4369-aff1-6e08072396c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3c2f14a930>]}
[0m07:56:24.260144 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m07:56:24.260601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dd5bc7ac-16de-4369-aff1-6e08072396c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3c40fd3f80>]}
[0m07:56:24.263312 [info ] [MainThread]: 
[0m07:56:24.266761 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m07:56:24.268792 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m07:56:24.295088 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m07:56:24.295523 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m07:56:24.295870 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:56:25.347981 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m07:56:25.351297 [debug] [ThreadPool]: On list_GP: Close
[0m07:56:26.005221 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m07:56:26.006430 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m07:56:26.007020 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging', identifier=None)"
[0m07:56:26.016719 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m07:56:26.017176 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m07:56:26.017542 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:56:27.254048 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m07:56:27.256150 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m07:56:27.706099 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m07:56:27.713197 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m07:56:27.726374 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m07:56:27.726759 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m07:56:27.727030 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:56:27.730367 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m07:56:27.731732 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m07:56:27.732125 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:56:28.756968 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m07:56:28.761815 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m07:56:28.787955 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m07:56:28.791548 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m07:56:29.308011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dd5bc7ac-16de-4369-aff1-6e08072396c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3c2e84b4d0>]}
[0m07:56:29.309517 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m07:56:29.310347 [info ] [MainThread]: 
[0m07:56:29.342039 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_flight_status
[0m07:56:29.342670 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [RUN]
[0m07:56:29.344525 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_flight_status'
[0m07:56:29.344949 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_flight_status
[0m07:56:29.359922 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_flight_status"
[0m07:56:29.360581 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (compile): 2025-11-26 07:56:29.345187 => 2025-11-26 07:56:29.360480
[0m07:56:29.360918 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_flight_status
[0m07:56:29.400922 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_flight_status"
[0m07:56:29.403311 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_flight_status"
[0m07:56:29.403583 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_flight_status"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
  
   as (
    select 
    DATE_FROM_PARTS(year, month, day_of_month) AS flight_date,
    
    lower(op_unique_carrier)
 as Airline_Code,
    op_carrier_fl_num::INT as Flight_Number,
    
    lower(origin)
 as Origin_Airport_Code,
    
    lower(origin_city_name)
 as Origin_City,
    
    lower(origin_state_nm)
 as Origin_State,
    
    lower(dest)
 as Destination_Airport_Code,
    
    lower(dest_city_name)
 as Destination_City,
    
    lower(dest_state_nm)
 as Destination_State,
    crs_dep_time::INT as Scheduled_Departure_Time,
    dep_time::INT as Actual_Departure_Time,
    dep_delay::INT as Departure_Delay,
    taxi_out::INT as Taxi_Out_Time,
    wheels_off::INT as Wheels_Off_Time,
    wheels_on::INT as Wheels_On_Time,
    taxi_in::INT as Taxi_In_Time,
    crs_arr_time::INT as Scheduled_Arrival_Time,
    arr_time::INT as Actual_Arrival_Time,
    arr_delay::INT as Arrival_Delay,
    CASE cancelled WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_cancelled,
    CASE cancellation_code WHEN 'A' THEN 'Carrier'  WHEN 'B' THEN 'Weather'  WHEN 'C' THEN 'National Air System'  WHEN 'D' THEN 'Security'  ELSE 'still available' END as Cancellation_Reason,
    CASE diverted WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_diverted,
    crs_elapsed_time::INT as Scheduled_Flight_Duration,
    actual_elapsed_time::INT as Actual_Flight_Duration,
    air_time,
    distance,
    carrier_delay,
    weather_delay,
    nas_delay,
    security_delay,
    late_aircraft_delay,
    isDelete,
    CASE operation WHEN 'c' THEN 'Create'  WHEN 'u' THEN 'Update'  WHEN 'd' THEN 'Delete'  WHEN 'r' THEN 'Snapshot'  ELSE 'Unknown' END as operation_type,
    TO_TIMESTAMP_LTZ(event_time / 1000) as event_time,
    ingestion_time  as ingestion_datetime
from GP.RAW.flights
  );
[0m07:56:29.403775 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:56:30.683334 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m07:56:30.708378 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (execute): 2025-11-26 07:56:29.361163 => 2025-11-26 07:56:30.708294
[0m07:56:30.708722 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: Close
[0m07:56:31.117305 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd5bc7ac-16de-4369-aff1-6e08072396c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3c2f219ac0>]}
[0m07:56:31.118369 [info ] [Thread-1 (]: 1 of 1 OK created sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [[32mSUCCESS 1[0m in 1.77s]
[0m07:56:31.121599 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_flight_status
[0m07:56:31.124554 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m07:56:31.125412 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:56:31.125715 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_flight_status' was properly closed.
[0m07:56:31.125970 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m07:56:31.126265 [info ] [MainThread]: 
[0m07:56:31.126619 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 6.86 seconds (6.86s).
[0m07:56:31.127087 [debug] [MainThread]: Command end result
[0m07:56:31.137540 [info ] [MainThread]: 
[0m07:56:31.138052 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:56:31.138389 [info ] [MainThread]: 
[0m07:56:31.138699 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m07:56:31.139111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3c2f60e480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3c2e849520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3c2f2878f0>]}
[0m07:56:31.139445 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 07:59:51.438133 | 1a5ab017-599d-4590-97d5-740c2aedb4a9 ==============================
[0m07:59:51.438133 [info ] [MainThread]: Running with dbt=1.4.0
[0m07:59:51.440190 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_destination'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:59:51.440447 [debug] [MainThread]: Tracking: tracking
[0m07:59:51.440733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4df8f10650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4df8e1bcb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e20005790>]}
[0m07:59:51.484098 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:59:51.484550 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:59:51.494487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1a5ab017-599d-4590-97d5-740c2aedb4a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4df8fed1f0>]}
[0m07:59:51.506997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1a5ab017-599d-4590-97d5-740c2aedb4a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4df8d229f0>]}
[0m07:59:51.507553 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m07:59:51.507974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1a5ab017-599d-4590-97d5-740c2aedb4a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4df9358ef0>]}
[0m07:59:51.510281 [info ] [MainThread]: 
[0m07:59:51.513284 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m07:59:51.515155 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m07:59:51.541847 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m07:59:51.542294 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m07:59:51.542633 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:59:52.796461 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m07:59:52.799444 [debug] [ThreadPool]: On list_GP: Close
[0m07:59:53.219095 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m07:59:53.220139 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m07:59:53.220576 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m07:59:53.228444 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m07:59:53.228830 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m07:59:53.229128 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:59:54.226405 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m07:59:54.228856 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m07:59:54.570224 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m07:59:54.582511 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m07:59:54.591103 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m07:59:54.591521 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m07:59:54.591861 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:59:54.595607 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m07:59:54.595979 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m07:59:54.596241 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:59:55.504810 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m07:59:55.508018 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m07:59:55.523776 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m07:59:55.526810 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m07:59:56.154753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1a5ab017-599d-4590-97d5-740c2aedb4a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4df8d22900>]}
[0m07:59:56.156131 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m07:59:56.156622 [info ] [MainThread]: 
[0m07:59:56.187531 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_destination
[0m07:59:56.188218 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [RUN]
[0m07:59:56.190151 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_destination'
[0m07:59:56.190622 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_destination
[0m07:59:56.196957 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_destination"
[0m07:59:56.197639 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (compile): 2025-11-26 07:59:56.190892 => 2025-11-26 07:59:56.197511
[0m07:59:56.198074 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_destination
[0m07:59:56.273973 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_destination"
[0m07:59:56.275311 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m07:59:56.275604 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  as
        (


with distinct_values as(
    select
    distinct destination_city as city,destination_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as destination_id,
    city,
    state
    from distinct_values


        );
[0m07:59:56.275832 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:00:00.005714 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 4 seconds
[0m08:00:00.020118 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m08:00:00.020509 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination__dbt_tmp cascade
[0m08:00:00.217835 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m08:00:00.248691 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (execute): 2025-11-26 07:59:56.198297 => 2025-11-26 08:00:00.248608
[0m08:00:00.249030 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: Close
[0m08:00:00.591642 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a5ab017-599d-4590-97d5-740c2aedb4a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4df830b440>]}
[0m08:00:00.592536 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [[32mSUCCESS 1[0m in 4.40s]
[0m08:00:00.595613 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_destination
[0m08:00:00.598370 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:00:00.599365 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:00:00.599717 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_destination' was properly closed.
[0m08:00:00.600037 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m08:00:00.600386 [info ] [MainThread]: 
[0m08:00:00.600786 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 9.09 seconds (9.09s).
[0m08:00:00.601361 [debug] [MainThread]: Command end result
[0m08:00:00.613617 [info ] [MainThread]: 
[0m08:00:00.614169 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:00:00.614534 [info ] [MainThread]: 
[0m08:00:00.614883 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:00:00.615354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4df82bebd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4df82bd4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4df82beab0>]}
[0m08:00:00.615734 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 08:02:07.856917 | 806d3a0a-e35c-4e00-9fcd-05bbc65aa335 ==============================
[0m08:02:07.856917 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:02:07.860075 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_origin'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:02:07.860514 [debug] [MainThread]: Tracking: tracking
[0m08:02:07.861347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e835e8560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e82372900>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e821eaf60>]}
[0m08:02:07.928977 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:02:07.929457 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:02:07.942386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '806d3a0a-e35c-4e00-9fcd-05bbc65aa335', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e825c7950>]}
[0m08:02:07.958320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '806d3a0a-e35c-4e00-9fcd-05bbc65aa335', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e81dfe930>]}
[0m08:02:07.959008 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:02:07.959499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '806d3a0a-e35c-4e00-9fcd-05bbc65aa335', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e824a3bc0>]}
[0m08:02:07.962294 [info ] [MainThread]: 
[0m08:02:07.965917 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:02:07.968207 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m08:02:07.996306 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m08:02:07.996806 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m08:02:07.997162 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:02:09.316254 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m08:02:09.321660 [debug] [ThreadPool]: On list_GP: Close
[0m08:02:09.712271 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:02:09.714632 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:02:09.716157 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m08:02:09.747748 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:02:09.750386 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:02:09.752596 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:02:10.700460 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m08:02:10.702140 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:02:11.090895 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:02:11.098539 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:02:11.113958 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:02:11.120040 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:02:11.121716 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:02:11.122236 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:02:11.122867 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:02:11.125978 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:02:11.991116 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m08:02:11.994844 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:02:12.245661 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m08:02:12.248674 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:02:12.725068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '806d3a0a-e35c-4e00-9fcd-05bbc65aa335', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ea9cf7e30>]}
[0m08:02:12.726680 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:02:12.727340 [info ] [MainThread]: 
[0m08:02:12.771026 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_origin
[0m08:02:12.772179 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [RUN]
[0m08:02:12.775911 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_origin'
[0m08:02:12.776769 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_origin
[0m08:02:12.789760 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_origin"
[0m08:02:12.791182 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (compile): 2025-11-26 08:02:12.777284 => 2025-11-26 08:02:12.790966
[0m08:02:12.791987 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_origin
[0m08:02:12.888986 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_origin"
[0m08:02:12.890417 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m08:02:12.890768 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  as
        (


with distinct_values as(
    select
    distinct origin_city as city,origin_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as origin_id,
    city,
    state
    from distinct_values


        );
[0m08:02:12.891033 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:02:15.257152 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:02:15.284806 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m08:02:15.286106 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin__dbt_tmp cascade
[0m08:02:15.784853 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m08:02:15.819231 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (execute): 2025-11-26 08:02:12.792405 => 2025-11-26 08:02:15.819137
[0m08:02:15.819624 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: Close
[0m08:02:16.529850 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '806d3a0a-e35c-4e00-9fcd-05bbc65aa335', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e8159d220>]}
[0m08:02:16.530535 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [[32mSUCCESS 1[0m in 3.76s]
[0m08:02:16.532984 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_origin
[0m08:02:16.535644 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:02:16.536476 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:02:16.536754 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_origin' was properly closed.
[0m08:02:16.536982 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m08:02:16.537237 [info ] [MainThread]: 
[0m08:02:16.537559 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 8.57 seconds (8.57s).
[0m08:02:16.538053 [debug] [MainThread]: Command end result
[0m08:02:16.549359 [info ] [MainThread]: 
[0m08:02:16.549946 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:02:16.550328 [info ] [MainThread]: 
[0m08:02:16.550658 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:02:16.551124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e81f3bec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e81f39820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e835b8a10>]}
[0m08:02:16.551516 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 08:02:48.398149 | 7821f2d5-0d72-436d-a6e8-901a6a080b44 ==============================
[0m08:02:48.398149 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:02:48.401264 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_flight_status'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:02:48.401641 [debug] [MainThread]: Tracking: tracking
[0m08:02:48.402086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5002bc2f00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5002bc0110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5002bc1880>]}
[0m08:02:48.459701 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:02:48.460176 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:02:48.472911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7821f2d5-0d72-436d-a6e8-901a6a080b44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500382f410>]}
[0m08:02:48.490468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7821f2d5-0d72-436d-a6e8-901a6a080b44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50030a0200>]}
[0m08:02:48.491142 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:02:48.491611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7821f2d5-0d72-436d-a6e8-901a6a080b44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5003f5d670>]}
[0m08:02:48.495065 [info ] [MainThread]: 
[0m08:02:48.498568 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:02:48.500698 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m08:02:48.529966 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m08:02:48.530433 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m08:02:48.530770 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:02:49.868854 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m08:02:49.871967 [debug] [ThreadPool]: On list_GP: Close
[0m08:02:50.270049 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:02:50.270821 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:02:50.271198 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m08:02:50.278448 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:02:50.278853 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:02:50.279162 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:02:51.085083 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m08:02:51.086639 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:02:51.466728 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:02:51.478405 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:02:51.483399 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:02:51.488486 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:02:51.489182 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:02:51.489770 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:02:51.490308 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:02:51.490871 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:02:52.411981 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m08:02:52.415570 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:02:52.564624 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m08:02:52.567442 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:02:53.308299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7821f2d5-0d72-436d-a6e8-901a6a080b44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50088776b0>]}
[0m08:02:53.309504 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:02:53.309979 [info ] [MainThread]: 
[0m08:02:53.343817 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_flight_status
[0m08:02:53.344674 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [RUN]
[0m08:02:53.346987 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_flight_status'
[0m08:02:53.347740 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_flight_status
[0m08:02:53.353733 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_flight_status"
[0m08:02:53.354961 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (compile): 2025-11-26 08:02:53.348130 => 2025-11-26 08:02:53.354741
[0m08:02:53.355796 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_flight_status
[0m08:02:53.545012 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_flight_status"
[0m08:02:53.547093 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m08:02:53.547564 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  as
        (
with distinct_values as(
    select distinct CANCELLATION_REASON,is_cancelled,is_diverted
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select 
row_number() over(order by is_cancelled) as status_id,
CANCELLATION_REASON,
is_cancelled,
is_diverted
from distinct_values
        );
[0m08:02:53.547894 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:02:54.961352 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:02:54.977489 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m08:02:54.978213 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status__dbt_tmp cascade
[0m08:02:55.366544 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m08:02:55.413488 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (execute): 2025-11-26 08:02:53.356299 => 2025-11-26 08:02:55.413300
[0m08:02:55.414216 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: Close
[0m08:02:56.193807 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7821f2d5-0d72-436d-a6e8-901a6a080b44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5001ec1250>]}
[0m08:02:56.195140 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [[32mSUCCESS 1[0m in 2.85s]
[0m08:02:56.199575 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_flight_status
[0m08:02:56.202714 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:02:56.203831 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:02:56.204256 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_flight_status' was properly closed.
[0m08:02:56.204548 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m08:02:56.204904 [info ] [MainThread]: 
[0m08:02:56.205386 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.71 seconds (7.71s).
[0m08:02:56.206024 [debug] [MainThread]: Command end result
[0m08:02:56.224468 [info ] [MainThread]: 
[0m08:02:56.225456 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:02:56.226012 [info ] [MainThread]: 
[0m08:02:56.226447 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:02:56.227054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5002e1bb60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5002a9acf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5002a9a900>]}
[0m08:02:56.227844 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 08:19:34.665215 | 5b9899bc-4c68-414d-adf5-4573d5e884fa ==============================
[0m08:19:34.665215 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:19:34.667349 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_origin'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:19:34.667641 [debug] [MainThread]: Tracking: tracking
[0m08:19:34.667969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f935be005c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f936d5c97f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93611f08f0>]}
[0m08:19:34.711031 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:19:34.711442 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:19:34.721482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b9899bc-4c68-414d-adf5-4573d5e884fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f935bebd880>]}
[0m08:19:34.734384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b9899bc-4c68-414d-adf5-4573d5e884fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f935b5f6de0>]}
[0m08:19:34.734905 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:19:34.735306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b9899bc-4c68-414d-adf5-4573d5e884fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9386b380e0>]}
[0m08:19:34.737473 [info ] [MainThread]: 
[0m08:19:34.740289 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:19:34.742066 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m08:19:34.767104 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m08:19:34.767535 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m08:19:34.767841 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:19:36.996830 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m08:19:37.000044 [debug] [ThreadPool]: On list_GP: Close
[0m08:19:37.653137 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:19:37.654104 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:19:37.654544 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m08:19:37.663448 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:19:37.663873 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:19:37.664226 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:19:39.022640 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m08:19:39.024816 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:19:39.817083 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:19:39.829220 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:19:39.838153 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:19:39.838780 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:19:39.843344 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:19:39.843864 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:19:39.844417 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:19:39.845924 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:19:41.139753 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m08:19:41.143386 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:19:41.155248 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m08:19:41.158013 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:19:41.704778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b9899bc-4c68-414d-adf5-4573d5e884fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9387523200>]}
[0m08:19:41.705941 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:19:41.706361 [info ] [MainThread]: 
[0m08:19:41.735481 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_origin
[0m08:19:41.736035 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [RUN]
[0m08:19:41.737467 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_origin'
[0m08:19:41.737811 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_origin
[0m08:19:41.743496 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_origin"
[0m08:19:41.744090 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (compile): 2025-11-26 08:19:41.738028 => 2025-11-26 08:19:41.744000
[0m08:19:41.744403 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_origin
[0m08:19:41.820046 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_origin"
[0m08:19:41.821173 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m08:19:41.821441 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  as
        (


with distinct_values as(
    select
    distinct origin_city as city,origin_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as origin_id,
    city,
    state
    from distinct_values


        );
[0m08:19:41.821639 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:19:47.450964 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 6 seconds
[0m08:19:47.463710 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m08:19:47.464069 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin__dbt_tmp cascade
[0m08:19:47.815762 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m08:19:47.846948 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (execute): 2025-11-26 08:19:41.744609 => 2025-11-26 08:19:47.846858
[0m08:19:47.847266 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: Close
[0m08:19:48.407646 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b9899bc-4c68-414d-adf5-4573d5e884fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f935ad90800>]}
[0m08:19:48.408707 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [[32mSUCCESS 1[0m in 6.67s]
[0m08:19:48.411950 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_origin
[0m08:19:48.414994 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:19:48.416187 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:19:48.416625 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m08:19:48.417016 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_origin' was properly closed.
[0m08:19:48.417452 [info ] [MainThread]: 
[0m08:19:48.417984 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 13.68 seconds (13.68s).
[0m08:19:48.418647 [debug] [MainThread]: Command end result
[0m08:19:48.430955 [info ] [MainThread]: 
[0m08:19:48.431489 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:19:48.431840 [info ] [MainThread]: 
[0m08:19:48.432151 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:19:48.432550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f936d58a7e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f935be005c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f935be00320>]}
[0m08:19:48.432878 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 08:20:14.862418 | 614f4126-7cce-44ec-96e2-c70ea1c18595 ==============================
[0m08:20:14.862418 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:20:14.864505 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['fact_flights'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:20:14.864760 [debug] [MainThread]: Tracking: tracking
[0m08:20:14.865063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81ebe26ae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81c4cb0650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81c4cb0500>]}
[0m08:20:14.906803 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:20:14.907200 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:20:14.917147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '614f4126-7cce-44ec-96e2-c70ea1c18595', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81c6fe2e10>]}
[0m08:20:14.929552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '614f4126-7cce-44ec-96e2-c70ea1c18595', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81c4b66a20>]}
[0m08:20:14.930085 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:20:14.930468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '614f4126-7cce-44ec-96e2-c70ea1c18595', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81c518c7a0>]}
[0m08:20:14.932491 [info ] [MainThread]: 
[0m08:20:14.935266 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:20:14.937039 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m08:20:14.962864 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m08:20:14.963310 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m08:20:14.963605 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:20:16.246205 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m08:20:16.250881 [debug] [ThreadPool]: On list_GP: Close
[0m08:20:16.650144 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:20:16.651222 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:20:16.651678 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m08:20:16.659532 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:20:16.659903 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:20:16.660219 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:20:17.478696 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m08:20:17.481188 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:20:17.921084 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:20:17.933566 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:20:17.941437 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:20:17.941804 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:20:17.942087 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:20:17.947921 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:20:17.948278 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:20:17.948523 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:20:18.738637 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m08:20:18.742548 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:20:18.879227 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m08:20:18.883045 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:20:20.195032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '614f4126-7cce-44ec-96e2-c70ea1c18595', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81c4d5e1b0>]}
[0m08:20:20.196255 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:20:20.196708 [info ] [MainThread]: 
[0m08:20:20.230111 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.fact_flights
[0m08:20:20.230758 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [RUN]
[0m08:20:20.232623 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.fact_flights'
[0m08:20:20.233097 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.fact_flights
[0m08:20:20.241244 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.fact_flights"
[0m08:20:20.242050 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (compile): 2025-11-26 08:20:20.233366 => 2025-11-26 08:20:20.241915
[0m08:20:20.242482 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.fact_flights
[0m08:20:20.331082 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.fact_flights"
[0m08:20:20.334015 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m08:20:20.334306 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  as
        (
select
d_date.date_id as date_id,
sdt.time_id as Scheduled_Departure_Time_id,
adt.time_id as Actual_Departure_Time_id,
wot.time_id as Wheels_Off_Time_id,
wot2.time_id as Wheels_On_Time_id,
sat.time_id as Scheduled_Arrival_Time_id,
aat.time_id as Actual_Arrival_Time_id,
origin.origin_id as origin_id,
dest.destination_id as destination_id, 
fl_stat.status_id as status_id,
AIRLINE_CODE,
FLIGHT_NUMBER,
Departure_Delay,
Taxi_Out_Time,
Taxi_In_Time,
Arrival_Delay,
Scheduled_Flight_Duration,
Actual_Flight_Duration,
Air_Time,
Distance,
Carrier_Delay,
Weather_Delay,
NAS_Delay,
Security_Delay,
Late_Aircraft_Delay
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status as stg 
left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date as d_date
on stg.flight_date=d_date.date_day

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sdt
on stg.Scheduled_Departure_Time=sdt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as adt 
on stg.Actual_Departure_Time=adt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot
on stg.Wheels_Off_Time=wot.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot2 
on stg.Wheels_On_Time=wot2.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sat
on stg.Scheduled_Arrival_Time=sat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as aat
on stg.Actual_Arrival_Time=aat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin as origin
on origin.city=stg.origin_city and origin.state=stg.origin_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination as dest
on dest.city=stg.destination_city and dest.state=stg.destination_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status as fl_stat 
on stg.IS_CANCELLED=fl_stat.IS_CANCELLED and stg.IS_DIVERTED=fl_stat.IS_DIVERTED
        );
[0m08:20:20.334515 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:20:23.848537 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 4 seconds
[0m08:20:23.861616 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m08:20:23.862027 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights__dbt_tmp cascade
[0m08:20:24.052784 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m08:20:24.081590 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (execute): 2025-11-26 08:20:20.242727 => 2025-11-26 08:20:24.081510
[0m08:20:24.081900 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: Close
[0m08:20:24.431635 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '614f4126-7cce-44ec-96e2-c70ea1c18595', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81bff320f0>]}
[0m08:20:24.432411 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [[32mSUCCESS 1[0m in 4.20s]
[0m08:20:24.435436 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.fact_flights
[0m08:20:24.438461 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:20:24.439682 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:20:24.440312 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m08:20:24.440774 [debug] [MainThread]: Connection 'model.airflow_dbt_project.fact_flights' was properly closed.
[0m08:20:24.441150 [info ] [MainThread]: 
[0m08:20:24.441557 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 9.51 seconds (9.51s).
[0m08:20:24.442114 [debug] [MainThread]: Command end result
[0m08:20:24.454200 [info ] [MainThread]: 
[0m08:20:24.454800 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:20:24.455225 [info ] [MainThread]: 
[0m08:20:24.455577 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:20:24.456050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81c4a65550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81dffb6630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81c4c34500>]}
[0m08:20:24.456426 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 08:21:40.852166 | 5a93b9f3-85b6-46dd-a6ae-f61e7189461b ==============================
[0m08:21:40.852166 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:21:40.854405 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m08:21:40.854687 [debug] [MainThread]: Tracking: tracking
[0m08:21:40.855020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1327dcc950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1326107920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1326108b00>]}
[0m08:21:40.903719 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:21:40.904184 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:21:40.915630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5a93b9f3-85b6-46dd-a6ae-f61e7189461b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1326624b60>]}
[0m08:21:40.929985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5a93b9f3-85b6-46dd-a6ae-f61e7189461b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1325de3050>]}
[0m08:21:40.930586 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:21:40.931058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a93b9f3-85b6-46dd-a6ae-f61e7189461b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13264569c0>]}
[0m08:21:40.934511 [info ] [MainThread]: 
[0m08:21:40.938040 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:21:40.941800 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:21:40.943355 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:21:40.986277 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:21:40.986763 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:21:40.987102 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:21:40.992188 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:21:40.992647 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:21:40.992964 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:21:42.129199 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m08:21:42.131913 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:21:43.460163 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m08:21:43.462730 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:21:44.336702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a93b9f3-85b6-46dd-a6ae-f61e7189461b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1325e8c950>]}
[0m08:21:44.337728 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:21:44.338141 [info ] [MainThread]: 
[0m08:21:44.369104 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m08:21:44.369763 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m08:21:44.370266 [info ] [Thread-1 (]: 1 of 17 START test is_positive_fact_flights_CARRIER_DELAY ...................... [RUN]
[0m08:21:44.370837 [info ] [Thread-2 (]: 2 of 17 START test is_positive_fact_flights_LATE_AIRCRAFT_DELAY ................ [RUN]
[0m08:21:44.371902 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec'
[0m08:21:44.372898 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa'
[0m08:21:44.373338 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m08:21:44.373750 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m08:21:44.392702 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m08:21:44.394937 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m08:21:44.395564 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (compile): 2025-11-26 08:21:44.384464 => 2025-11-26 08:21:44.395460
[0m08:21:44.395960 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (compile): 2025-11-26 08:21:44.374068 => 2025-11-26 08:21:44.395844
[0m08:21:44.396482 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m08:21:44.396910 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m08:21:44.459785 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m08:21:44.460568 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m08:21:44.462010 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m08:21:44.462855 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m08:21:44.463216 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where CARRIER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:21:44.463627 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where LATE_AIRCRAFT_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:21:44.463950 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:21:44.464255 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:21:45.426805 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:21:45.440132 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (execute): 2025-11-26 08:21:44.402427 => 2025-11-26 08:21:45.439985
[0m08:21:45.440654 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: Close
[0m08:21:45.891182 [info ] [Thread-1 (]: 1 of 17 PASS is_positive_fact_flights_CARRIER_DELAY ............................ [[32mPASS[0m in 1.52s]
[0m08:21:45.893233 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m08:21:45.893670 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m08:21:45.893926 [info ] [Thread-1 (]: 3 of 17 START test is_positive_fact_flights_NAS_DELAY .......................... [RUN]
[0m08:21:45.894608 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3'
[0m08:21:45.895015 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m08:21:45.900288 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m08:21:45.900828 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (compile): 2025-11-26 08:21:45.895198 => 2025-11-26 08:21:45.900746
[0m08:21:45.901146 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m08:21:45.904100 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m08:21:45.905028 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m08:21:45.905306 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where NAS_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:21:45.905520 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:21:46.003230 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:21:46.005756 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (execute): 2025-11-26 08:21:44.397264 => 2025-11-26 08:21:46.005664
[0m08:21:46.006097 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: Close
[0m08:21:46.695835 [info ] [Thread-2 (]: 2 of 17 PASS is_positive_fact_flights_LATE_AIRCRAFT_DELAY ...................... [[32mPASS[0m in 2.32s]
[0m08:21:46.696359 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m08:21:46.696709 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m08:21:46.696942 [info ] [Thread-2 (]: 4 of 17 START test is_positive_fact_flights_SECURITY_DELAY ..................... [RUN]
[0m08:21:46.697610 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384'
[0m08:21:46.697848 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m08:21:46.702795 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m08:21:46.703564 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (compile): 2025-11-26 08:21:46.698018 => 2025-11-26 08:21:46.703460
[0m08:21:46.703908 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m08:21:46.707163 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m08:21:46.708122 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m08:21:46.708399 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where SECURITY_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:21:46.708628 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:21:47.408306 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:21:47.410508 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (execute): 2025-11-26 08:21:45.901339 => 2025-11-26 08:21:47.410427
[0m08:21:47.410801 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: Close
[0m08:21:48.375443 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:21:48.377751 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (execute): 2025-11-26 08:21:46.704130 => 2025-11-26 08:21:48.377666
[0m08:21:48.378081 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: Close
[0m08:21:48.458961 [info ] [Thread-1 (]: 3 of 17 PASS is_positive_fact_flights_NAS_DELAY ................................ [[32mPASS[0m in 2.56s]
[0m08:21:48.459509 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m08:21:48.459905 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m08:21:48.460257 [info ] [Thread-1 (]: 5 of 17 START test is_positive_fact_flights_TAXI_IN_TIME ....................... [RUN]
[0m08:21:48.461025 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c'
[0m08:21:48.461312 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m08:21:48.466831 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m08:21:48.467422 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (compile): 2025-11-26 08:21:48.461604 => 2025-11-26 08:21:48.467333
[0m08:21:48.467751 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m08:21:48.471316 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m08:21:48.472331 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m08:21:48.472632 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_IN_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:21:48.472866 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:21:49.660198 [info ] [Thread-2 (]: 4 of 17 PASS is_positive_fact_flights_SECURITY_DELAY ........................... [[32mPASS[0m in 2.96s]
[0m08:21:49.661039 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m08:21:49.661581 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m08:21:49.661959 [info ] [Thread-2 (]: 6 of 17 START test is_positive_fact_flights_TAXI_OUT_TIME ...................... [RUN]
[0m08:21:49.662937 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da'
[0m08:21:49.663262 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m08:21:49.668856 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m08:21:49.669418 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (compile): 2025-11-26 08:21:49.663474 => 2025-11-26 08:21:49.669337
[0m08:21:49.669719 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m08:21:49.672724 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m08:21:49.673622 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m08:21:49.673885 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_OUT_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:21:49.674106 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:21:49.913912 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:21:49.918681 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (execute): 2025-11-26 08:21:48.467979 => 2025-11-26 08:21:49.918565
[0m08:21:49.919101 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: Close
[0m08:21:50.678070 [info ] [Thread-1 (]: 5 of 17 PASS is_positive_fact_flights_TAXI_IN_TIME ............................. [[32mPASS[0m in 2.22s]
[0m08:21:50.678868 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m08:21:50.679434 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m08:21:50.680140 [info ] [Thread-1 (]: 7 of 17 START test is_positive_fact_flights_WEATHER_DELAY ...................... [RUN]
[0m08:21:50.684042 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474'
[0m08:21:50.685362 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m08:21:50.691749 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m08:21:50.693072 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (compile): 2025-11-26 08:21:50.685698 => 2025-11-26 08:21:50.692952
[0m08:21:50.693546 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m08:21:50.696957 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m08:21:50.697969 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m08:21:50.698256 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where WEATHER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:21:50.698476 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:21:51.457289 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:21:51.461027 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (execute): 2025-11-26 08:21:49.669911 => 2025-11-26 08:21:51.460894
[0m08:21:51.461468 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: Close
[0m08:21:52.106256 [info ] [Thread-2 (]: 6 of 17 PASS is_positive_fact_flights_TAXI_OUT_TIME ............................ [[32mPASS[0m in 2.44s]
[0m08:21:52.107102 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m08:21:52.107694 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m08:21:52.108097 [info ] [Thread-2 (]: 8 of 17 START test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:21:52.109054 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9'
[0m08:21:52.109379 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m08:21:52.123522 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m08:21:52.124158 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (compile): 2025-11-26 08:21:52.109598 => 2025-11-26 08:21:52.124069
[0m08:21:52.124489 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m08:21:52.127215 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m08:21:52.128471 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m08:21:52.128741 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:21:52.128970 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:21:52.430814 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:21:52.434857 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (execute): 2025-11-26 08:21:50.693807 => 2025-11-26 08:21:52.434739
[0m08:21:52.435257 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: Close
[0m08:21:52.874894 [info ] [Thread-1 (]: 7 of 17 PASS is_positive_fact_flights_WEATHER_DELAY ............................ [[32mPASS[0m in 2.19s]
[0m08:21:52.875600 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m08:21:52.876091 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m08:21:52.876403 [info ] [Thread-1 (]: 9 of 17 START test relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:21:52.877289 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079'
[0m08:21:52.877598 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m08:21:52.886656 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m08:21:52.887247 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (compile): 2025-11-26 08:21:52.877925 => 2025-11-26 08:21:52.887163
[0m08:21:52.887565 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m08:21:52.890271 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m08:21:52.891535 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m08:21:52.891802 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:21:52.892039 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:21:53.873227 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:21:53.877494 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (execute): 2025-11-26 08:21:52.124709 => 2025-11-26 08:21:53.877369
[0m08:21:53.877953 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: Close
[0m08:21:53.885217 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:21:53.888491 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (execute): 2025-11-26 08:21:52.887763 => 2025-11-26 08:21:53.888386
[0m08:21:53.888878 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: Close
[0m08:21:54.297326 [info ] [Thread-1 (]: 9 of 17 PASS relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.42s]
[0m08:21:54.298222 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m08:21:54.298807 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m08:21:54.299206 [info ] [Thread-1 (]: 10 of 17 START test relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:21:54.300193 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608'
[0m08:21:54.300562 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m08:21:54.310986 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m08:21:54.312609 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (compile): 2025-11-26 08:21:54.301038 => 2025-11-26 08:21:54.312490
[0m08:21:54.313027 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m08:21:54.316049 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m08:21:54.318701 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m08:21:54.319054 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:21:54.319304 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:21:54.772247 [info ] [Thread-2 (]: 8 of 17 PASS relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 2.66s]
[0m08:21:54.772776 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m08:21:54.773148 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m08:21:54.773504 [info ] [Thread-2 (]: 11 of 17 START test relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:21:54.774227 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932'
[0m08:21:54.774479 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m08:21:54.782808 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m08:21:54.783518 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (compile): 2025-11-26 08:21:54.774697 => 2025-11-26 08:21:54.783414
[0m08:21:54.783858 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m08:21:54.787366 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m08:21:54.788911 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m08:21:54.789256 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:21:54.789526 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:21:55.546318 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:21:55.549381 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (execute): 2025-11-26 08:21:54.313255 => 2025-11-26 08:21:55.549268
[0m08:21:55.549791 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: Close
[0m08:21:55.797674 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:21:55.800733 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (execute): 2025-11-26 08:21:54.784069 => 2025-11-26 08:21:55.800627
[0m08:21:55.801131 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: Close
[0m08:21:56.033040 [info ] [Thread-1 (]: 10 of 17 PASS relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.73s]
[0m08:21:56.033896 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m08:21:56.034481 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m08:21:56.034869 [info ] [Thread-1 (]: 12 of 17 START test relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:21:56.035842 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5'
[0m08:21:56.036184 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m08:21:56.045250 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m08:21:56.045817 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (compile): 2025-11-26 08:21:56.036406 => 2025-11-26 08:21:56.045734
[0m08:21:56.046147 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m08:21:56.048889 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m08:21:56.050217 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m08:21:56.050480 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_Off_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_Off_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:21:56.050696 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:21:56.522906 [info ] [Thread-2 (]: 11 of 17 PASS relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.75s]
[0m08:21:56.523676 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m08:21:56.524224 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m08:21:56.524578 [info ] [Thread-2 (]: 13 of 17 START test relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:21:56.525488 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850'
[0m08:21:56.525817 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m08:21:56.534614 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m08:21:56.535201 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (compile): 2025-11-26 08:21:56.526029 => 2025-11-26 08:21:56.535106
[0m08:21:56.535531 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m08:21:56.538204 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m08:21:56.539456 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m08:21:56.539740 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_On_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_On_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:21:56.539965 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:21:57.776686 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:21:57.781070 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (execute): 2025-11-26 08:21:56.046347 => 2025-11-26 08:21:57.780952
[0m08:21:57.781497 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: Close
[0m08:21:58.755187 [info ] [Thread-1 (]: 12 of 17 PASS relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 2.72s]
[0m08:21:58.756064 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m08:21:58.756677 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m08:21:58.757066 [info ] [Thread-1 (]: 14 of 17 START test relationships_fact_flights_date_id__date_id__ref_dim_date_ . [RUN]
[0m08:21:58.758098 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9'
[0m08:21:58.758643 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m08:21:58.769049 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m08:21:58.769765 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (compile): 2025-11-26 08:21:58.758909 => 2025-11-26 08:21:58.769657
[0m08:21:58.770198 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m08:21:58.773583 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m08:21:58.775013 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m08:21:58.775333 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select date_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where date_id is not null
),

parent as (
    select date_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:21:58.775577 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:22:01.137182 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:22:01.140440 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (execute): 2025-11-26 08:21:58.770447 => 2025-11-26 08:22:01.140315
[0m08:22:01.140867 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: Close
[0m08:22:01.669540 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 5 seconds
[0m08:22:01.674019 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (execute): 2025-11-26 08:21:56.535731 => 2025-11-26 08:22:01.673869
[0m08:22:01.674563 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: Close
[0m08:22:02.098761 [info ] [Thread-1 (]: 14 of 17 PASS relationships_fact_flights_date_id__date_id__ref_dim_date_ ....... [[32mPASS[0m in 3.34s]
[0m08:22:02.099429 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m08:22:02.099904 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m08:22:02.100254 [info ] [Thread-1 (]: 15 of 17 START test relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [RUN]
[0m08:22:02.101134 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5'
[0m08:22:02.101478 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m08:22:02.110442 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m08:22:02.111018 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (compile): 2025-11-26 08:22:02.101817 => 2025-11-26 08:22:02.110921
[0m08:22:02.111346 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m08:22:02.114048 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m08:22:02.115340 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m08:22:02.115610 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select destination_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where destination_id is not null
),

parent as (
    select destination_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:22:02.115820 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:22:02.478532 [info ] [Thread-2 (]: 13 of 17 PASS relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 5.95s]
[0m08:22:02.479348 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m08:22:02.479901 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m08:22:02.480305 [info ] [Thread-2 (]: 16 of 17 START test relationships_fact_flights_origin_id__origin_id__ref_dim_origin_  [RUN]
[0m08:22:02.481368 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24'
[0m08:22:02.481774 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m08:22:02.491278 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m08:22:02.491911 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (compile): 2025-11-26 08:22:02.482027 => 2025-11-26 08:22:02.491821
[0m08:22:02.492285 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m08:22:02.495074 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m08:22:02.496353 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m08:22:02.496627 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select origin_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where origin_id is not null
),

parent as (
    select origin_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:22:02.496849 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:22:04.709612 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m08:22:04.713577 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (execute): 2025-11-26 08:22:02.111552 => 2025-11-26 08:22:04.713460
[0m08:22:04.714010 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: Close
[0m08:22:06.125502 [info ] [Thread-1 (]: 15 of 17 PASS relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [[32mPASS[0m in 4.02s]
[0m08:22:06.126213 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m08:22:06.126716 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m08:22:06.127143 [info ] [Thread-1 (]: 17 of 17 START test relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [RUN]
[0m08:22:06.128018 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa'
[0m08:22:06.128325 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m08:22:06.137499 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m08:22:06.138083 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (compile): 2025-11-26 08:22:06.128519 => 2025-11-26 08:22:06.137999
[0m08:22:06.138392 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m08:22:06.141176 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m08:22:06.142419 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m08:22:06.142694 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select status_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where status_id is not null
),

parent as (
    select status_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:22:06.142911 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:22:07.204350 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 5 seconds
[0m08:22:07.208767 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (execute): 2025-11-26 08:22:02.492498 => 2025-11-26 08:22:07.208638
[0m08:22:07.209214 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: Close
[0m08:22:07.828226 [info ] [Thread-2 (]: 16 of 17 PASS relationships_fact_flights_origin_id__origin_id__ref_dim_origin_ . [[32mPASS[0m in 5.35s]
[0m08:22:07.829423 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m08:22:11.848446 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 6 seconds
[0m08:22:11.851735 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (execute): 2025-11-26 08:22:06.138586 => 2025-11-26 08:22:11.851622
[0m08:22:11.852413 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: Close
[0m08:22:12.542526 [info ] [Thread-1 (]: 17 of 17 PASS relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [[32mPASS[0m in 6.41s]
[0m08:22:12.543325 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m08:22:12.545993 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:22:12.546828 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:22:12.547142 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa' was properly closed.
[0m08:22:12.547378 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24' was properly closed.
[0m08:22:12.547669 [info ] [MainThread]: 
[0m08:22:12.548040 [info ] [MainThread]: Finished running 17 tests in 0 hours 0 minutes and 31.61 seconds (31.61s).
[0m08:22:12.549096 [debug] [MainThread]: Command end result
[0m08:22:12.560222 [info ] [MainThread]: 
[0m08:22:12.560713 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:22:12.561062 [info ] [MainThread]: 
[0m08:22:12.561352 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=0 SKIP=0 TOTAL=17
[0m08:22:12.561769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13268d89b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13264569c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1326456ab0>]}
[0m08:22:12.562118 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 08:22:48.046375 | 041b6c33-e51c-49ab-8812-e90c04a9972d ==============================
[0m08:22:48.046375 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:22:48.054649 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'source-freshness', 'rpc_method': 'source-freshness', 'indirect_selection': 'eager'}
[0m08:22:48.055972 [debug] [MainThread]: Tracking: tracking
[0m08:22:48.057203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17ef7f3a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17efeb37a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1805fc07d0>]}
[0m08:22:48.214879 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:22:48.216091 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:22:48.250413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '041b6c33-e51c-49ab-8812-e90c04a9972d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17ef4556d0>]}
[0m08:22:48.297259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '041b6c33-e51c-49ab-8812-e90c04a9972d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17ef32b2c0>]}
[0m08:22:48.299196 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:22:48.300504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '041b6c33-e51c-49ab-8812-e90c04a9972d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17f4824290>]}
[0m08:22:48.309207 [info ] [MainThread]: 
[0m08:22:48.319744 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:22:48.325322 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:22:48.335282 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:22:48.431272 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:22:48.432636 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:22:48.433525 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:22:48.434465 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:22:48.435194 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:22:48.435918 [debug] [ThreadPool]: Opening a new connection, currently in state init


============================== 2025-11-26 08:22:49.891630 | 7796853a-3355-49db-ae78-f7a1aa4e6eda ==============================
[0m08:22:49.891630 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:22:49.898784 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'source-freshness', 'rpc_method': 'source-freshness', 'indirect_selection': 'eager'}
[0m08:22:49.899653 [debug] [MainThread]: Tracking: tracking
[0m08:22:49.900688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43e1de6ab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43ccc12ab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43ee5bf4a0>]}
[0m08:22:49.943052 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m08:22:49.948169 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:22:49.981756 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:22:49.982537 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:22:49.993866 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m08:22:49.999111 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:22:50.000104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7796853a-3355-49db-ae78-f7a1aa4e6eda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43ccaa44a0>]}
[0m08:22:50.027225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7796853a-3355-49db-ae78-f7a1aa4e6eda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43cc8dadb0>]}
[0m08:22:50.028531 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:22:50.029847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7796853a-3355-49db-ae78-f7a1aa4e6eda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43ee5bf590>]}
[0m08:22:50.036291 [info ] [MainThread]: 
[0m08:22:50.043558 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:22:50.047810 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:22:50.055756 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:22:50.122987 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:22:50.132315 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:22:50.133038 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:22:50.133735 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:22:50.134394 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:22:50.134944 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:22:50.657005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '041b6c33-e51c-49ab-8812-e90c04a9972d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17ef32ae10>]}
[0m08:22:50.659649 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:22:50.660951 [info ] [MainThread]: 
[0m08:22:50.750347 [debug] [Thread-1 (]: Began running node source.airflow_dbt_project.raw_data.flights
[0m08:22:50.751500 [info ] [Thread-1 (]: 1 of 1 START freshness of raw_data.flights ..................................... [RUN]
[0m08:22:50.753913 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m08:22:50.754910 [debug] [Thread-1 (]: Began compiling node source.airflow_dbt_project.raw_data.flights
[0m08:22:50.755814 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (compile): 2025-11-26 08:22:50.755589 => 2025-11-26 08:22:50.755615
[0m08:22:50.756538 [debug] [Thread-1 (]: Began executing node source.airflow_dbt_project.raw_data.flights
[0m08:22:50.758667 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m08:22:50.797499 [debug] [Thread-1 (]: Using snowflake connection "source.airflow_dbt_project.raw_data.flights"
[0m08:22:50.798520 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "source.airflow_dbt_project.raw_data.flights"} */
select
      max(INGESTION_TIME) as max_loaded_at,
      convert_timezone('UTC', current_timestamp()) as snapshotted_at
    from GP.RAW.flights
[0m08:22:50.799205 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:22:52.714149 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m08:22:52.719558 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:22:52.802113 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:22:52.805835 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: Close
[0m08:22:53.665887 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (execute): 2025-11-26 08:22:50.757072 => 2025-11-26 08:22:53.665583
[0m08:22:53.670847 [warn ] [Thread-1 (]: 1 of 1 WARN freshness of raw_data.flights ...................................... [[33mWARN[0m in 2.92s]
[0m08:22:53.680004 [debug] [Thread-1 (]: Finished running node source.airflow_dbt_project.raw_data.flights
[0m08:22:53.686827 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:22:53.688165 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m08:22:53.689275 [debug] [MainThread]: Connection 'source.airflow_dbt_project.raw_data.flights' was properly closed.
[0m08:22:53.706205 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 4 seconds
[0m08:22:53.713609 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:22:53.724417 [info ] [MainThread]: Done.
[0m08:22:53.726035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17f4824290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17f511ac90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f17ef7f3b60>]}
[0m08:22:53.727084 [debug] [MainThread]: Flushing usage events
[0m08:22:54.936879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7796853a-3355-49db-ae78-f7a1aa4e6eda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43cc8da930>]}
[0m08:22:54.938965 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:22:54.939686 [info ] [MainThread]: 
[0m08:22:55.001290 [debug] [Thread-1 (]: Began running node source.airflow_dbt_project.raw_data.flights
[0m08:22:55.002210 [info ] [Thread-1 (]: 1 of 1 START freshness of raw_data.flights ..................................... [RUN]
[0m08:22:55.004490 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m08:22:55.005518 [debug] [Thread-1 (]: Began compiling node source.airflow_dbt_project.raw_data.flights
[0m08:22:55.006392 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (compile): 2025-11-26 08:22:55.006187 => 2025-11-26 08:22:55.006208
[0m08:22:55.007127 [debug] [Thread-1 (]: Began executing node source.airflow_dbt_project.raw_data.flights
[0m08:22:55.008812 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m08:22:55.039189 [debug] [Thread-1 (]: Using snowflake connection "source.airflow_dbt_project.raw_data.flights"
[0m08:22:55.040109 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "source.airflow_dbt_project.raw_data.flights"} */
select
      max(INGESTION_TIME) as max_loaded_at,
      convert_timezone('UTC', current_timestamp()) as snapshotted_at
    from GP.RAW.flights
[0m08:22:55.040673 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:22:56.082678 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:22:56.090737 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: Close
[0m08:22:56.708476 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (execute): 2025-11-26 08:22:55.007580 => 2025-11-26 08:22:56.708186
[0m08:22:56.713565 [warn ] [Thread-1 (]: 1 of 1 WARN freshness of raw_data.flights ...................................... [[33mWARN[0m in 1.71s]
[0m08:22:56.723073 [debug] [Thread-1 (]: Finished running node source.airflow_dbt_project.raw_data.flights
[0m08:22:56.728794 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:22:56.729802 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m08:22:56.730503 [debug] [MainThread]: Connection 'source.airflow_dbt_project.raw_data.flights' was properly closed.
[0m08:22:56.764850 [info ] [MainThread]: Done.
[0m08:22:56.766869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43e1d66ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43cc7014f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43cc7012e0>]}
[0m08:22:56.768534 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 08:23:14.116157 | 4ca09372-3e86-4adb-89d2-20c4a68c4632 ==============================
[0m08:23:14.116157 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:23:14.121990 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['staging.*'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:23:14.122855 [debug] [MainThread]: Tracking: tracking
[0m08:23:14.123902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f813d0745f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8159d28380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f813cbd0050>]}
[0m08:23:14.216514 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:23:14.217239 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:23:14.236715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4ca09372-3e86-4adb-89d2-20c4a68c4632', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815e7998b0>]}
[0m08:23:14.261663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4ca09372-3e86-4adb-89d2-20c4a68c4632', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f813caaea80>]}
[0m08:23:14.262710 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:23:14.263679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4ca09372-3e86-4adb-89d2-20c4a68c4632', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f813cf82900>]}
[0m08:23:14.268289 [info ] [MainThread]: 
[0m08:23:14.274116 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:23:14.278636 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m08:23:14.352354 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m08:23:14.353750 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m08:23:14.355011 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:23:16.686265 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m08:23:16.691078 [debug] [ThreadPool]: On list_GP: Close
[0m08:23:17.389651 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:23:17.392065 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:23:17.393223 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging', identifier=None)"
[0m08:23:17.413648 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:23:17.414730 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:23:17.415546 [debug] [ThreadPool]: Opening a new connection, currently in state closed


============================== 2025-11-26 08:23:17.465584 | cccc7ab8-78ce-4b52-b504-1474e73e251d ==============================
[0m08:23:17.465584 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:23:17.477110 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['staging.*'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:23:17.478338 [debug] [MainThread]: Tracking: tracking
[0m08:23:17.479687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa009894950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0098948f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa009894890>]}
[0m08:23:17.655053 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:23:17.656451 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:23:17.694320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cccc7ab8-78ce-4b52-b504-1474e73e251d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa009d80e30>]}
[0m08:23:17.738303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cccc7ab8-78ce-4b52-b504-1474e73e251d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa00acc8fe0>]}
[0m08:23:17.740171 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:23:17.741779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cccc7ab8-78ce-4b52-b504-1474e73e251d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa00981a930>]}
[0m08:23:17.750668 [info ] [MainThread]: 
[0m08:23:17.762369 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:23:17.768188 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m08:23:17.842846 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m08:23:17.844003 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m08:23:17.844780 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:23:19.812027 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m08:23:19.819921 [debug] [ThreadPool]: On list_GP: Close
[0m08:23:20.998533 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:23:21.000956 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:23:21.002125 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging', identifier=None)"
[0m08:23:21.013319 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 4 seconds
[0m08:23:21.018643 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:23:21.025387 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:23:21.026533 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:23:21.027448 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:23:21.655722 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:23:21.665419 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:23:21.684560 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:23:21.691710 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:23:21.693870 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:23:21.694831 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:23:21.695683 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:23:21.699966 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:23:23.236737 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m08:23:23.244436 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:23:23.246403 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m08:23:23.256006 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:23:23.897994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4ca09372-3e86-4adb-89d2-20c4a68c4632', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f813cd75040>]}
[0m08:23:23.900825 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:23:23.902021 [info ] [MainThread]: 
[0m08:23:23.986383 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_flight_status
[0m08:23:23.988519 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [RUN]
[0m08:23:23.994772 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_flight_status'
[0m08:23:23.996338 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_flight_status
[0m08:23:24.051372 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_flight_status"
[0m08:23:24.053396 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (compile): 2025-11-26 08:23:23.997026 => 2025-11-26 08:23:24.053098
[0m08:23:24.054437 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_flight_status
[0m08:23:24.183727 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_flight_status"
[0m08:23:24.194451 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_flight_status"
[0m08:23:24.195477 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_flight_status"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
  
   as (
    select 
    DATE_FROM_PARTS(year, month, day_of_month) AS flight_date,
    
    lower(op_unique_carrier)
 as Airline_Code,
    op_carrier_fl_num::INT as Flight_Number,
    
    lower(origin)
 as Origin_Airport_Code,
    
    lower(origin_city_name)
 as Origin_City,
    
    lower(origin_state_nm)
 as Origin_State,
    
    lower(dest)
 as Destination_Airport_Code,
    
    lower(dest_city_name)
 as Destination_City,
    
    lower(dest_state_nm)
 as Destination_State,
    crs_dep_time::INT as Scheduled_Departure_Time,
    dep_time::INT as Actual_Departure_Time,
    dep_delay::INT as Departure_Delay,
    taxi_out::INT as Taxi_Out_Time,
    wheels_off::INT as Wheels_Off_Time,
    wheels_on::INT as Wheels_On_Time,
    taxi_in::INT as Taxi_In_Time,
    crs_arr_time::INT as Scheduled_Arrival_Time,
    arr_time::INT as Actual_Arrival_Time,
    arr_delay::INT as Arrival_Delay,
    CASE cancelled WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_cancelled,
    CASE cancellation_code WHEN 'A' THEN 'Carrier'  WHEN 'B' THEN 'Weather'  WHEN 'C' THEN 'National Air System'  WHEN 'D' THEN 'Security'  ELSE 'still available' END as Cancellation_Reason,
    CASE diverted WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_diverted,
    crs_elapsed_time::INT as Scheduled_Flight_Duration,
    actual_elapsed_time::INT as Actual_Flight_Duration,
    air_time,
    distance,
    carrier_delay,
    weather_delay,
    nas_delay,
    security_delay,
    late_aircraft_delay,
    isDelete,
    CASE operation WHEN 'c' THEN 'Create'  WHEN 'u' THEN 'Update'  WHEN 'd' THEN 'Delete'  WHEN 'r' THEN 'Snapshot'  ELSE 'Unknown' END as operation_type,
    TO_TIMESTAMP_LTZ(event_time / 1000) as event_time,
    ingestion_time  as ingestion_datetime
from GP.RAW.flights
  );
[0m08:23:24.196309 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:23:29.415487 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 5 seconds
[0m08:23:29.486771 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (execute): 2025-11-26 08:23:24.055079 => 2025-11-26 08:23:29.486542
[0m08:23:29.487862 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: Close
[0m08:23:29.910718 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4ca09372-3e86-4adb-89d2-20c4a68c4632', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f813c9a9850>]}
[0m08:23:29.913361 [info ] [Thread-1 (]: 1 of 1 OK created sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [[32mSUCCESS 1[0m in 5.92s]
[0m08:23:29.921147 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_flight_status
[0m08:23:29.927136 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:23:29.929377 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:23:29.930258 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_flight_status' was properly closed.
[0m08:23:29.931563 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m08:23:29.932499 [info ] [MainThread]: 
[0m08:23:29.933578 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 15.66 seconds (15.66s).
[0m08:23:29.935039 [debug] [MainThread]: Command end result
[0m08:23:29.965182 [info ] [MainThread]: 
[0m08:23:29.966583 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:23:29.967755 [info ] [MainThread]: 
[0m08:23:29.969140 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:23:29.971487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f813c9f8e30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8137f926c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f813cd75040>]}
[0m08:23:29.973286 [debug] [MainThread]: Flushing usage events
[0m08:23:36.830485 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 16 seconds
[0m08:23:36.834499 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:23:37.288657 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:23:37.302684 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:23:37.342151 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:23:37.349651 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:23:37.353181 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:23:37.354501 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:23:37.356290 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:23:37.364897 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:23:38.368529 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m08:23:38.377661 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:23:38.421957 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m08:23:38.431308 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:23:39.458132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cccc7ab8-78ce-4b52-b504-1474e73e251d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa00b066ab0>]}
[0m08:23:39.462141 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:23:39.464350 [info ] [MainThread]: 
[0m08:23:39.543969 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_flight_status
[0m08:23:39.545604 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [RUN]
[0m08:23:39.550283 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_flight_status'
[0m08:23:39.551514 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_flight_status
[0m08:23:39.593281 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_flight_status"
[0m08:23:39.596184 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (compile): 2025-11-26 08:23:39.552258 => 2025-11-26 08:23:39.595563
[0m08:23:39.598159 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_flight_status
[0m08:23:39.710615 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_flight_status"
[0m08:23:39.717119 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_flight_status"
[0m08:23:39.717891 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_flight_status"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
  
   as (
    select 
    DATE_FROM_PARTS(year, month, day_of_month) AS flight_date,
    
    lower(op_unique_carrier)
 as Airline_Code,
    op_carrier_fl_num::INT as Flight_Number,
    
    lower(origin)
 as Origin_Airport_Code,
    
    lower(origin_city_name)
 as Origin_City,
    
    lower(origin_state_nm)
 as Origin_State,
    
    lower(dest)
 as Destination_Airport_Code,
    
    lower(dest_city_name)
 as Destination_City,
    
    lower(dest_state_nm)
 as Destination_State,
    crs_dep_time::INT as Scheduled_Departure_Time,
    dep_time::INT as Actual_Departure_Time,
    dep_delay::INT as Departure_Delay,
    taxi_out::INT as Taxi_Out_Time,
    wheels_off::INT as Wheels_Off_Time,
    wheels_on::INT as Wheels_On_Time,
    taxi_in::INT as Taxi_In_Time,
    crs_arr_time::INT as Scheduled_Arrival_Time,
    arr_time::INT as Actual_Arrival_Time,
    arr_delay::INT as Arrival_Delay,
    CASE cancelled WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_cancelled,
    CASE cancellation_code WHEN 'A' THEN 'Carrier'  WHEN 'B' THEN 'Weather'  WHEN 'C' THEN 'National Air System'  WHEN 'D' THEN 'Security'  ELSE 'still available' END as Cancellation_Reason,
    CASE diverted WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_diverted,
    crs_elapsed_time::INT as Scheduled_Flight_Duration,
    actual_elapsed_time::INT as Actual_Flight_Duration,
    air_time,
    distance,
    carrier_delay,
    weather_delay,
    nas_delay,
    security_delay,
    late_aircraft_delay,
    isDelete,
    CASE operation WHEN 'c' THEN 'Create'  WHEN 'u' THEN 'Update'  WHEN 'd' THEN 'Delete'  WHEN 'r' THEN 'Snapshot'  ELSE 'Unknown' END as operation_type,
    TO_TIMESTAMP_LTZ(event_time / 1000) as event_time,
    ingestion_time  as ingestion_datetime
from GP.RAW.flights
  );
[0m08:23:39.718502 [debug] [Thread-1 (]: Opening a new connection, currently in state closed


============================== 2025-11-26 08:23:47.172750 | 04cd1a57-7300-4d65-9d4e-ff4027ec8da1 ==============================
[0m08:23:47.172750 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:23:47.177212 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_destination'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:23:47.177834 [debug] [MainThread]: Tracking: tracking
[0m08:23:47.178488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd43ca53530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd43c4687a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd43c4e8680>]}
[0m08:23:47.256435 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:23:47.257070 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:23:47.280446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04cd1a57-7300-4d65-9d4e-ff4027ec8da1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd43c4c5430>]}
[0m08:23:47.310087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04cd1a57-7300-4d65-9d4e-ff4027ec8da1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd450f8cc50>]}
[0m08:23:47.311373 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:23:47.312573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04cd1a57-7300-4d65-9d4e-ff4027ec8da1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd43c4687a0>]}
[0m08:23:47.317769 [info ] [MainThread]: 
[0m08:23:47.326127 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:23:47.329745 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m08:23:47.386136 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m08:23:47.387210 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m08:23:47.388001 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:23:47.929757 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 8 seconds
[0m08:23:48.009121 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (execute): 2025-11-26 08:23:39.598922 => 2025-11-26 08:23:48.008851
[0m08:23:48.010340 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: Close
[0m08:23:48.970740 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m08:23:48.974647 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cccc7ab8-78ce-4b52-b504-1474e73e251d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa008be7f20>]}
[0m08:23:48.976352 [debug] [ThreadPool]: On list_GP: Close
[0m08:23:48.976677 [info ] [Thread-1 (]: 1 of 1 OK created sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [[32mSUCCESS 1[0m in 9.43s]
[0m08:23:48.983793 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_flight_status
[0m08:23:48.988441 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:23:48.989973 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:23:48.990511 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_flight_status' was properly closed.
[0m08:23:48.990893 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m08:23:48.991414 [info ] [MainThread]: 
[0m08:23:48.992126 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 31.24 seconds (31.24s).
[0m08:23:48.992865 [debug] [MainThread]: Command end result
[0m08:23:49.013742 [info ] [MainThread]: 
[0m08:23:49.015130 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:23:49.016609 [info ] [MainThread]: 
[0m08:23:49.017390 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:23:49.018600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa008ced2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0099a1b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa00974af60>]}
[0m08:23:49.019658 [debug] [MainThread]: Flushing usage events
[0m08:23:50.387243 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:23:50.390471 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:23:50.392177 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m08:23:50.417872 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:23:50.419014 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:23:50.420144 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:23:53.735768 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 3 seconds
[0m08:23:53.746276 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:23:54.740062 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:23:54.765074 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:23:54.780319 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:23:54.786944 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:23:54.793371 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:23:54.795738 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:23:54.802501 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:23:54.804043 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:23:56.752689 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m08:23:56.762138 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:23:56.905469 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m08:23:56.913827 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:24:00.067487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04cd1a57-7300-4d65-9d4e-ff4027ec8da1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4646a0a40>]}
[0m08:24:00.070518 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:24:00.074117 [info ] [MainThread]: 
[0m08:24:00.195216 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_destination
[0m08:24:00.198775 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [RUN]
[0m08:24:00.204252 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_destination'
[0m08:24:00.205521 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_destination
[0m08:24:00.227371 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_destination"
[0m08:24:00.229315 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (compile): 2025-11-26 08:24:00.206228 => 2025-11-26 08:24:00.229000
[0m08:24:00.233091 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_destination
[0m08:24:00.493391 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_destination"
[0m08:24:00.495614 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m08:24:00.496236 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  as
        (


with distinct_values as(
    select
    distinct destination_city as city,destination_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as destination_id,
    city,
    state
    from distinct_values


        );
[0m08:24:00.496641 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:24:06.705318 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 6 seconds
[0m08:24:06.746009 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m08:24:06.747318 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination__dbt_tmp cascade


============================== 2025-11-26 08:24:07.424274 | c094335d-b08b-4bd6-acb6-0ba87eeac93b ==============================
[0m08:24:07.424274 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:24:07.431020 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_origin'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:24:07.431960 [debug] [MainThread]: Tracking: tracking
[0m08:24:07.432981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e52dc8260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e52dc82f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e52dc8290>]}
[0m08:24:07.489254 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:24:07.517896 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:24:07.519026 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:24:07.539629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c094335d-b08b-4bd6-acb6-0ba87eeac93b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e53a466f0>]}
[0m08:24:07.549749 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (execute): 2025-11-26 08:24:00.234062 => 2025-11-26 08:24:07.549569
[0m08:24:07.550483 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: Close
[0m08:24:07.563291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c094335d-b08b-4bd6-acb6-0ba87eeac93b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e52c76900>]}
[0m08:24:07.564297 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:24:07.565040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c094335d-b08b-4bd6-acb6-0ba87eeac93b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e530e7500>]}
[0m08:24:07.571690 [info ] [MainThread]: 
[0m08:24:07.579541 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:24:07.583847 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m08:24:07.646803 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m08:24:07.648128 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m08:24:07.649100 [debug] [ThreadPool]: Opening a new connection, currently in state init


============================== 2025-11-26 08:24:08.236433 | 0ef2f98f-328c-4061-a258-4748cd5a1c19 ==============================
[0m08:24:08.236433 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:24:08.243798 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_flight_status'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:24:08.244581 [debug] [MainThread]: Tracking: tracking
[0m08:24:08.245410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f032ca30710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f032ca307a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f032ca30770>]}
[0m08:24:08.259673 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04cd1a57-7300-4d65-9d4e-ff4027ec8da1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd43c2c3b90>]}
[0m08:24:08.261401 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [[32mSUCCESS 1[0m in 8.06s]
[0m08:24:08.268600 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_destination
[0m08:24:08.275552 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:24:08.278209 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:24:08.279113 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m08:24:08.280088 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_destination' was properly closed.
[0m08:24:08.281203 [info ] [MainThread]: 
[0m08:24:08.282178 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 20.96 seconds (20.96s).
[0m08:24:08.283544 [debug] [MainThread]: Command end result
[0m08:24:08.330332 [info ] [MainThread]: 
[0m08:24:08.332745 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:24:08.334363 [info ] [MainThread]: 
[0m08:24:08.336001 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:24:08.338019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd43c29f3b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd450fa8290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd43c2ab920>]}
[0m08:24:08.339626 [debug] [MainThread]: Flushing usage events
[0m08:24:08.382408 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:24:08.383729 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:24:08.419425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0ef2f98f-328c-4061-a258-4748cd5a1c19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f032d168da0>]}
[0m08:24:08.473326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0ef2f98f-328c-4061-a258-4748cd5a1c19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f032ceaf6e0>]}
[0m08:24:08.476032 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:24:08.477888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0ef2f98f-328c-4061-a258-4748cd5a1c19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f033974da00>]}
[0m08:24:08.486549 [info ] [MainThread]: 
[0m08:24:08.498014 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:24:08.504341 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m08:24:08.581986 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m08:24:08.583134 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m08:24:08.584051 [debug] [ThreadPool]: Opening a new connection, currently in state init


============================== 2025-11-26 08:24:08.613202 | fed15aab-1a42-476e-8c76-162e8e5af8cb ==============================
[0m08:24:08.613202 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:24:08.624056 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_destination'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:24:08.625673 [debug] [MainThread]: Tracking: tracking
[0m08:24:08.627287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ec9ed88f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ec9ed89e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ec9ed8980>]}
[0m08:24:08.770178 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:24:08.771512 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:24:08.812993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fed15aab-1a42-476e-8c76-162e8e5af8cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ef1213620>]}
[0m08:24:08.859724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fed15aab-1a42-476e-8c76-162e8e5af8cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ecb32ee70>]}
[0m08:24:08.861685 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:24:08.863618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fed15aab-1a42-476e-8c76-162e8e5af8cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ef12f46e0>]}
[0m08:24:08.873250 [info ] [MainThread]: 
[0m08:24:08.884997 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:24:08.891661 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m08:24:08.985822 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m08:24:08.986967 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m08:24:08.987763 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:24:10.523232 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 3 seconds
[0m08:24:10.532463 [debug] [ThreadPool]: On list_GP: Close
[0m08:24:10.534067 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m08:24:10.538743 [debug] [ThreadPool]: On list_GP: Close
[0m08:24:11.371773 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m08:24:11.382023 [debug] [ThreadPool]: On list_GP: Close
[0m08:24:11.743496 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:11.746459 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:11.747901 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m08:24:11.775835 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:24:11.777338 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:24:11.778578 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:24:11.859289 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:11.861749 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:11.862949 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m08:24:11.883592 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:24:11.884665 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:24:11.885470 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:24:12.874593 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m08:24:12.878605 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:24:12.878800 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m08:24:12.882819 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:24:13.315749 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:24:13.316696 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:24:13.327860 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:13.335385 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:13.358077 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:24:13.365788 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:24:13.368708 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:24:13.370014 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:24:13.371367 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:24:13.373902 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:24:13.373012 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:24:13.375712 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:24:13.377385 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:24:13.376860 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:24:13.378118 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:24:13.379151 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:24:13.430723 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:13.433184 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:13.434322 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m08:24:13.450497 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:24:13.453188 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:24:13.453906 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:24:14.477042 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m08:24:14.484717 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:24:14.484348 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m08:24:14.494195 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:24:14.727170 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m08:24:14.732596 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:24:14.991650 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m08:24:15.003866 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:24:15.161288 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m08:24:15.170115 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:24:15.186293 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:24:15.197385 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:15.273729 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:24:15.283457 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:24:15.284688 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:24:15.286431 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:24:15.288162 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:24:15.289549 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:24:15.390610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fed15aab-1a42-476e-8c76-162e8e5af8cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ef2028bf0>]}
[0m08:24:15.393846 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:24:15.395362 [info ] [MainThread]: 
[0m08:24:15.469559 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_destination
[0m08:24:15.471620 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [RUN]
[0m08:24:15.477058 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_destination'
[0m08:24:15.478317 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_destination
[0m08:24:15.492318 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_destination"
[0m08:24:15.493776 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (compile): 2025-11-26 08:24:15.479192 => 2025-11-26 08:24:15.493537
[0m08:24:15.494673 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_destination
[0m08:24:15.663167 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_destination"
[0m08:24:15.665473 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m08:24:15.666096 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  as
        (


with distinct_values as(
    select
    distinct destination_city as city,destination_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as destination_id,
    city,
    state
    from distinct_values


        );
[0m08:24:15.666515 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:24:15.778712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c094335d-b08b-4bd6-acb6-0ba87eeac93b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e52c75ee0>]}
[0m08:24:15.781021 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:24:15.782148 [info ] [MainThread]: 
[0m08:24:15.836044 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_origin
[0m08:24:15.837266 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [RUN]
[0m08:24:15.840174 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_origin'
[0m08:24:15.840909 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_origin
[0m08:24:15.852622 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_origin"
[0m08:24:15.854122 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (compile): 2025-11-26 08:24:15.841363 => 2025-11-26 08:24:15.853827
[0m08:24:15.854884 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_origin
[0m08:24:16.015320 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_origin"
[0m08:24:16.017872 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m08:24:16.018530 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  as
        (


with distinct_values as(
    select
    distinct origin_city as city,origin_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as origin_id,
    city,
    state
    from distinct_values


        );
[0m08:24:16.019051 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:24:16.505590 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m08:24:16.512279 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:24:17.464624 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:24:17.516067 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m08:24:17.517325 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination__dbt_tmp cascade
[0m08:24:17.563698 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:24:17.600918 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m08:24:17.602225 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin__dbt_tmp cascade
[0m08:24:17.737498 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m08:24:17.817127 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m08:24:17.856841 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (execute): 2025-11-26 08:24:15.495224 => 2025-11-26 08:24:17.856573
[0m08:24:17.858068 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: Close
[0m08:24:17.915966 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (execute): 2025-11-26 08:24:15.855397 => 2025-11-26 08:24:17.915574
[0m08:24:17.917473 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: Close
[0m08:24:18.338902 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c094335d-b08b-4bd6-acb6-0ba87eeac93b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e5221a210>]}
[0m08:24:18.340718 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [[32mSUCCESS 1[0m in 2.50s]
[0m08:24:18.349596 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_origin
[0m08:24:18.351225 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fed15aab-1a42-476e-8c76-162e8e5af8cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ec9cd8740>]}
[0m08:24:18.353702 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [[32mSUCCESS 1[0m in 2.88s]
[0m08:24:18.356580 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:24:18.359705 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:24:18.360678 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m08:24:18.361456 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_origin' was properly closed.
[0m08:24:18.362254 [info ] [MainThread]: 
[0m08:24:18.363206 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 10.79 seconds (10.79s).
[0m08:24:18.363412 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_destination
[0m08:24:18.364501 [debug] [MainThread]: Command end result
[0m08:24:18.370627 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:24:18.374347 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:24:18.375590 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m08:24:18.376743 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_destination' was properly closed.
[0m08:24:18.378068 [info ] [MainThread]: 
[0m08:24:18.379675 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 9.50 seconds (9.50s).
[0m08:24:18.381685 [debug] [MainThread]: Command end result
[0m08:24:18.396412 [info ] [MainThread]: 
[0m08:24:18.398326 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:24:18.399344 [info ] [MainThread]: 
[0m08:24:18.400442 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:24:18.401896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e52098dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e52bc8b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e52bc8aa0>]}
[0m08:24:18.403520 [debug] [MainThread]: Flushing usage events
[0m08:24:18.415365 [info ] [MainThread]: 
[0m08:24:18.416891 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:24:18.418014 [info ] [MainThread]: 
[0m08:24:18.419365 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:24:18.420743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ec9b92a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ef2028bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ec9ccee70>]}
[0m08:24:18.422049 [debug] [MainThread]: Flushing usage events
[0m08:24:18.518816 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m08:24:18.523723 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:24:18.967684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0ef2f98f-328c-4061-a258-4748cd5a1c19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0354cd72c0>]}
[0m08:24:18.970201 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:24:18.971406 [info ] [MainThread]: 
[0m08:24:19.039731 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_flight_status
[0m08:24:19.040861 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [RUN]
[0m08:24:19.042781 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_flight_status'
[0m08:24:19.043571 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_flight_status
[0m08:24:19.054138 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_flight_status"
[0m08:24:19.055552 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (compile): 2025-11-26 08:24:19.044036 => 2025-11-26 08:24:19.055345
[0m08:24:19.056251 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_flight_status
[0m08:24:19.256728 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_flight_status"
[0m08:24:19.260973 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m08:24:19.261940 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  as
        (
with distinct_values as(
    select distinct CANCELLATION_REASON,is_cancelled,is_diverted
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select 
row_number() over(order by is_cancelled) as status_id,
CANCELLATION_REASON,
is_cancelled,
is_diverted
from distinct_values
        );
[0m08:24:19.262760 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:24:21.086962 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:24:21.129224 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m08:24:21.130276 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status__dbt_tmp cascade
[0m08:24:22.334910 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:24:22.419529 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (execute): 2025-11-26 08:24:19.056799 => 2025-11-26 08:24:22.419270
[0m08:24:22.420609 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: Close
[0m08:24:22.760894 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ef2f98f-328c-4061-a258-4748cd5a1c19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f032c831610>]}
[0m08:24:22.767214 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [[32mSUCCESS 1[0m in 3.72s]
[0m08:24:22.781538 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_flight_status
[0m08:24:22.790784 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:24:22.797033 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:24:22.799614 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m08:24:22.805161 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_flight_status' was properly closed.
[0m08:24:22.807595 [info ] [MainThread]: 
[0m08:24:22.811155 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 14.32 seconds (14.32s).
[0m08:24:22.813156 [debug] [MainThread]: Command end result
[0m08:24:22.836700 [info ] [MainThread]: 
[0m08:24:22.837819 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:24:22.838737 [info ] [MainThread]: 
[0m08:24:22.839659 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:24:22.840835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f032c5406b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f032cbad9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f032c8e6b70>]}
[0m08:24:22.841734 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 08:24:26.051616 | 4e1e6ece-3133-4107-8345-2a30113cfbbe ==============================
[0m08:24:26.051616 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:24:26.057212 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_origin'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:24:26.057892 [debug] [MainThread]: Tracking: tracking
[0m08:24:26.058831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb3e7647d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb3e765ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb4d533890>]}
[0m08:24:26.157504 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:24:26.158287 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:24:26.181419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4e1e6ece-3133-4107-8345-2a30113cfbbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb69985850>]}
[0m08:24:26.209987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4e1e6ece-3133-4107-8345-2a30113cfbbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb3f3bec00>]}
[0m08:24:26.211275 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:24:26.212214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e1e6ece-3133-4107-8345-2a30113cfbbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb3eca85f0>]}
[0m08:24:26.216468 [info ] [MainThread]: 
[0m08:24:26.222674 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:24:26.226550 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m08:24:26.288011 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m08:24:26.288809 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m08:24:26.289365 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:24:27.876966 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m08:24:27.881425 [debug] [ThreadPool]: On list_GP: Close
[0m08:24:28.224774 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:28.226278 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:28.226911 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m08:24:28.244904 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:24:28.245641 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:24:28.246153 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:24:29.099396 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m08:24:29.102368 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:24:29.478367 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:24:29.488579 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:29.568694 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:24:29.570007 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:24:29.573469 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:24:29.574590 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:24:29.575829 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:24:29.581489 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:24:33.420804 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 4 seconds
[0m08:24:33.425655 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:24:33.436541 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 4 seconds
[0m08:24:33.443306 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:24:34.427010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e1e6ece-3133-4107-8345-2a30113cfbbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb3f1fdeb0>]}
[0m08:24:34.428943 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:24:34.429835 [info ] [MainThread]: 
[0m08:24:34.488826 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_origin
[0m08:24:34.489885 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [RUN]
[0m08:24:34.491772 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_origin'
[0m08:24:34.492455 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_origin
[0m08:24:34.506778 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_origin"
[0m08:24:34.508396 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (compile): 2025-11-26 08:24:34.492838 => 2025-11-26 08:24:34.508120
[0m08:24:34.509763 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_origin
[0m08:24:34.694480 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_origin"
[0m08:24:34.696788 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m08:24:34.697477 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  as
        (


with distinct_values as(
    select
    distinct origin_city as city,origin_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as origin_id,
    city,
    state
    from distinct_values


        );
[0m08:24:34.698014 [debug] [Thread-1 (]: Opening a new connection, currently in state closed


============================== 2025-11-26 08:24:36.155863 | 025e073e-bb9f-42fe-81cf-3aaa1db20c16 ==============================
[0m08:24:36.155863 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:24:36.167512 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_flight_status'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:24:36.168522 [debug] [MainThread]: Tracking: tracking
[0m08:24:36.169470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a1e174590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a1cd78b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a1cd78a70>]}
[0m08:24:36.258475 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:24:36.293093 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m08:24:36.294620 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin__dbt_tmp cascade
[0m08:24:36.343060 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:24:36.344410 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:24:36.377362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '025e073e-bb9f-42fe-81cf-3aaa1db20c16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a27b38f50>]}
[0m08:24:36.421144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '025e073e-bb9f-42fe-81cf-3aaa1db20c16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a1e16d010>]}
[0m08:24:36.423002 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:24:36.424346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '025e073e-bb9f-42fe-81cf-3aaa1db20c16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a1d7e1790>]}
[0m08:24:36.430688 [info ] [MainThread]: 
[0m08:24:36.440684 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:24:36.445361 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m08:24:36.486446 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m08:24:36.533798 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m08:24:36.535297 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m08:24:36.536581 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:24:36.597701 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (execute): 2025-11-26 08:24:34.510274 => 2025-11-26 08:24:36.597369
[0m08:24:36.599297 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: Close
[0m08:24:37.659625 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e1e6ece-3133-4107-8345-2a30113cfbbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb3dba6f60>]}
[0m08:24:37.661079 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [[32mSUCCESS 1[0m in 3.17s]
[0m08:24:37.665365 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_origin
[0m08:24:37.670249 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:24:37.672642 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:24:37.673536 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m08:24:37.674194 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_origin' was properly closed.
[0m08:24:37.674806 [info ] [MainThread]: 
[0m08:24:37.676060 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 11.46 seconds (11.46s).
[0m08:24:37.676973 [debug] [MainThread]: Command end result
[0m08:24:37.694666 [info ] [MainThread]: 
[0m08:24:37.695608 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:24:37.696303 [info ] [MainThread]: 
[0m08:24:37.696875 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:24:37.697658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb3e69ab70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb6a787bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb6991cec0>]}
[0m08:24:37.698340 [debug] [MainThread]: Flushing usage events
[0m08:24:37.748140 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m08:24:37.753146 [debug] [ThreadPool]: On list_GP: Close
[0m08:24:38.100128 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:38.101855 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:38.102628 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m08:24:38.117903 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:24:38.118715 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:24:38.119327 [debug] [ThreadPool]: Opening a new connection, currently in state closed


============================== 2025-11-26 08:24:40.253589 | d1c14807-410d-4b6c-8fb6-01bbf7ad1bec ==============================
[0m08:24:40.253589 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:24:40.257295 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['fact_flights'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:24:40.257695 [debug] [MainThread]: Tracking: tracking
[0m08:24:40.258150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f461158ee40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4611a7a9c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f461c333bf0>]}
[0m08:24:40.345756 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:24:40.346536 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:24:40.364788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd1c14807-410d-4b6c-8fb6-01bbf7ad1bec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f461158f650>]}
[0m08:24:40.387485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd1c14807-410d-4b6c-8fb6-01bbf7ad1bec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4611a75880>]}
[0m08:24:40.388644 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:24:40.389420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd1c14807-410d-4b6c-8fb6-01bbf7ad1bec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46116344a0>]}
[0m08:24:40.393148 [info ] [MainThread]: 
[0m08:24:40.397763 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:24:40.400580 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m08:24:40.436660 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m08:24:40.437327 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m08:24:40.437751 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:24:41.589996 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 3 seconds
[0m08:24:41.594469 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:24:42.004720 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m08:24:42.011478 [debug] [ThreadPool]: On list_GP: Close
[0m08:24:42.307060 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:24:42.329296 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:42.366276 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:24:42.369377 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:24:42.370489 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:24:42.371450 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:24:42.372216 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:24:42.372841 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:24:42.849094 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:42.850293 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:42.850907 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m08:24:42.862394 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:24:42.863017 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:24:42.863409 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:24:44.264274 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m08:24:44.268173 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:24:44.418341 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m08:24:44.422245 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:24:45.047669 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:24:45.073199 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:24:45.098724 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:24:45.105231 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:24:45.112094 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:24:45.115211 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:24:45.123208 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:24:45.124901 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:24:45.429527 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 3 seconds
[0m08:24:45.433162 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:24:46.038115 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m08:24:46.041576 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:24:46.096261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '025e073e-bb9f-42fe-81cf-3aaa1db20c16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a1ca52b70>]}
[0m08:24:46.098537 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:24:46.099457 [info ] [MainThread]: 
[0m08:24:46.149734 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_flight_status
[0m08:24:46.150580 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [RUN]
[0m08:24:46.153486 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_flight_status'
[0m08:24:46.154095 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_flight_status
[0m08:24:46.163540 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_flight_status"
[0m08:24:46.165166 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (compile): 2025-11-26 08:24:46.155815 => 2025-11-26 08:24:46.164798
[0m08:24:46.165873 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_flight_status
[0m08:24:46.316008 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_flight_status"
[0m08:24:46.318105 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m08:24:46.318642 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  as
        (
with distinct_values as(
    select distinct CANCELLATION_REASON,is_cancelled,is_diverted
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select 
row_number() over(order by is_cancelled) as status_id,
CANCELLATION_REASON,
is_cancelled,
is_diverted
from distinct_values
        );
[0m08:24:46.319022 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:24:47.387395 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m08:24:47.397206 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:24:48.023616 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:24:48.068412 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m08:24:48.069766 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status__dbt_tmp cascade
[0m08:24:48.290526 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m08:24:48.444486 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (execute): 2025-11-26 08:24:46.166303 => 2025-11-26 08:24:48.444180
[0m08:24:48.445999 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: Close
[0m08:24:48.603645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd1c14807-410d-4b6c-8fb6-01bbf7ad1bec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46119caab0>]}
[0m08:24:48.605225 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:24:48.605985 [info ] [MainThread]: 
[0m08:24:48.658809 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.fact_flights
[0m08:24:48.660121 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [RUN]
[0m08:24:48.662876 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.fact_flights'
[0m08:24:48.663677 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.fact_flights
[0m08:24:48.675675 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.fact_flights"
[0m08:24:48.677063 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (compile): 2025-11-26 08:24:48.664168 => 2025-11-26 08:24:48.676809
[0m08:24:48.677753 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.fact_flights
[0m08:24:48.789635 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '025e073e-bb9f-42fe-81cf-3aaa1db20c16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a1c238860>]}
[0m08:24:48.790688 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [[32mSUCCESS 1[0m in 2.64s]
[0m08:24:48.795274 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_flight_status
[0m08:24:48.799402 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:24:48.800690 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:24:48.801158 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_flight_status' was properly closed.
[0m08:24:48.801482 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m08:24:48.801885 [info ] [MainThread]: 
[0m08:24:48.802471 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 12.37 seconds (12.37s).
[0m08:24:48.803390 [debug] [MainThread]: Command end result
[0m08:24:48.818248 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.fact_flights"
[0m08:24:48.821773 [info ] [MainThread]: 
[0m08:24:48.822568 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:24:48.823102 [info ] [MainThread]: 
[0m08:24:48.823154 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m08:24:48.823564 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:24:48.823690 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  as
        (
select
d_date.date_id as date_id,
sdt.time_id as Scheduled_Departure_Time_id,
adt.time_id as Actual_Departure_Time_id,
wot.time_id as Wheels_Off_Time_id,
wot2.time_id as Wheels_On_Time_id,
sat.time_id as Scheduled_Arrival_Time_id,
aat.time_id as Actual_Arrival_Time_id,
origin.origin_id as origin_id,
dest.destination_id as destination_id, 
fl_stat.status_id as status_id,
AIRLINE_CODE,
FLIGHT_NUMBER,
Departure_Delay,
Taxi_Out_Time,
Taxi_In_Time,
Arrival_Delay,
Scheduled_Flight_Duration,
Actual_Flight_Duration,
Air_Time,
Distance,
Carrier_Delay,
Weather_Delay,
NAS_Delay,
Security_Delay,
Late_Aircraft_Delay
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status as stg 
left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date as d_date
on stg.flight_date=d_date.date_day

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sdt
on stg.Scheduled_Departure_Time=sdt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as adt 
on stg.Actual_Departure_Time=adt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot
on stg.Wheels_Off_Time=wot.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot2 
on stg.Wheels_On_Time=wot2.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sat
on stg.Scheduled_Arrival_Time=sat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as aat
on stg.Actual_Arrival_Time=aat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin as origin
on origin.city=stg.origin_city and origin.state=stg.origin_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination as dest
on dest.city=stg.destination_city and dest.state=stg.destination_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status as fl_stat 
on stg.IS_CANCELLED=fl_stat.IS_CANCELLED and stg.IS_DIVERTED=fl_stat.IS_DIVERTED
        );
[0m08:24:48.824103 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:24:48.824314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a1e5c4800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a452cccb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a1cf1d010>]}
[0m08:24:48.824808 [debug] [MainThread]: Flushing usage events
[0m08:24:50.660986 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:24:50.677265 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m08:24:50.677782 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights__dbt_tmp cascade
[0m08:24:50.889038 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m08:24:50.939448 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (execute): 2025-11-26 08:24:48.678139 => 2025-11-26 08:24:50.939259
[0m08:24:50.940401 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: Close
[0m08:24:51.810788 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1c14807-410d-4b6c-8fb6-01bbf7ad1bec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f461088dfa0>]}
[0m08:24:51.812000 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [[32mSUCCESS 1[0m in 3.15s]
[0m08:24:51.816485 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.fact_flights
[0m08:24:51.820679 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:24:51.822148 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:24:51.822674 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m08:24:51.823072 [debug] [MainThread]: Connection 'model.airflow_dbt_project.fact_flights' was properly closed.
[0m08:24:51.823522 [info ] [MainThread]: 
[0m08:24:51.824164 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 11.43 seconds (11.43s).
[0m08:24:51.825239 [debug] [MainThread]: Command end result
[0m08:24:51.844785 [info ] [MainThread]: 
[0m08:24:51.845769 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:24:51.846496 [info ] [MainThread]: 
[0m08:24:51.847107 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:24:51.847889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46241cb440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46112cd1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f461170e930>]}
[0m08:24:51.848546 [debug] [MainThread]: Flushing usage events
[0m08:24:52.839092 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m08:24:55.864601 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.


============================== 2025-11-26 08:25:10.086189 | a499b323-3f90-4b7b-9f28-a55ab8d3cdab ==============================
[0m08:25:10.086189 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:25:10.093832 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['fact_flights'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:25:10.094838 [debug] [MainThread]: Tracking: tracking
[0m08:25:10.095888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc830f9c8f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc830f9c890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc830f9ca70>]}
[0m08:25:10.281139 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:25:10.282427 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:25:10.320416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a499b323-3f90-4b7b-9f28-a55ab8d3cdab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8316fe870>]}
[0m08:25:10.365029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a499b323-3f90-4b7b-9f28-a55ab8d3cdab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc832d76ae0>]}
[0m08:25:10.367071 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:25:10.368742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a499b323-3f90-4b7b-9f28-a55ab8d3cdab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8312fa240>]}
[0m08:25:10.375611 [info ] [MainThread]: 
[0m08:25:10.384217 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:25:10.388780 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m08:25:10.460234 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m08:25:10.461452 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m08:25:10.462638 [debug] [ThreadPool]: Opening a new connection, currently in state init


============================== 2025-11-26 08:25:13.826270 | c2ee4940-de6c-407e-bd79-df73c8e276fb ==============================
[0m08:25:13.826270 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:25:13.830058 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m08:25:13.830701 [debug] [MainThread]: Tracking: tracking
[0m08:25:13.831381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab27aaed20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab27f72c60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab27f73d10>]}
[0m08:25:13.902850 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:25:13.903566 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:25:13.921712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c2ee4940-de6c-407e-bd79-df73c8e276fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab2c6f6a50>]}
[0m08:25:13.941514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c2ee4940-de6c-407e-bd79-df73c8e276fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab2778a9f0>]}
[0m08:25:13.942398 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:25:13.943293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c2ee4940-de6c-407e-bd79-df73c8e276fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab27f5c590>]}
[0m08:25:13.948544 [info ] [MainThread]: 
[0m08:25:13.954126 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:25:13.958974 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:25:13.972517 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:25:14.023150 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:25:14.029137 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:25:14.029843 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:25:14.030591 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:25:14.031462 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:25:14.037622 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:25:16.605322 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m08:25:16.610331 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:25:19.967239 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 6 seconds
[0m08:25:19.972599 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:25:21.202562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c2ee4940-de6c-407e-bd79-df73c8e276fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab2778a7b0>]}
[0m08:25:21.205869 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:25:21.207250 [info ] [MainThread]: 
[0m08:25:21.303394 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m08:25:21.305468 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m08:25:21.309435 [info ] [Thread-1 (]: 1 of 17 START test is_positive_fact_flights_CARRIER_DELAY ...................... [RUN]
[0m08:25:21.311230 [info ] [Thread-2 (]: 2 of 17 START test is_positive_fact_flights_LATE_AIRCRAFT_DELAY ................ [RUN]
[0m08:25:21.315399 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec'
[0m08:25:21.319280 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa'
[0m08:25:21.321296 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m08:25:21.323196 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m08:25:21.414233 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m08:25:21.419202 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m08:25:21.421801 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (compile): 2025-11-26 08:25:21.324499 => 2025-11-26 08:25:21.421449
[0m08:25:21.422870 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (compile): 2025-11-26 08:25:21.335404 => 2025-11-26 08:25:21.422620
[0m08:25:21.424009 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m08:25:21.425099 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m08:25:21.567766 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m08:25:21.576352 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m08:25:21.579214 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m08:25:21.580289 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where CARRIER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:25:21.581112 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:21.582811 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m08:25:21.586834 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where LATE_AIRCRAFT_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:25:21.587512 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:25:23.025746 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:23.034193 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:23.085309 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (execute): 2025-11-26 08:25:21.437576 => 2025-11-26 08:25:23.085022
[0m08:25:23.091813 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: Close
[0m08:25:23.092905 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (execute): 2025-11-26 08:25:21.426001 => 2025-11-26 08:25:23.091233
[0m08:25:23.099401 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: Close
[0m08:25:23.649251 [info ] [Thread-1 (]: 1 of 17 PASS is_positive_fact_flights_CARRIER_DELAY ............................ [[32mPASS[0m in 2.34s]
[0m08:25:23.662391 [info ] [Thread-2 (]: 2 of 17 PASS is_positive_fact_flights_LATE_AIRCRAFT_DELAY ...................... [[32mPASS[0m in 2.35s]
[0m08:25:23.664752 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m08:25:23.666316 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m08:25:23.668105 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m08:25:23.669970 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m08:25:23.672093 [info ] [Thread-1 (]: 3 of 17 START test is_positive_fact_flights_NAS_DELAY .......................... [RUN]
[0m08:25:23.674035 [info ] [Thread-2 (]: 4 of 17 START test is_positive_fact_flights_SECURITY_DELAY ..................... [RUN]
[0m08:25:23.677759 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3'
[0m08:25:23.680107 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384'
[0m08:25:23.681215 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m08:25:23.682144 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m08:25:23.709170 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m08:25:23.713147 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m08:25:23.715055 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (compile): 2025-11-26 08:25:23.685056 => 2025-11-26 08:25:23.714746
[0m08:25:23.716038 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (compile): 2025-11-26 08:25:23.682863 => 2025-11-26 08:25:23.715830
[0m08:25:23.716893 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m08:25:23.717813 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m08:25:23.727275 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m08:25:23.738280 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m08:25:23.741434 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m08:25:23.743816 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m08:25:23.744793 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where NAS_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:25:23.746273 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where SECURITY_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:25:23.747271 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:23.748074 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:25:25.226669 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:25.231281 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (execute): 2025-11-26 08:25:23.718461 => 2025-11-26 08:25:25.231107
[0m08:25:25.231907 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: Close
[0m08:25:25.671790 [info ] [Thread-2 (]: 4 of 17 PASS is_positive_fact_flights_SECURITY_DELAY ........................... [[32mPASS[0m in 1.99s]
[0m08:25:25.672982 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m08:25:25.673816 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m08:25:25.674461 [info ] [Thread-2 (]: 5 of 17 START test is_positive_fact_flights_TAXI_IN_TIME ....................... [RUN]
[0m08:25:25.676742 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c'
[0m08:25:25.677663 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m08:25:25.687845 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m08:25:25.689080 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (compile): 2025-11-26 08:25:25.678131 => 2025-11-26 08:25:25.688875
[0m08:25:25.689796 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m08:25:25.698880 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m08:25:25.701015 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m08:25:25.701612 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_IN_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:25:25.702020 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:25:25.744373 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 15 seconds
[0m08:25:25.748297 [debug] [ThreadPool]: On list_GP: Close
[0m08:25:25.812238 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:25:25.817075 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (execute): 2025-11-26 08:25:23.728326 => 2025-11-26 08:25:25.816924
[0m08:25:25.817629 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: Close
[0m08:25:26.649586 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:25:26.651981 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:25:26.653097 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m08:25:26.673221 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:25:26.674327 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:25:26.675156 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:25:26.695775 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:26.703673 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (execute): 2025-11-26 08:25:25.690799 => 2025-11-26 08:25:26.703360
[0m08:25:26.704725 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: Close
[0m08:25:26.737308 [info ] [Thread-1 (]: 3 of 17 PASS is_positive_fact_flights_NAS_DELAY ................................ [[32mPASS[0m in 3.06s]
[0m08:25:26.739256 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m08:25:26.740520 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m08:25:26.741985 [info ] [Thread-1 (]: 6 of 17 START test is_positive_fact_flights_TAXI_OUT_TIME ...................... [RUN]
[0m08:25:26.745136 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da'
[0m08:25:26.746135 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m08:25:26.760178 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m08:25:26.761750 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (compile): 2025-11-26 08:25:26.746744 => 2025-11-26 08:25:26.761521
[0m08:25:26.762674 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m08:25:26.771978 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m08:25:26.774666 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m08:25:26.775459 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_OUT_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:25:26.776080 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:27.113792 [info ] [Thread-2 (]: 5 of 17 PASS is_positive_fact_flights_TAXI_IN_TIME ............................. [[32mPASS[0m in 1.44s]
[0m08:25:27.115694 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m08:25:27.117043 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m08:25:27.117988 [info ] [Thread-2 (]: 7 of 17 START test is_positive_fact_flights_WEATHER_DELAY ...................... [RUN]
[0m08:25:27.120383 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474'
[0m08:25:27.121367 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m08:25:27.137091 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m08:25:27.138886 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (compile): 2025-11-26 08:25:27.121977 => 2025-11-26 08:25:27.138628
[0m08:25:27.139855 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m08:25:27.148800 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m08:25:27.151549 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m08:25:27.152512 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where WEATHER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:25:27.153191 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:25:27.502117 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:27.505661 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:25:27.849293 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:25:27.860715 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:25:27.882846 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:25:27.887310 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:25:27.888612 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:25:27.889895 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:25:27.891048 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:25:27.892180 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:25:28.038416 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:28.043000 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (execute): 2025-11-26 08:25:27.140443 => 2025-11-26 08:25:28.042807
[0m08:25:28.043653 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: Close
[0m08:25:28.513254 [info ] [Thread-2 (]: 7 of 17 PASS is_positive_fact_flights_WEATHER_DELAY ............................ [[32mPASS[0m in 1.39s]
[0m08:25:28.513995 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m08:25:28.514597 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m08:25:28.514970 [info ] [Thread-2 (]: 8 of 17 START test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:25:28.515897 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9'
[0m08:25:28.516516 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m08:25:28.530240 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m08:25:28.530850 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (compile): 2025-11-26 08:25:28.516875 => 2025-11-26 08:25:28.530765
[0m08:25:28.531227 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m08:25:28.534125 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m08:25:28.535486 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m08:25:28.535781 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:25:28.536023 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:25:28.843587 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m08:25:28.847031 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:25:29.841386 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m08:25:29.846770 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:25:29.888380 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m08:25:29.893172 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (execute): 2025-11-26 08:25:26.763293 => 2025-11-26 08:25:29.892992
[0m08:25:29.893873 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: Close
[0m08:25:30.765917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a499b323-3f90-4b7b-9f28-a55ab8d3cdab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc858b671a0>]}
[0m08:25:30.767292 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:25:30.767788 [info ] [MainThread]: 
[0m08:25:30.803548 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.fact_flights
[0m08:25:30.804290 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [RUN]
[0m08:25:30.806268 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.fact_flights'
[0m08:25:30.806777 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.fact_flights
[0m08:25:30.814869 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.fact_flights"
[0m08:25:30.815648 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (compile): 2025-11-26 08:25:30.807114 => 2025-11-26 08:25:30.815534
[0m08:25:30.816065 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.fact_flights
[0m08:25:30.844790 [info ] [Thread-1 (]: 6 of 17 PASS is_positive_fact_flights_TAXI_OUT_TIME ............................ [[32mPASS[0m in 4.10s]
[0m08:25:30.845428 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m08:25:30.845904 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m08:25:30.846250 [info ] [Thread-1 (]: 9 of 17 START test relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:25:30.847266 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079'
[0m08:25:30.847590 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m08:25:30.857317 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m08:25:30.858045 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (compile): 2025-11-26 08:25:30.847806 => 2025-11-26 08:25:30.857937
[0m08:25:30.858435 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m08:25:30.861541 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m08:25:30.863008 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m08:25:30.863323 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:25:30.863580 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:30.901275 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.fact_flights"
[0m08:25:30.904045 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m08:25:30.904317 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  as
        (
select
d_date.date_id as date_id,
sdt.time_id as Scheduled_Departure_Time_id,
adt.time_id as Actual_Departure_Time_id,
wot.time_id as Wheels_Off_Time_id,
wot2.time_id as Wheels_On_Time_id,
sat.time_id as Scheduled_Arrival_Time_id,
aat.time_id as Actual_Arrival_Time_id,
origin.origin_id as origin_id,
dest.destination_id as destination_id, 
fl_stat.status_id as status_id,
AIRLINE_CODE,
FLIGHT_NUMBER,
Departure_Delay,
Taxi_Out_Time,
Taxi_In_Time,
Arrival_Delay,
Scheduled_Flight_Duration,
Actual_Flight_Duration,
Air_Time,
Distance,
Carrier_Delay,
Weather_Delay,
NAS_Delay,
Security_Delay,
Late_Aircraft_Delay
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status as stg 
left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date as d_date
on stg.flight_date=d_date.date_day

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sdt
on stg.Scheduled_Departure_Time=sdt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as adt 
on stg.Actual_Departure_Time=adt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot
on stg.Wheels_Off_Time=wot.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot2 
on stg.Wheels_On_Time=wot2.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sat
on stg.Scheduled_Arrival_Time=sat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as aat
on stg.Actual_Arrival_Time=aat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin as origin
on origin.city=stg.origin_city and origin.state=stg.origin_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination as dest
on dest.city=stg.destination_city and dest.state=stg.destination_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status as fl_stat 
on stg.IS_CANCELLED=fl_stat.IS_CANCELLED and stg.IS_DIVERTED=fl_stat.IS_DIVERTED
        );
[0m08:25:30.904523 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:31.013302 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:25:31.017316 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (execute): 2025-11-26 08:25:28.531495 => 2025-11-26 08:25:31.017191
[0m08:25:31.017766 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: Close
[0m08:25:31.957782 [info ] [Thread-2 (]: 8 of 17 PASS relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 3.44s]
[0m08:25:31.958696 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m08:25:31.959301 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m08:25:31.959669 [info ] [Thread-2 (]: 10 of 17 START test relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:25:31.960630 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608'
[0m08:25:31.960981 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m08:25:31.970774 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m08:25:31.971406 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (compile): 2025-11-26 08:25:31.961212 => 2025-11-26 08:25:31.971316
[0m08:25:31.971752 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m08:25:31.974569 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m08:25:31.975898 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m08:25:31.976225 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:25:31.976458 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:25:32.702618 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:25:32.716801 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m08:25:32.717181 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights__dbt_tmp cascade
[0m08:25:32.815874 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:25:32.818416 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (execute): 2025-11-26 08:25:30.858674 => 2025-11-26 08:25:32.818315
[0m08:25:32.818736 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: Close
[0m08:25:33.331544 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:33.372437 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (execute): 2025-11-26 08:25:30.816313 => 2025-11-26 08:25:33.372309
[0m08:25:33.372969 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: Close
[0m08:25:34.111445 [info ] [Thread-1 (]: 9 of 17 PASS relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 3.26s]
[0m08:25:34.111965 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m08:25:34.112321 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m08:25:34.112664 [info ] [Thread-1 (]: 11 of 17 START test relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:25:34.113367 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932'
[0m08:25:34.113618 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m08:25:34.121648 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m08:25:34.122289 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (compile): 2025-11-26 08:25:34.113786 => 2025-11-26 08:25:34.122174
[0m08:25:34.122631 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m08:25:34.125369 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m08:25:34.126761 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m08:25:34.127084 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:25:34.127331 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:34.255728 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:25:34.259061 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (execute): 2025-11-26 08:25:31.971977 => 2025-11-26 08:25:34.258939
[0m08:25:34.259507 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: Close
[0m08:25:34.636426 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a499b323-3f90-4b7b-9f28-a55ab8d3cdab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc830d2a630>]}
[0m08:25:34.637153 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [[32mSUCCESS 1[0m in 3.83s]
[0m08:25:34.639628 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.fact_flights
[0m08:25:34.642441 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:25:34.643304 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:25:34.643606 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m08:25:34.643845 [debug] [MainThread]: Connection 'model.airflow_dbt_project.fact_flights' was properly closed.
[0m08:25:34.644167 [info ] [MainThread]: 
[0m08:25:34.644533 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 24.27 seconds (24.27s).
[0m08:25:34.645010 [debug] [MainThread]: Command end result
[0m08:25:34.656015 [info ] [MainThread]: 
[0m08:25:34.656536 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:25:34.656897 [info ] [MainThread]: 
[0m08:25:34.657237 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:25:34.657682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc831518e60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8302f87d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc831361880>]}
[0m08:25:34.658058 [debug] [MainThread]: Flushing usage events
[0m08:25:35.860097 [info ] [Thread-2 (]: 10 of 17 PASS relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 3.90s]
[0m08:25:35.860876 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m08:25:35.861332 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m08:25:35.861645 [info ] [Thread-2 (]: 12 of 17 START test relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:25:35.862438 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5'
[0m08:25:35.862772 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m08:25:35.874101 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m08:25:35.874884 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (compile): 2025-11-26 08:25:35.863094 => 2025-11-26 08:25:35.874742
[0m08:25:35.875501 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m08:25:35.878697 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m08:25:35.881009 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m08:25:35.881461 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_Off_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_Off_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:25:35.881780 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:25:36.168423 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:25:36.172208 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (execute): 2025-11-26 08:25:34.122831 => 2025-11-26 08:25:36.172069
[0m08:25:36.172727 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: Close
[0m08:25:36.642000 [info ] [Thread-1 (]: 11 of 17 PASS relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 2.53s]
[0m08:25:36.642490 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m08:25:36.642838 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m08:25:36.643086 [info ] [Thread-1 (]: 13 of 17 START test relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:25:36.643767 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850'
[0m08:25:36.644026 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m08:25:36.652098 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m08:25:36.652684 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (compile): 2025-11-26 08:25:36.644190 => 2025-11-26 08:25:36.652597
[0m08:25:36.653027 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m08:25:36.655812 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m08:25:36.657135 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m08:25:36.657419 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_On_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_On_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:25:36.657657 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:37.775723 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:37.779135 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (execute): 2025-11-26 08:25:36.653247 => 2025-11-26 08:25:37.779015
[0m08:25:37.779595 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: Close
[0m08:25:37.804207 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:25:37.807712 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (execute): 2025-11-26 08:25:35.875761 => 2025-11-26 08:25:37.807589
[0m08:25:37.808205 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: Close
[0m08:25:38.386260 [info ] [Thread-1 (]: 13 of 17 PASS relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.74s]
[0m08:25:38.386778 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m08:25:38.387170 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m08:25:38.387427 [info ] [Thread-1 (]: 14 of 17 START test relationships_fact_flights_date_id__date_id__ref_dim_date_ . [RUN]
[0m08:25:38.388125 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9'
[0m08:25:38.388386 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m08:25:38.397119 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m08:25:38.397865 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (compile): 2025-11-26 08:25:38.388564 => 2025-11-26 08:25:38.397757
[0m08:25:38.398282 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m08:25:38.401426 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m08:25:38.403249 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m08:25:38.403761 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select date_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where date_id is not null
),

parent as (
    select date_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:25:38.404174 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:39.191442 [info ] [Thread-2 (]: 12 of 17 PASS relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 3.33s]
[0m08:25:39.191951 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m08:25:39.192291 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m08:25:39.192534 [info ] [Thread-2 (]: 15 of 17 START test relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [RUN]
[0m08:25:39.193322 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5'
[0m08:25:39.193576 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m08:25:39.201652 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m08:25:39.202274 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (compile): 2025-11-26 08:25:39.193748 => 2025-11-26 08:25:39.202185
[0m08:25:39.202603 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m08:25:39.205425 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m08:25:39.206783 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m08:25:39.207085 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select destination_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where destination_id is not null
),

parent as (
    select destination_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:25:39.207326 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:25:39.688500 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:39.691580 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (execute): 2025-11-26 08:25:38.398520 => 2025-11-26 08:25:39.691476
[0m08:25:39.691982 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: Close
[0m08:25:40.350738 [info ] [Thread-1 (]: 14 of 17 PASS relationships_fact_flights_date_id__date_id__ref_dim_date_ ....... [[32mPASS[0m in 1.96s]
[0m08:25:40.351321 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m08:25:40.351740 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m08:25:40.352153 [info ] [Thread-1 (]: 16 of 17 START test relationships_fact_flights_origin_id__origin_id__ref_dim_origin_  [RUN]
[0m08:25:40.352993 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24'
[0m08:25:40.353300 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m08:25:40.362941 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m08:25:40.363808 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (compile): 2025-11-26 08:25:40.353507 => 2025-11-26 08:25:40.363674
[0m08:25:40.364269 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m08:25:40.367959 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m08:25:40.369628 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m08:25:40.370012 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select origin_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where origin_id is not null
),

parent as (
    select origin_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:25:40.370307 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:41.915897 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:25:41.918733 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (execute): 2025-11-26 08:25:40.364537 => 2025-11-26 08:25:41.918628
[0m08:25:41.919164 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: Close
[0m08:25:41.977642 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 3 seconds
[0m08:25:41.981712 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (execute): 2025-11-26 08:25:39.202811 => 2025-11-26 08:25:41.981569
[0m08:25:41.982263 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: Close


============================== 2025-11-26 08:25:42.688195 | 3b27e358-8272-4e38-bfbf-a038c09c586e ==============================
[0m08:25:42.688195 [info ] [MainThread]: Running with dbt=1.4.0
[0m08:25:42.691060 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m08:25:42.691436 [debug] [MainThread]: Tracking: tracking
[0m08:25:42.691840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96b552f4a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96b567a360>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96b564aae0>]}
[0m08:25:42.745713 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:25:42.746169 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:25:42.755978 [info ] [Thread-1 (]: 16 of 17 PASS relationships_fact_flights_origin_id__origin_id__ref_dim_origin_ . [[32mPASS[0m in 2.40s]
[0m08:25:42.757066 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m08:25:42.757878 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m08:25:42.758475 [info ] [Thread-1 (]: 17 of 17 START test relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [RUN]
[0m08:25:42.760174 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa'
[0m08:25:42.760787 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m08:25:42.761789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b27e358-8272-4e38-bfbf-a038c09c586e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96b618ffe0>]}
[0m08:25:42.773378 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m08:25:42.774159 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (compile): 2025-11-26 08:25:42.761269 => 2025-11-26 08:25:42.774037
[0m08:25:42.774598 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m08:25:42.778136 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m08:25:42.779126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b27e358-8272-4e38-bfbf-a038c09c586e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96b5206a20>]}
[0m08:25:42.779790 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m08:25:42.779774 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m08:25:42.780166 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select status_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where status_id is not null
),

parent as (
    select status_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:25:42.780287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b27e358-8272-4e38-bfbf-a038c09c586e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96c07f0440>]}
[0m08:25:42.780448 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:42.783817 [info ] [MainThread]: 
[0m08:25:42.787443 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:25:42.791323 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m08:25:42.804004 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m08:25:42.829399 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m08:25:42.829866 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m08:25:42.830204 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:25:42.841994 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m08:25:42.842569 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m08:25:42.843074 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:25:43.178005 [info ] [Thread-2 (]: 15 of 17 PASS relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [[32mPASS[0m in 3.98s]
[0m08:25:43.178598 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m08:25:49.196489 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 6 seconds
[0m08:25:49.200514 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (execute): 2025-11-26 08:25:42.774862 => 2025-11-26 08:25:49.200406
[0m08:25:49.200913 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: Close
[0m08:25:49.305314 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 6 seconds
[0m08:25:49.309147 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m08:25:49.355668 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 7 seconds
[0m08:25:49.359897 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m08:25:49.704770 [info ] [Thread-1 (]: 17 of 17 PASS relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [[32mPASS[0m in 6.95s]
[0m08:25:49.705855 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m08:25:49.709398 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:25:49.710753 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:25:49.711257 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5' was properly closed.
[0m08:25:49.711553 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa' was properly closed.
[0m08:25:49.711905 [info ] [MainThread]: 
[0m08:25:49.712385 [info ] [MainThread]: Finished running 17 tests in 0 hours 0 minutes and 35.76 seconds (35.76s).
[0m08:25:49.713704 [debug] [MainThread]: Command end result
[0m08:25:49.729490 [info ] [MainThread]: 
[0m08:25:49.730164 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:25:49.730719 [info ] [MainThread]: 
[0m08:25:49.731151 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=0 SKIP=0 TOTAL=17
[0m08:25:49.731727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab2c514fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab24d0b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab24d0bbf0>]}
[0m08:25:49.732186 [debug] [MainThread]: Flushing usage events
[0m08:25:49.788924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b27e358-8272-4e38-bfbf-a038c09c586e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96b5236330>]}
[0m08:25:49.790145 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m08:25:49.790623 [info ] [MainThread]: 
[0m08:25:49.821100 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m08:25:49.821638 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m08:25:49.822058 [info ] [Thread-1 (]: 1 of 17 START test is_positive_fact_flights_CARRIER_DELAY ...................... [RUN]
[0m08:25:49.822536 [info ] [Thread-2 (]: 2 of 17 START test is_positive_fact_flights_LATE_AIRCRAFT_DELAY ................ [RUN]
[0m08:25:49.823422 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec'
[0m08:25:49.824209 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa'
[0m08:25:49.824714 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m08:25:49.825116 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m08:25:49.836285 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m08:25:49.841864 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m08:25:49.842658 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (compile): 2025-11-26 08:25:49.825395 => 2025-11-26 08:25:49.842555
[0m08:25:49.843023 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m08:25:49.843327 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (compile): 2025-11-26 08:25:49.836606 => 2025-11-26 08:25:49.843227
[0m08:25:49.854767 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m08:25:49.888803 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m08:25:49.889426 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m08:25:49.890335 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m08:25:49.890588 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where LATE_AIRCRAFT_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:25:49.890793 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:25:49.892160 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m08:25:49.893152 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where CARRIER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:25:49.893373 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:50.818379 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:50.830498 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (execute): 2025-11-26 08:25:49.843605 => 2025-11-26 08:25:50.830392
[0m08:25:50.830902 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: Close
[0m08:25:51.267137 [info ] [Thread-1 (]: 1 of 17 PASS is_positive_fact_flights_CARRIER_DELAY ............................ [[32mPASS[0m in 1.44s]
[0m08:25:51.270114 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m08:25:51.270696 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m08:25:51.271114 [info ] [Thread-1 (]: 3 of 17 START test is_positive_fact_flights_NAS_DELAY .......................... [RUN]
[0m08:25:51.272025 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3'
[0m08:25:51.272339 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m08:25:51.278741 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m08:25:51.279359 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (compile): 2025-11-26 08:25:51.272553 => 2025-11-26 08:25:51.279277
[0m08:25:51.279694 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m08:25:51.282872 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m08:25:51.283838 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m08:25:51.284132 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where NAS_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:25:51.284377 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:52.233272 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:52.237165 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (execute): 2025-11-26 08:25:51.279906 => 2025-11-26 08:25:52.237048
[0m08:25:52.237643 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: Close
[0m08:25:52.616953 [info ] [Thread-1 (]: 3 of 17 PASS is_positive_fact_flights_NAS_DELAY ................................ [[32mPASS[0m in 1.35s]
[0m08:25:52.617519 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m08:25:52.617911 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m08:25:52.618180 [info ] [Thread-1 (]: 4 of 17 START test is_positive_fact_flights_SECURITY_DELAY ..................... [RUN]
[0m08:25:52.618942 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384'
[0m08:25:52.619228 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m08:25:52.624900 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m08:25:52.625535 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (compile): 2025-11-26 08:25:52.619411 => 2025-11-26 08:25:52.625441
[0m08:25:52.625889 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m08:25:52.629400 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m08:25:52.630432 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m08:25:52.630736 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where SECURITY_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:25:52.630978 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:53.473736 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:53.477089 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (execute): 2025-11-26 08:25:52.626109 => 2025-11-26 08:25:53.476972
[0m08:25:53.477535 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: Close
[0m08:25:53.647627 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 4 seconds
[0m08:25:53.651364 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (execute): 2025-11-26 08:25:49.860237 => 2025-11-26 08:25:53.650712
[0m08:25:53.651874 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: Close
[0m08:25:54.320761 [info ] [Thread-1 (]: 4 of 17 PASS is_positive_fact_flights_SECURITY_DELAY ........................... [[32mPASS[0m in 1.70s]
[0m08:25:54.321384 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m08:25:54.321883 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m08:25:54.322217 [info ] [Thread-1 (]: 5 of 17 START test is_positive_fact_flights_TAXI_IN_TIME ....................... [RUN]
[0m08:25:54.323162 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c'
[0m08:25:54.323580 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m08:25:54.329077 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m08:25:54.329740 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (compile): 2025-11-26 08:25:54.323857 => 2025-11-26 08:25:54.329622
[0m08:25:54.330214 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m08:25:54.333688 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m08:25:54.334688 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m08:25:54.334980 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_IN_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:25:54.335213 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:55.299581 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:55.304060 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (execute): 2025-11-26 08:25:54.330426 => 2025-11-26 08:25:55.303922
[0m08:25:55.304486 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: Close
[0m08:25:55.653362 [info ] [Thread-1 (]: 5 of 17 PASS is_positive_fact_flights_TAXI_IN_TIME ............................. [[32mPASS[0m in 1.33s]
[0m08:25:55.654082 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m08:25:55.654553 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m08:25:55.655036 [info ] [Thread-1 (]: 6 of 17 START test is_positive_fact_flights_TAXI_OUT_TIME ...................... [RUN]
[0m08:25:55.655943 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da'
[0m08:25:55.656260 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m08:25:55.661493 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m08:25:55.662078 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (compile): 2025-11-26 08:25:55.656466 => 2025-11-26 08:25:55.661998
[0m08:25:55.662396 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m08:25:55.665594 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m08:25:55.666535 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m08:25:55.666812 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_OUT_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:25:55.667040 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:56.009662 [info ] [Thread-2 (]: 2 of 17 PASS is_positive_fact_flights_LATE_AIRCRAFT_DELAY ...................... [[32mPASS[0m in 6.19s]
[0m08:25:56.010378 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m08:25:56.010817 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m08:25:56.011167 [info ] [Thread-2 (]: 7 of 17 START test is_positive_fact_flights_WEATHER_DELAY ...................... [RUN]
[0m08:25:56.012083 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474'
[0m08:25:56.012445 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m08:25:56.018406 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m08:25:56.019025 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (compile): 2025-11-26 08:25:56.012763 => 2025-11-26 08:25:56.018900
[0m08:25:56.019380 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m08:25:56.022633 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m08:25:56.023630 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m08:25:56.023916 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where WEATHER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m08:25:56.024156 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:25:56.445223 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:56.449462 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (execute): 2025-11-26 08:25:55.662591 => 2025-11-26 08:25:56.449345
[0m08:25:56.449891 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: Close
[0m08:25:56.784388 [info ] [Thread-1 (]: 6 of 17 PASS is_positive_fact_flights_TAXI_OUT_TIME ............................ [[32mPASS[0m in 1.13s]
[0m08:25:56.785125 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m08:25:56.785630 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m08:25:56.785988 [info ] [Thread-1 (]: 8 of 17 START test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:25:56.786942 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9'
[0m08:25:56.787292 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m08:25:56.801688 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m08:25:56.802284 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (compile): 2025-11-26 08:25:56.787511 => 2025-11-26 08:25:56.802199
[0m08:25:56.802623 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m08:25:56.805341 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m08:25:56.806615 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m08:25:56.806899 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:25:56.807159 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:56.814466 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:56.817602 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (execute): 2025-11-26 08:25:56.019592 => 2025-11-26 08:25:56.817506
[0m08:25:56.817972 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: Close
[0m08:25:57.148368 [info ] [Thread-2 (]: 7 of 17 PASS is_positive_fact_flights_WEATHER_DELAY ............................ [[32mPASS[0m in 1.14s]
[0m08:25:57.148985 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m08:25:57.149411 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m08:25:57.149686 [info ] [Thread-2 (]: 9 of 17 START test relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:25:57.150467 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079'
[0m08:25:57.150765 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m08:25:57.159254 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m08:25:57.159834 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (compile): 2025-11-26 08:25:57.150974 => 2025-11-26 08:25:57.159748
[0m08:25:57.160179 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m08:25:57.162955 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m08:25:57.164235 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m08:25:57.164506 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:25:57.164725 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:25:57.644694 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:57.649727 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (execute): 2025-11-26 08:25:56.802865 => 2025-11-26 08:25:57.649551
[0m08:25:57.650487 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: Close
[0m08:25:58.014202 [info ] [Thread-1 (]: 8 of 17 PASS relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.23s]
[0m08:25:58.015048 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m08:25:58.015701 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m08:25:58.016394 [info ] [Thread-1 (]: 10 of 17 START test relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:25:58.017482 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608'
[0m08:25:58.017892 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m08:25:58.027699 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m08:25:58.028306 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (compile): 2025-11-26 08:25:58.018312 => 2025-11-26 08:25:58.028215
[0m08:25:58.028653 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m08:25:58.031767 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m08:25:58.033298 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m08:25:58.033630 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:25:58.033924 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:25:58.567134 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:25:58.572110 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (execute): 2025-11-26 08:25:57.160387 => 2025-11-26 08:25:58.571968
[0m08:25:58.572689 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: Close
[0m08:25:59.512889 [info ] [Thread-2 (]: 9 of 17 PASS relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 2.36s]
[0m08:25:59.513537 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m08:25:59.514088 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m08:25:59.514498 [info ] [Thread-2 (]: 11 of 17 START test relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:25:59.515320 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932'
[0m08:25:59.515608 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m08:25:59.524650 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m08:25:59.525299 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (compile): 2025-11-26 08:25:59.515794 => 2025-11-26 08:25:59.525201
[0m08:25:59.525671 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m08:25:59.528667 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m08:25:59.530100 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m08:25:59.530402 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:25:59.530682 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:25:59.803619 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:25:59.807819 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (execute): 2025-11-26 08:25:58.028863 => 2025-11-26 08:25:59.807697
[0m08:25:59.808269 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: Close
[0m08:26:00.716093 [info ] [Thread-1 (]: 10 of 17 PASS relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 2.70s]
[0m08:26:00.716736 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m08:26:00.717262 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m08:26:00.717600 [info ] [Thread-1 (]: 12 of 17 START test relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:26:00.718478 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5'
[0m08:26:00.718777 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m08:26:00.728647 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m08:26:00.729449 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (compile): 2025-11-26 08:26:00.718991 => 2025-11-26 08:26:00.729326
[0m08:26:00.729881 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m08:26:00.733399 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m08:26:00.734967 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m08:26:00.735318 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_Off_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_Off_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:26:00.735592 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:26:01.223825 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m08:26:01.226789 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (execute): 2025-11-26 08:25:59.525893 => 2025-11-26 08:26:01.226683
[0m08:26:01.227198 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: Close
[0m08:26:01.483061 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:26:01.487352 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (execute): 2025-11-26 08:26:00.730165 => 2025-11-26 08:26:01.487235
[0m08:26:01.487816 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: Close
[0m08:26:01.875679 [info ] [Thread-1 (]: 12 of 17 PASS relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.16s]
[0m08:26:01.876408 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m08:26:01.876948 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m08:26:01.877301 [info ] [Thread-1 (]: 13 of 17 START test relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [RUN]
[0m08:26:01.878232 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850'
[0m08:26:01.878567 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m08:26:01.888401 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m08:26:01.889028 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (compile): 2025-11-26 08:26:01.878797 => 2025-11-26 08:26:01.888938
[0m08:26:01.889388 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m08:26:01.892249 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m08:26:01.893536 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m08:26:01.893807 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_On_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_On_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:26:01.894035 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:26:02.053099 [info ] [Thread-2 (]: 11 of 17 PASS relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 2.54s]
[0m08:26:02.053886 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m08:26:02.054425 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m08:26:02.054772 [info ] [Thread-2 (]: 14 of 17 START test relationships_fact_flights_date_id__date_id__ref_dim_date_ . [RUN]
[0m08:26:02.055847 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9'
[0m08:26:02.056592 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m08:26:02.065752 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m08:26:02.066449 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (compile): 2025-11-26 08:26:02.056978 => 2025-11-26 08:26:02.066360
[0m08:26:02.066799 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m08:26:02.069680 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m08:26:02.071484 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m08:26:02.071760 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select date_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where date_id is not null
),

parent as (
    select date_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:26:02.071985 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:26:02.750762 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:26:02.754950 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (execute): 2025-11-26 08:26:01.889598 => 2025-11-26 08:26:02.754808
[0m08:26:02.755396 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: Close
[0m08:26:02.896826 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:26:02.901094 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (execute): 2025-11-26 08:26:02.067053 => 2025-11-26 08:26:02.900973
[0m08:26:02.901529 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: Close
[0m08:26:03.098578 [info ] [Thread-1 (]: 13 of 17 PASS relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.22s]
[0m08:26:03.099334 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m08:26:03.099841 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m08:26:03.100199 [info ] [Thread-1 (]: 15 of 17 START test relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [RUN]
[0m08:26:03.101064 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5'
[0m08:26:03.101402 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m08:26:03.110371 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m08:26:03.111166 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (compile): 2025-11-26 08:26:03.101656 => 2025-11-26 08:26:03.111058
[0m08:26:03.111537 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m08:26:03.114311 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m08:26:03.115596 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m08:26:03.115869 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select destination_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where destination_id is not null
),

parent as (
    select destination_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:26:03.116097 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:26:03.276894 [info ] [Thread-2 (]: 14 of 17 PASS relationships_fact_flights_date_id__date_id__ref_dim_date_ ....... [[32mPASS[0m in 1.22s]
[0m08:26:03.277562 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m08:26:03.278096 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m08:26:03.278419 [info ] [Thread-2 (]: 16 of 17 START test relationships_fact_flights_origin_id__origin_id__ref_dim_origin_  [RUN]
[0m08:26:03.279464 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24'
[0m08:26:03.279782 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m08:26:03.289413 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m08:26:03.290420 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (compile): 2025-11-26 08:26:03.280023 => 2025-11-26 08:26:03.290284
[0m08:26:03.290890 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m08:26:03.294182 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m08:26:03.295618 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m08:26:03.295938 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select origin_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where origin_id is not null
),

parent as (
    select origin_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:26:03.296174 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:26:03.956026 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:26:03.960418 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (execute): 2025-11-26 08:26:03.111753 => 2025-11-26 08:26:03.960302
[0m08:26:03.960847 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: Close
[0m08:26:04.090384 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m08:26:04.094221 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (execute): 2025-11-26 08:26:03.291337 => 2025-11-26 08:26:04.094113
[0m08:26:04.094611 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: Close
[0m08:26:04.329264 [info ] [Thread-1 (]: 15 of 17 PASS relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [[32mPASS[0m in 1.23s]
[0m08:26:04.330122 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m08:26:04.330716 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m08:26:04.331111 [info ] [Thread-1 (]: 17 of 17 START test relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [RUN]
[0m08:26:04.332088 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa'
[0m08:26:04.332421 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m08:26:04.341819 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m08:26:04.342434 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (compile): 2025-11-26 08:26:04.332635 => 2025-11-26 08:26:04.342350
[0m08:26:04.342814 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m08:26:04.345630 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m08:26:04.346896 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m08:26:04.347188 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select status_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where status_id is not null
),

parent as (
    select status_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m08:26:04.347410 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:26:04.435504 [info ] [Thread-2 (]: 16 of 17 PASS relationships_fact_flights_origin_id__origin_id__ref_dim_origin_ . [[32mPASS[0m in 1.16s]
[0m08:26:04.436343 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m08:26:06.980804 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m08:26:06.983686 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (execute): 2025-11-26 08:26:04.343075 => 2025-11-26 08:26:06.983578
[0m08:26:06.984077 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: Close
[0m08:26:07.667477 [info ] [Thread-1 (]: 17 of 17 PASS relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [[32mPASS[0m in 3.34s]
[0m08:26:07.668144 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m08:26:07.670126 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m08:26:07.670811 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:26:07.671062 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24' was properly closed.
[0m08:26:07.671257 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa' was properly closed.
[0m08:26:07.671506 [info ] [MainThread]: 
[0m08:26:07.671820 [info ] [MainThread]: Finished running 17 tests in 0 hours 0 minutes and 24.89 seconds (24.89s).
[0m08:26:07.672797 [debug] [MainThread]: Command end result
[0m08:26:07.683445 [info ] [MainThread]: 
[0m08:26:07.684008 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:26:07.684409 [info ] [MainThread]: 
[0m08:26:07.684750 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=0 SKIP=0 TOTAL=17
[0m08:26:07.685224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d0fc5910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96b659c6b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96b52b4ec0>]}
[0m08:26:07.685596 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 11:34:07.100791 | 0df46387-4109-495b-b382-57ab0735fdaa ==============================
[0m11:34:07.100791 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:34:07.106069 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'source-freshness', 'rpc_method': 'source-freshness', 'indirect_selection': 'eager'}
[0m11:34:07.106941 [debug] [MainThread]: Tracking: tracking
[0m11:34:07.107713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5fc2d4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5f6e4ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5f6e4b30>]}
[0m11:34:07.139822 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:34:07.140774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0df46387-4109-495b-b382-57ab0735fdaa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5f6e51c0>]}
[0m11:34:09.213137 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_date.sql
[0m11:34:09.255407 [debug] [MainThread]: 1603: static parser failed on marts/dim_destination.sql
[0m11:34:09.275271 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_destination.sql
[0m11:34:09.280172 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_flight_status.sql
[0m11:34:09.291315 [debug] [MainThread]: 1603: static parser failed on marts/dim_origin.sql
[0m11:34:09.305965 [debug] [MainThread]: 1602: parser fallback to jinja rendering on marts/dim_origin.sql
[0m11:34:09.311751 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_time.sql
[0m11:34:09.322304 [debug] [MainThread]: 1699: static parser successfully parsed marts/fact_flights.sql
[0m11:34:09.342646 [debug] [MainThread]: 1603: static parser failed on staging/stg_flight_status.sql
[0m11:34:09.422841 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_flight_status.sql
[0m11:34:10.136605 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.airflow_dbt_project.amount_validation' (tests/amount_validation.sql) depends on a node named 'stg_orders' in package '' which was not found
[0m11:34:10.201277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0df46387-4109-495b-b382-57ab0735fdaa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5f5b3f50>]}
[0m11:34:10.219077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0df46387-4109-495b-b382-57ab0735fdaa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5f5b0e00>]}
[0m11:34:10.220288 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m11:34:10.221224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0df46387-4109-495b-b382-57ab0735fdaa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e8b1f4f80>]}
[0m11:34:10.225722 [info ] [MainThread]: 
[0m11:34:10.230419 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:34:10.234288 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m11:34:10.242754 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:34:10.343251 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m11:34:10.344700 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m11:34:10.346830 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m11:34:10.347751 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:34:10.348929 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m11:34:10.358228 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:34:12.801249 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m11:34:12.806017 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m11:34:12.811257 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m11:34:12.816833 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m11:34:13.429404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0df46387-4109-495b-b382-57ab0735fdaa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5f5cac30>]}
[0m11:34:13.432548 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:34:13.433899 [info ] [MainThread]: 
[0m11:34:13.570192 [debug] [Thread-1 (]: Began running node source.airflow_dbt_project.raw_data.flights
[0m11:34:13.571363 [info ] [Thread-1 (]: 1 of 1 START freshness of raw_data.flights ..................................... [RUN]
[0m11:34:13.573971 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m11:34:13.575094 [debug] [Thread-1 (]: Began compiling node source.airflow_dbt_project.raw_data.flights
[0m11:34:13.575992 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (compile): 2025-11-26 11:34:13.575722 => 2025-11-26 11:34:13.575762
[0m11:34:13.576702 [debug] [Thread-1 (]: Began executing node source.airflow_dbt_project.raw_data.flights
[0m11:34:13.578904 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m11:34:13.616295 [debug] [Thread-1 (]: Using snowflake connection "source.airflow_dbt_project.raw_data.flights"
[0m11:34:13.617813 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "source.airflow_dbt_project.raw_data.flights"} */
select
      max(INGESTION_TIME) as max_loaded_at,
      convert_timezone('UTC', current_timestamp()) as snapshotted_at
    from GP.RAW.flights
[0m11:34:13.619079 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:34:14.640078 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:34:14.646227 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: Close
[0m11:34:15.257528 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (execute): 2025-11-26 11:34:13.577330 => 2025-11-26 11:34:15.257236
[0m11:34:15.260157 [info ] [Thread-1 (]: 1 of 1 PASS freshness of raw_data.flights ...................................... [[32mPASS[0m in 1.69s]
[0m11:34:15.266834 [debug] [Thread-1 (]: Finished running node source.airflow_dbt_project.raw_data.flights
[0m11:34:15.271375 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:34:15.272454 [debug] [MainThread]: Connection 'source.airflow_dbt_project.raw_data.flights' was properly closed.
[0m11:34:15.273286 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m11:34:15.304001 [info ] [MainThread]: Done.
[0m11:34:15.305591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5ccd2090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5f5146b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5f515f70>]}
[0m11:34:15.306721 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 11:34:30.982022 | 06320959-f5c5-43ca-b9a7-a37af51bf0c3 ==============================
[0m11:34:30.982022 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:34:30.991002 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['staging.*'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:34:30.992812 [debug] [MainThread]: Tracking: tracking
[0m11:34:30.994254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa9d346f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa8d0886b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa8d0885c0>]}
[0m11:34:31.117203 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:34:31.118021 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:34:31.142575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '06320959-f5c5-43ca-b9a7-a37af51bf0c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa8d6358b0>]}
[0m11:34:31.182610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '06320959-f5c5-43ca-b9a7-a37af51bf0c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa8ed0f440>]}
[0m11:34:31.184509 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m11:34:31.186327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '06320959-f5c5-43ca-b9a7-a37af51bf0c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa9d346f60>]}
[0m11:34:31.194167 [info ] [MainThread]: 
[0m11:34:31.202776 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:34:31.207549 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:34:31.272804 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:34:31.274104 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:34:31.275006 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:34:33.483013 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m11:34:33.487085 [debug] [ThreadPool]: On list_GP: Close
[0m11:34:34.101575 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m11:34:34.104527 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m11:34:34.105766 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging', identifier=None)"
[0m11:34:34.130289 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m11:34:34.131429 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m11:34:34.132377 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:34:35.220598 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m11:34:35.222718 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m11:34:35.841338 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m11:34:35.843414 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:34:35.869493 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m11:34:35.875948 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m11:34:35.877785 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m11:34:35.878630 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:34:35.879487 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m11:34:35.881933 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:34:36.864273 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m11:34:36.868990 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m11:34:36.925956 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m11:34:36.929724 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m11:34:37.287660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '06320959-f5c5-43ca-b9a7-a37af51bf0c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa8d558b30>]}
[0m11:34:37.291289 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:34:37.292475 [info ] [MainThread]: 
[0m11:34:37.378847 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_flight_status
[0m11:34:37.380432 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [RUN]
[0m11:34:37.384583 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_flight_status'
[0m11:34:37.385659 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_flight_status
[0m11:34:37.433244 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_flight_status"
[0m11:34:37.435495 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (compile): 2025-11-26 11:34:37.386298 => 2025-11-26 11:34:37.435206
[0m11:34:37.436653 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_flight_status
[0m11:34:37.575590 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_flight_status"
[0m11:34:37.585280 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_flight_status"
[0m11:34:37.586326 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_flight_status"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
  
   as (
    select 
    DATE_FROM_PARTS(year, month, day_of_month) AS flight_date,
    
    lower(op_unique_carrier)
 as Airline_Code,
    op_carrier_fl_num::INT as Flight_Number,
    
    lower(origin)
 as Origin_Airport_Code,
    
    lower(origin_city_name)
 as Origin_City,
    
    lower(origin_state_nm)
 as Origin_State,
    
    lower(dest)
 as Destination_Airport_Code,
    
    lower(dest_city_name)
 as Destination_City,
    
    lower(dest_state_nm)
 as Destination_State,
    crs_dep_time::INT as Scheduled_Departure_Time,
    dep_time::INT as Actual_Departure_Time,
    dep_delay::INT as Departure_Delay,
    taxi_out::INT as Taxi_Out_Time,
    wheels_off::INT as Wheels_Off_Time,
    wheels_on::INT as Wheels_On_Time,
    taxi_in::INT as Taxi_In_Time,
    crs_arr_time::INT as Scheduled_Arrival_Time,
    arr_time::INT as Actual_Arrival_Time,
    arr_delay::INT as Arrival_Delay,
    CASE cancelled WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_cancelled,
    CASE cancellation_code WHEN 'A' THEN 'Carrier'  WHEN 'B' THEN 'Weather'  WHEN 'C' THEN 'National Air System'  WHEN 'D' THEN 'Security'  ELSE 'still available' END as Cancellation_Reason,
    CASE diverted WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_diverted,
    crs_elapsed_time::INT as Scheduled_Flight_Duration,
    actual_elapsed_time::INT as Actual_Flight_Duration,
    air_time,
    distance,
    carrier_delay,
    weather_delay,
    nas_delay,
    security_delay,
    late_aircraft_delay,
    isDelete,
    CASE operation WHEN 'c' THEN 'Create'  WHEN 'u' THEN 'Update'  WHEN 'd' THEN 'Delete'  WHEN 'r' THEN 'Snapshot'  ELSE 'Unknown' END as operation_type,
    TO_TIMESTAMP_LTZ(event_time / 1000) as event_time,
    ingestion_time  as ingestion_datetime
from GP.RAW.flights
  );
[0m11:34:37.587092 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:34:39.012113 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:34:39.080620 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (execute): 2025-11-26 11:34:37.437379 => 2025-11-26 11:34:39.080388
[0m11:34:39.081636 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: Close
[0m11:34:39.728154 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06320959-f5c5-43ca-b9a7-a37af51bf0c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa8c666330>]}
[0m11:34:39.729292 [info ] [Thread-1 (]: 1 of 1 OK created sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [[32mSUCCESS 1[0m in 2.35s]
[0m11:34:39.733643 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_flight_status
[0m11:34:39.737293 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:34:39.738817 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:34:39.739347 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m11:34:39.739747 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_flight_status' was properly closed.
[0m11:34:39.740190 [info ] [MainThread]: 
[0m11:34:39.740691 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 8.54 seconds (8.54s).
[0m11:34:39.741539 [debug] [MainThread]: Command end result
[0m11:34:39.758662 [info ] [MainThread]: 
[0m11:34:39.760226 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:34:39.761067 [info ] [MainThread]: 
[0m11:34:39.761683 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:34:39.762445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa8e846ba0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa8dc9f110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa8dd45820>]}
[0m11:34:39.763146 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 11:34:58.754524 | a52351f7-b237-4986-981a-9a1422478b83 ==============================
[0m11:34:58.754524 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:34:58.759981 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_destination'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:34:58.761066 [debug] [MainThread]: Tracking: tracking
[0m11:34:58.762237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f224782d7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f224782f1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2247830800>]}
[0m11:34:58.854959 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:34:58.856059 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:34:58.880770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a52351f7-b237-4986-981a-9a1422478b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f224ce45910>]}
[0m11:34:58.913567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a52351f7-b237-4986-981a-9a1422478b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22478710d0>]}
[0m11:34:58.914589 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m11:34:58.915413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a52351f7-b237-4986-981a-9a1422478b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2272ca5fa0>]}
[0m11:34:58.919234 [info ] [MainThread]: 
[0m11:34:58.924289 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:34:58.927604 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'


============================== 2025-11-26 11:34:58.964022 | dff67b6a-20aa-49a3-bf60-0f938b0021c9 ==============================
[0m11:34:58.964022 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:34:58.968826 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_origin'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:34:58.969229 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:34:58.969525 [debug] [MainThread]: Tracking: tracking
[0m11:34:58.970139 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:34:58.970282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7abe2f4230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7abde5c860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7abde5c890>]}
[0m11:34:58.970636 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:34:59.055968 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:34:59.056732 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:34:59.074207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dff67b6a-20aa-49a3-bf60-0f938b0021c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7abf67a480>]}
[0m11:34:59.100305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dff67b6a-20aa-49a3-bf60-0f938b0021c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7abe185e80>]}
[0m11:34:59.101548 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m11:34:59.102398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dff67b6a-20aa-49a3-bf60-0f938b0021c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7abdf6dca0>]}
[0m11:34:59.106754 [info ] [MainThread]: 
[0m11:34:59.111837 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:34:59.115157 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:34:59.160207 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:34:59.161061 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:34:59.161869 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:35:01.646201 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m11:35:01.648354 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 3 seconds
[0m11:35:01.654249 [debug] [ThreadPool]: On list_GP: Close
[0m11:35:01.658350 [debug] [ThreadPool]: On list_GP: Close
[0m11:35:02.160280 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:35:02.161232 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:35:02.162925 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:35:02.163692 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:35:02.164196 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m11:35:02.164872 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m11:35:02.189592 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m11:35:02.190285 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m11:35:02.190850 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m11:35:02.191914 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:35:02.191515 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m11:35:02.192862 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:35:03.205569 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m11:35:03.210191 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m11:35:03.354676 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m11:35:03.360090 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m11:35:03.695574 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m11:35:03.703294 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:35:03.729686 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m11:35:03.736761 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m11:35:03.738722 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m11:35:03.739562 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:35:03.740777 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m11:35:03.746127 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:35:03.874084 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m11:35:03.884261 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:35:03.950416 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m11:35:03.957224 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m11:35:03.959951 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m11:35:03.961213 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:35:03.962690 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m11:35:03.970297 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:35:04.622293 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m11:35:04.629766 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m11:35:04.838919 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m11:35:04.845698 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m11:35:04.960482 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m11:35:04.970139 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m11:35:04.979842 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m11:35:04.987645 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m11:35:05.237194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a52351f7-b237-4986-981a-9a1422478b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2247b887d0>]}
[0m11:35:05.240130 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:35:05.241719 [info ] [MainThread]: 
[0m11:35:05.330815 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_destination
[0m11:35:05.332440 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [RUN]
[0m11:35:05.336687 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_destination'
[0m11:35:05.337851 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_destination
[0m11:35:05.355520 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_destination"
[0m11:35:05.357457 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (compile): 2025-11-26 11:35:05.338628 => 2025-11-26 11:35:05.357169
[0m11:35:05.358530 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_destination
[0m11:35:05.457899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dff67b6a-20aa-49a3-bf60-0f938b0021c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7abe3a0650>]}
[0m11:35:05.461465 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:35:05.463109 [info ] [MainThread]: 
[0m11:35:05.556726 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_origin
[0m11:35:05.558580 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [RUN]
[0m11:35:05.562599 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_origin'
[0m11:35:05.564092 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_origin
[0m11:35:05.589588 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_origin"
[0m11:35:05.591638 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (compile): 2025-11-26 11:35:05.567650 => 2025-11-26 11:35:05.591335
[0m11:35:05.593007 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_origin
[0m11:35:05.611795 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_destination"
[0m11:35:05.616720 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m11:35:05.617982 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  as
        (


with distinct_values as(
    select
    distinct destination_city as city,destination_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as destination_id,
    city,
    state
    from distinct_values


        );
[0m11:35:05.619052 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:35:05.878353 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_origin"
[0m11:35:05.880841 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m11:35:05.881574 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  as
        (


with distinct_values as(
    select
    distinct origin_city as city,origin_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as origin_id,
    city,
    state
    from distinct_values


        );
[0m11:35:05.882147 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:35:07.477134 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m11:35:07.494723 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m11:35:07.495344 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination__dbt_tmp cascade
[0m11:35:07.787089 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m11:35:07.877157 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (execute): 2025-11-26 11:35:05.359203 => 2025-11-26 11:35:07.876789
[0m11:35:07.878641 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: Close
[0m11:35:08.015693 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m11:35:08.047233 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m11:35:08.048267 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin__dbt_tmp cascade
[0m11:35:08.963482 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:35:09.070285 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (execute): 2025-11-26 11:35:05.593857 => 2025-11-26 11:35:09.069956
[0m11:35:09.071740 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: Close
[0m11:35:09.990530 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dff67b6a-20aa-49a3-bf60-0f938b0021c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7abd1366f0>]}
[0m11:35:09.992099 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a52351f7-b237-4986-981a-9a1422478b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2246ccb320>]}
[0m11:35:09.992084 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [[32mSUCCESS 1[0m in 4.43s]
[0m11:35:09.993698 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [[32mSUCCESS 1[0m in 4.66s]
[0m11:35:09.998850 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_origin
[0m11:35:09.999342 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_destination
[0m11:35:10.004690 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:35:10.006024 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:35:10.006442 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:35:10.007303 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m11:35:10.008147 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_origin' was properly closed.
[0m11:35:10.008338 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:35:10.008842 [info ] [MainThread]: 
[0m11:35:10.009827 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m11:35:10.010381 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 10.90 seconds (10.90s).
[0m11:35:10.011082 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_destination' was properly closed.
[0m11:35:10.012285 [debug] [MainThread]: Command end result
[0m11:35:10.012027 [info ] [MainThread]: 
[0m11:35:10.013178 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 11.09 seconds (11.09s).
[0m11:35:10.014688 [debug] [MainThread]: Command end result
[0m11:35:10.044596 [info ] [MainThread]: 
[0m11:35:10.046175 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:35:10.047286 [info ] [MainThread]: 
[0m11:35:10.048393 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:35:10.049833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7abdb9f380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7abdf6c050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ae5184c20>]}
[0m11:35:10.051014 [debug] [MainThread]: Flushing usage events
[0m11:35:10.051513 [info ] [MainThread]: 
[0m11:35:10.053433 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:35:10.055121 [info ] [MainThread]: 
[0m11:35:10.056540 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:35:10.058393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f224ccd8cb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2247f70e00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2247b887d0>]}
[0m11:35:10.059672 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 11:35:25.978281 | 7f1a5079-5e83-4b22-9300-ef8560dba371 ==============================
[0m11:35:25.978281 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:35:25.985163 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_flight_status'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:35:25.985968 [debug] [MainThread]: Tracking: tracking
[0m11:35:25.986745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f7b640a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f7b640aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f7b640b00>]}
[0m11:35:26.101653 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:35:26.102539 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:35:26.124167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7f1a5079-5e83-4b22-9300-ef8560dba371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f7be09460>]}
[0m11:35:26.149272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7f1a5079-5e83-4b22-9300-ef8560dba371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f802b7f50>]}
[0m11:35:26.150213 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m11:35:26.150908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7f1a5079-5e83-4b22-9300-ef8560dba371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f7badc7d0>]}
[0m11:35:26.154596 [info ] [MainThread]: 
[0m11:35:26.160488 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:35:26.164506 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:35:26.210504 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:35:26.211380 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:35:26.212063 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:35:28.107703 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m11:35:28.118223 [debug] [ThreadPool]: On list_GP: Close
[0m11:35:28.682599 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:35:28.683881 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:35:28.684491 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m11:35:28.699551 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m11:35:28.700295 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m11:35:28.700856 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:35:30.108948 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m11:35:30.113372 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m11:35:30.589590 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:35:30.600999 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m11:35:30.618528 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m11:35:30.619146 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m11:35:30.619868 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m11:35:30.620775 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m11:35:30.621379 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:35:30.622150 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:35:31.561548 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m11:35:31.565326 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m11:35:32.516751 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m11:35:32.523421 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m11:35:33.086155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7f1a5079-5e83-4b22-9300-ef8560dba371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f8012b6b0>]}
[0m11:35:33.089672 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:35:33.091081 [info ] [MainThread]: 
[0m11:35:33.177028 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_flight_status
[0m11:35:33.178626 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [RUN]
[0m11:35:33.183594 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_flight_status'
[0m11:35:33.185680 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_flight_status
[0m11:35:33.197570 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_flight_status"
[0m11:35:33.199413 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (compile): 2025-11-26 11:35:33.186832 => 2025-11-26 11:35:33.199141
[0m11:35:33.200506 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_flight_status
[0m11:35:33.462394 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_flight_status"
[0m11:35:33.466017 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m11:35:33.466986 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  as
        (
with distinct_values as(
    select distinct CANCELLATION_REASON,is_cancelled,is_diverted
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select 
row_number() over(order by is_cancelled) as status_id,
CANCELLATION_REASON,
is_cancelled,
is_diverted
from distinct_values
        );
[0m11:35:33.467866 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:35:35.638170 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m11:35:35.668744 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m11:35:35.669788 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status__dbt_tmp cascade
[0m11:35:36.048390 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m11:35:36.137660 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (execute): 2025-11-26 11:35:33.201167 => 2025-11-26 11:35:36.137418
[0m11:35:36.138716 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: Close
[0m11:35:36.766755 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f1a5079-5e83-4b22-9300-ef8560dba371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f7b3e9cd0>]}
[0m11:35:36.767984 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [[32mSUCCESS 1[0m in 3.59s]
[0m11:35:36.771716 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_flight_status
[0m11:35:36.774994 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:35:36.776191 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:35:36.776614 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m11:35:36.776946 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_flight_status' was properly closed.
[0m11:35:36.777345 [info ] [MainThread]: 
[0m11:35:36.777821 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 10.62 seconds (10.62s).
[0m11:35:36.778573 [debug] [MainThread]: Command end result
[0m11:35:36.795935 [info ] [MainThread]: 
[0m11:35:36.796712 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:35:36.797241 [info ] [MainThread]: 
[0m11:35:36.797794 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:35:36.798487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f80aa4230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f7b9ba780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f7b6e4650>]}
[0m11:35:36.799244 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 11:35:55.449873 | 97819afd-5ef8-41e4-8820-48b2089c96e3 ==============================
[0m11:35:55.449873 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:35:55.454393 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['fact_flights'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:35:55.455012 [debug] [MainThread]: Tracking: tracking
[0m11:35:55.455888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd1af2c650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd1af2c680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd1af2c080>]}
[0m11:35:55.529169 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:35:55.529942 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:35:55.552377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97819afd-5ef8-41e4-8820-48b2089c96e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd1bad85f0>]}
[0m11:35:55.584919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '97819afd-5ef8-41e4-8820-48b2089c96e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd1af4cce0>]}
[0m11:35:55.586488 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m11:35:55.588116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '97819afd-5ef8-41e4-8820-48b2089c96e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd20701a90>]}
[0m11:35:55.593707 [info ] [MainThread]: 
[0m11:35:55.599826 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:35:55.603701 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m11:35:55.655102 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m11:35:55.656233 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m11:35:55.657393 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:35:58.064043 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m11:35:58.068130 [debug] [ThreadPool]: On list_GP: Close
[0m11:35:58.679434 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:35:58.680778 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:35:58.681430 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m11:35:58.695311 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m11:35:58.695986 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m11:35:58.696469 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:36:00.111960 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:00.116244 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m11:36:00.730184 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m11:36:00.736823 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:36:00.755564 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m11:36:00.762815 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m11:36:00.764846 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m11:36:00.765669 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:36:00.766670 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m11:36:00.770612 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:36:02.270134 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m11:36:02.282995 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m11:36:02.504139 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m11:36:02.510863 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m11:36:02.893948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '97819afd-5ef8-41e4-8820-48b2089c96e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd1b973560>]}
[0m11:36:02.896940 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:36:02.898237 [info ] [MainThread]: 
[0m11:36:02.983800 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.fact_flights
[0m11:36:02.985317 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [RUN]
[0m11:36:02.989493 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.fact_flights'
[0m11:36:02.990573 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.fact_flights
[0m11:36:03.011667 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.fact_flights"
[0m11:36:03.014020 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (compile): 2025-11-26 11:36:02.991192 => 2025-11-26 11:36:03.013677
[0m11:36:03.015151 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.fact_flights
[0m11:36:03.270282 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.fact_flights"
[0m11:36:03.279799 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m11:36:03.280963 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  as
        (
select
d_date.date_id as date_id,
sdt.time_id as Scheduled_Departure_Time_id,
adt.time_id as Actual_Departure_Time_id,
wot.time_id as Wheels_Off_Time_id,
wot2.time_id as Wheels_On_Time_id,
sat.time_id as Scheduled_Arrival_Time_id,
aat.time_id as Actual_Arrival_Time_id,
origin.origin_id as origin_id,
dest.destination_id as destination_id, 
fl_stat.status_id as status_id,
AIRLINE_CODE,
FLIGHT_NUMBER,
Departure_Delay,
Taxi_Out_Time,
Taxi_In_Time,
Arrival_Delay,
Scheduled_Flight_Duration,
Actual_Flight_Duration,
Air_Time,
Distance,
Carrier_Delay,
Weather_Delay,
NAS_Delay,
Security_Delay,
Late_Aircraft_Delay
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status as stg 
left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date as d_date
on stg.flight_date=d_date.date_day

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sdt
on stg.Scheduled_Departure_Time=sdt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as adt 
on stg.Actual_Departure_Time=adt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot
on stg.Wheels_Off_Time=wot.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot2 
on stg.Wheels_On_Time=wot2.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sat
on stg.Scheduled_Arrival_Time=sat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as aat
on stg.Actual_Arrival_Time=aat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin as origin
on origin.city=stg.origin_city and origin.state=stg.origin_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination as dest
on dest.city=stg.destination_city and dest.state=stg.destination_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status as fl_stat 
on stg.IS_CANCELLED=fl_stat.IS_CANCELLED and stg.IS_DIVERTED=fl_stat.IS_DIVERTED
        );
[0m11:36:03.281907 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:36:07.380614 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 4 seconds
[0m11:36:07.399724 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m11:36:07.400429 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights__dbt_tmp cascade
[0m11:36:07.687910 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m11:36:07.739112 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (execute): 2025-11-26 11:36:03.015775 => 2025-11-26 11:36:07.738933
[0m11:36:07.739869 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: Close
[0m11:36:08.410247 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97819afd-5ef8-41e4-8820-48b2089c96e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd1acbfce0>]}
[0m11:36:08.412075 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [[32mSUCCESS 1[0m in 5.42s]
[0m11:36:08.418925 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.fact_flights
[0m11:36:08.425175 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:36:08.427537 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:36:08.428395 [debug] [MainThread]: Connection 'model.airflow_dbt_project.fact_flights' was properly closed.
[0m11:36:08.428981 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m11:36:08.429693 [info ] [MainThread]: 
[0m11:36:08.430601 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 12.83 seconds (12.83s).
[0m11:36:08.431774 [debug] [MainThread]: Command end result
[0m11:36:08.463080 [info ] [MainThread]: 
[0m11:36:08.464641 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:36:08.466291 [info ] [MainThread]: 
[0m11:36:08.467995 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:36:08.469349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd3636a9f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd1a3d4440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd1a3d7680>]}
[0m11:36:08.470321 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 11:36:23.336553 | 17eb3acb-4fb5-4d83-912c-a06c93ed334e ==============================
[0m11:36:23.336553 [info ] [MainThread]: Running with dbt=1.4.0
[0m11:36:23.345226 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m11:36:23.346805 [debug] [MainThread]: Tracking: tracking
[0m11:36:23.348388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1c8daf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b43526ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1c8aaf60>]}
[0m11:36:23.555407 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:36:23.557355 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:36:23.599112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '17eb3acb-4fb5-4d83-912c-a06c93ed334e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b3e7b1cd0>]}
[0m11:36:23.640319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '17eb3acb-4fb5-4d83-912c-a06c93ed334e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1c43d160>]}
[0m11:36:23.641728 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m11:36:23.643272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17eb3acb-4fb5-4d83-912c-a06c93ed334e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1c531af0>]}
[0m11:36:23.652206 [info ] [MainThread]: 
[0m11:36:23.659787 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:36:23.665514 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m11:36:23.674384 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m11:36:23.919383 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m11:36:23.921558 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m11:36:23.926711 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m11:36:23.929358 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m11:36:23.930629 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:36:23.931768 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:36:27.366300 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m11:36:27.382915 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m11:36:27.866890 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 4 seconds
[0m11:36:27.879298 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m11:36:28.381257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17eb3acb-4fb5-4d83-912c-a06c93ed334e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1c43d0a0>]}
[0m11:36:28.383748 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m11:36:28.384954 [info ] [MainThread]: 
[0m11:36:28.463524 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m11:36:28.465232 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m11:36:28.466133 [info ] [Thread-1 (]: 1 of 17 START test is_positive_fact_flights_CARRIER_DELAY ...................... [RUN]
[0m11:36:28.467750 [info ] [Thread-2 (]: 2 of 17 START test is_positive_fact_flights_LATE_AIRCRAFT_DELAY ................ [RUN]
[0m11:36:28.470573 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec'
[0m11:36:28.473152 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa'
[0m11:36:28.474327 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m11:36:28.475272 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m11:36:28.525725 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m11:36:28.529412 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m11:36:28.531084 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (compile): 2025-11-26 11:36:28.475863 => 2025-11-26 11:36:28.530774
[0m11:36:28.532539 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m11:36:28.544898 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (compile): 2025-11-26 11:36:28.486298 => 2025-11-26 11:36:28.544485
[0m11:36:28.552452 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m11:36:28.715859 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m11:36:28.717127 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m11:36:28.719283 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m11:36:28.719943 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where CARRIER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m11:36:28.720493 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:36:28.721941 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m11:36:28.725882 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where LATE_AIRCRAFT_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m11:36:28.726528 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:36:30.448544 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m11:36:30.446028 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m11:36:30.505817 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (execute): 2025-11-26 11:36:28.558670 => 2025-11-26 11:36:30.505527
[0m11:36:30.515284 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: Close
[0m11:36:30.518988 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (execute): 2025-11-26 11:36:28.533319 => 2025-11-26 11:36:30.518760
[0m11:36:30.524711 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: Close
[0m11:36:31.141473 [info ] [Thread-1 (]: 1 of 17 PASS is_positive_fact_flights_CARRIER_DELAY ............................ [[32mPASS[0m in 2.67s]
[0m11:36:31.145233 [info ] [Thread-2 (]: 2 of 17 PASS is_positive_fact_flights_LATE_AIRCRAFT_DELAY ...................... [[32mPASS[0m in 2.67s]
[0m11:36:31.152456 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m11:36:31.153720 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m11:36:31.155157 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m11:36:31.156841 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m11:36:31.158359 [info ] [Thread-1 (]: 3 of 17 START test is_positive_fact_flights_NAS_DELAY .......................... [RUN]
[0m11:36:31.159717 [info ] [Thread-2 (]: 4 of 17 START test is_positive_fact_flights_SECURITY_DELAY ..................... [RUN]
[0m11:36:31.161901 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3'
[0m11:36:31.164115 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384'
[0m11:36:31.164947 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m11:36:31.165766 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m11:36:31.186277 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m11:36:31.191920 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m11:36:31.193405 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (compile): 2025-11-26 11:36:31.168629 => 2025-11-26 11:36:31.193180
[0m11:36:31.194360 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (compile): 2025-11-26 11:36:31.166652 => 2025-11-26 11:36:31.194212
[0m11:36:31.195247 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m11:36:31.196164 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m11:36:31.203713 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m11:36:31.210973 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m11:36:31.213521 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m11:36:31.217869 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m11:36:31.218743 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where NAS_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m11:36:31.219711 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where SECURITY_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m11:36:31.220589 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:36:31.221792 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:36:32.423511 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:32.426517 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:32.437303 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (execute): 2025-11-26 11:36:31.196990 => 2025-11-26 11:36:32.436976
[0m11:36:32.447738 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (execute): 2025-11-26 11:36:31.204779 => 2025-11-26 11:36:32.447482
[0m11:36:32.449177 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: Close
[0m11:36:32.450545 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: Close
[0m11:36:33.001120 [info ] [Thread-2 (]: 4 of 17 PASS is_positive_fact_flights_SECURITY_DELAY ........................... [[32mPASS[0m in 1.84s]
[0m11:36:33.006384 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m11:36:33.009715 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m11:36:33.013934 [info ] [Thread-2 (]: 5 of 17 START test is_positive_fact_flights_TAXI_IN_TIME ....................... [RUN]
[0m11:36:33.017622 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c'
[0m11:36:33.019725 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m11:36:33.041148 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m11:36:33.044417 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (compile): 2025-11-26 11:36:33.021662 => 2025-11-26 11:36:33.043996
[0m11:36:33.046836 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m11:36:33.060949 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m11:36:33.064109 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m11:36:33.065262 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_IN_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m11:36:33.066190 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:36:33.182545 [info ] [Thread-1 (]: 3 of 17 PASS is_positive_fact_flights_NAS_DELAY ................................ [[32mPASS[0m in 2.02s]
[0m11:36:33.184362 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m11:36:33.185823 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m11:36:33.187005 [info ] [Thread-1 (]: 6 of 17 START test is_positive_fact_flights_TAXI_OUT_TIME ...................... [RUN]
[0m11:36:33.189663 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da'
[0m11:36:33.190621 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m11:36:33.208385 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m11:36:33.210149 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (compile): 2025-11-26 11:36:33.191400 => 2025-11-26 11:36:33.209859
[0m11:36:33.211143 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m11:36:33.219976 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m11:36:33.222964 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m11:36:33.223875 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_OUT_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m11:36:33.225086 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:36:33.980146 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:33.986763 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (execute): 2025-11-26 11:36:33.048795 => 2025-11-26 11:36:33.986495
[0m11:36:33.987892 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: Close
[0m11:36:34.102925 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:34.108759 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (execute): 2025-11-26 11:36:33.211819 => 2025-11-26 11:36:34.108544
[0m11:36:34.109560 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: Close
[0m11:36:34.370830 [info ] [Thread-2 (]: 5 of 17 PASS is_positive_fact_flights_TAXI_IN_TIME ............................. [[32mPASS[0m in 1.35s]
[0m11:36:34.371957 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m11:36:34.372917 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m11:36:34.374146 [info ] [Thread-2 (]: 7 of 17 START test is_positive_fact_flights_WEATHER_DELAY ...................... [RUN]
[0m11:36:34.376327 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474'
[0m11:36:34.376980 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m11:36:34.389094 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m11:36:34.390655 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (compile): 2025-11-26 11:36:34.377507 => 2025-11-26 11:36:34.390404
[0m11:36:34.391484 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m11:36:34.399215 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m11:36:34.401535 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m11:36:34.402233 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where WEATHER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m11:36:34.402727 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:36:34.471981 [info ] [Thread-1 (]: 6 of 17 PASS is_positive_fact_flights_TAXI_OUT_TIME ............................ [[32mPASS[0m in 1.28s]
[0m11:36:34.473063 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m11:36:34.473828 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m11:36:34.474450 [info ] [Thread-1 (]: 8 of 17 START test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m11:36:34.476420 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9'
[0m11:36:34.477294 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m11:36:34.504267 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m11:36:34.505678 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (compile): 2025-11-26 11:36:34.477989 => 2025-11-26 11:36:34.505424
[0m11:36:34.506474 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m11:36:34.513316 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m11:36:34.515997 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m11:36:34.516622 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m11:36:34.517238 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:36:35.255750 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:35.261635 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (execute): 2025-11-26 11:36:34.391952 => 2025-11-26 11:36:35.261452
[0m11:36:35.262375 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: Close
[0m11:36:35.495119 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:35.502555 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (execute): 2025-11-26 11:36:34.506976 => 2025-11-26 11:36:35.502308
[0m11:36:35.503555 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: Close
[0m11:36:35.626813 [info ] [Thread-2 (]: 7 of 17 PASS is_positive_fact_flights_WEATHER_DELAY ............................ [[32mPASS[0m in 1.25s]
[0m11:36:35.628352 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m11:36:35.629514 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m11:36:35.630433 [info ] [Thread-2 (]: 9 of 17 START test relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m11:36:35.633602 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079'
[0m11:36:35.634787 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m11:36:35.659026 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m11:36:35.660773 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (compile): 2025-11-26 11:36:35.635639 => 2025-11-26 11:36:35.660519
[0m11:36:35.661784 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m11:36:35.670098 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m11:36:35.674416 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m11:36:35.675464 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m11:36:35.676529 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:36:35.880557 [info ] [Thread-1 (]: 8 of 17 PASS relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.40s]
[0m11:36:35.882112 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m11:36:35.883247 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m11:36:35.884318 [info ] [Thread-1 (]: 10 of 17 START test relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m11:36:35.886611 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608'
[0m11:36:35.887518 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m11:36:35.915242 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m11:36:35.916723 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (compile): 2025-11-26 11:36:35.888099 => 2025-11-26 11:36:35.916514
[0m11:36:35.917675 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m11:36:35.926973 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m11:36:35.931495 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m11:36:35.932735 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m11:36:35.933676 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:36:36.974130 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:36.978486 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (execute): 2025-11-26 11:36:35.662436 => 2025-11-26 11:36:36.978347
[0m11:36:36.979056 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: Close
[0m11:36:37.045583 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:37.049336 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (execute): 2025-11-26 11:36:35.918212 => 2025-11-26 11:36:37.049201
[0m11:36:37.049842 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: Close
[0m11:36:37.361482 [info ] [Thread-2 (]: 9 of 17 PASS relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.73s]
[0m11:36:37.362457 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m11:36:37.363100 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m11:36:37.363736 [info ] [Thread-2 (]: 11 of 17 START test relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m11:36:37.365171 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932'
[0m11:36:37.365737 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m11:36:37.381016 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m11:36:37.382068 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (compile): 2025-11-26 11:36:37.366106 => 2025-11-26 11:36:37.381909
[0m11:36:37.382584 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m11:36:37.387298 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m11:36:37.389483 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m11:36:37.389914 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m11:36:37.390292 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:36:37.421398 [info ] [Thread-1 (]: 10 of 17 PASS relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.54s]
[0m11:36:37.422326 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m11:36:37.422985 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m11:36:37.423559 [info ] [Thread-1 (]: 12 of 17 START test relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [RUN]
[0m11:36:37.424702 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5'
[0m11:36:37.425151 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m11:36:37.438953 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m11:36:37.440326 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (compile): 2025-11-26 11:36:37.425459 => 2025-11-26 11:36:37.440114
[0m11:36:37.441106 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m11:36:37.447991 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m11:36:37.450937 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m11:36:37.451663 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_Off_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_Off_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m11:36:37.452375 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:36:38.304058 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:38.308272 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (execute): 2025-11-26 11:36:37.382918 => 2025-11-26 11:36:38.308084
[0m11:36:38.308963 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: Close
[0m11:36:38.369772 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:38.378140 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (execute): 2025-11-26 11:36:37.441646 => 2025-11-26 11:36:38.377856
[0m11:36:38.379521 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: Close
[0m11:36:38.673602 [info ] [Thread-2 (]: 11 of 17 PASS relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.31s]
[0m11:36:38.675918 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m11:36:38.678444 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m11:36:38.680170 [info ] [Thread-2 (]: 13 of 17 START test relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [RUN]
[0m11:36:38.683176 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850'
[0m11:36:38.684660 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m11:36:38.709204 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m11:36:38.710820 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (compile): 2025-11-26 11:36:38.685488 => 2025-11-26 11:36:38.710586
[0m11:36:38.711751 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m11:36:38.719884 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m11:36:38.723853 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m11:36:38.724758 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_On_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_On_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m11:36:38.725557 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:36:38.750280 [info ] [Thread-1 (]: 12 of 17 PASS relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.33s]
[0m11:36:38.751852 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m11:36:38.753052 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m11:36:38.754327 [info ] [Thread-1 (]: 14 of 17 START test relationships_fact_flights_date_id__date_id__ref_dim_date_ . [RUN]
[0m11:36:38.756861 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9'
[0m11:36:38.757785 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m11:36:38.786332 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m11:36:38.789164 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (compile): 2025-11-26 11:36:38.758409 => 2025-11-26 11:36:38.788769
[0m11:36:38.790872 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m11:36:38.801469 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m11:36:38.807432 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m11:36:38.809160 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select date_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where date_id is not null
),

parent as (
    select date_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m11:36:38.811066 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:36:39.661015 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:39.664944 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (execute): 2025-11-26 11:36:38.712346 => 2025-11-26 11:36:39.664801
[0m11:36:39.665510 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: Close
[0m11:36:39.753537 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:39.758668 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (execute): 2025-11-26 11:36:38.792086 => 2025-11-26 11:36:39.758517
[0m11:36:39.759245 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: Close
[0m11:36:40.023472 [info ] [Thread-2 (]: 13 of 17 PASS relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.34s]
[0m11:36:40.024343 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m11:36:40.024964 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m11:36:40.025388 [info ] [Thread-2 (]: 15 of 17 START test relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [RUN]
[0m11:36:40.026971 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5'
[0m11:36:40.027843 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m11:36:40.042774 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m11:36:40.043889 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (compile): 2025-11-26 11:36:40.028339 => 2025-11-26 11:36:40.043728
[0m11:36:40.044706 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m11:36:40.048660 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m11:36:40.050952 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m11:36:40.051510 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select destination_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where destination_id is not null
),

parent as (
    select destination_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m11:36:40.051926 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:36:40.129626 [info ] [Thread-1 (]: 14 of 17 PASS relationships_fact_flights_date_id__date_id__ref_dim_date_ ....... [[32mPASS[0m in 1.37s]
[0m11:36:40.130358 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m11:36:40.130888 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m11:36:40.131586 [info ] [Thread-1 (]: 16 of 17 START test relationships_fact_flights_origin_id__origin_id__ref_dim_origin_  [RUN]
[0m11:36:40.132981 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24'
[0m11:36:40.133479 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m11:36:40.152723 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m11:36:40.154342 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (compile): 2025-11-26 11:36:40.133767 => 2025-11-26 11:36:40.154174
[0m11:36:40.154941 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m11:36:40.159627 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m11:36:40.162215 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m11:36:40.162779 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select origin_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where origin_id is not null
),

parent as (
    select origin_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m11:36:40.163218 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:36:41.383089 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:41.391990 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:41.396646 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (execute): 2025-11-26 11:36:40.155330 => 2025-11-26 11:36:41.396314
[0m11:36:41.404249 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (execute): 2025-11-26 11:36:40.045091 => 2025-11-26 11:36:41.403983
[0m11:36:41.406016 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: Close
[0m11:36:41.407673 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: Close
[0m11:36:42.610731 [info ] [Thread-1 (]: 16 of 17 PASS relationships_fact_flights_origin_id__origin_id__ref_dim_origin_ . [[32mPASS[0m in 2.48s]
[0m11:36:42.613538 [info ] [Thread-2 (]: 15 of 17 PASS relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [[32mPASS[0m in 2.59s]
[0m11:36:42.614480 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m11:36:42.615315 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m11:36:42.616237 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m11:36:42.617245 [info ] [Thread-1 (]: 17 of 17 START test relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [RUN]
[0m11:36:42.618662 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa'
[0m11:36:42.619198 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m11:36:42.632802 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m11:36:42.633837 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (compile): 2025-11-26 11:36:42.619531 => 2025-11-26 11:36:42.633688
[0m11:36:42.634413 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m11:36:42.640771 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m11:36:42.643194 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m11:36:42.643813 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select status_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where status_id is not null
),

parent as (
    select status_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m11:36:42.644311 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:36:43.937956 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m11:36:43.943386 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (execute): 2025-11-26 11:36:42.634800 => 2025-11-26 11:36:43.943202
[0m11:36:43.944272 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: Close
[0m11:36:44.864889 [info ] [Thread-1 (]: 17 of 17 PASS relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [[32mPASS[0m in 2.25s]
[0m11:36:44.866500 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m11:36:44.873337 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m11:36:44.876281 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:36:44.877351 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5' was properly closed.
[0m11:36:44.878322 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa' was properly closed.
[0m11:36:44.879562 [info ] [MainThread]: 
[0m11:36:44.881084 [info ] [MainThread]: Finished running 17 tests in 0 hours 0 minutes and 21.23 seconds (21.23s).
[0m11:36:44.885019 [debug] [MainThread]: Command end result
[0m11:36:44.916836 [info ] [MainThread]: 
[0m11:36:44.918349 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:36:44.919444 [info ] [MainThread]: 
[0m11:36:44.920423 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=0 SKIP=0 TOTAL=17
[0m11:36:44.921760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1da38a40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b15535730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1c41c950>]}
[0m11:36:44.922899 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 12:53:46.984588 | b09e456b-7dbd-40cf-9abd-bb287ef01d8b ==============================
[0m12:53:46.984588 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:53:46.987812 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'source-freshness', 'rpc_method': 'source-freshness', 'indirect_selection': 'eager'}
[0m12:53:46.988251 [debug] [MainThread]: Tracking: tracking
[0m12:53:46.988644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4969557f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe495a0c5c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe49552cef0>]}
[0m12:53:47.052997 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:53:47.053505 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:53:47.067543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b09e456b-7dbd-40cf-9abd-bb287ef01d8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4973262d0>]}
[0m12:53:47.084541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b09e456b-7dbd-40cf-9abd-bb287ef01d8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4954c9190>]}
[0m12:53:47.085224 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m12:53:47.085712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b09e456b-7dbd-40cf-9abd-bb287ef01d8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe495cfc470>]}
[0m12:53:47.088707 [info ] [MainThread]: 
[0m12:53:47.092634 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:53:47.095575 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:53:47.102502 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:53:47.165906 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:53:47.166474 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:53:47.166874 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:53:47.172538 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m12:53:47.173067 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m12:53:47.173435 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:53:48.700162 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m12:53:48.710431 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m12:53:48.747641 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m12:53:48.756780 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:53:49.131837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b09e456b-7dbd-40cf-9abd-bb287ef01d8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe497306c00>]}
[0m12:53:49.135166 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:53:49.136860 [info ] [MainThread]: 
[0m12:53:49.250528 [debug] [Thread-1 (]: Began running node source.airflow_dbt_project.raw_data.flights
[0m12:53:49.251763 [info ] [Thread-1 (]: 1 of 1 START freshness of raw_data.flights ..................................... [RUN]
[0m12:53:49.254296 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m12:53:49.255411 [debug] [Thread-1 (]: Began compiling node source.airflow_dbt_project.raw_data.flights
[0m12:53:49.256847 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (compile): 2025-11-26 12:53:49.256174 => 2025-11-26 12:53:49.256417
[0m12:53:49.257951 [debug] [Thread-1 (]: Began executing node source.airflow_dbt_project.raw_data.flights
[0m12:53:49.260259 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m12:53:49.297502 [debug] [Thread-1 (]: Using snowflake connection "source.airflow_dbt_project.raw_data.flights"
[0m12:53:49.298516 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "source.airflow_dbt_project.raw_data.flights"} */
select
      max(INGESTION_TIME) as max_loaded_at,
      convert_timezone('UTC', current_timestamp()) as snapshotted_at
    from GP.RAW.flights
[0m12:53:49.299203 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:53:50.196621 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:53:50.201235 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: Close
[0m12:53:50.569814 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (execute): 2025-11-26 12:53:49.258560 => 2025-11-26 12:53:50.569521
[0m12:53:50.571761 [info ] [Thread-1 (]: 1 of 1 PASS freshness of raw_data.flights ...................................... [[32mPASS[0m in 1.32s]
[0m12:53:50.577486 [debug] [Thread-1 (]: Finished running node source.airflow_dbt_project.raw_data.flights
[0m12:53:50.581570 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:53:50.582250 [debug] [MainThread]: Connection 'source.airflow_dbt_project.raw_data.flights' was properly closed.
[0m12:53:50.583262 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m12:53:50.608735 [info ] [MainThread]: Done.
[0m12:53:50.610445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe49614ffe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe497776c30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe49522f980>]}
[0m12:53:50.611696 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 12:54:06.622024 | 88e64577-a8fd-44c5-9f55-6b6a682200dd ==============================
[0m12:54:06.622024 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:54:06.629704 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['staging.*'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m12:54:06.630627 [debug] [MainThread]: Tracking: tracking
[0m12:54:06.631688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f157bb66810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1580148b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f157bb88800>]}
[0m12:54:06.776477 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:54:06.777561 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:54:06.807230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '88e64577-a8fd-44c5-9f55-6b6a682200dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15a776e960>]}
[0m12:54:06.844688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '88e64577-a8fd-44c5-9f55-6b6a682200dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f157bba8f80>]}
[0m12:54:06.846217 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m12:54:06.847999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '88e64577-a8fd-44c5-9f55-6b6a682200dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15801ac500>]}
[0m12:54:06.854715 [info ] [MainThread]: 
[0m12:54:06.863493 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:54:06.868796 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m12:54:06.927367 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m12:54:06.928438 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m12:54:06.929251 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:54:09.422221 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m12:54:09.431338 [debug] [ThreadPool]: On list_GP: Close
[0m12:54:09.838355 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:54:09.840648 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:54:09.842115 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging', identifier=None)"
[0m12:54:09.872301 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:54:09.873477 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:54:09.874399 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:54:10.752791 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:54:10.758210 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:54:11.268640 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:54:11.278198 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:54:11.347159 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:54:11.356082 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:54:11.359301 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m12:54:11.361827 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:54:11.363203 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m12:54:11.370220 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:54:12.310294 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m12:54:12.316163 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:54:12.325929 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m12:54:12.337421 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m12:54:12.741110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '88e64577-a8fd-44c5-9f55-6b6a682200dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15a7823260>]}
[0m12:54:12.744942 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:54:12.746692 [info ] [MainThread]: 
[0m12:54:12.846670 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_flight_status
[0m12:54:12.852185 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [RUN]
[0m12:54:12.859070 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_flight_status'
[0m12:54:12.860823 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_flight_status
[0m12:54:12.952914 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_flight_status"
[0m12:54:12.955373 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (compile): 2025-11-26 12:54:12.861641 => 2025-11-26 12:54:12.954932
[0m12:54:12.957121 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_flight_status
[0m12:54:13.135832 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_flight_status"
[0m12:54:13.147233 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_flight_status"
[0m12:54:13.148380 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_flight_status"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
  
   as (
    select 
    DATE_FROM_PARTS(year, month, day_of_month) AS flight_date,
    
    lower(op_unique_carrier)
 as Airline_Code,
    op_carrier_fl_num::INT as Flight_Number,
    
    lower(origin)
 as Origin_Airport_Code,
    
    lower(origin_city_name)
 as Origin_City,
    
    lower(origin_state_nm)
 as Origin_State,
    
    lower(dest)
 as Destination_Airport_Code,
    
    lower(dest_city_name)
 as Destination_City,
    
    lower(dest_state_nm)
 as Destination_State,
    crs_dep_time::INT as Scheduled_Departure_Time,
    dep_time::INT as Actual_Departure_Time,
    dep_delay::INT as Departure_Delay,
    taxi_out::INT as Taxi_Out_Time,
    wheels_off::INT as Wheels_Off_Time,
    wheels_on::INT as Wheels_On_Time,
    taxi_in::INT as Taxi_In_Time,
    crs_arr_time::INT as Scheduled_Arrival_Time,
    arr_time::INT as Actual_Arrival_Time,
    arr_delay::INT as Arrival_Delay,
    CASE cancelled WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_cancelled,
    CASE cancellation_code WHEN 'A' THEN 'Carrier'  WHEN 'B' THEN 'Weather'  WHEN 'C' THEN 'National Air System'  WHEN 'D' THEN 'Security'  ELSE 'still available' END as Cancellation_Reason,
    CASE diverted WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_diverted,
    crs_elapsed_time::INT as Scheduled_Flight_Duration,
    actual_elapsed_time::INT as Actual_Flight_Duration,
    air_time,
    distance,
    carrier_delay,
    weather_delay,
    nas_delay,
    security_delay,
    late_aircraft_delay,
    isDelete,
    CASE operation WHEN 'c' THEN 'Create'  WHEN 'u' THEN 'Update'  WHEN 'd' THEN 'Delete'  WHEN 'r' THEN 'Snapshot'  ELSE 'Unknown' END as operation_type,
    TO_TIMESTAMP_LTZ(event_time / 1000) as event_time,
    ingestion_time  as ingestion_datetime
from GP.RAW.flights
  );
[0m12:54:13.149453 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:54:14.331207 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:54:14.404254 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (execute): 2025-11-26 12:54:12.958767 => 2025-11-26 12:54:14.403916
[0m12:54:14.405394 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: Close
[0m12:54:14.844864 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '88e64577-a8fd-44c5-9f55-6b6a682200dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f157b1258b0>]}
[0m12:54:14.846306 [info ] [Thread-1 (]: 1 of 1 OK created sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [[32mSUCCESS 1[0m in 1.99s]
[0m12:54:14.850412 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_flight_status
[0m12:54:14.854795 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:54:14.856523 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:54:14.857271 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m12:54:14.857984 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_flight_status' was properly closed.
[0m12:54:14.858876 [info ] [MainThread]: 
[0m12:54:14.859874 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 8.00 seconds (8.00s).
[0m12:54:14.861205 [debug] [MainThread]: Command end result
[0m12:54:14.881839 [info ] [MainThread]: 
[0m12:54:14.882810 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:54:14.883492 [info ] [MainThread]: 
[0m12:54:14.884109 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m12:54:14.884883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15801ac500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f157b125460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f157b1259a0>]}
[0m12:54:14.885453 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 12:54:31.673834 | 43b98c23-4bce-44d1-9487-ebafe7ea2915 ==============================
[0m12:54:31.673834 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:54:31.677599 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_destination'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m12:54:31.678106 [debug] [MainThread]: Tracking: tracking
[0m12:54:31.678667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f548acf1cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5482b0c380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f545f905e50>]}


============================== 2025-11-26 12:54:31.719803 | 946265e0-ec8b-4620-8e60-05fcd25ba886 ==============================
[0m12:54:31.719803 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:54:31.726003 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_origin'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m12:54:31.726773 [debug] [MainThread]: Tracking: tracking
[0m12:54:31.727724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87577e8590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f874f91c560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8742488f50>]}
[0m12:54:31.749899 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:54:31.750585 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:54:31.771335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '43b98c23-4bce-44d1-9487-ebafe7ea2915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f545f9046e0>]}
[0m12:54:31.796568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '43b98c23-4bce-44d1-9487-ebafe7ea2915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f545f9a0c20>]}
[0m12:54:31.797741 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m12:54:31.798756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43b98c23-4bce-44d1-9487-ebafe7ea2915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f545fa4c620>]}
[0m12:54:31.803983 [info ] [MainThread]: 
[0m12:54:31.809637 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:54:31.812895 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m12:54:31.857003 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:54:31.857908 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:54:31.860412 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m12:54:31.861485 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m12:54:31.862463 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:54:31.886809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '946265e0-ec8b-4620-8e60-05fcd25ba886', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f874f90da00>]}
[0m12:54:31.921189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '946265e0-ec8b-4620-8e60-05fcd25ba886', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87423e0e00>]}
[0m12:54:31.922861 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m12:54:31.924360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '946265e0-ec8b-4620-8e60-05fcd25ba886', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8742541160>]}
[0m12:54:31.931752 [info ] [MainThread]: 
[0m12:54:31.939068 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:54:31.943218 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m12:54:31.996041 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m12:54:31.996871 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m12:54:31.997524 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:54:33.176684 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m12:54:33.180158 [debug] [ThreadPool]: On list_GP: Close
[0m12:54:33.216645 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m12:54:33.220709 [debug] [ThreadPool]: On list_GP: Close
[0m12:54:33.583080 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:54:33.583222 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:54:33.584418 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:54:33.584609 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:54:33.585086 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m12:54:33.585428 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m12:54:33.599656 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m12:54:33.600404 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m12:54:33.600909 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m12:54:33.601398 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m12:54:33.601999 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:54:33.602132 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:54:34.502681 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:54:34.503079 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:54:34.504912 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m12:54:34.505557 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m12:54:34.917598 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:54:34.918338 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:54:34.925607 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:54:34.929979 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:54:34.939140 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m12:54:34.944811 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m12:54:34.944669 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:54:34.945551 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m12:54:34.946364 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:54:34.947235 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:54:34.947984 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:54:34.951003 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m12:54:34.955701 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:54:34.956532 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:54:34.957734 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:54:34.962165 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:54:35.837847 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m12:54:35.840359 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m12:54:35.845873 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:54:35.843415 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m12:54:35.855260 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m12:54:35.851918 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m12:54:35.864780 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m12:54:35.860708 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:54:36.360028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43b98c23-4bce-44d1-9487-ebafe7ea2915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f545f7c9bb0>]}
[0m12:54:36.361315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '946265e0-ec8b-4620-8e60-05fcd25ba886', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8742152720>]}
[0m12:54:36.362789 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:54:36.363215 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:54:36.363981 [info ] [MainThread]: 
[0m12:54:36.363984 [info ] [MainThread]: 
[0m12:54:36.447061 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_origin
[0m12:54:36.448720 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [RUN]
[0m12:54:36.453590 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_origin'
[0m12:54:36.454728 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_origin
[0m12:54:36.458784 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_destination
[0m12:54:36.460442 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [RUN]
[0m12:54:36.467419 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_destination'
[0m12:54:36.469108 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_destination
[0m12:54:36.472743 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_origin"
[0m12:54:36.474618 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (compile): 2025-11-26 12:54:36.455341 => 2025-11-26 12:54:36.474287
[0m12:54:36.475753 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_origin
[0m12:54:36.493078 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_destination"
[0m12:54:36.495454 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (compile): 2025-11-26 12:54:36.470184 => 2025-11-26 12:54:36.495015
[0m12:54:36.497007 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_destination
[0m12:54:36.694911 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_origin"
[0m12:54:36.699442 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m12:54:36.700719 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  as
        (


with distinct_values as(
    select
    distinct origin_city as city,origin_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as origin_id,
    city,
    state
    from distinct_values


        );
[0m12:54:36.701998 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:54:36.761590 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_destination"
[0m12:54:36.766392 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m12:54:36.767855 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  as
        (


with distinct_values as(
    select
    distinct destination_city as city,destination_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as destination_id,
    city,
    state
    from distinct_values


        );
[0m12:54:36.769074 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:54:39.726645 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m12:54:39.726733 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m12:54:39.756757 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m12:54:39.757897 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin__dbt_tmp cascade
[0m12:54:39.758831 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m12:54:39.759866 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination__dbt_tmp cascade
[0m12:54:40.034097 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m12:54:40.034942 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m12:54:40.127202 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (execute): 2025-11-26 12:54:36.498178 => 2025-11-26 12:54:40.126961
[0m12:54:40.128220 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: Close
[0m12:54:40.131986 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (execute): 2025-11-26 12:54:36.476469 => 2025-11-26 12:54:40.131743
[0m12:54:40.133118 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: Close
[0m12:54:40.549351 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43b98c23-4bce-44d1-9487-ebafe7ea2915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f545ec87290>]}
[0m12:54:40.550014 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '946265e0-ec8b-4620-8e60-05fcd25ba886', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87416905f0>]}
[0m12:54:40.551488 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [[32mSUCCESS 1[0m in 4.09s]
[0m12:54:40.551898 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [[32mSUCCESS 1[0m in 4.10s]
[0m12:54:40.560162 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_origin
[0m12:54:40.560987 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_destination
[0m12:54:40.566393 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:54:40.567024 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:54:40.568664 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:54:40.569469 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_origin' was properly closed.
[0m12:54:40.569462 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:54:40.570141 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m12:54:40.570318 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_destination' was properly closed.
[0m12:54:40.570924 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m12:54:40.570901 [info ] [MainThread]: 
[0m12:54:40.571707 [info ] [MainThread]: 
[0m12:54:40.572742 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 8.77 seconds (8.77s).
[0m12:54:40.572814 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 8.64 seconds (8.64s).
[0m12:54:40.574393 [debug] [MainThread]: Command end result
[0m12:54:40.575444 [debug] [MainThread]: Command end result
[0m12:54:40.603839 [info ] [MainThread]: 
[0m12:54:40.606000 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:54:40.607666 [info ] [MainThread]: 
[0m12:54:40.609329 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m12:54:40.610262 [info ] [MainThread]: 
[0m12:54:40.610931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f545ec81190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f545ec80ce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f545ec816a0>]}
[0m12:54:40.611873 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:54:40.612841 [debug] [MainThread]: Flushing usage events
[0m12:54:40.613005 [info ] [MainThread]: 
[0m12:54:40.614097 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m12:54:40.615534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f876950e840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f874284f8c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8741868710>]}
[0m12:54:40.616663 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 12:54:58.113414 | b4c22b8e-c117-42ce-8b08-f9f5d6ac11fa ==============================
[0m12:54:58.113414 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:54:58.122085 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_flight_status'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m12:54:58.123460 [debug] [MainThread]: Tracking: tracking
[0m12:54:58.124775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e613f2f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e614eae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d8c584d0>]}
[0m12:54:58.264047 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:54:58.264894 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:54:58.286149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b4c22b8e-c117-42ce-8b08-f9f5d6ac11fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e612de50>]}
[0m12:54:58.311147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b4c22b8e-c117-42ce-8b08-f9f5d6ac11fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d8bf8d10>]}
[0m12:54:58.312624 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m12:54:58.313864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b4c22b8e-c117-42ce-8b08-f9f5d6ac11fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d90105c0>]}
[0m12:54:58.318777 [info ] [MainThread]: 
[0m12:54:58.323916 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:54:58.327656 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m12:54:58.401628 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m12:54:58.402796 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m12:54:58.403634 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:55:00.310459 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m12:55:00.315431 [debug] [ThreadPool]: On list_GP: Close
[0m12:55:00.722878 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:55:00.724910 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:55:00.725953 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m12:55:00.751646 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m12:55:00.752830 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m12:55:00.753566 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:55:01.639767 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:55:01.643659 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m12:55:02.053012 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:55:02.060534 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:55:02.101988 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m12:55:02.112758 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m12:55:02.117057 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:55:02.118548 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:55:02.120131 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:55:02.129656 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:55:03.073274 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m12:55:03.082492 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m12:55:03.083877 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m12:55:03.089088 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:55:03.490616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b4c22b8e-c117-42ce-8b08-f9f5d6ac11fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d8fc0710>]}
[0m12:55:03.494914 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:55:03.497641 [info ] [MainThread]: 
[0m12:55:03.591948 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_flight_status
[0m12:55:03.593815 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [RUN]
[0m12:55:03.596363 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_flight_status'
[0m12:55:03.597337 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_flight_status
[0m12:55:03.610532 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_flight_status"
[0m12:55:03.612581 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (compile): 2025-11-26 12:55:03.600030 => 2025-11-26 12:55:03.612185
[0m12:55:03.613467 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_flight_status
[0m12:55:03.799440 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_flight_status"
[0m12:55:03.803116 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m12:55:03.804061 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  as
        (
with distinct_values as(
    select distinct CANCELLATION_REASON,is_cancelled,is_diverted
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select 
row_number() over(order by is_cancelled) as status_id,
CANCELLATION_REASON,
is_cancelled,
is_diverted
from distinct_values
        );
[0m12:55:03.805024 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:55:05.427745 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m12:55:05.448509 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m12:55:05.449191 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status__dbt_tmp cascade
[0m12:55:05.650937 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m12:55:05.694587 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (execute): 2025-11-26 12:55:03.613927 => 2025-11-26 12:55:05.694461
[0m12:55:05.695134 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: Close
[0m12:55:06.149238 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b4c22b8e-c117-42ce-8b08-f9f5d6ac11fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d80cfc80>]}
[0m12:55:06.151220 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [[32mSUCCESS 1[0m in 2.55s]
[0m12:55:06.157447 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_flight_status
[0m12:55:06.162389 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:55:06.164145 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:55:06.164680 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m12:55:06.165062 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_flight_status' was properly closed.
[0m12:55:06.165595 [info ] [MainThread]: 
[0m12:55:06.166173 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.85 seconds (7.85s).
[0m12:55:06.166865 [debug] [MainThread]: Command end result
[0m12:55:06.189490 [info ] [MainThread]: 
[0m12:55:06.190439 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:55:06.191238 [info ] [MainThread]: 
[0m12:55:06.192261 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m12:55:06.193403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96e61c5010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d9fa5f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d3f0af00>]}
[0m12:55:06.194294 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 12:55:21.810127 | 4a8b8096-203c-41ef-8012-c082fd692c8a ==============================
[0m12:55:21.810127 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:55:21.817872 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['fact_flights'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m12:55:21.819173 [debug] [MainThread]: Tracking: tracking
[0m12:55:21.820173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef90dcb620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefa33e7560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef90e9d640>]}
[0m12:55:21.957956 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:55:21.958985 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:55:21.988103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4a8b8096-203c-41ef-8012-c082fd692c8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef914e0440>]}
[0m12:55:22.027724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4a8b8096-203c-41ef-8012-c082fd692c8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef908d1100>]}
[0m12:55:22.029612 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m12:55:22.030839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4a8b8096-203c-41ef-8012-c082fd692c8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef909351f0>]}
[0m12:55:22.038501 [info ] [MainThread]: 
[0m12:55:22.046581 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:55:22.051837 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m12:55:22.116336 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m12:55:22.117663 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m12:55:22.118520 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:55:23.872537 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m12:55:23.876623 [debug] [ThreadPool]: On list_GP: Close
[0m12:55:24.373733 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:55:24.374898 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:55:24.375519 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m12:55:24.389165 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m12:55:24.389810 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m12:55:24.390323 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:55:25.296508 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:55:25.300996 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m12:55:25.815083 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:55:25.824306 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:55:25.878819 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:55:25.883188 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m12:55:25.884325 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:55:25.885959 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m12:55:25.887944 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:55:25.889319 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:55:26.952840 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m12:55:26.956427 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m12:55:26.964848 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m12:55:26.970259 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:55:27.462602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4a8b8096-203c-41ef-8012-c082fd692c8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef90c3e660>]}
[0m12:55:27.465542 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:55:27.466738 [info ] [MainThread]: 
[0m12:55:27.558807 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.fact_flights
[0m12:55:27.560724 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [RUN]
[0m12:55:27.564723 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.fact_flights'
[0m12:55:27.566766 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.fact_flights
[0m12:55:27.587442 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.fact_flights"
[0m12:55:27.589208 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (compile): 2025-11-26 12:55:27.567648 => 2025-11-26 12:55:27.588910
[0m12:55:27.590200 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.fact_flights
[0m12:55:27.831133 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.fact_flights"
[0m12:55:27.840119 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m12:55:27.841055 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  as
        (
select
d_date.date_id as date_id,
sdt.time_id as Scheduled_Departure_Time_id,
adt.time_id as Actual_Departure_Time_id,
wot.time_id as Wheels_Off_Time_id,
wot2.time_id as Wheels_On_Time_id,
sat.time_id as Scheduled_Arrival_Time_id,
aat.time_id as Actual_Arrival_Time_id,
origin.origin_id as origin_id,
dest.destination_id as destination_id, 
fl_stat.status_id as status_id,
AIRLINE_CODE,
FLIGHT_NUMBER,
Departure_Delay,
Taxi_Out_Time,
Taxi_In_Time,
Arrival_Delay,
Scheduled_Flight_Duration,
Actual_Flight_Duration,
Air_Time,
Distance,
Carrier_Delay,
Weather_Delay,
NAS_Delay,
Security_Delay,
Late_Aircraft_Delay
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status as stg 
left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date as d_date
on stg.flight_date=d_date.date_day

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sdt
on stg.Scheduled_Departure_Time=sdt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as adt 
on stg.Actual_Departure_Time=adt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot
on stg.Wheels_Off_Time=wot.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot2 
on stg.Wheels_On_Time=wot2.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sat
on stg.Scheduled_Arrival_Time=sat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as aat
on stg.Actual_Arrival_Time=aat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin as origin
on origin.city=stg.origin_city and origin.state=stg.origin_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination as dest
on dest.city=stg.destination_city and dest.state=stg.destination_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status as fl_stat 
on stg.IS_CANCELLED=fl_stat.IS_CANCELLED and stg.IS_DIVERTED=fl_stat.IS_DIVERTED
        );
[0m12:55:27.841727 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:55:30.527526 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m12:55:30.561345 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m12:55:30.562377 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights__dbt_tmp cascade
[0m12:55:30.824417 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m12:55:30.913159 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (execute): 2025-11-26 12:55:27.590828 => 2025-11-26 12:55:30.912906
[0m12:55:30.914181 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: Close
[0m12:55:31.546115 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a8b8096-203c-41ef-8012-c082fd692c8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef905077a0>]}
[0m12:55:31.548018 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [[32mSUCCESS 1[0m in 3.98s]
[0m12:55:31.553384 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.fact_flights
[0m12:55:31.559619 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:55:31.562589 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:55:31.563797 [debug] [MainThread]: Connection 'model.airflow_dbt_project.fact_flights' was properly closed.
[0m12:55:31.564841 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m12:55:31.566016 [info ] [MainThread]: 
[0m12:55:31.567834 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 9.53 seconds (9.53s).
[0m12:55:31.569502 [debug] [MainThread]: Command end result
[0m12:55:31.611279 [info ] [MainThread]: 
[0m12:55:31.612782 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:55:31.614127 [info ] [MainThread]: 
[0m12:55:31.615175 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m12:55:31.616456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef905cc110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef905cd7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef905cec00>]}
[0m12:55:31.617551 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 12:55:46.930240 | 2fe5ea19-9c32-41f2-8935-ad8b41b00db8 ==============================
[0m12:55:46.930240 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:55:46.934220 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m12:55:46.934657 [debug] [MainThread]: Tracking: tracking
[0m12:55:46.935080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcad60b09e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcad60b0a40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcad60b0ad0>]}
[0m12:55:46.990378 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:55:46.990890 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:55:47.004349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2fe5ea19-9c32-41f2-8935-ad8b41b00db8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcad604cf80>]}
[0m12:55:47.021468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2fe5ea19-9c32-41f2-8935-ad8b41b00db8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcadc0e6ba0>]}
[0m12:55:47.022198 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m12:55:47.022694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2fe5ea19-9c32-41f2-8935-ad8b41b00db8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcad6564470>]}
[0m12:55:47.026085 [info ] [MainThread]: 
[0m12:55:47.029624 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:55:47.032316 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:55:47.039185 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:55:47.078513 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:55:47.079307 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m12:55:47.079805 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:55:47.080230 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m12:55:47.080684 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:55:47.081081 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:55:48.635870 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m12:55:48.639367 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:55:48.671218 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m12:55:48.674702 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m12:55:49.041567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2fe5ea19-9c32-41f2-8935-ad8b41b00db8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcadc0e6300>]}
[0m12:55:49.043604 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:55:49.044337 [info ] [MainThread]: 
[0m12:55:49.090398 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m12:55:49.091067 [info ] [Thread-1 (]: 1 of 17 START test is_positive_fact_flights_CARRIER_DELAY ...................... [RUN]
[0m12:55:49.092120 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m12:55:49.093166 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec'
[0m12:55:49.093655 [info ] [Thread-2 (]: 2 of 17 START test is_positive_fact_flights_LATE_AIRCRAFT_DELAY ................ [RUN]
[0m12:55:49.094238 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m12:55:49.095202 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa'
[0m12:55:49.105990 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m12:55:49.117298 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m12:55:49.119156 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m12:55:49.120053 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (compile): 2025-11-26 12:55:49.111889 => 2025-11-26 12:55:49.119905
[0m12:55:49.120517 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m12:55:49.126503 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (compile): 2025-11-26 12:55:49.095535 => 2025-11-26 12:55:49.126293
[0m12:55:49.132449 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m12:55:49.186684 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m12:55:49.186155 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m12:55:49.188386 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m12:55:49.189281 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m12:55:49.189589 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where CARRIER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m12:55:49.189893 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where LATE_AIRCRAFT_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m12:55:49.190197 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:55:49.190485 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:55:51.154319 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m12:55:51.166017 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (execute): 2025-11-26 12:55:49.138146 => 2025-11-26 12:55:51.165862
[0m12:55:51.167477 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: Close
[0m12:55:51.168603 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m12:55:51.173734 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (execute): 2025-11-26 12:55:49.120793 => 2025-11-26 12:55:51.173619
[0m12:55:51.175081 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: Close
[0m12:55:51.571865 [info ] [Thread-2 (]: 2 of 17 PASS is_positive_fact_flights_LATE_AIRCRAFT_DELAY ...................... [[32mPASS[0m in 2.48s]
[0m12:55:51.574529 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m12:55:51.575069 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m12:55:51.575414 [info ] [Thread-2 (]: 3 of 17 START test is_positive_fact_flights_NAS_DELAY .......................... [RUN]
[0m12:55:51.576330 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3'
[0m12:55:51.576654 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m12:55:51.584171 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m12:55:51.584943 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (compile): 2025-11-26 12:55:51.577127 => 2025-11-26 12:55:51.584804
[0m12:55:51.585390 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m12:55:51.589386 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m12:55:51.590792 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m12:55:51.591241 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where NAS_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m12:55:51.591569 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:55:52.044647 [info ] [Thread-1 (]: 1 of 17 PASS is_positive_fact_flights_CARRIER_DELAY ............................ [[32mPASS[0m in 2.95s]
[0m12:55:52.045607 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m12:55:52.046325 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m12:55:52.046999 [info ] [Thread-1 (]: 4 of 17 START test is_positive_fact_flights_SECURITY_DELAY ..................... [RUN]
[0m12:55:52.048483 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384'
[0m12:55:52.049014 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m12:55:52.057791 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m12:55:52.058720 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (compile): 2025-11-26 12:55:52.049381 => 2025-11-26 12:55:52.058574
[0m12:55:52.059238 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m12:55:52.067103 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m12:55:52.068964 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m12:55:52.069513 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where SECURITY_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m12:55:52.069918 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:55:52.694988 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:55:52.699440 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (execute): 2025-11-26 12:55:51.585651 => 2025-11-26 12:55:52.699280
[0m12:55:52.700012 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: Close
[0m12:55:52.952657 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:55:52.956850 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (execute): 2025-11-26 12:55:52.059527 => 2025-11-26 12:55:52.956704
[0m12:55:52.957388 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: Close
[0m12:55:53.254865 [info ] [Thread-2 (]: 3 of 17 PASS is_positive_fact_flights_NAS_DELAY ................................ [[32mPASS[0m in 1.68s]
[0m12:55:53.255844 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m12:55:53.256647 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m12:55:53.257350 [info ] [Thread-2 (]: 5 of 17 START test is_positive_fact_flights_TAXI_IN_TIME ....................... [RUN]
[0m12:55:53.258823 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c'
[0m12:55:53.259386 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m12:55:53.268821 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m12:55:53.270081 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (compile): 2025-11-26 12:55:53.259723 => 2025-11-26 12:55:53.269883
[0m12:55:53.270689 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m12:55:53.276359 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m12:55:53.278256 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m12:55:53.278970 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_IN_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m12:55:53.279421 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:55:53.430017 [info ] [Thread-1 (]: 4 of 17 PASS is_positive_fact_flights_SECURITY_DELAY ........................... [[32mPASS[0m in 1.38s]
[0m12:55:53.431020 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m12:55:53.432099 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m12:55:53.432674 [info ] [Thread-1 (]: 6 of 17 START test is_positive_fact_flights_TAXI_OUT_TIME ...................... [RUN]
[0m12:55:53.433967 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da'
[0m12:55:53.434489 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m12:55:53.444992 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m12:55:53.446430 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (compile): 2025-11-26 12:55:53.435002 => 2025-11-26 12:55:53.446229
[0m12:55:53.447137 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m12:55:53.452318 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m12:55:53.454738 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m12:55:53.455276 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_OUT_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m12:55:53.455779 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:55:54.398801 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:55:54.403647 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (execute): 2025-11-26 12:55:53.271090 => 2025-11-26 12:55:54.403474
[0m12:55:54.404342 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: Close
[0m12:55:54.434586 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:55:54.439688 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (execute): 2025-11-26 12:55:53.447527 => 2025-11-26 12:55:54.439500
[0m12:55:54.440471 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: Close
[0m12:55:54.889176 [info ] [Thread-1 (]: 6 of 17 PASS is_positive_fact_flights_TAXI_OUT_TIME ............................ [[32mPASS[0m in 1.46s]
[0m12:55:54.891824 [info ] [Thread-2 (]: 5 of 17 PASS is_positive_fact_flights_TAXI_IN_TIME ............................. [[32mPASS[0m in 1.63s]
[0m12:55:54.893063 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m12:55:54.894060 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m12:55:54.894943 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m12:55:54.895777 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m12:55:54.896701 [info ] [Thread-1 (]: 7 of 17 START test is_positive_fact_flights_WEATHER_DELAY ...................... [RUN]
[0m12:55:54.897452 [info ] [Thread-2 (]: 8 of 17 START test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m12:55:54.898722 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474'
[0m12:55:54.899900 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9'
[0m12:55:54.900462 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m12:55:54.901119 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m12:55:54.910640 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m12:55:54.934669 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m12:55:54.935474 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (compile): 2025-11-26 12:55:54.901583 => 2025-11-26 12:55:54.935238
[0m12:55:54.936461 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m12:55:54.942882 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m12:55:54.943831 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (compile): 2025-11-26 12:55:54.911418 => 2025-11-26 12:55:54.943535
[0m12:55:54.945267 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m12:55:54.951443 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m12:55:54.953057 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m12:55:54.953978 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where WEATHER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m12:55:54.954557 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:55:54.959306 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m12:55:54.961236 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m12:55:54.961914 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:55:55.970892 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:55:55.978441 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (execute): 2025-11-26 12:55:54.936994 => 2025-11-26 12:55:55.978180
[0m12:55:55.979475 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: Close
[0m12:55:56.227517 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:55:56.236866 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (execute): 2025-11-26 12:55:54.945915 => 2025-11-26 12:55:56.236568
[0m12:55:56.237937 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: Close
[0m12:55:56.424923 [info ] [Thread-1 (]: 7 of 17 PASS is_positive_fact_flights_WEATHER_DELAY ............................ [[32mPASS[0m in 1.53s]
[0m12:55:56.426247 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m12:55:56.427157 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m12:55:56.428228 [info ] [Thread-1 (]: 9 of 17 START test relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m12:55:56.434330 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079'
[0m12:55:56.435248 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m12:55:56.454612 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m12:55:56.455775 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (compile): 2025-11-26 12:55:56.436185 => 2025-11-26 12:55:56.455603
[0m12:55:56.456490 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m12:55:56.462761 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m12:55:56.465731 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m12:55:56.466359 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m12:55:56.466818 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:55:56.613401 [info ] [Thread-2 (]: 8 of 17 PASS relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.71s]
[0m12:55:56.614206 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m12:55:56.614953 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m12:55:56.615744 [info ] [Thread-2 (]: 10 of 17 START test relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m12:55:56.617389 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608'
[0m12:55:56.617917 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m12:55:56.630123 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m12:55:56.631139 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (compile): 2025-11-26 12:55:56.618274 => 2025-11-26 12:55:56.630983
[0m12:55:56.631631 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m12:55:56.636439 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m12:55:56.639272 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m12:55:56.639745 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m12:55:56.640105 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:55:57.396878 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:55:57.403376 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (execute): 2025-11-26 12:55:56.456932 => 2025-11-26 12:55:57.403196
[0m12:55:57.404095 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: Close
[0m12:55:57.653565 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:55:57.657908 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (execute): 2025-11-26 12:55:56.631911 => 2025-11-26 12:55:57.657719
[0m12:55:57.658666 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: Close
[0m12:55:57.757121 [info ] [Thread-1 (]: 9 of 17 PASS relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.32s]
[0m12:55:57.757887 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m12:55:57.758517 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m12:55:57.759076 [info ] [Thread-1 (]: 11 of 17 START test relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m12:55:57.760262 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932'
[0m12:55:57.760739 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m12:55:57.774090 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m12:55:57.775305 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (compile): 2025-11-26 12:55:57.761049 => 2025-11-26 12:55:57.775124
[0m12:55:57.775958 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m12:55:57.780440 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m12:55:57.783064 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m12:55:57.783618 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m12:55:57.784017 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:55:58.023100 [info ] [Thread-2 (]: 10 of 17 PASS relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.41s]
[0m12:55:58.024018 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m12:55:58.024744 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m12:55:58.025641 [info ] [Thread-2 (]: 12 of 17 START test relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [RUN]
[0m12:55:58.027092 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5'
[0m12:55:58.027676 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m12:55:58.040272 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m12:55:58.041235 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (compile): 2025-11-26 12:55:58.027995 => 2025-11-26 12:55:58.041101
[0m12:55:58.041797 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m12:55:58.045972 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m12:55:58.048208 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m12:55:58.048669 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_Off_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_Off_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m12:55:58.049087 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:55:58.692630 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:55:58.705060 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (execute): 2025-11-26 12:55:57.776330 => 2025-11-26 12:55:58.704762
[0m12:55:58.707982 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: Close
[0m12:55:59.001476 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:55:59.009726 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (execute): 2025-11-26 12:55:58.042140 => 2025-11-26 12:55:59.009403
[0m12:55:59.010974 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: Close
[0m12:55:59.191677 [info ] [Thread-1 (]: 11 of 17 PASS relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.43s]
[0m12:55:59.193198 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m12:55:59.194366 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m12:55:59.195555 [info ] [Thread-1 (]: 13 of 17 START test relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [RUN]
[0m12:55:59.197837 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850'
[0m12:55:59.198651 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m12:55:59.229894 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m12:55:59.233891 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (compile): 2025-11-26 12:55:59.199214 => 2025-11-26 12:55:59.233502
[0m12:55:59.235434 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m12:55:59.244730 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m12:55:59.248395 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m12:55:59.249228 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_On_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_On_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m12:55:59.249876 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:55:59.415700 [info ] [Thread-2 (]: 12 of 17 PASS relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.39s]
[0m12:55:59.417080 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m12:55:59.418137 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m12:55:59.419070 [info ] [Thread-2 (]: 14 of 17 START test relationships_fact_flights_date_id__date_id__ref_dim_date_ . [RUN]
[0m12:55:59.420595 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9'
[0m12:55:59.421210 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m12:55:59.436367 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m12:55:59.437965 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (compile): 2025-11-26 12:55:59.421774 => 2025-11-26 12:55:59.437760
[0m12:55:59.438793 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m12:55:59.444184 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m12:55:59.446752 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m12:55:59.447362 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select date_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where date_id is not null
),

parent as (
    select date_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m12:55:59.447749 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:56:00.280073 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:56:00.287552 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (execute): 2025-11-26 12:55:59.236371 => 2025-11-26 12:56:00.287292
[0m12:56:00.288555 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: Close
[0m12:56:00.727815 [info ] [Thread-1 (]: 13 of 17 PASS relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.53s]
[0m12:56:00.728969 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m12:56:00.729973 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m12:56:00.731522 [info ] [Thread-1 (]: 15 of 17 START test relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [RUN]
[0m12:56:00.733278 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5'
[0m12:56:00.734150 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m12:56:00.754542 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m12:56:00.755845 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (compile): 2025-11-26 12:56:00.734859 => 2025-11-26 12:56:00.755652
[0m12:56:00.756627 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m12:56:00.761927 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m12:56:00.764501 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m12:56:00.765172 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select destination_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where destination_id is not null
),

parent as (
    select destination_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m12:56:00.765707 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:56:01.327937 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m12:56:01.335697 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (execute): 2025-11-26 12:55:59.439250 => 2025-11-26 12:56:01.335405
[0m12:56:01.336794 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: Close
[0m12:56:01.752295 [info ] [Thread-2 (]: 14 of 17 PASS relationships_fact_flights_date_id__date_id__ref_dim_date_ ....... [[32mPASS[0m in 2.33s]
[0m12:56:01.753800 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m12:56:01.754904 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m12:56:01.755675 [info ] [Thread-2 (]: 16 of 17 START test relationships_fact_flights_origin_id__origin_id__ref_dim_origin_  [RUN]
[0m12:56:01.757822 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24'
[0m12:56:01.759306 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m12:56:01.782207 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m12:56:01.783753 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (compile): 2025-11-26 12:56:01.759829 => 2025-11-26 12:56:01.783523
[0m12:56:01.784740 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m12:56:01.792513 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m12:56:01.796545 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m12:56:01.797744 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select origin_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where origin_id is not null
),

parent as (
    select origin_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m12:56:01.801309 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:56:01.803933 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:56:01.819642 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (execute): 2025-11-26 12:56:00.757106 => 2025-11-26 12:56:01.819356
[0m12:56:01.820877 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: Close
[0m12:56:02.265210 [info ] [Thread-1 (]: 15 of 17 PASS relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [[32mPASS[0m in 1.53s]
[0m12:56:02.267789 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m12:56:02.269894 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m12:56:02.271155 [info ] [Thread-1 (]: 17 of 17 START test relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [RUN]
[0m12:56:02.274141 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa'
[0m12:56:02.277933 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m12:56:02.331057 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m12:56:02.345093 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (compile): 2025-11-26 12:56:02.290104 => 2025-11-26 12:56:02.344738
[0m12:56:02.346270 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m12:56:02.356148 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m12:56:02.360146 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m12:56:02.361019 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select status_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where status_id is not null
),

parent as (
    select status_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m12:56:02.361647 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:56:02.878369 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:56:02.884192 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (execute): 2025-11-26 12:56:01.785394 => 2025-11-26 12:56:02.884018
[0m12:56:02.884813 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: Close
[0m12:56:03.288070 [info ] [Thread-2 (]: 16 of 17 PASS relationships_fact_flights_origin_id__origin_id__ref_dim_origin_ . [[32mPASS[0m in 1.53s]
[0m12:56:03.289918 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m12:56:03.489864 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:56:03.497779 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (execute): 2025-11-26 12:56:02.346945 => 2025-11-26 12:56:03.497502
[0m12:56:03.498801 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: Close
[0m12:56:03.903332 [info ] [Thread-1 (]: 17 of 17 PASS relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [[32mPASS[0m in 1.63s]
[0m12:56:03.904857 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m12:56:03.911067 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:56:03.913619 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:56:03.914558 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24' was properly closed.
[0m12:56:03.915843 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa' was properly closed.
[0m12:56:03.917413 [info ] [MainThread]: 
[0m12:56:03.919638 [info ] [MainThread]: Finished running 17 tests in 0 hours 0 minutes and 16.89 seconds (16.89s).
[0m12:56:03.924020 [debug] [MainThread]: Command end result
[0m12:56:03.959131 [info ] [MainThread]: 
[0m12:56:03.960808 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:56:03.962247 [info ] [MainThread]: 
[0m12:56:03.963705 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=0 SKIP=0 TOTAL=17
[0m12:56:03.965154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcad5dba780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcad5dbb1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcad5db9e20>]}
[0m12:56:03.966197 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 12:59:25.980674 | 2c6df8bd-e36d-49d8-9375-c8c934ce81ba ==============================
[0m12:59:25.980674 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:59:25.985982 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'source-freshness', 'rpc_method': 'source-freshness', 'indirect_selection': 'eager'}
[0m12:59:25.986720 [debug] [MainThread]: Tracking: tracking
[0m12:59:25.987583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e605651f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e87711640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e759ea660>]}
[0m12:59:26.087106 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:59:26.087850 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:59:26.112624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c6df8bd-e36d-49d8-9375-c8c934ce81ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e8219ef00>]}
[0m12:59:26.150183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c6df8bd-e36d-49d8-9375-c8c934ce81ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e6db1d6d0>]}
[0m12:59:26.151221 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m12:59:26.152052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c6df8bd-e36d-49d8-9375-c8c934ce81ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e618e4260>]}
[0m12:59:26.156841 [info ] [MainThread]: 
[0m12:59:26.162699 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:59:26.167320 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:59:26.175480 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:59:26.281730 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m12:59:26.280800 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:59:26.283958 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m12:59:26.287588 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:59:26.288768 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:59:26.289866 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:59:28.009098 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m12:59:28.015347 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:59:28.028441 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m12:59:28.037767 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m12:59:28.503342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c6df8bd-e36d-49d8-9375-c8c934ce81ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e60a0be60>]}
[0m12:59:28.504794 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:59:28.505485 [info ] [MainThread]: 
[0m12:59:28.554225 [debug] [Thread-1 (]: Began running node source.airflow_dbt_project.raw_data.flights
[0m12:59:28.554822 [info ] [Thread-1 (]: 1 of 1 START freshness of raw_data.flights ..................................... [RUN]
[0m12:59:28.556174 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m12:59:28.556730 [debug] [Thread-1 (]: Began compiling node source.airflow_dbt_project.raw_data.flights
[0m12:59:28.557318 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (compile): 2025-11-26 12:59:28.557116 => 2025-11-26 12:59:28.557137
[0m12:59:28.557958 [debug] [Thread-1 (]: Began executing node source.airflow_dbt_project.raw_data.flights
[0m12:59:28.559246 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m12:59:28.579801 [debug] [Thread-1 (]: Using snowflake connection "source.airflow_dbt_project.raw_data.flights"
[0m12:59:28.580353 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "source.airflow_dbt_project.raw_data.flights"} */
select
      max(INGESTION_TIME) as max_loaded_at,
      convert_timezone('UTC', current_timestamp()) as snapshotted_at
    from GP.RAW.flights
[0m12:59:28.580737 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:59:29.570831 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:59:29.577239 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: Close
[0m12:59:30.039770 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (execute): 2025-11-26 12:59:28.558347 => 2025-11-26 12:59:30.039375
[0m12:59:30.043728 [info ] [Thread-1 (]: 1 of 1 PASS freshness of raw_data.flights ...................................... [[32mPASS[0m in 1.49s]
[0m12:59:30.052135 [debug] [Thread-1 (]: Finished running node source.airflow_dbt_project.raw_data.flights
[0m12:59:30.056899 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:59:30.058004 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m12:59:30.058853 [debug] [MainThread]: Connection 'source.airflow_dbt_project.raw_data.flights' was properly closed.
[0m12:59:30.086748 [info ] [MainThread]: Done.
[0m12:59:30.088416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e60169d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e60169d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e60168470>]}
[0m12:59:30.089506 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 12:59:44.356946 | d98f7f1c-c856-48f3-81a5-ee7a6ad8f53f ==============================
[0m12:59:44.356946 [info ] [MainThread]: Running with dbt=1.4.0
[0m12:59:44.359024 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['staging.*'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m12:59:44.359359 [debug] [MainThread]: Tracking: tracking
[0m12:59:44.359704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2621988590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f260b56c560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f260bac7980>]}
[0m12:59:44.399801 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:59:44.400203 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:59:44.410057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd98f7f1c-c856-48f3-81a5-ee7a6ad8f53f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2610deddc0>]}
[0m12:59:44.423317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd98f7f1c-c856-48f3-81a5-ee7a6ad8f53f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f260b5b1280>]}
[0m12:59:44.423854 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m12:59:44.424301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd98f7f1c-c856-48f3-81a5-ee7a6ad8f53f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f260bf844d0>]}
[0m12:59:44.426548 [info ] [MainThread]: 
[0m12:59:44.429425 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:59:44.431182 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m12:59:44.454966 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m12:59:44.455441 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m12:59:44.455797 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:59:45.801375 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m12:59:45.804521 [debug] [ThreadPool]: On list_GP: Close
[0m12:59:46.208374 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:59:46.209442 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:59:46.209970 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging', identifier=None)"
[0m12:59:46.221283 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:59:46.221815 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:59:46.222202 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:59:47.232749 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m12:59:47.235272 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:59:47.661173 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m12:59:47.666525 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m12:59:47.679961 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m12:59:47.680366 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m12:59:47.680622 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:59:47.684836 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m12:59:47.685221 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m12:59:47.685545 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:59:48.719179 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m12:59:48.726856 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m12:59:48.753485 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m12:59:48.761681 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m12:59:49.154304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd98f7f1c-c856-48f3-81a5-ee7a6ad8f53f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2636886c30>]}
[0m12:59:49.155510 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m12:59:49.156011 [info ] [MainThread]: 
[0m12:59:49.187988 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_flight_status
[0m12:59:49.188785 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [RUN]
[0m12:59:49.190490 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_flight_status'
[0m12:59:49.190913 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_flight_status
[0m12:59:49.205848 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_flight_status"
[0m12:59:49.206554 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (compile): 2025-11-26 12:59:49.191216 => 2025-11-26 12:59:49.206384
[0m12:59:49.206909 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_flight_status
[0m12:59:49.270083 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_flight_status"
[0m12:59:49.275090 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_flight_status"
[0m12:59:49.275664 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_flight_status"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
  
   as (
    select 
    DATE_FROM_PARTS(year, month, day_of_month) AS flight_date,
    
    lower(op_unique_carrier)
 as Airline_Code,
    op_carrier_fl_num::INT as Flight_Number,
    
    lower(origin)
 as Origin_Airport_Code,
    
    lower(origin_city_name)
 as Origin_City,
    
    lower(origin_state_nm)
 as Origin_State,
    
    lower(dest)
 as Destination_Airport_Code,
    
    lower(dest_city_name)
 as Destination_City,
    
    lower(dest_state_nm)
 as Destination_State,
    crs_dep_time::INT as Scheduled_Departure_Time,
    dep_time::INT as Actual_Departure_Time,
    dep_delay::INT as Departure_Delay,
    taxi_out::INT as Taxi_Out_Time,
    wheels_off::INT as Wheels_Off_Time,
    wheels_on::INT as Wheels_On_Time,
    taxi_in::INT as Taxi_In_Time,
    crs_arr_time::INT as Scheduled_Arrival_Time,
    arr_time::INT as Actual_Arrival_Time,
    arr_delay::INT as Arrival_Delay,
    CASE cancelled WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_cancelled,
    CASE cancellation_code WHEN 'A' THEN 'Carrier'  WHEN 'B' THEN 'Weather'  WHEN 'C' THEN 'National Air System'  WHEN 'D' THEN 'Security'  ELSE 'still available' END as Cancellation_Reason,
    CASE diverted WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_diverted,
    crs_elapsed_time::INT as Scheduled_Flight_Duration,
    actual_elapsed_time::INT as Actual_Flight_Duration,
    air_time,
    distance,
    carrier_delay,
    weather_delay,
    nas_delay,
    security_delay,
    late_aircraft_delay,
    isDelete,
    CASE operation WHEN 'c' THEN 'Create'  WHEN 'u' THEN 'Update'  WHEN 'd' THEN 'Delete'  WHEN 'r' THEN 'Snapshot'  ELSE 'Unknown' END as operation_type,
    TO_TIMESTAMP_LTZ(event_time / 1000) as event_time,
    ingestion_time  as ingestion_datetime
from GP.RAW.flights
  );
[0m12:59:49.275982 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:59:50.304192 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m12:59:50.374974 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (execute): 2025-11-26 12:59:49.207120 => 2025-11-26 12:59:50.374688
[0m12:59:50.376108 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: Close
[0m12:59:50.816762 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd98f7f1c-c856-48f3-81a5-ee7a6ad8f53f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f260bc86ea0>]}
[0m12:59:50.818027 [info ] [Thread-1 (]: 1 of 1 OK created sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [[32mSUCCESS 1[0m in 1.63s]
[0m12:59:50.822118 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_flight_status
[0m12:59:50.826954 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:59:50.829381 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:59:50.830207 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_flight_status' was properly closed.
[0m12:59:50.831345 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m12:59:50.832260 [info ] [MainThread]: 
[0m12:59:50.833403 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 6.41 seconds (6.41s).
[0m12:59:50.834958 [debug] [MainThread]: Command end result
[0m12:59:50.856492 [info ] [MainThread]: 
[0m12:59:50.857464 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:59:50.858078 [info ] [MainThread]: 
[0m12:59:50.858607 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m12:59:50.859383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f260b5b3e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f260b5b1370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f260b5b26f0>]}
[0m12:59:50.860067 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 13:00:09.482003 | 6c92c8d2-9e4e-4cdc-b029-2628ce1ef6be ==============================
[0m13:00:09.482003 [info ] [MainThread]: Running with dbt=1.4.0
[0m13:00:09.493445 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_origin'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:00:09.494908 [debug] [MainThread]: Tracking: tracking
[0m13:00:09.496680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bbb308b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb95304d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb95307a0>]}
[0m13:00:09.588777 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:00:09.589576 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:00:09.611591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6c92c8d2-9e4e-4cdc-b029-2628ce1ef6be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb9a3f770>]}
[0m13:00:09.648828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6c92c8d2-9e4e-4cdc-b029-2628ce1ef6be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb9a6cc50>]}
[0m13:00:09.650308 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m13:00:09.651476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c92c8d2-9e4e-4cdc-b029-2628ce1ef6be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb9b48ec0>]}
[0m13:00:09.657367 [info ] [MainThread]: 
[0m13:00:09.665393 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:00:09.669650 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m13:00:09.735618 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m13:00:09.737159 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m13:00:09.738282 [debug] [ThreadPool]: Opening a new connection, currently in state init


============================== 2025-11-26 13:00:09.872472 | cb9e902c-e252-497c-9f85-c21f2f21f08d ==============================
[0m13:00:09.872472 [info ] [MainThread]: Running with dbt=1.4.0
[0m13:00:09.879874 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_destination'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:00:09.880822 [debug] [MainThread]: Tracking: tracking
[0m13:00:09.881961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4322ea5670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4322a70650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f432316c7a0>]}
[0m13:00:10.001120 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:00:10.002222 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:00:10.034094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cb9e902c-e252-497c-9f85-c21f2f21f08d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4328220c50>]}
[0m13:00:10.071153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cb9e902c-e252-497c-9f85-c21f2f21f08d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4322a0cfb0>]}
[0m13:00:10.072856 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m13:00:10.074256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cb9e902c-e252-497c-9f85-c21f2f21f08d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4323758800>]}
[0m13:00:10.080565 [info ] [MainThread]: 
[0m13:00:10.088480 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:00:10.092791 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m13:00:10.171404 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m13:00:10.172858 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m13:00:10.173929 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:00:11.826676 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m13:00:11.831958 [debug] [ThreadPool]: On list_GP: Close
[0m13:00:12.063652 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m13:00:12.067230 [debug] [ThreadPool]: On list_GP: Close
[0m13:00:12.323725 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m13:00:12.326095 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m13:00:12.327389 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m13:00:12.352015 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m13:00:12.353196 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m13:00:12.353979 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:00:12.548689 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m13:00:12.550902 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m13:00:12.551946 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m13:00:12.576593 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m13:00:12.577720 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m13:00:12.578597 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:00:13.462399 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m13:00:13.464684 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m13:00:13.570897 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m13:00:13.574982 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m13:00:13.858958 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m13:00:13.868797 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m13:00:13.915004 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m13:00:13.918832 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m13:00:13.919986 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m13:00:13.921390 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m13:00:13.923018 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:00:13.924142 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:00:13.979808 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m13:00:13.988733 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m13:00:14.034721 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m13:00:14.041162 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m13:00:14.049856 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:00:14.053066 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m13:00:14.059671 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m13:00:14.060811 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:00:14.897694 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m13:00:14.901613 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m13:00:14.913653 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m13:00:14.917505 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m13:00:15.084546 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m13:00:15.089162 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m13:00:15.325668 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m13:00:15.329107 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m13:00:15.499549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c92c8d2-9e4e-4cdc-b029-2628ce1ef6be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb95b1370>]}
[0m13:00:15.502364 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m13:00:15.503522 [info ] [MainThread]: 
[0m13:00:15.587649 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_origin
[0m13:00:15.589516 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [RUN]
[0m13:00:15.594862 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_origin'
[0m13:00:15.596104 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_origin
[0m13:00:15.613916 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_origin"
[0m13:00:15.615885 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (compile): 2025-11-26 13:00:15.596794 => 2025-11-26 13:00:15.615472
[0m13:00:15.617077 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_origin
[0m13:00:15.709462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cb9e902c-e252-497c-9f85-c21f2f21f08d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f432340f7a0>]}
[0m13:00:15.712595 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m13:00:15.713857 [info ] [MainThread]: 
[0m13:00:15.798316 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_destination
[0m13:00:15.800201 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [RUN]
[0m13:00:15.805537 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_destination'
[0m13:00:15.807018 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_destination
[0m13:00:15.824338 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_destination"
[0m13:00:15.826010 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (compile): 2025-11-26 13:00:15.807881 => 2025-11-26 13:00:15.825746
[0m13:00:15.826985 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_destination
[0m13:00:15.862337 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_origin"
[0m13:00:15.865712 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m13:00:15.866644 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  as
        (


with distinct_values as(
    select
    distinct origin_city as city,origin_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as origin_id,
    city,
    state
    from distinct_values


        );
[0m13:00:15.867351 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:00:16.061476 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_destination"
[0m13:00:16.065904 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m13:00:16.066969 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  as
        (


with distinct_values as(
    select
    distinct destination_city as city,destination_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as destination_id,
    city,
    state
    from distinct_values


        );
[0m13:00:16.068301 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:00:17.438534 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:00:17.458614 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m13:00:17.459261 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination__dbt_tmp cascade
[0m13:00:17.469211 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m13:00:17.488232 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m13:00:17.488887 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin__dbt_tmp cascade
[0m13:00:17.678196 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m13:00:17.685221 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m13:00:17.731670 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (execute): 2025-11-26 13:00:15.827616 => 2025-11-26 13:00:17.731520
[0m13:00:17.732417 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: Close
[0m13:00:17.740847 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (execute): 2025-11-26 13:00:15.617763 => 2025-11-26 13:00:17.740682
[0m13:00:17.741550 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: Close
[0m13:00:18.125867 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cb9e902c-e252-497c-9f85-c21f2f21f08d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43227afb60>]}
[0m13:00:18.127541 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [[32mSUCCESS 1[0m in 2.32s]
[0m13:00:18.133192 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_destination
[0m13:00:18.137863 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:00:18.139240 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:00:18.139964 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m13:00:18.140440 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_destination' was properly closed.
[0m13:00:18.140943 [info ] [MainThread]: 
[0m13:00:18.141585 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 8.06 seconds (8.06s).
[0m13:00:18.142405 [debug] [MainThread]: Command end result
[0m13:00:18.165740 [info ] [MainThread]: 
[0m13:00:18.167071 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:00:18.167877 [info ] [MainThread]: 
[0m13:00:18.168807 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:00:18.169962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4322ed6c60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4323d55820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4323f8d8b0>]}
[0m13:00:18.171020 [debug] [MainThread]: Flushing usage events
[0m13:00:18.171618 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c92c8d2-9e4e-4cdc-b029-2628ce1ef6be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb885bf80>]}
[0m13:00:18.173438 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [[32mSUCCESS 1[0m in 2.58s]
[0m13:00:18.180608 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_origin
[0m13:00:18.185581 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:00:18.187470 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:00:18.188124 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m13:00:18.188654 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_origin' was properly closed.
[0m13:00:18.190009 [info ] [MainThread]: 
[0m13:00:18.191842 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 8.53 seconds (8.53s).
[0m13:00:18.193203 [debug] [MainThread]: Command end result
[0m13:00:18.218410 [info ] [MainThread]: 
[0m13:00:18.219557 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:00:18.220398 [info ] [MainThread]: 
[0m13:00:18.221316 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:00:18.222189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb97a8680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bbb34ff50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb9acffe0>]}
[0m13:00:18.222859 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 13:00:32.514372 | 286f3dc1-594e-474e-9db2-cc89d065d80e ==============================
[0m13:00:32.514372 [info ] [MainThread]: Running with dbt=1.4.0
[0m13:00:32.519952 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_flight_status'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:00:32.520496 [debug] [MainThread]: Tracking: tracking
[0m13:00:32.521717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f2bdab020>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f2bdab860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f31366900>]}
[0m13:00:32.598223 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:00:32.598951 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:00:32.615618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '286f3dc1-594e-474e-9db2-cc89d065d80e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f31275610>]}
[0m13:00:32.636086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '286f3dc1-594e-474e-9db2-cc89d065d80e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f2bded250>]}
[0m13:00:32.636832 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m13:00:32.637405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '286f3dc1-594e-474e-9db2-cc89d065d80e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f40188ec0>]}
[0m13:00:32.641177 [info ] [MainThread]: 
[0m13:00:32.645323 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:00:32.648783 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m13:00:32.683895 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m13:00:32.684540 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m13:00:32.684935 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:00:34.555959 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m13:00:34.562659 [debug] [ThreadPool]: On list_GP: Close
[0m13:00:35.058123 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m13:00:35.060664 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m13:00:35.061993 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m13:00:35.087708 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m13:00:35.088825 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m13:00:35.089781 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:00:36.382013 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m13:00:36.384327 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m13:00:36.811555 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m13:00:36.821128 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m13:00:36.881087 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m13:00:36.883688 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m13:00:36.884664 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m13:00:36.885684 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m13:00:36.886615 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:00:36.887474 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:00:38.345565 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m13:00:38.349481 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m13:00:38.356660 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m13:00:38.361172 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m13:00:38.904158 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '286f3dc1-594e-474e-9db2-cc89d065d80e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f2b20f920>]}
[0m13:00:38.906479 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m13:00:38.907520 [info ] [MainThread]: 
[0m13:00:38.965672 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_flight_status
[0m13:00:38.968082 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [RUN]
[0m13:00:38.971545 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_flight_status'
[0m13:00:38.972652 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_flight_status
[0m13:00:38.982141 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_flight_status"
[0m13:00:38.983651 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (compile): 2025-11-26 13:00:38.973604 => 2025-11-26 13:00:38.983435
[0m13:00:38.984419 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_flight_status
[0m13:00:39.150976 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_flight_status"
[0m13:00:39.153085 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m13:00:39.153638 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  as
        (
with distinct_values as(
    select distinct CANCELLATION_REASON,is_cancelled,is_diverted
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select 
row_number() over(order by is_cancelled) as status_id,
CANCELLATION_REASON,
is_cancelled,
is_diverted
from distinct_values
        );
[0m13:00:39.154110 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:00:41.094588 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m13:00:41.125690 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m13:00:41.126774 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status__dbt_tmp cascade
[0m13:00:41.332015 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m13:00:41.426420 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (execute): 2025-11-26 13:00:38.984810 => 2025-11-26 13:00:41.426121
[0m13:00:41.427565 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: Close
[0m13:00:42.300719 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '286f3dc1-594e-474e-9db2-cc89d065d80e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f2bbe6db0>]}
[0m13:00:42.306400 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [[32mSUCCESS 1[0m in 3.33s]
[0m13:00:42.317512 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_flight_status
[0m13:00:42.330305 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:00:42.338280 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:00:42.343237 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m13:00:42.346422 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_flight_status' was properly closed.
[0m13:00:42.348830 [info ] [MainThread]: 
[0m13:00:42.351315 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 9.71 seconds (9.71s).
[0m13:00:42.356805 [debug] [MainThread]: Command end result
[0m13:00:42.469076 [info ] [MainThread]: 
[0m13:00:42.470949 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:00:42.476382 [info ] [MainThread]: 
[0m13:00:42.478350 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:00:42.483632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f30358200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f30618cb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f301871a0>]}
[0m13:00:42.489400 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 13:00:57.478231 | 9e2d7a7c-0b90-4a8e-8248-1ecf76bfc7b4 ==============================
[0m13:00:57.478231 [info ] [MainThread]: Running with dbt=1.4.0
[0m13:00:57.485298 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['fact_flights'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:00:57.486519 [debug] [MainThread]: Tracking: tracking
[0m13:00:57.487550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0164d6fdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0164d447a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0164f42000>]}
[0m13:00:57.615522 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:00:57.616579 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:00:57.645637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9e2d7a7c-0b90-4a8e-8248-1ecf76bfc7b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0165380e00>]}
[0m13:00:57.685376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9e2d7a7c-0b90-4a8e-8248-1ecf76bfc7b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0165243dd0>]}
[0m13:00:57.686820 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m13:00:57.687981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e2d7a7c-0b90-4a8e-8248-1ecf76bfc7b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f016fb3e1b0>]}
[0m13:00:57.694455 [info ] [MainThread]: 
[0m13:00:57.702395 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:00:57.706720 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m13:00:57.768747 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m13:00:57.769803 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m13:00:57.770590 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:00:59.733496 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m13:00:59.740082 [debug] [ThreadPool]: On list_GP: Close
[0m13:01:00.347766 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m13:01:00.349125 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m13:01:00.349680 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m13:01:00.369384 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m13:01:00.372805 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m13:01:00.373924 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:01:01.781803 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m13:01:01.786005 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m13:01:02.261925 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m13:01:02.272012 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m13:01:02.326204 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m13:01:02.329607 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m13:01:02.331075 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m13:01:02.332486 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m13:01:02.334151 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:01:02.335437 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:01:04.446321 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m13:01:04.453855 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m13:01:04.461932 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m13:01:04.475360 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m13:01:06.405736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e2d7a7c-0b90-4a8e-8248-1ecf76bfc7b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0164d9d2e0>]}
[0m13:01:06.409475 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m13:01:06.410999 [info ] [MainThread]: 
[0m13:01:06.499941 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.fact_flights
[0m13:01:06.501967 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [RUN]
[0m13:01:06.505521 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.fact_flights'
[0m13:01:06.506774 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.fact_flights
[0m13:01:06.537945 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.fact_flights"
[0m13:01:06.540492 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (compile): 2025-11-26 13:01:06.509899 => 2025-11-26 13:01:06.540143
[0m13:01:06.542030 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.fact_flights
[0m13:01:06.786743 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.fact_flights"
[0m13:01:06.796285 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m13:01:06.797240 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  as
        (
select
d_date.date_id as date_id,
sdt.time_id as Scheduled_Departure_Time_id,
adt.time_id as Actual_Departure_Time_id,
wot.time_id as Wheels_Off_Time_id,
wot2.time_id as Wheels_On_Time_id,
sat.time_id as Scheduled_Arrival_Time_id,
aat.time_id as Actual_Arrival_Time_id,
origin.origin_id as origin_id,
dest.destination_id as destination_id, 
fl_stat.status_id as status_id,
AIRLINE_CODE,
FLIGHT_NUMBER,
Departure_Delay,
Taxi_Out_Time,
Taxi_In_Time,
Arrival_Delay,
Scheduled_Flight_Duration,
Actual_Flight_Duration,
Air_Time,
Distance,
Carrier_Delay,
Weather_Delay,
NAS_Delay,
Security_Delay,
Late_Aircraft_Delay
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status as stg 
left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date as d_date
on stg.flight_date=d_date.date_day

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sdt
on stg.Scheduled_Departure_Time=sdt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as adt 
on stg.Actual_Departure_Time=adt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot
on stg.Wheels_Off_Time=wot.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot2 
on stg.Wheels_On_Time=wot2.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sat
on stg.Scheduled_Arrival_Time=sat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as aat
on stg.Actual_Arrival_Time=aat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin as origin
on origin.city=stg.origin_city and origin.state=stg.origin_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination as dest
on dest.city=stg.destination_city and dest.state=stg.destination_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status as fl_stat 
on stg.IS_CANCELLED=fl_stat.IS_CANCELLED and stg.IS_DIVERTED=fl_stat.IS_DIVERTED
        );
[0m13:01:06.797908 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:01:13.042869 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 6 seconds
[0m13:01:13.076710 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m13:01:13.077823 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights__dbt_tmp cascade
[0m13:01:14.270273 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:01:14.322694 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (execute): 2025-11-26 13:01:06.543215 => 2025-11-26 13:01:14.322542
[0m13:01:14.323349 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: Close
[0m13:01:14.886668 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e2d7a7c-0b90-4a8e-8248-1ecf76bfc7b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0164218650>]}
[0m13:01:14.887786 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [[32mSUCCESS 1[0m in 8.38s]
[0m13:01:14.892204 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.fact_flights
[0m13:01:14.896704 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:01:14.899187 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:01:14.899873 [debug] [MainThread]: Connection 'model.airflow_dbt_project.fact_flights' was properly closed.
[0m13:01:14.900678 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m13:01:14.901537 [info ] [MainThread]: 
[0m13:01:14.902717 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 17.21 seconds (17.21s).
[0m13:01:14.903781 [debug] [MainThread]: Command end result
[0m13:01:14.922788 [info ] [MainThread]: 
[0m13:01:14.923658 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:01:14.924283 [info ] [MainThread]: 
[0m13:01:14.924793 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:01:14.925424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0164dfb560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0165d57fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f018bfa5910>]}
[0m13:01:14.925949 [debug] [MainThread]: Flushing usage events
[0m13:01:20.293957 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.


============================== 2025-11-26 13:01:35.573847 | e6baef4a-7a0d-43fd-8b80-7851fd7ee91a ==============================
[0m13:01:35.573847 [info ] [MainThread]: Running with dbt=1.4.0
[0m13:01:35.577705 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m13:01:35.578182 [debug] [MainThread]: Tracking: tracking
[0m13:01:35.578677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15b231bb60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15b1c284d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15c6b8c3b0>]}
[0m13:01:35.645024 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:01:35.645615 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:01:35.661917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e6baef4a-7a0d-43fd-8b80-7851fd7ee91a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15b2abef90>]}
[0m13:01:35.683633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e6baef4a-7a0d-43fd-8b80-7851fd7ee91a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15b17890a0>]}
[0m13:01:35.684644 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m13:01:35.685566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e6baef4a-7a0d-43fd-8b80-7851fd7ee91a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15b231bb60>]}
[0m13:01:35.689854 [info ] [MainThread]: 
[0m13:01:35.694808 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:01:35.698184 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m13:01:35.700804 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m13:01:35.794302 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m13:01:35.796819 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m13:01:35.798130 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m13:01:35.799285 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m13:01:35.800623 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:01:35.802424 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:01:37.665552 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m13:01:37.670509 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m13:01:37.677756 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m13:01:37.681648 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m13:01:38.541547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e6baef4a-7a0d-43fd-8b80-7851fd7ee91a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15b1ce6270>]}
[0m13:01:38.543002 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m13:01:38.543627 [info ] [MainThread]: 
[0m13:01:38.589895 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m13:01:38.590850 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m13:01:38.591592 [info ] [Thread-1 (]: 1 of 17 START test is_positive_fact_flights_CARRIER_DELAY ...................... [RUN]
[0m13:01:38.592514 [info ] [Thread-2 (]: 2 of 17 START test is_positive_fact_flights_LATE_AIRCRAFT_DELAY ................ [RUN]
[0m13:01:38.593915 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec'
[0m13:01:38.595127 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa'
[0m13:01:38.595750 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m13:01:38.596560 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m13:01:38.624546 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m13:01:38.622765 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m13:01:38.626106 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (compile): 2025-11-26 13:01:38.597064 => 2025-11-26 13:01:38.625916
[0m13:01:38.626652 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m13:01:38.638769 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (compile): 2025-11-26 13:01:38.607567 => 2025-11-26 13:01:38.638503
[0m13:01:38.639847 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m13:01:38.719789 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m13:01:38.720566 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m13:01:38.722371 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m13:01:38.722865 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where CARRIER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m13:01:38.724106 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m13:01:38.724643 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:01:38.725191 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where LATE_AIRCRAFT_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m13:01:38.728762 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:41.155403 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m13:01:41.156677 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m13:01:41.171560 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (execute): 2025-11-26 13:01:38.627076 => 2025-11-26 13:01:41.171351
[0m13:01:41.175747 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (execute): 2025-11-26 13:01:38.640331 => 2025-11-26 13:01:41.175623
[0m13:01:41.176452 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: Close
[0m13:01:41.177078 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: Close
[0m13:01:41.613995 [info ] [Thread-2 (]: 2 of 17 PASS is_positive_fact_flights_LATE_AIRCRAFT_DELAY ...................... [[32mPASS[0m in 3.02s]
[0m13:01:41.616836 [info ] [Thread-1 (]: 1 of 17 PASS is_positive_fact_flights_CARRIER_DELAY ............................ [[32mPASS[0m in 3.02s]
[0m13:01:41.620747 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m13:01:41.621644 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m13:01:41.622652 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m13:01:41.623974 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m13:01:41.624982 [info ] [Thread-2 (]: 3 of 17 START test is_positive_fact_flights_NAS_DELAY .......................... [RUN]
[0m13:01:41.625962 [info ] [Thread-1 (]: 4 of 17 START test is_positive_fact_flights_SECURITY_DELAY ..................... [RUN]
[0m13:01:41.627477 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3'
[0m13:01:41.628833 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384'
[0m13:01:41.629517 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m13:01:41.630294 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m13:01:41.644993 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m13:01:41.648875 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m13:01:41.650077 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (compile): 2025-11-26 13:01:41.630812 => 2025-11-26 13:01:41.649839
[0m13:01:41.650931 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m13:01:41.655676 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m13:01:41.656380 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (compile): 2025-11-26 13:01:41.637514 => 2025-11-26 13:01:41.656191
[0m13:01:41.657334 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m13:01:41.662429 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m13:01:41.664237 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m13:01:41.664941 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where NAS_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m13:01:41.665463 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:41.670017 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m13:01:41.670617 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where SECURITY_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m13:01:41.671094 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:01:42.661654 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:01:42.670158 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (execute): 2025-11-26 13:01:41.657792 => 2025-11-26 13:01:42.669864
[0m13:01:42.671219 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: Close
[0m13:01:42.753848 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:01:42.761568 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (execute): 2025-11-26 13:01:41.651433 => 2025-11-26 13:01:42.761289
[0m13:01:42.762682 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: Close
[0m13:01:43.310439 [info ] [Thread-1 (]: 4 of 17 PASS is_positive_fact_flights_SECURITY_DELAY ........................... [[32mPASS[0m in 1.68s]
[0m13:01:43.312600 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m13:01:43.314696 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m13:01:43.316242 [info ] [Thread-1 (]: 5 of 17 START test is_positive_fact_flights_TAXI_IN_TIME ....................... [RUN]
[0m13:01:43.318804 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c'
[0m13:01:43.319734 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m13:01:43.335921 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m13:01:43.337528 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (compile): 2025-11-26 13:01:43.320321 => 2025-11-26 13:01:43.337289
[0m13:01:43.338454 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m13:01:43.346249 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m13:01:43.348976 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m13:01:43.349813 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_IN_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m13:01:43.350509 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:01:43.792003 [info ] [Thread-2 (]: 3 of 17 PASS is_positive_fact_flights_NAS_DELAY ................................ [[32mPASS[0m in 2.16s]
[0m13:01:43.793136 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m13:01:43.794166 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m13:01:43.794973 [info ] [Thread-2 (]: 6 of 17 START test is_positive_fact_flights_TAXI_OUT_TIME ...................... [RUN]
[0m13:01:43.796709 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da'
[0m13:01:43.797334 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m13:01:43.809189 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m13:01:43.810599 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (compile): 2025-11-26 13:01:43.798224 => 2025-11-26 13:01:43.810365
[0m13:01:43.811818 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m13:01:43.819288 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m13:01:43.821664 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m13:01:43.822316 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_OUT_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m13:01:43.822889 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:44.375935 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:01:44.380523 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (execute): 2025-11-26 13:01:43.339013 => 2025-11-26 13:01:44.380362
[0m13:01:44.381129 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: Close
[0m13:01:44.999909 [info ] [Thread-1 (]: 5 of 17 PASS is_positive_fact_flights_TAXI_IN_TIME ............................. [[32mPASS[0m in 1.68s]
[0m13:01:45.001233 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m13:01:45.002640 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m13:01:45.003729 [info ] [Thread-1 (]: 7 of 17 START test is_positive_fact_flights_WEATHER_DELAY ...................... [RUN]
[0m13:01:45.005798 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474'
[0m13:01:45.006594 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m13:01:45.017124 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m13:01:45.018380 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (compile): 2025-11-26 13:01:45.007108 => 2025-11-26 13:01:45.018163
[0m13:01:45.019122 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m13:01:45.025090 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m13:01:45.026798 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m13:01:45.027259 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where WEATHER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m13:01:45.027594 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:01:45.118739 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:01:45.123928 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (execute): 2025-11-26 13:01:43.812498 => 2025-11-26 13:01:45.123771
[0m13:01:45.124528 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: Close
[0m13:01:45.639657 [info ] [Thread-2 (]: 6 of 17 PASS is_positive_fact_flights_TAXI_OUT_TIME ............................ [[32mPASS[0m in 1.84s]
[0m13:01:45.641142 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m13:01:45.642216 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m13:01:45.642948 [info ] [Thread-2 (]: 8 of 17 START test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m13:01:45.645109 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9'
[0m13:01:45.646253 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m13:01:45.682165 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m13:01:45.684005 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (compile): 2025-11-26 13:01:45.646785 => 2025-11-26 13:01:45.683550
[0m13:01:45.685075 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m13:01:45.692967 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m13:01:45.696925 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m13:01:45.697796 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:01:45.698466 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:47.144334 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:01:47.152256 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (execute): 2025-11-26 13:01:45.685678 => 2025-11-26 13:01:47.151940
[0m13:01:47.153351 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: Close
[0m13:01:47.874560 [info ] [Thread-2 (]: 8 of 17 PASS relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 2.23s]
[0m13:01:47.876370 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m13:01:47.877720 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m13:01:47.878904 [info ] [Thread-2 (]: 9 of 17 START test relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m13:01:47.881600 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079'
[0m13:01:47.882707 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m13:01:47.912085 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m13:01:47.913815 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (compile): 2025-11-26 13:01:47.883350 => 2025-11-26 13:01:47.913507
[0m13:01:47.914993 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m13:01:47.923209 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m13:01:47.927162 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m13:01:47.928112 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:01:47.928828 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:49.497233 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 4 seconds
[0m13:01:49.502967 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (execute): 2025-11-26 13:01:45.019534 => 2025-11-26 13:01:49.502790
[0m13:01:49.503688 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: Close
[0m13:01:49.920075 [info ] [Thread-1 (]: 7 of 17 PASS is_positive_fact_flights_WEATHER_DELAY ............................ [[32mPASS[0m in 4.92s]
[0m13:01:49.920989 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m13:01:49.921708 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m13:01:49.922551 [info ] [Thread-1 (]: 10 of 17 START test relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m13:01:49.924057 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608'
[0m13:01:49.924617 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m13:01:49.940773 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m13:01:49.942940 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (compile): 2025-11-26 13:01:49.924943 => 2025-11-26 13:01:49.942663
[0m13:01:49.944370 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m13:01:49.953608 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m13:01:49.957703 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m13:01:49.958886 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:01:49.959941 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:01:50.420234 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m13:01:50.424297 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (execute): 2025-11-26 13:01:47.915697 => 2025-11-26 13:01:50.424141
[0m13:01:50.425130 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: Close
[0m13:01:50.930783 [info ] [Thread-2 (]: 9 of 17 PASS relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 3.05s]
[0m13:01:50.931621 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m13:01:50.932256 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m13:01:50.932897 [info ] [Thread-2 (]: 11 of 17 START test relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m13:01:50.934303 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932'
[0m13:01:50.934804 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m13:01:50.949363 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m13:01:50.951022 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (compile): 2025-11-26 13:01:50.935110 => 2025-11-26 13:01:50.950723
[0m13:01:50.951822 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m13:01:50.956223 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m13:01:50.958334 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m13:01:50.958852 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:01:50.959283 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:51.036140 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:01:51.043828 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (execute): 2025-11-26 13:01:49.945485 => 2025-11-26 13:01:51.043637
[0m13:01:51.044510 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: Close
[0m13:01:51.654389 [info ] [Thread-1 (]: 10 of 17 PASS relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.73s]
[0m13:01:51.656909 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m13:01:51.658907 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m13:01:51.661732 [info ] [Thread-1 (]: 12 of 17 START test relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [RUN]
[0m13:01:51.666813 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5'
[0m13:01:51.668458 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m13:01:51.714433 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m13:01:51.723193 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (compile): 2025-11-26 13:01:51.680363 => 2025-11-26 13:01:51.722890
[0m13:01:51.724345 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m13:01:51.734057 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m13:01:51.738699 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m13:01:51.739715 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_Off_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_Off_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:01:51.740655 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:01:52.468106 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m13:01:52.478150 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (execute): 2025-11-26 13:01:50.952213 => 2025-11-26 13:01:52.477717
[0m13:01:52.479587 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: Close
[0m13:01:52.877229 [info ] [Thread-2 (]: 11 of 17 PASS relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.94s]
[0m13:01:52.878221 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m13:01:52.879974 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m13:01:52.880895 [info ] [Thread-2 (]: 13 of 17 START test relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [RUN]
[0m13:01:52.882649 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850'
[0m13:01:52.883400 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m13:01:52.885138 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:01:52.905250 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (execute): 2025-11-26 13:01:51.725231 => 2025-11-26 13:01:52.905075
[0m13:01:52.905905 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: Close
[0m13:01:52.907819 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m13:01:52.913548 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (compile): 2025-11-26 13:01:52.885806 => 2025-11-26 13:01:52.913358
[0m13:01:52.914224 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m13:01:52.920553 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m13:01:52.923090 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m13:01:52.923760 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_On_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_On_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:01:52.924311 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:53.286702 [info ] [Thread-1 (]: 12 of 17 PASS relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.62s]
[0m13:01:53.296804 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m13:01:53.300577 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m13:01:53.301286 [info ] [Thread-1 (]: 14 of 17 START test relationships_fact_flights_date_id__date_id__ref_dim_date_ . [RUN]
[0m13:01:53.302606 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9'
[0m13:01:53.303204 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m13:01:53.321497 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m13:01:53.322816 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (compile): 2025-11-26 13:01:53.303621 => 2025-11-26 13:01:53.322612
[0m13:01:53.323750 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m13:01:53.328828 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m13:01:53.330863 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m13:01:53.331341 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select date_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where date_id is not null
),

parent as (
    select date_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:01:53.331696 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:01:53.898595 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:01:53.902903 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (execute): 2025-11-26 13:01:52.914599 => 2025-11-26 13:01:53.902758
[0m13:01:53.903515 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: Close
[0m13:01:54.217387 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:01:54.221727 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (execute): 2025-11-26 13:01:53.324225 => 2025-11-26 13:01:54.221580
[0m13:01:54.222261 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: Close
[0m13:01:54.331122 [info ] [Thread-2 (]: 13 of 17 PASS relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.45s]
[0m13:01:54.332248 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m13:01:54.333028 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m13:01:54.333903 [info ] [Thread-2 (]: 15 of 17 START test relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [RUN]
[0m13:01:54.335223 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5'
[0m13:01:54.335660 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m13:01:54.350788 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m13:01:54.352184 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (compile): 2025-11-26 13:01:54.335950 => 2025-11-26 13:01:54.351942
[0m13:01:54.352949 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m13:01:54.358024 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m13:01:54.360676 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m13:01:54.361236 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select destination_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where destination_id is not null
),

parent as (
    select destination_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:01:54.361628 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:54.597334 [info ] [Thread-1 (]: 14 of 17 PASS relationships_fact_flights_date_id__date_id__ref_dim_date_ ....... [[32mPASS[0m in 1.29s]
[0m13:01:54.599260 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m13:01:54.600669 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m13:01:54.602212 [info ] [Thread-1 (]: 16 of 17 START test relationships_fact_flights_origin_id__origin_id__ref_dim_origin_  [RUN]
[0m13:01:54.604697 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24'
[0m13:01:54.605694 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m13:01:54.635085 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m13:01:54.637070 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (compile): 2025-11-26 13:01:54.606498 => 2025-11-26 13:01:54.636707
[0m13:01:54.638219 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m13:01:54.649239 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m13:01:54.653536 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m13:01:54.654469 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select origin_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where origin_id is not null
),

parent as (
    select origin_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:01:54.655246 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:01:55.444561 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:01:55.453111 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (execute): 2025-11-26 13:01:54.353415 => 2025-11-26 13:01:55.452761
[0m13:01:55.454166 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: Close
[0m13:01:55.849074 [info ] [Thread-2 (]: 15 of 17 PASS relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [[32mPASS[0m in 1.51s]
[0m13:01:55.850777 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m13:01:55.852024 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m13:01:55.852927 [info ] [Thread-2 (]: 17 of 17 START test relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [RUN]
[0m13:01:55.854596 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa'
[0m13:01:55.855328 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m13:01:55.879639 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m13:01:55.881410 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (compile): 2025-11-26 13:01:55.855863 => 2025-11-26 13:01:55.881120
[0m13:01:55.882477 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m13:01:55.890582 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m13:01:55.896433 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m13:01:55.898990 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:01:55.899953 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select status_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where status_id is not null
),

parent as (
    select status_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:01:55.910208 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (execute): 2025-11-26 13:01:54.639157 => 2025-11-26 13:01:55.909843
[0m13:01:55.911194 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:55.912588 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: Close
[0m13:01:56.661768 [info ] [Thread-1 (]: 16 of 17 PASS relationships_fact_flights_origin_id__origin_id__ref_dim_origin_ . [[32mPASS[0m in 2.06s]
[0m13:01:56.662744 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m13:01:57.074268 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m13:01:57.079951 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (execute): 2025-11-26 13:01:55.883116 => 2025-11-26 13:01:57.079712
[0m13:01:57.080892 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: Close
[0m13:01:57.489270 [info ] [Thread-2 (]: 17 of 17 PASS relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [[32mPASS[0m in 1.64s]
[0m13:01:57.491088 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m13:01:57.497021 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m13:01:57.499413 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:01:57.500287 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa' was properly closed.
[0m13:01:57.501091 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24' was properly closed.
[0m13:01:57.501962 [info ] [MainThread]: 
[0m13:01:57.502951 [info ] [MainThread]: Finished running 17 tests in 0 hours 0 minutes and 21.81 seconds (21.81s).
[0m13:01:57.506157 [debug] [MainThread]: Command end result
[0m13:01:57.542163 [info ] [MainThread]: 
[0m13:01:57.543552 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:01:57.544617 [info ] [MainThread]: 
[0m13:01:57.545533 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=0 SKIP=0 TOTAL=17
[0m13:01:57.546811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15b14c4bc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15b156aa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15b1569a00>]}
[0m13:01:57.547982 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 21:18:33.210458 | 4fbcfad3-e538-459e-8281-eb81f6d91e39 ==============================
[0m21:18:33.210458 [info ] [MainThread]: Running with dbt=1.4.0
[0m21:18:33.213872 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'source-freshness', 'rpc_method': 'source-freshness', 'indirect_selection': 'eager'}
[0m21:18:33.214342 [debug] [MainThread]: Tracking: tracking
[0m21:18:33.214734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35bae0f740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f358fe6f0e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35946bc7d0>]}
[0m21:18:33.267737 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:18:33.268159 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:18:33.279253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4fbcfad3-e538-459e-8281-eb81f6d91e39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f358fe9cb90>]}
[0m21:18:33.295418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4fbcfad3-e538-459e-8281-eb81f6d91e39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f358f9ecd10>]}
[0m21:18:33.296129 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:18:33.296615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4fbcfad3-e538-459e-8281-eb81f6d91e39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f358fe52960>]}
[0m21:18:33.299579 [info ] [MainThread]: 
[0m21:18:33.303093 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:18:33.305631 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m21:18:33.318008 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:18:33.354554 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m21:18:33.355640 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m21:18:33.356077 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m21:18:33.356511 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m21:18:33.356885 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:18:33.357262 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:18:36.721876 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 3 seconds
[0m21:18:36.725363 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m21:18:37.254216 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 4 seconds
[0m21:18:37.257543 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m21:18:37.704013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4fbcfad3-e538-459e-8281-eb81f6d91e39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f359e7e07a0>]}
[0m21:18:37.705254 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m21:18:37.705759 [info ] [MainThread]: 
[0m21:18:37.736664 [debug] [Thread-1 (]: Began running node source.airflow_dbt_project.raw_data.flights
[0m21:18:37.737164 [info ] [Thread-1 (]: 1 of 1 START freshness of raw_data.flights ..................................... [RUN]
[0m21:18:37.738269 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m21:18:37.738629 [debug] [Thread-1 (]: Began compiling node source.airflow_dbt_project.raw_data.flights
[0m21:18:37.738928 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (compile): 2025-11-26 21:18:37.738842 => 2025-11-26 21:18:37.738851
[0m21:18:37.739180 [debug] [Thread-1 (]: Began executing node source.airflow_dbt_project.raw_data.flights
[0m21:18:37.739914 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m21:18:37.751235 [debug] [Thread-1 (]: Using snowflake connection "source.airflow_dbt_project.raw_data.flights"
[0m21:18:37.751559 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "source.airflow_dbt_project.raw_data.flights"} */
select
      max(INGESTION_TIME) as max_loaded_at,
      convert_timezone('UTC', current_timestamp()) as snapshotted_at
    from GP.RAW.flights
[0m21:18:37.751782 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:18:40.065041 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m21:18:40.068365 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: Close
[0m21:18:40.675160 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (execute): 2025-11-26 21:18:37.739370 => 2025-11-26 21:18:40.674911
[0m21:18:40.678270 [warn ] [Thread-1 (]: 1 of 1 WARN freshness of raw_data.flights ...................................... [[33mWARN[0m in 2.94s]
[0m21:18:40.685364 [debug] [Thread-1 (]: Finished running node source.airflow_dbt_project.raw_data.flights
[0m21:18:40.688582 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:18:40.689262 [debug] [MainThread]: Connection 'source.airflow_dbt_project.raw_data.flights' was properly closed.
[0m21:18:40.689785 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m21:18:40.712090 [info ] [MainThread]: Done.
[0m21:18:40.713520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35b2dc68d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f358feffb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f358fa98530>]}
[0m21:18:40.714522 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 21:18:52.291121 | 3ceece9c-38ca-4d50-93df-a69d2510122e ==============================
[0m21:18:52.291121 [info ] [MainThread]: Running with dbt=1.4.0
[0m21:18:52.294915 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['staging.*'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m21:18:52.295537 [debug] [MainThread]: Tracking: tracking
[0m21:18:52.296107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef5618d40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef5618da0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef5618d10>]}
[0m21:18:52.366016 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:18:52.366883 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:18:52.384636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3ceece9c-38ca-4d50-93df-a69d2510122e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef73d0ad0>]}
[0m21:18:52.408714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3ceece9c-38ca-4d50-93df-a69d2510122e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef5dcbad0>]}
[0m21:18:52.409667 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:18:52.410358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3ceece9c-38ca-4d50-93df-a69d2510122e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef69ecf50>]}
[0m21:18:52.414341 [info ] [MainThread]: 
[0m21:18:52.419664 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:18:52.422382 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m21:18:52.453945 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m21:18:52.454733 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m21:18:52.455353 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:18:58.090429 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 6 seconds
[0m21:18:58.093285 [debug] [ThreadPool]: On list_GP: Close
[0m21:19:00.214418 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m21:19:00.215360 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m21:19:00.215801 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging', identifier=None)"
[0m21:19:00.225755 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m21:19:00.226211 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m21:19:00.226550 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:05.552004 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 5 seconds
[0m21:19:05.553936 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m21:19:07.709610 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:19:07.716953 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m21:19:07.731945 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m21:19:07.733094 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m21:19:07.733460 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m21:19:07.733811 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m21:19:07.734128 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:19:07.734629 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:15.590806 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 8 seconds
[0m21:19:15.594462 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m21:19:15.595547 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 8 seconds
[0m21:19:15.599435 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m21:19:16.519514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3ceece9c-38ca-4d50-93df-a69d2510122e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef565ab10>]}
[0m21:19:16.520771 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m21:19:16.521348 [info ] [MainThread]: 
[0m21:19:16.557687 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_flight_status
[0m21:19:16.558442 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [RUN]
[0m21:19:16.559597 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_flight_status'
[0m21:19:16.560038 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_flight_status
[0m21:19:16.578771 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_flight_status"
[0m21:19:16.579810 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (compile): 2025-11-26 21:19:16.560353 => 2025-11-26 21:19:16.579669
[0m21:19:16.580246 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_flight_status
[0m21:19:16.630180 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_flight_status"
[0m21:19:16.635188 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_flight_status"
[0m21:19:16.636006 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_flight_status"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
  
   as (
    select 
    DATE_FROM_PARTS(year, month, day_of_month) AS flight_date,
    
    lower(op_unique_carrier)
 as Airline_Code,
    op_carrier_fl_num::INT as Flight_Number,
    
    lower(origin)
 as Origin_Airport_Code,
    
    lower(origin_city_name)
 as Origin_City,
    
    lower(origin_state_nm)
 as Origin_State,
    
    lower(dest)
 as Destination_Airport_Code,
    
    lower(dest_city_name)
 as Destination_City,
    
    lower(dest_state_nm)
 as Destination_State,
    crs_dep_time::INT as Scheduled_Departure_Time,
    dep_time::INT as Actual_Departure_Time,
    dep_delay::INT as Departure_Delay,
    taxi_out::INT as Taxi_Out_Time,
    wheels_off::INT as Wheels_Off_Time,
    wheels_on::INT as Wheels_On_Time,
    taxi_in::INT as Taxi_In_Time,
    crs_arr_time::INT as Scheduled_Arrival_Time,
    arr_time::INT as Actual_Arrival_Time,
    arr_delay::INT as Arrival_Delay,
    CASE cancelled WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_cancelled,
    CASE cancellation_code WHEN 'A' THEN 'Carrier'  WHEN 'B' THEN 'Weather'  WHEN 'C' THEN 'National Air System'  WHEN 'D' THEN 'Security'  ELSE 'still available' END as Cancellation_Reason,
    CASE diverted WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_diverted,
    crs_elapsed_time::INT as Scheduled_Flight_Duration,
    actual_elapsed_time::INT as Actual_Flight_Duration,
    air_time,
    distance,
    carrier_delay,
    weather_delay,
    nas_delay,
    security_delay,
    late_aircraft_delay,
    isDelete,
    CASE operation WHEN 'c' THEN 'Create'  WHEN 'u' THEN 'Update'  WHEN 'd' THEN 'Delete'  WHEN 'r' THEN 'Snapshot'  ELSE 'Unknown' END as operation_type,
    TO_TIMESTAMP_LTZ(event_time / 1000) as event_time,
    ingestion_time  as ingestion_datetime
from GP.RAW.flights
  );
[0m21:19:16.636326 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:19:19.145765 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 3 seconds
[0m21:19:19.170828 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (execute): 2025-11-26 21:19:16.580507 => 2025-11-26 21:19:19.170747
[0m21:19:19.171196 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: Close
[0m21:19:19.686660 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ceece9c-38ca-4d50-93df-a69d2510122e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef4a930b0>]}
[0m21:19:19.687617 [info ] [Thread-1 (]: 1 of 1 OK created sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [[32mSUCCESS 1[0m in 3.13s]
[0m21:19:19.690581 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_flight_status
[0m21:19:19.693071 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:19:19.693881 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:19:19.694174 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m21:19:19.694411 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_flight_status' was properly closed.
[0m21:19:19.694710 [info ] [MainThread]: 
[0m21:19:19.695097 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 27.28 seconds (27.28s).
[0m21:19:19.695590 [debug] [MainThread]: Command end result
[0m21:19:19.705381 [info ] [MainThread]: 
[0m21:19:19.705851 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:19:19.706175 [info ] [MainThread]: 
[0m21:19:19.706494 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:19:19.706893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef56d9d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef48d7f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef49f01a0>]}
[0m21:19:19.707222 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 21:19:29.510332 | a19b15bf-67d8-49f3-8ebd-c6bd7fa46bb9 ==============================
[0m21:19:29.510332 [info ] [MainThread]: Running with dbt=1.4.0
[0m21:19:29.515591 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_destination'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m21:19:29.516243 [debug] [MainThread]: Tracking: tracking
[0m21:19:29.517024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdad03890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfcdd05370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfcd724dd0>]}
[0m21:19:29.615539 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:19:29.616280 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:19:29.634987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a19b15bf-67d8-49f3-8ebd-c6bd7fa46bb9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfcdec28d0>]}
[0m21:19:29.657866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a19b15bf-67d8-49f3-8ebd-c6bd7fa46bb9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfef3d21b0>]}
[0m21:19:29.658780 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:19:29.659508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a19b15bf-67d8-49f3-8ebd-c6bd7fa46bb9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfcdb3c140>]}
[0m21:19:29.663072 [info ] [MainThread]: 
[0m21:19:29.668047 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:19:29.670844 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m21:19:29.707875 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m21:19:29.708528 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m21:19:29.709038 [debug] [ThreadPool]: Opening a new connection, currently in state init


============================== 2025-11-26 21:19:29.720660 | 30648b2d-c2e9-4367-ac75-ef5f022a2d08 ==============================
[0m21:19:29.720660 [info ] [MainThread]: Running with dbt=1.4.0
[0m21:19:29.724474 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_origin'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m21:19:29.725025 [debug] [MainThread]: Tracking: tracking
[0m21:19:29.725630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7dd668cb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7dd7b4fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7ddb7bce0>]}
[0m21:19:29.806578 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:19:29.807165 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:19:29.822942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '30648b2d-c2e9-4367-ac75-ef5f022a2d08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7dd770e00>]}
[0m21:19:29.842375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '30648b2d-c2e9-4367-ac75-ef5f022a2d08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80480d490>]}
[0m21:19:29.843184 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:19:29.843929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '30648b2d-c2e9-4367-ac75-ef5f022a2d08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7deed5f70>]}
[0m21:19:29.847752 [info ] [MainThread]: 
[0m21:19:29.852723 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:19:29.855408 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m21:19:29.893972 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m21:19:29.894700 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m21:19:29.895250 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:19:30.950973 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m21:19:30.954623 [debug] [ThreadPool]: On list_GP: Close
[0m21:19:31.170356 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m21:19:31.173180 [debug] [ThreadPool]: On list_GP: Close
[0m21:19:31.326019 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:19:31.327723 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:19:31.328655 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m21:19:31.344270 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m21:19:31.344964 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m21:19:31.345477 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:31.565001 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:19:31.566120 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:19:31.566673 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m21:19:31.580002 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m21:19:31.580740 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m21:19:31.581179 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:32.279200 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m21:19:32.282625 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m21:19:32.515471 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m21:19:32.518474 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m21:19:32.648825 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:19:32.658405 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m21:19:32.700185 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m21:19:32.697758 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m21:19:32.701428 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m21:19:32.702450 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m21:19:32.703263 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:32.704177 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:19:32.922212 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m21:19:32.930534 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:19:32.959392 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m21:19:32.965939 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m21:19:32.966723 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m21:19:32.967575 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:32.968521 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m21:19:32.974661 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:19:33.720818 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m21:19:33.725578 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m21:19:33.742909 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m21:19:33.747923 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m21:19:33.811135 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m21:19:33.814829 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m21:19:33.832803 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m21:19:33.838190 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m21:19:34.169534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a19b15bf-67d8-49f3-8ebd-c6bd7fa46bb9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfcda787d0>]}
[0m21:19:34.171557 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m21:19:34.172503 [info ] [MainThread]: 
[0m21:19:34.199245 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '30648b2d-c2e9-4367-ac75-ef5f022a2d08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7dde7af90>]}
[0m21:19:34.201477 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m21:19:34.202503 [info ] [MainThread]: 
[0m21:19:34.226949 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_destination
[0m21:19:34.227848 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [RUN]
[0m21:19:34.229379 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_destination'
[0m21:19:34.230034 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_destination
[0m21:19:34.241866 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_destination"
[0m21:19:34.243085 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (compile): 2025-11-26 21:19:34.230449 => 2025-11-26 21:19:34.242909
[0m21:19:34.243676 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_destination
[0m21:19:34.258332 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_origin
[0m21:19:34.259375 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [RUN]
[0m21:19:34.262270 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_origin'
[0m21:19:34.263150 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_origin
[0m21:19:34.274419 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_origin"
[0m21:19:34.276006 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (compile): 2025-11-26 21:19:34.263696 => 2025-11-26 21:19:34.275694
[0m21:19:34.277040 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_origin
[0m21:19:34.413424 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_destination"
[0m21:19:34.417142 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m21:19:34.418101 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  as
        (


with distinct_values as(
    select
    distinct destination_city as city,destination_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as destination_id,
    city,
    state
    from distinct_values


        );
[0m21:19:34.419579 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:19:34.473898 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_origin"
[0m21:19:34.477589 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m21:19:34.478573 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  as
        (


with distinct_values as(
    select
    distinct origin_city as city,origin_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as origin_id,
    city,
    state
    from distinct_values


        );
[0m21:19:34.479276 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:19:36.532713 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m21:19:36.536253 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m21:19:36.552221 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m21:19:36.552992 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination__dbt_tmp cascade
[0m21:19:36.559158 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m21:19:36.559877 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin__dbt_tmp cascade
[0m21:19:36.748728 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m21:19:36.758810 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m21:19:36.793763 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (execute): 2025-11-26 21:19:34.244034 => 2025-11-26 21:19:36.793621
[0m21:19:36.794347 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: Close
[0m21:19:36.803660 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (execute): 2025-11-26 21:19:34.277619 => 2025-11-26 21:19:36.803496
[0m21:19:36.804286 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: Close
[0m21:19:37.458906 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30648b2d-c2e9-4367-ac75-ef5f022a2d08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7dd49fb30>]}
[0m21:19:37.459662 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [[32mSUCCESS 1[0m in 3.20s]
[0m21:19:37.460523 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a19b15bf-67d8-49f3-8ebd-c6bd7fa46bb9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfcc9f0b60>]}
[0m21:19:37.461263 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [[32mSUCCESS 1[0m in 3.23s]
[0m21:19:37.463487 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_origin
[0m21:19:37.464453 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_destination
[0m21:19:37.466446 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:19:37.467450 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:19:37.467552 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:19:37.467921 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m21:19:37.468195 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_origin' was properly closed.
[0m21:19:37.468517 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:19:37.468549 [info ] [MainThread]: 
[0m21:19:37.468997 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.62 seconds (7.62s).
[0m21:19:37.469008 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m21:19:37.469437 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_destination' was properly closed.
[0m21:19:37.469585 [debug] [MainThread]: Command end result
[0m21:19:37.469816 [info ] [MainThread]: 
[0m21:19:37.470345 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.81 seconds (7.81s).
[0m21:19:37.471017 [debug] [MainThread]: Command end result
[0m21:19:37.482203 [info ] [MainThread]: 
[0m21:19:37.482846 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:19:37.483300 [info ] [MainThread]: 
[0m21:19:37.483735 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:19:37.484264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7dd405550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7dd4dfef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7dd4df9b0>]}
[0m21:19:37.484695 [debug] [MainThread]: Flushing usage events
[0m21:19:37.484534 [info ] [MainThread]: 
[0m21:19:37.485565 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:19:37.486367 [info ] [MainThread]: 
[0m21:19:37.487125 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:19:37.488068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfce4ac7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfcd46f1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfcd7665a0>]}
[0m21:19:37.488732 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 21:19:47.957368 | 04cb7af6-c777-4d7b-a5b5-ecbeb45c56d1 ==============================
[0m21:19:47.957368 [info ] [MainThread]: Running with dbt=1.4.0
[0m21:19:47.959897 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_flight_status'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m21:19:47.960217 [debug] [MainThread]: Tracking: tracking
[0m21:19:47.960588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8369e1acf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8369497890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8368540aa0>]}
[0m21:19:48.005667 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:19:48.006121 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:19:48.018552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04cb7af6-c777-4d7b-a5b5-ecbeb45c56d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8363f44f80>]}
[0m21:19:48.034367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04cb7af6-c777-4d7b-a5b5-ecbeb45c56d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8363fa7bf0>]}
[0m21:19:48.035083 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:19:48.035901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04cb7af6-c777-4d7b-a5b5-ecbeb45c56d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8368629760>]}
[0m21:19:48.038915 [info ] [MainThread]: 
[0m21:19:48.042529 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:19:48.044697 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m21:19:48.070350 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m21:19:48.070757 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m21:19:48.071042 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:19:49.893954 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m21:19:49.898352 [debug] [ThreadPool]: On list_GP: Close
[0m21:19:50.269628 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:19:50.271382 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:19:50.272398 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m21:19:50.289449 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m21:19:50.290124 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m21:19:50.290626 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:51.280708 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m21:19:51.284640 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m21:19:51.749379 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m21:19:51.757505 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:19:51.787349 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m21:19:51.789200 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m21:19:51.789932 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m21:19:51.790793 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m21:19:51.791662 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:19:51.792394 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:52.675106 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m21:19:52.678946 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m21:19:52.686682 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m21:19:52.691633 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m21:19:53.170266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04cb7af6-c777-4d7b-a5b5-ecbeb45c56d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8363fa7bf0>]}
[0m21:19:53.173424 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m21:19:53.174288 [info ] [MainThread]: 
[0m21:19:53.232809 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_flight_status
[0m21:19:53.234315 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [RUN]
[0m21:19:53.236517 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_flight_status'
[0m21:19:53.237375 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_flight_status
[0m21:19:53.249181 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_flight_status"
[0m21:19:53.250986 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (compile): 2025-11-26 21:19:53.237971 => 2025-11-26 21:19:53.250748
[0m21:19:53.251917 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_flight_status
[0m21:19:53.471893 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_flight_status"
[0m21:19:53.476054 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m21:19:53.476986 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  as
        (
with distinct_values as(
    select distinct CANCELLATION_REASON,is_cancelled,is_diverted
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select 
row_number() over(order by is_cancelled) as status_id,
CANCELLATION_REASON,
is_cancelled,
is_diverted
from distinct_values
        );
[0m21:19:53.477732 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:19:55.133237 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m21:19:55.149990 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m21:19:55.150630 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status__dbt_tmp cascade
[0m21:19:55.353204 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m21:19:55.412873 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (execute): 2025-11-26 21:19:53.252480 => 2025-11-26 21:19:55.412703
[0m21:19:55.413845 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: Close
[0m21:19:55.910330 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04cb7af6-c777-4d7b-a5b5-ecbeb45c56d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83634c7290>]}
[0m21:19:55.911576 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [[32mSUCCESS 1[0m in 2.67s]
[0m21:19:55.915940 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_flight_status
[0m21:19:55.920438 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:19:55.921833 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:19:55.922367 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_flight_status' was properly closed.
[0m21:19:55.922752 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m21:19:55.923237 [info ] [MainThread]: 
[0m21:19:55.923893 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.88 seconds (7.88s).
[0m21:19:55.924747 [debug] [MainThread]: Command end result
[0m21:19:55.944205 [info ] [MainThread]: 
[0m21:19:55.945118 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:19:55.945727 [info ] [MainThread]: 
[0m21:19:55.946219 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:19:55.946897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8381bd7620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8369569d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f836332c1d0>]}
[0m21:19:55.947699 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 21:20:05.953405 | 75d2a2b9-205d-4809-b5e6-508d3d289dca ==============================
[0m21:20:05.953405 [info ] [MainThread]: Running with dbt=1.4.0
[0m21:20:05.956642 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['fact_flights'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m21:20:05.957111 [debug] [MainThread]: Tracking: tracking
[0m21:20:05.957678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b63c4590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b6c31190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b69feff0>]}
[0m21:20:06.023155 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:20:06.023766 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:20:06.037725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '75d2a2b9-205d-4809-b5e6-508d3d289dca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b5972b70>]}
[0m21:20:06.056044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '75d2a2b9-205d-4809-b5e6-508d3d289dca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b5634bf0>]}
[0m21:20:06.056867 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:20:06.057493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '75d2a2b9-205d-4809-b5e6-508d3d289dca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b63c4590>]}
[0m21:20:06.060497 [info ] [MainThread]: 
[0m21:20:06.064473 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:20:06.067032 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m21:20:06.100868 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m21:20:06.101448 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m21:20:06.101849 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:20:07.402847 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m21:20:07.405702 [debug] [ThreadPool]: On list_GP: Close
[0m21:20:07.814604 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:20:07.815941 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:20:07.816588 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m21:20:07.830543 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m21:20:07.831100 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m21:20:07.831506 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:20:08.873966 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:08.876374 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m21:20:09.224652 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:20:09.236601 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m21:20:09.253283 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m21:20:09.255106 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m21:20:09.255725 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m21:20:09.256418 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m21:20:09.257042 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:20:09.257629 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:20:10.101949 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m21:20:10.104434 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m21:20:10.119197 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m21:20:10.121630 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m21:20:10.476212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '75d2a2b9-205d-4809-b5e6-508d3d289dca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b5418350>]}
[0m21:20:10.477544 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m21:20:10.478073 [info ] [MainThread]: 
[0m21:20:10.517106 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.fact_flights
[0m21:20:10.517773 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [RUN]
[0m21:20:10.519641 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.fact_flights'
[0m21:20:10.520087 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.fact_flights
[0m21:20:10.528156 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.fact_flights"
[0m21:20:10.528922 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (compile): 2025-11-26 21:20:10.520369 => 2025-11-26 21:20:10.528806
[0m21:20:10.529352 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.fact_flights
[0m21:20:10.616476 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.fact_flights"
[0m21:20:10.619877 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m21:20:10.620212 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  as
        (
select
d_date.date_id as date_id,
sdt.time_id as Scheduled_Departure_Time_id,
adt.time_id as Actual_Departure_Time_id,
wot.time_id as Wheels_Off_Time_id,
wot2.time_id as Wheels_On_Time_id,
sat.time_id as Scheduled_Arrival_Time_id,
aat.time_id as Actual_Arrival_Time_id,
origin.origin_id as origin_id,
dest.destination_id as destination_id, 
fl_stat.status_id as status_id,
AIRLINE_CODE,
FLIGHT_NUMBER,
Departure_Delay,
Taxi_Out_Time,
Taxi_In_Time,
Arrival_Delay,
Scheduled_Flight_Duration,
Actual_Flight_Duration,
Air_Time,
Distance,
Carrier_Delay,
Weather_Delay,
NAS_Delay,
Security_Delay,
Late_Aircraft_Delay
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status as stg 
left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date as d_date
on stg.flight_date=d_date.date_day

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sdt
on stg.Scheduled_Departure_Time=sdt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as adt 
on stg.Actual_Departure_Time=adt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot
on stg.Wheels_Off_Time=wot.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot2 
on stg.Wheels_On_Time=wot2.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sat
on stg.Scheduled_Arrival_Time=sat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as aat
on stg.Actual_Arrival_Time=aat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin as origin
on origin.city=stg.origin_city and origin.state=stg.origin_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination as dest
on dest.city=stg.destination_city and dest.state=stg.destination_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status as fl_stat 
on stg.IS_CANCELLED=fl_stat.IS_CANCELLED and stg.IS_DIVERTED=fl_stat.IS_DIVERTED
        );
[0m21:20:10.620481 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:20:12.931841 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m21:20:12.944803 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m21:20:12.945236 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights__dbt_tmp cascade
[0m21:20:13.145085 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m21:20:13.183445 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (execute): 2025-11-26 21:20:10.529617 => 2025-11-26 21:20:13.183322
[0m21:20:13.183970 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: Close
[0m21:20:13.564967 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75d2a2b9-205d-4809-b5e6-508d3d289dca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b53328d0>]}
[0m21:20:13.566449 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [[32mSUCCESS 1[0m in 3.05s]
[0m21:20:13.572483 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.fact_flights
[0m21:20:13.577180 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:20:13.578985 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:20:13.579687 [debug] [MainThread]: Connection 'model.airflow_dbt_project.fact_flights' was properly closed.
[0m21:20:13.580159 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m21:20:13.580735 [info ] [MainThread]: 
[0m21:20:13.581539 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.52 seconds (7.52s).
[0m21:20:13.582491 [debug] [MainThread]: Command end result
[0m21:20:13.612602 [info ] [MainThread]: 
[0m21:20:13.614074 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:20:13.616172 [info ] [MainThread]: 
[0m21:20:13.617809 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:20:13.619960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b48daa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b48d8110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b48dab10>]}
[0m21:20:13.621392 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 21:20:23.849799 | 934577c9-4a6d-4520-aa0e-0a6262d2f965 ==============================
[0m21:20:23.849799 [info ] [MainThread]: Running with dbt=1.4.0
[0m21:20:23.851938 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m21:20:23.852219 [debug] [MainThread]: Tracking: tracking
[0m21:20:23.852545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb976bec920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb976bec7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb976bec8f0>]}
[0m21:20:23.894049 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:20:23.894439 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:20:23.904428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '934577c9-4a6d-4520-aa0e-0a6262d2f965', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb977338ec0>]}
[0m21:20:23.918221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '934577c9-4a6d-4520-aa0e-0a6262d2f965', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb976c0cf20>]}
[0m21:20:23.918837 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:20:23.919269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '934577c9-4a6d-4520-aa0e-0a6262d2f965', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb976cb7e90>]}
[0m21:20:23.922167 [info ] [MainThread]: 
[0m21:20:23.925179 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:20:23.927441 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m21:20:23.941070 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m21:20:23.959070 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m21:20:23.959500 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m21:20:23.959803 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:20:23.962374 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m21:20:23.966338 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m21:20:23.966750 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:20:25.679095 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m21:20:25.680657 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 2 seconds
[0m21:20:25.684007 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m21:20:25.686860 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m21:20:26.151920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '934577c9-4a6d-4520-aa0e-0a6262d2f965', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb976c0d640>]}
[0m21:20:26.153081 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m21:20:26.153608 [info ] [MainThread]: 
[0m21:20:26.192892 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m21:20:26.193513 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m21:20:26.193985 [info ] [Thread-1 (]: 1 of 17 START test is_positive_fact_flights_CARRIER_DELAY ...................... [RUN]
[0m21:20:26.194575 [info ] [Thread-2 (]: 2 of 17 START test is_positive_fact_flights_LATE_AIRCRAFT_DELAY ................ [RUN]
[0m21:20:26.195752 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec'
[0m21:20:26.196729 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa'
[0m21:20:26.197194 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m21:20:26.197630 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m21:20:26.216039 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m21:20:26.216899 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m21:20:26.217624 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (compile): 2025-11-26 21:20:26.208237 => 2025-11-26 21:20:26.217517
[0m21:20:26.217981 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m21:20:26.223584 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (compile): 2025-11-26 21:20:26.197929 => 2025-11-26 21:20:26.223382
[0m21:20:26.224164 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m21:20:26.288252 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m21:20:26.289021 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m21:20:26.290106 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m21:20:26.290423 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where CARRIER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m21:20:26.290683 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:20:26.292393 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m21:20:26.292751 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where LATE_AIRCRAFT_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m21:20:26.294772 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:20:27.351618 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:27.364539 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (execute): 2025-11-26 21:20:26.229701 => 2025-11-26 21:20:27.364409
[0m21:20:27.365005 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: Close
[0m21:20:27.748136 [info ] [Thread-1 (]: 1 of 17 PASS is_positive_fact_flights_CARRIER_DELAY ............................ [[32mPASS[0m in 1.55s]
[0m21:20:27.751583 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m21:20:27.752213 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m21:20:27.752927 [info ] [Thread-1 (]: 3 of 17 START test is_positive_fact_flights_NAS_DELAY .......................... [RUN]
[0m21:20:27.754079 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3'
[0m21:20:27.754534 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m21:20:27.761846 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m21:20:27.762914 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (compile): 2025-11-26 21:20:27.754793 => 2025-11-26 21:20:27.762786
[0m21:20:27.763510 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m21:20:27.767218 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m21:20:27.768442 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m21:20:27.768800 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where NAS_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m21:20:27.769383 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:20:28.020148 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m21:20:28.023750 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (execute): 2025-11-26 21:20:26.218199 => 2025-11-26 21:20:28.023623
[0m21:20:28.024156 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: Close
[0m21:20:28.703850 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:28.707268 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (execute): 2025-11-26 21:20:27.763778 => 2025-11-26 21:20:28.707152
[0m21:20:28.707711 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: Close
[0m21:20:28.710900 [info ] [Thread-2 (]: 2 of 17 PASS is_positive_fact_flights_LATE_AIRCRAFT_DELAY ...................... [[32mPASS[0m in 2.51s]
[0m21:20:28.712728 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m21:20:28.713358 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m21:20:28.713714 [info ] [Thread-2 (]: 4 of 17 START test is_positive_fact_flights_SECURITY_DELAY ..................... [RUN]
[0m21:20:28.714670 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384'
[0m21:20:28.715341 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m21:20:28.722827 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m21:20:28.723774 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (compile): 2025-11-26 21:20:28.715760 => 2025-11-26 21:20:28.723675
[0m21:20:28.724156 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m21:20:28.727878 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m21:20:28.728932 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m21:20:28.729224 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where SECURITY_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m21:20:28.729475 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:20:29.115997 [info ] [Thread-1 (]: 3 of 17 PASS is_positive_fact_flights_NAS_DELAY ................................ [[32mPASS[0m in 1.36s]
[0m21:20:29.116813 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m21:20:29.117339 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m21:20:29.117868 [info ] [Thread-1 (]: 5 of 17 START test is_positive_fact_flights_TAXI_IN_TIME ....................... [RUN]
[0m21:20:29.118801 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c'
[0m21:20:29.119156 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m21:20:29.127891 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m21:20:29.128665 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (compile): 2025-11-26 21:20:29.119410 => 2025-11-26 21:20:29.128558
[0m21:20:29.129050 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m21:20:29.132435 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m21:20:29.133732 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m21:20:29.134342 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_IN_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m21:20:29.134649 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:20:29.687544 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:29.692437 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (execute): 2025-11-26 21:20:28.724409 => 2025-11-26 21:20:29.692225
[0m21:20:29.693173 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: Close
[0m21:20:29.975874 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:29.980080 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (execute): 2025-11-26 21:20:29.129276 => 2025-11-26 21:20:29.979956
[0m21:20:29.980529 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: Close
[0m21:20:30.105561 [info ] [Thread-2 (]: 4 of 17 PASS is_positive_fact_flights_SECURITY_DELAY ........................... [[32mPASS[0m in 1.39s]
[0m21:20:30.106581 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m21:20:30.107368 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m21:20:30.108002 [info ] [Thread-2 (]: 6 of 17 START test is_positive_fact_flights_TAXI_OUT_TIME ...................... [RUN]
[0m21:20:30.109555 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da'
[0m21:20:30.110003 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m21:20:30.117351 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m21:20:30.118108 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (compile): 2025-11-26 21:20:30.110271 => 2025-11-26 21:20:30.118011
[0m21:20:30.118513 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m21:20:30.121616 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m21:20:30.122685 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m21:20:30.123005 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_OUT_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m21:20:30.123258 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:20:30.329339 [info ] [Thread-1 (]: 5 of 17 PASS is_positive_fact_flights_TAXI_IN_TIME ............................. [[32mPASS[0m in 1.21s]
[0m21:20:30.330171 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m21:20:30.330720 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m21:20:30.331230 [info ] [Thread-1 (]: 7 of 17 START test is_positive_fact_flights_WEATHER_DELAY ...................... [RUN]
[0m21:20:30.332282 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474'
[0m21:20:30.332667 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m21:20:30.338978 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m21:20:30.339707 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (compile): 2025-11-26 21:20:30.332929 => 2025-11-26 21:20:30.339602
[0m21:20:30.340116 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m21:20:30.344004 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m21:20:30.345164 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m21:20:30.345509 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where WEATHER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m21:20:30.345776 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:20:31.010221 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:31.013819 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (execute): 2025-11-26 21:20:30.118755 => 2025-11-26 21:20:31.013696
[0m21:20:31.014290 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: Close
[0m21:20:31.264817 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:31.268380 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (execute): 2025-11-26 21:20:30.340410 => 2025-11-26 21:20:31.268257
[0m21:20:31.268851 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: Close
[0m21:20:31.469175 [info ] [Thread-2 (]: 6 of 17 PASS is_positive_fact_flights_TAXI_OUT_TIME ............................ [[32mPASS[0m in 1.36s]
[0m21:20:31.469813 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m21:20:31.470265 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m21:20:31.470612 [info ] [Thread-2 (]: 8 of 17 START test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m21:20:31.471469 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9'
[0m21:20:31.471804 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m21:20:31.486769 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m21:20:31.487549 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (compile): 2025-11-26 21:20:31.472010 => 2025-11-26 21:20:31.487415
[0m21:20:31.488001 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m21:20:31.491823 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m21:20:31.493417 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m21:20:31.493809 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m21:20:31.494125 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:20:31.773208 [info ] [Thread-1 (]: 7 of 17 PASS is_positive_fact_flights_WEATHER_DELAY ............................ [[32mPASS[0m in 1.44s]
[0m21:20:31.774038 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m21:20:31.774621 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m21:20:31.774995 [info ] [Thread-1 (]: 9 of 17 START test relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m21:20:31.775997 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079'
[0m21:20:31.776377 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m21:20:31.787809 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m21:20:31.788676 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (compile): 2025-11-26 21:20:31.776627 => 2025-11-26 21:20:31.788551
[0m21:20:31.789149 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m21:20:31.792917 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m21:20:31.794610 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m21:20:31.794977 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m21:20:31.795288 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:20:32.420564 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:32.424417 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (execute): 2025-11-26 21:20:31.488261 => 2025-11-26 21:20:32.424276
[0m21:20:32.424891 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: Close
[0m21:20:32.753171 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:32.756696 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (execute): 2025-11-26 21:20:31.789440 => 2025-11-26 21:20:32.756576
[0m21:20:32.757133 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: Close
[0m21:20:32.871280 [info ] [Thread-2 (]: 8 of 17 PASS relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.40s]
[0m21:20:32.872119 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m21:20:32.872705 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m21:20:32.873065 [info ] [Thread-2 (]: 10 of 17 START test relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m21:20:32.874072 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608'
[0m21:20:32.874454 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m21:20:32.884251 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m21:20:32.884979 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (compile): 2025-11-26 21:20:32.874689 => 2025-11-26 21:20:32.884861
[0m21:20:32.885477 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m21:20:32.892700 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m21:20:32.894665 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m21:20:32.895067 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m21:20:32.895397 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:20:33.118647 [info ] [Thread-1 (]: 9 of 17 PASS relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.34s]
[0m21:20:33.119479 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m21:20:33.120034 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m21:20:33.120427 [info ] [Thread-1 (]: 11 of 17 START test relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m21:20:33.121515 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932'
[0m21:20:33.122161 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m21:20:33.134461 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m21:20:33.135453 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (compile): 2025-11-26 21:20:33.122491 => 2025-11-26 21:20:33.135287
[0m21:20:33.135985 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m21:20:33.140042 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m21:20:33.142070 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m21:20:33.142493 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m21:20:33.142813 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:20:33.780732 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:33.784592 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (execute): 2025-11-26 21:20:32.885734 => 2025-11-26 21:20:33.784456
[0m21:20:33.785108 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: Close
[0m21:20:34.040215 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:34.043743 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (execute): 2025-11-26 21:20:33.136314 => 2025-11-26 21:20:34.043634
[0m21:20:34.044115 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: Close
[0m21:20:34.153610 [info ] [Thread-2 (]: 10 of 17 PASS relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.28s]
[0m21:20:34.154371 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m21:20:34.154903 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m21:20:34.155429 [info ] [Thread-2 (]: 12 of 17 START test relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [RUN]
[0m21:20:34.156428 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5'
[0m21:20:34.156779 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m21:20:34.166625 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m21:20:34.167245 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (compile): 2025-11-26 21:20:34.157019 => 2025-11-26 21:20:34.167155
[0m21:20:34.167602 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m21:20:34.170488 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m21:20:34.171810 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m21:20:34.172112 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_Off_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_Off_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m21:20:34.172349 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:20:34.401006 [info ] [Thread-1 (]: 11 of 17 PASS relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.28s]
[0m21:20:34.401752 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m21:20:34.402246 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m21:20:34.402596 [info ] [Thread-1 (]: 13 of 17 START test relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [RUN]
[0m21:20:34.403472 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850'
[0m21:20:34.403904 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m21:20:34.412667 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m21:20:34.413372 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (compile): 2025-11-26 21:20:34.404131 => 2025-11-26 21:20:34.413243
[0m21:20:34.413744 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m21:20:34.417025 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m21:20:34.418841 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m21:20:34.419248 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_On_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_On_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m21:20:34.419584 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:20:35.391276 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:35.395166 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (execute): 2025-11-26 21:20:34.413995 => 2025-11-26 21:20:35.395050
[0m21:20:35.395646 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: Close
[0m21:20:35.746786 [info ] [Thread-1 (]: 13 of 17 PASS relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.34s]
[0m21:20:35.747531 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m21:20:35.748078 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m21:20:35.748769 [info ] [Thread-1 (]: 14 of 17 START test relationships_fact_flights_date_id__date_id__ref_dim_date_ . [RUN]
[0m21:20:35.750065 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9'
[0m21:20:35.750600 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m21:20:35.762194 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m21:20:35.763087 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (compile): 2025-11-26 21:20:35.751015 => 2025-11-26 21:20:35.762924
[0m21:20:35.763571 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m21:20:35.767241 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m21:20:35.768883 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m21:20:35.769247 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select date_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where date_id is not null
),

parent as (
    select date_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m21:20:35.769578 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:20:36.621060 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2 seconds
[0m21:20:36.625447 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (execute): 2025-11-26 21:20:34.167820 => 2025-11-26 21:20:36.625316
[0m21:20:36.625900 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: Close
[0m21:20:36.702411 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:36.707224 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (execute): 2025-11-26 21:20:35.763862 => 2025-11-26 21:20:36.707103
[0m21:20:36.707716 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: Close
[0m21:20:36.970437 [info ] [Thread-2 (]: 12 of 17 PASS relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 2.81s]
[0m21:20:36.971177 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m21:20:36.971815 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m21:20:36.972342 [info ] [Thread-2 (]: 15 of 17 START test relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [RUN]
[0m21:20:36.973269 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5'
[0m21:20:36.973601 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m21:20:36.982743 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m21:20:36.983384 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (compile): 2025-11-26 21:20:36.973829 => 2025-11-26 21:20:36.983271
[0m21:20:36.983749 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m21:20:36.986559 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m21:20:36.987862 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m21:20:36.988157 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select destination_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where destination_id is not null
),

parent as (
    select destination_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m21:20:36.988422 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:20:37.065733 [info ] [Thread-1 (]: 14 of 17 PASS relationships_fact_flights_date_id__date_id__ref_dim_date_ ....... [[32mPASS[0m in 1.32s]
[0m21:20:37.066442 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m21:20:37.066978 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m21:20:37.067317 [info ] [Thread-1 (]: 16 of 17 START test relationships_fact_flights_origin_id__origin_id__ref_dim_origin_  [RUN]
[0m21:20:37.068223 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24'
[0m21:20:37.068572 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m21:20:37.077181 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m21:20:37.077736 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (compile): 2025-11-26 21:20:37.068899 => 2025-11-26 21:20:37.077653
[0m21:20:37.078039 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m21:20:37.080658 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m21:20:37.081883 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m21:20:37.082156 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select origin_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where origin_id is not null
),

parent as (
    select origin_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m21:20:37.082414 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:20:37.921057 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:37.925375 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (execute): 2025-11-26 21:20:36.983959 => 2025-11-26 21:20:37.925240
[0m21:20:37.925809 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: Close
[0m21:20:38.027023 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:38.030939 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (execute): 2025-11-26 21:20:37.078229 => 2025-11-26 21:20:38.030819
[0m21:20:38.031427 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: Close
[0m21:20:38.286912 [info ] [Thread-2 (]: 15 of 17 PASS relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [[32mPASS[0m in 1.31s]
[0m21:20:38.288169 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m21:20:38.289082 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m21:20:38.289673 [info ] [Thread-2 (]: 17 of 17 START test relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [RUN]
[0m21:20:38.290653 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa'
[0m21:20:38.291161 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m21:20:38.300535 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m21:20:38.301154 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (compile): 2025-11-26 21:20:38.291457 => 2025-11-26 21:20:38.301054
[0m21:20:38.301535 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m21:20:38.304390 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m21:20:38.305701 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m21:20:38.305989 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select status_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where status_id is not null
),

parent as (
    select status_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m21:20:38.306225 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:20:38.392068 [info ] [Thread-1 (]: 16 of 17 PASS relationships_fact_flights_origin_id__origin_id__ref_dim_origin_ . [[32mPASS[0m in 1.32s]
[0m21:20:38.392907 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m21:20:39.456048 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m21:20:39.460052 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (execute): 2025-11-26 21:20:38.301760 => 2025-11-26 21:20:39.459930
[0m21:20:39.460497 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: Close
[0m21:20:40.172069 [info ] [Thread-2 (]: 17 of 17 PASS relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [[32mPASS[0m in 1.88s]
[0m21:20:40.172826 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m21:20:40.175468 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m21:20:40.176352 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:20:40.176656 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24' was properly closed.
[0m21:20:40.176924 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa' was properly closed.
[0m21:20:40.177274 [info ] [MainThread]: 
[0m21:20:40.177679 [info ] [MainThread]: Finished running 17 tests in 0 hours 0 minutes and 16.25 seconds (16.25s).
[0m21:20:40.178948 [debug] [MainThread]: Command end result
[0m21:20:40.190849 [info ] [MainThread]: 
[0m21:20:40.191423 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:20:40.191827 [info ] [MainThread]: 
[0m21:20:40.192175 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=0 SKIP=0 TOTAL=17
[0m21:20:40.192719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb97707a900>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb976bc9010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb98cfc5fa0>]}
[0m21:20:40.193138 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 23:09:19.694840 | e5990610-bfd1-4b79-aa8e-90aebd5f9d97 ==============================
[0m23:09:19.694840 [info ] [MainThread]: Running with dbt=1.4.0
[0m23:09:19.699428 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'which': 'source-freshness', 'rpc_method': 'source-freshness', 'indirect_selection': 'eager'}
[0m23:09:19.700023 [debug] [MainThread]: Tracking: tracking
[0m23:09:19.700678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe464d4bb60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4551d20f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe454a21580>]}
[0m23:09:19.814937 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:09:19.816970 [debug] [MainThread]: Partial parsing: updated file: airflow_dbt_project://models/marts/dim_time.sql
[0m23:09:19.865359 [debug] [MainThread]: 1699: static parser successfully parsed marts/dim_time.sql
[0m23:09:19.943496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e5990610-bfd1-4b79-aa8e-90aebd5f9d97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe45490cd40>]}
[0m23:09:19.966578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e5990610-bfd1-4b79-aa8e-90aebd5f9d97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe454844200>]}
[0m23:09:19.967685 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m23:09:19.968652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e5990610-bfd1-4b79-aa8e-90aebd5f9d97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4554c4440>]}
[0m23:09:19.974066 [info ] [MainThread]: 
[0m23:09:19.978694 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:09:19.982761 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:09:19.985768 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m23:09:20.080503 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m23:09:20.081643 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m23:09:20.082490 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:09:20.098685 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:09:20.099962 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:09:20.102987 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:09:21.589411 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m23:09:21.600563 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:09:21.652496 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m23:09:21.666501 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m23:09:22.206788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e5990610-bfd1-4b79-aa8e-90aebd5f9d97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe464dec8f0>]}
[0m23:09:22.211551 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m23:09:22.213767 [info ] [MainThread]: 
[0m23:09:22.352338 [debug] [Thread-1 (]: Began running node source.airflow_dbt_project.raw_data.flights
[0m23:09:22.354051 [info ] [Thread-1 (]: 1 of 1 START freshness of raw_data.flights ..................................... [RUN]
[0m23:09:22.357551 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m23:09:22.358932 [debug] [Thread-1 (]: Began compiling node source.airflow_dbt_project.raw_data.flights
[0m23:09:22.359894 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (compile): 2025-11-26 23:09:22.359661 => 2025-11-26 23:09:22.359686
[0m23:09:22.360628 [debug] [Thread-1 (]: Began executing node source.airflow_dbt_project.raw_data.flights
[0m23:09:22.362406 [debug] [Thread-1 (]: Acquiring new snowflake connection 'source.airflow_dbt_project.raw_data.flights'
[0m23:09:22.391980 [debug] [Thread-1 (]: Using snowflake connection "source.airflow_dbt_project.raw_data.flights"
[0m23:09:22.392864 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "source.airflow_dbt_project.raw_data.flights"} */
select
      max(INGESTION_TIME) as max_loaded_at,
      convert_timezone('UTC', current_timestamp()) as snapshotted_at
    from GP.RAW.flights
[0m23:09:22.393382 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:09:23.725518 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:09:23.731339 [debug] [Thread-1 (]: On source.airflow_dbt_project.raw_data.flights: Close
[0m23:09:24.138595 [debug] [Thread-1 (]: Timing info for source.airflow_dbt_project.raw_data.flights (execute): 2025-11-26 23:09:22.361102 => 2025-11-26 23:09:24.138108
[0m23:09:24.141429 [info ] [Thread-1 (]: 1 of 1 PASS freshness of raw_data.flights ...................................... [[32mPASS[0m in 1.79s]
[0m23:09:24.145806 [debug] [Thread-1 (]: Finished running node source.airflow_dbt_project.raw_data.flights
[0m23:09:24.148837 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:09:24.149595 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m23:09:24.150151 [debug] [MainThread]: Connection 'source.airflow_dbt_project.raw_data.flights' was properly closed.
[0m23:09:24.173066 [info ] [MainThread]: Done.
[0m23:09:24.174170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe454a232c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe454ec3500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4562c0b30>]}
[0m23:09:24.174796 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 23:09:40.984925 | 41d97734-5b73-472b-8d50-1ee47d7aff33 ==============================
[0m23:09:40.984925 [info ] [MainThread]: Running with dbt=1.4.0
[0m23:09:41.008689 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['staging.*'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m23:09:41.011011 [debug] [MainThread]: Tracking: tracking
[0m23:09:41.013602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b35ffd40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b35ff950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b32d2ae0>]}
[0m23:09:41.205078 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:09:41.206083 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:09:41.240830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '41d97734-5b73-472b-8d50-1ee47d7aff33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b32d0e00>]}
[0m23:09:41.277200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41d97734-5b73-472b-8d50-1ee47d7aff33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26d95c58b0>]}
[0m23:09:41.278805 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m23:09:41.280581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41d97734-5b73-472b-8d50-1ee47d7aff33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b323a510>]}
[0m23:09:41.288622 [info ] [MainThread]: 
[0m23:09:41.297363 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:09:41.301979 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m23:09:41.365686 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m23:09:41.366880 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m23:09:41.367742 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:09:42.979675 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m23:09:42.987350 [debug] [ThreadPool]: On list_GP: Close
[0m23:09:43.609817 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m23:09:43.611078 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m23:09:43.611802 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging', identifier=None)"
[0m23:09:43.627288 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m23:09:43.628057 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m23:09:43.628807 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:09:44.781514 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m23:09:44.785616 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m23:09:45.156892 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m23:09:45.178537 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:09:45.222734 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m23:09:45.231077 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m23:09:45.235754 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:09:45.237331 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:09:45.238348 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:09:45.245680 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:09:46.668449 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m23:09:46.676482 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m23:09:51.226774 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 6 seconds
[0m23:09:51.230380 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:09:51.672383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41d97734-5b73-472b-8d50-1ee47d7aff33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26ded1f140>]}
[0m23:09:51.675643 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m23:09:51.676732 [info ] [MainThread]: 
[0m23:09:51.757567 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.stg_flight_status
[0m23:09:51.759220 [info ] [Thread-1 (]: 1 of 1 START sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [RUN]
[0m23:09:51.764738 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.stg_flight_status'
[0m23:09:51.766722 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.stg_flight_status
[0m23:09:51.815081 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.stg_flight_status"
[0m23:09:51.817402 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (compile): 2025-11-26 23:09:51.768151 => 2025-11-26 23:09:51.816993
[0m23:09:51.818917 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.stg_flight_status
[0m23:09:51.959009 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.stg_flight_status"
[0m23:09:51.965424 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.stg_flight_status"
[0m23:09:51.966527 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.stg_flight_status"} */
create or replace   view GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
  
   as (
    select 
    DATE_FROM_PARTS(year, month, day_of_month) AS flight_date,
    
    lower(op_unique_carrier)
 as Airline_Code,
    op_carrier_fl_num::INT as Flight_Number,
    
    lower(origin)
 as Origin_Airport_Code,
    
    lower(origin_city_name)
 as Origin_City,
    
    lower(origin_state_nm)
 as Origin_State,
    
    lower(dest)
 as Destination_Airport_Code,
    
    lower(dest_city_name)
 as Destination_City,
    
    lower(dest_state_nm)
 as Destination_State,
    crs_dep_time::INT as Scheduled_Departure_Time,
    dep_time::INT as Actual_Departure_Time,
    dep_delay::INT as Departure_Delay,
    taxi_out::INT as Taxi_Out_Time,
    wheels_off::INT as Wheels_Off_Time,
    wheels_on::INT as Wheels_On_Time,
    taxi_in::INT as Taxi_In_Time,
    crs_arr_time::INT as Scheduled_Arrival_Time,
    arr_time::INT as Actual_Arrival_Time,
    arr_delay::INT as Arrival_Delay,
    CASE cancelled WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_cancelled,
    CASE cancellation_code WHEN 'A' THEN 'Carrier'  WHEN 'B' THEN 'Weather'  WHEN 'C' THEN 'National Air System'  WHEN 'D' THEN 'Security'  ELSE 'still available' END as Cancellation_Reason,
    CASE diverted WHEN 0 THEN 'No'  WHEN 1 THEN 'Yes' END as is_diverted,
    crs_elapsed_time::INT as Scheduled_Flight_Duration,
    actual_elapsed_time::INT as Actual_Flight_Duration,
    air_time,
    distance,
    carrier_delay,
    weather_delay,
    nas_delay,
    security_delay,
    late_aircraft_delay,
    isDelete,
    CASE operation WHEN 'c' THEN 'Create'  WHEN 'u' THEN 'Update'  WHEN 'd' THEN 'Delete'  WHEN 'r' THEN 'Snapshot'  ELSE 'Unknown' END as operation_type,
    TO_TIMESTAMP_LTZ(event_time / 1000) as event_time,
    ingestion_time  as ingestion_datetime
from GP.RAW.flights
  );
[0m23:09:51.967524 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:09:52.990774 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:09:53.046640 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.stg_flight_status (execute): 2025-11-26 23:09:51.820031 => 2025-11-26 23:09:53.046454
[0m23:09:53.047446 [debug] [Thread-1 (]: On model.airflow_dbt_project.stg_flight_status: Close
[0m23:09:54.109046 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41d97734-5b73-472b-8d50-1ee47d7aff33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b25c2180>]}
[0m23:09:54.110609 [info ] [Thread-1 (]: 1 of 1 OK created sql view model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status  [[32mSUCCESS 1[0m in 2.35s]
[0m23:09:54.120102 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.stg_flight_status
[0m23:09:54.125846 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:09:54.127956 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:09:54.129094 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m23:09:54.129658 [debug] [MainThread]: Connection 'model.airflow_dbt_project.stg_flight_status' was properly closed.
[0m23:09:54.130201 [info ] [MainThread]: 
[0m23:09:54.131002 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 12.84 seconds (12.84s).
[0m23:09:54.132070 [debug] [MainThread]: Command end result
[0m23:09:54.154065 [info ] [MainThread]: 
[0m23:09:54.155216 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:09:54.155914 [info ] [MainThread]: 
[0m23:09:54.156539 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:09:54.157414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b2e47680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b2e45670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b2ea84a0>]}
[0m23:09:54.158082 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 23:10:12.017797 | 9068a5aa-e9f8-42ad-b35d-187f07a3c30f ==============================
[0m23:10:12.017797 [info ] [MainThread]: Running with dbt=1.4.0
[0m23:10:12.026227 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_destination'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m23:10:12.026976 [debug] [MainThread]: Tracking: tracking
[0m23:10:12.028000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb55e358bc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb55e358b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb55e732e10>]}


============================== 2025-11-26 23:10:12.042702 | e90ef95b-6026-4fa3-9a1b-50284b06f6c4 ==============================
[0m23:10:12.042702 [info ] [MainThread]: Running with dbt=1.4.0
[0m23:10:12.049314 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_origin'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m23:10:12.050098 [debug] [MainThread]: Tracking: tracking
[0m23:10:12.051012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8442dee180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8442a73200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8443d6cda0>]}
[0m23:10:12.156565 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:10:12.157516 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:10:12.160948 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:10:12.162092 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:10:12.187999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e90ef95b-6026-4fa3-9a1b-50284b06f6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8443011b80>]}
[0m23:10:12.197660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9068a5aa-e9f8-42ad-b35d-187f07a3c30f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb55e3b51c0>]}
[0m23:10:12.221244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e90ef95b-6026-4fa3-9a1b-50284b06f6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8442ab5040>]}
[0m23:10:12.222975 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m23:10:12.224257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e90ef95b-6026-4fa3-9a1b-50284b06f6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8442dee180>]}
[0m23:10:12.228676 [info ] [MainThread]: 
[0m23:10:12.233266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9068a5aa-e9f8-42ad-b35d-187f07a3c30f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb55e3f9280>]}
[0m23:10:12.234981 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:10:12.235057 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m23:10:12.237097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9068a5aa-e9f8-42ad-b35d-187f07a3c30f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5787c2240>]}
[0m23:10:12.239231 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m23:10:12.243187 [info ] [MainThread]: 
[0m23:10:12.249568 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:10:12.253421 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m23:10:12.294155 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m23:10:12.295073 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m23:10:12.295878 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:10:12.308972 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m23:10:12.309909 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m23:10:12.310789 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:10:13.786798 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m23:10:13.793278 [debug] [ThreadPool]: On list_GP: Close
[0m23:10:13.810633 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m23:10:13.817471 [debug] [ThreadPool]: On list_GP: Close
[0m23:10:14.209933 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:10:14.211251 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:10:14.211855 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:10:14.212786 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m23:10:14.213047 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:10:14.213923 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m23:10:14.229206 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:10:14.229623 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:10:14.230028 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:10:14.230358 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:10:14.230592 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:10:14.230872 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:10:15.237772 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m23:10:15.246141 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:10:15.248753 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m23:10:15.254956 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:10:15.621215 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m23:10:15.628952 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:10:15.656073 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m23:10:15.657414 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:10:15.657993 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m23:10:15.658597 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:10:15.659260 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:10:15.659964 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:10:16.671322 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m23:10:16.681216 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:10:16.707462 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m23:10:16.708096 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m23:10:16.708537 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:10:16.710555 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:10:16.716225 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:10:16.718243 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:10:16.973608 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m23:10:16.978682 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:10:17.813836 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m23:10:17.822465 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m23:10:17.826533 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m23:10:17.830739 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:10:18.098290 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2 seconds
[0m23:10:18.102887 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m23:10:18.313441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9068a5aa-e9f8-42ad-b35d-187f07a3c30f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb55eb667b0>]}
[0m23:10:18.315599 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m23:10:18.316950 [info ] [MainThread]: 
[0m23:10:18.375821 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_destination
[0m23:10:18.376752 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [RUN]
[0m23:10:18.379489 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_destination'
[0m23:10:18.380205 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_destination
[0m23:10:18.392710 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_destination"
[0m23:10:18.394759 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (compile): 2025-11-26 23:10:18.380630 => 2025-11-26 23:10:18.394437
[0m23:10:18.396170 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_destination
[0m23:10:18.511864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e90ef95b-6026-4fa3-9a1b-50284b06f6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8442a70b30>]}
[0m23:10:18.513796 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m23:10:18.514709 [info ] [MainThread]: 
[0m23:10:18.582929 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_origin
[0m23:10:18.584654 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [RUN]
[0m23:10:18.589127 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_origin'
[0m23:10:18.590444 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_origin
[0m23:10:18.601233 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_destination"
[0m23:10:18.604721 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m23:10:18.605532 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  as
        (


with distinct_values as(
    select
    distinct destination_city as city,destination_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as destination_id,
    city,
    state
    from distinct_values


        );
[0m23:10:18.606124 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:10:18.606588 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_origin"
[0m23:10:18.607909 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (compile): 2025-11-26 23:10:18.591317 => 2025-11-26 23:10:18.607706
[0m23:10:18.608815 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_origin
[0m23:10:18.766929 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_origin"
[0m23:10:18.769735 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m23:10:18.770406 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  as
        (


with distinct_values as(
    select
    distinct origin_city as city,origin_state as state
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select row_number() over(order by city) as origin_id,
    city,
    state
    from distinct_values


        );
[0m23:10:18.771031 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:10:20.351635 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m23:10:20.372491 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_destination"
[0m23:10:20.373271 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_destination"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination__dbt_tmp cascade
[0m23:10:20.764213 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m23:10:20.764231 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m23:10:20.819446 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_origin"
[0m23:10:20.820635 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_origin"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin__dbt_tmp cascade
[0m23:10:20.887377 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_destination (execute): 2025-11-26 23:10:18.396710 => 2025-11-26 23:10:20.887071
[0m23:10:20.888982 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_destination: Close
[0m23:10:21.023618 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m23:10:21.126988 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_origin (execute): 2025-11-26 23:10:18.609206 => 2025-11-26 23:10:21.126713
[0m23:10:21.128504 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_origin: Close
[0m23:10:21.278426 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9068a5aa-e9f8-42ad-b35d-187f07a3c30f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb55d8801a0>]}
[0m23:10:21.280576 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination  [[32mSUCCESS 1[0m in 2.90s]
[0m23:10:21.288574 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_destination
[0m23:10:21.294906 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:10:21.298883 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:10:21.300267 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m23:10:21.301163 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_destination' was properly closed.
[0m23:10:21.302011 [info ] [MainThread]: 
[0m23:10:21.303060 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 9.06 seconds (9.06s).
[0m23:10:21.304397 [debug] [MainThread]: Command end result
[0m23:10:21.336880 [info ] [MainThread]: 
[0m23:10:21.338579 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:10:21.340441 [info ] [MainThread]: 
[0m23:10:21.341721 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:10:21.343105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb55d82e2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb55eb20680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb55e3f9100>]}
[0m23:10:21.344223 [debug] [MainThread]: Flushing usage events
[0m23:10:21.617712 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e90ef95b-6026-4fa3-9a1b-50284b06f6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8441eed490>]}
[0m23:10:21.619140 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin  [[32mSUCCESS 1[0m in 3.03s]
[0m23:10:21.623884 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_origin
[0m23:10:21.628124 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:10:21.629955 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:10:21.630605 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_origin' was properly closed.
[0m23:10:21.631014 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight' was properly closed.
[0m23:10:21.631481 [info ] [MainThread]: 
[0m23:10:21.632098 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 9.40 seconds (9.40s).
[0m23:10:21.632999 [debug] [MainThread]: Command end result
[0m23:10:21.652754 [info ] [MainThread]: 
[0m23:10:21.653953 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:10:21.654706 [info ] [MainThread]: 
[0m23:10:21.655311 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:10:21.656038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8442dee180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8442a70b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8443672ea0>]}
[0m23:10:21.656601 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 23:10:47.971875 | 26b35c35-f8da-4f91-8d94-2280fd0a5c58 ==============================
[0m23:10:47.971875 [info ] [MainThread]: Running with dbt=1.4.0
[0m23:10:47.982395 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['dim_flight_status'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m23:10:47.983505 [debug] [MainThread]: Tracking: tracking
[0m23:10:47.984643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe25556cfe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe255a3b3b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe255d40710>]}
[0m23:10:48.317807 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:10:48.319150 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:10:48.371214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '26b35c35-f8da-4f91-8d94-2280fd0a5c58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27c730fe0>]}
[0m23:10:48.428897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '26b35c35-f8da-4f91-8d94-2280fd0a5c58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe2569c5490>]}
[0m23:10:48.430762 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m23:10:48.432584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '26b35c35-f8da-4f91-8d94-2280fd0a5c58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe2731d5850>]}
[0m23:10:48.440981 [info ] [MainThread]: 
[0m23:10:48.453103 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:10:48.460093 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m23:10:48.574132 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m23:10:48.576249 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m23:10:48.578010 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:10:50.876091 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2 seconds
[0m23:10:50.887737 [debug] [ThreadPool]: On list_GP: Close
[0m23:10:51.490398 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:10:51.493843 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:10:51.495622 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m23:10:51.522542 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:10:51.523898 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:10:51.524899 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:10:53.188967 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 2 seconds
[0m23:10:53.194216 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:10:53.650580 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m23:10:53.655524 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:10:53.754571 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m23:10:53.756686 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m23:10:53.751934 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:10:53.758405 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:10:53.759664 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:10:53.772665 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:10:55.073466 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m23:10:55.085657 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m23:10:55.104851 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m23:10:55.108417 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:10:55.606511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '26b35c35-f8da-4f91-8d94-2280fd0a5c58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe25525fc20>]}
[0m23:10:55.612332 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m23:10:55.614626 [info ] [MainThread]: 
[0m23:10:55.740637 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.dim_flight_status
[0m23:10:55.744548 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [RUN]
[0m23:10:55.751211 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.dim_flight_status'
[0m23:10:55.753095 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.dim_flight_status
[0m23:10:55.769348 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.dim_flight_status"
[0m23:10:55.772407 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (compile): 2025-11-26 23:10:55.754205 => 2025-11-26 23:10:55.771966
[0m23:10:55.773946 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.dim_flight_status
[0m23:10:56.155744 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.dim_flight_status"
[0m23:10:56.160224 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m23:10:56.161207 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  as
        (
with distinct_values as(
    select distinct CANCELLATION_REASON,is_cancelled,is_diverted
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status
)
select 
row_number() over(order by is_cancelled) as status_id,
CANCELLATION_REASON,
is_cancelled,
is_diverted
from distinct_values
        );
[0m23:10:56.162219 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:10:57.730006 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m23:10:57.775794 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.dim_flight_status"
[0m23:10:57.777197 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.dim_flight_status"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status__dbt_tmp cascade
[0m23:10:58.037594 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m23:10:58.162451 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.dim_flight_status (execute): 2025-11-26 23:10:55.775111 => 2025-11-26 23:10:58.162129
[0m23:10:58.163791 [debug] [Thread-1 (]: On model.airflow_dbt_project.dim_flight_status: Close
[0m23:10:58.665602 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26b35c35-f8da-4f91-8d94-2280fd0a5c58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27d13f2f0>]}
[0m23:10:58.667483 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status  [[32mSUCCESS 1[0m in 2.92s]
[0m23:10:58.674844 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.dim_flight_status
[0m23:10:58.681504 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:10:58.683845 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:10:58.684655 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m23:10:58.685262 [debug] [MainThread]: Connection 'model.airflow_dbt_project.dim_flight_status' was properly closed.
[0m23:10:58.685969 [info ] [MainThread]: 
[0m23:10:58.687375 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 10.24 seconds (10.24s).
[0m23:10:58.689892 [debug] [MainThread]: Command end result
[0m23:10:58.718792 [info ] [MainThread]: 
[0m23:10:58.720203 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:10:58.721162 [info ] [MainThread]: 
[0m23:10:58.722083 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:10:58.723224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe255273710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe25525fc20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27d13f2f0>]}
[0m23:10:58.724158 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 23:11:18.585604 | 1acc99d8-350a-42c7-a13b-edba97a217da ==============================
[0m23:11:18.585604 [info ] [MainThread]: Running with dbt=1.4.0
[0m23:11:18.591881 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'select': ['fact_flights'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m23:11:18.592636 [debug] [MainThread]: Tracking: tracking
[0m23:11:18.593379 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88a1ace300>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88a1cca840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88a1bef050>]}
[0m23:11:18.680932 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:11:18.681671 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:11:18.699615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1acc99d8-350a-42c7-a13b-edba97a217da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88a1bcc9e0>]}
[0m23:11:18.722220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1acc99d8-350a-42c7-a13b-edba97a217da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88a1acc500>]}
[0m23:11:18.723198 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m23:11:18.723826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1acc99d8-350a-42c7-a13b-edba97a217da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88c8c2d760>]}
[0m23:11:18.726698 [info ] [MainThread]: 
[0m23:11:18.730933 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:11:18.734126 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP'
[0m23:11:18.783472 [debug] [ThreadPool]: Using snowflake connection "list_GP"
[0m23:11:18.784274 [debug] [ThreadPool]: On list_GP: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP"} */
show terse schemas in database GP
    limit 10000
[0m23:11:18.784915 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:11:20.271394 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1 seconds
[0m23:11:20.282352 [debug] [ThreadPool]: On list_GP: Close
[0m23:11:20.714240 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:11:20.716458 [debug] [ThreadPool]: Acquiring new snowflake connection 'create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:11:20.717481 [debug] [ThreadPool]: Creating schema "ReferenceKeyMsg(database='gp', schema='-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight', identifier=None)"
[0m23:11:20.743722 [debug] [ThreadPool]: Using snowflake connection "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:11:20.744630 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
create schema if not exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:11:20.745149 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:11:21.893437 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:21.895588 [debug] [ThreadPool]: On create_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:11:22.312498 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:11:22.331772 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m23:11:22.359684 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:11:22.361874 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m23:11:22.362537 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:11:22.363189 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m23:11:22.363853 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:11:22.364465 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:11:23.211205 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m23:11:23.215272 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m23:11:23.242067 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m23:11:23.247263 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:11:24.776114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1acc99d8-350a-42c7-a13b-edba97a217da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88c9c30b60>]}
[0m23:11:24.778612 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m23:11:24.779674 [info ] [MainThread]: 
[0m23:11:24.843409 [debug] [Thread-1 (]: Began running node model.airflow_dbt_project.fact_flights
[0m23:11:24.844927 [info ] [Thread-1 (]: 1 of 1 START sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [RUN]
[0m23:11:24.846948 [debug] [Thread-1 (]: Acquiring new snowflake connection 'model.airflow_dbt_project.fact_flights'
[0m23:11:24.847885 [debug] [Thread-1 (]: Began compiling node model.airflow_dbt_project.fact_flights
[0m23:11:24.861600 [debug] [Thread-1 (]: Writing injected SQL for node "model.airflow_dbt_project.fact_flights"
[0m23:11:24.862966 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (compile): 2025-11-26 23:11:24.848381 => 2025-11-26 23:11:24.862764
[0m23:11:24.863694 [debug] [Thread-1 (]: Began executing node model.airflow_dbt_project.fact_flights
[0m23:11:25.009598 [debug] [Thread-1 (]: Writing runtime sql for node "model.airflow_dbt_project.fact_flights"
[0m23:11:25.016579 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m23:11:25.017620 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
create or replace transient table GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  as
        (
select
d_date.date_id as date_id,
sdt.time_id as Scheduled_Departure_Time_id,
adt.time_id as Actual_Departure_Time_id,
wot.time_id as Wheels_Off_Time_id,
wot2.time_id as Wheels_On_Time_id,
sat.time_id as Scheduled_Arrival_Time_id,
aat.time_id as Actual_Arrival_Time_id,
origin.origin_id as origin_id,
dest.destination_id as destination_id, 
fl_stat.status_id as status_id,
AIRLINE_CODE,
FLIGHT_NUMBER,
Departure_Delay,
Taxi_Out_Time,
Taxi_In_Time,
Arrival_Delay,
Scheduled_Flight_Duration,
Actual_Flight_Duration,
Air_Time,
Distance,
Carrier_Delay,
Weather_Delay,
NAS_Delay,
Security_Delay,
Late_Aircraft_Delay
from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging.stg_flight_status as stg 
left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date as d_date
on stg.flight_date=d_date.date_day

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sdt
on stg.Scheduled_Departure_Time=sdt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as adt 
on stg.Actual_Departure_Time=adt.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot
on stg.Wheels_Off_Time=wot.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as wot2 
on stg.Wheels_On_Time=wot2.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as sat
on stg.Scheduled_Arrival_Time=sat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time as aat
on stg.Actual_Arrival_Time=aat.hhmm

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin as origin
on origin.city=stg.origin_city and origin.state=stg.origin_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination as dest
on dest.city=stg.destination_city and dest.state=stg.destination_state 

left join GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status as fl_stat 
on stg.IS_CANCELLED=fl_stat.IS_CANCELLED and stg.IS_DIVERTED=fl_stat.IS_DIVERTED
        );
[0m23:11:25.018355 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:11:29.076711 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 4 seconds
[0m23:11:29.110207 [debug] [Thread-1 (]: Using snowflake connection "model.airflow_dbt_project.fact_flights"
[0m23:11:29.111433 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "model.airflow_dbt_project.fact_flights"} */
drop view if exists GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights__dbt_tmp cascade
[0m23:11:29.322209 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0 seconds
[0m23:11:29.393658 [debug] [Thread-1 (]: Timing info for model.airflow_dbt_project.fact_flights (execute): 2025-11-26 23:11:24.864151 => 2025-11-26 23:11:29.393400
[0m23:11:29.394573 [debug] [Thread-1 (]: On model.airflow_dbt_project.fact_flights: Close
[0m23:11:29.819830 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1acc99d8-350a-42c7-a13b-edba97a217da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88a0f01670>]}
[0m23:11:29.821794 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model -- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights  [[32mSUCCESS 1[0m in 4.97s]
[0m23:11:29.826491 [debug] [Thread-1 (]: Finished running node model.airflow_dbt_project.fact_flights
[0m23:11:29.832263 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:11:29.834737 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:11:29.835701 [debug] [MainThread]: Connection 'model.airflow_dbt_project.fact_flights' was properly closed.
[0m23:11:29.836555 [debug] [MainThread]: Connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging' was properly closed.
[0m23:11:29.838138 [info ] [MainThread]: 
[0m23:11:29.839105 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 11.11 seconds (11.11s).
[0m23:11:29.839961 [debug] [MainThread]: Command end result
[0m23:11:29.861424 [info ] [MainThread]: 
[0m23:11:29.862650 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:11:29.863545 [info ] [MainThread]: 
[0m23:11:29.864231 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:11:29.865639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88a18e5df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88a18e5400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88a20f1370>]}
[0m23:11:29.866558 [debug] [MainThread]: Flushing usage events


============================== 2025-11-26 23:11:44.185919 | d8b8fe56-6436-45a5-a765-5d2bacd3681b ==============================
[0m23:11:44.185919 [info ] [MainThread]: Running with dbt=1.4.0
[0m23:11:44.196812 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'project_dir': '/opt/airflow/dbt', 'indirect_selection': 'eager', 'select': ['test_type:generic'], 'which': 'test', 'rpc_method': 'test'}
[0m23:11:44.198344 [debug] [MainThread]: Tracking: tracking
[0m23:11:44.200530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d68257830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d855b2810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d696d1ee0>]}
[0m23:11:44.379954 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:11:44.381222 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:11:44.419267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd8b8fe56-6436-45a5-a765-5d2bacd3681b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d72f01cd0>]}
[0m23:11:44.464828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd8b8fe56-6436-45a5-a765-5d2bacd3681b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d68299040>]}
[0m23:11:44.466832 [info ] [MainThread]: Found 7 models, 17 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m23:11:44.468525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd8b8fe56-6436-45a5-a765-5d2bacd3681b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d68793c20>]}
[0m23:11:44.480431 [info ] [MainThread]: 
[0m23:11:44.492462 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:11:44.503353 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging'
[0m23:11:44.508067 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight'
[0m23:11:44.635966 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight"
[0m23:11:44.638433 [debug] [ThreadPool]: Using snowflake connection "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging"
[0m23:11:44.639358 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        mart_flight"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight
[0m23:11:44.640069 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "connection_name": "list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema\n\n        staging"} */
show terse objects in GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging
[0m23:11:44.640906 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:11:44.641639 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:11:45.982603 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1 seconds
[0m23:11:45.990963 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        staging: Close
[0m23:11:46.034099 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1 seconds
[0m23:11:46.040766 [debug] [ThreadPool]: On list_GP_-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight: Close
[0m23:11:46.645582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd8b8fe56-6436-45a5-a765-5d2bacd3681b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d6846bc80>]}
[0m23:11:46.647678 [info ] [MainThread]: Concurrency: 2 threads (target='snowflake_dev')
[0m23:11:46.648829 [info ] [MainThread]: 
[0m23:11:46.707222 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m23:11:46.708149 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m23:11:46.708835 [info ] [Thread-1 (]: 1 of 17 START test is_positive_fact_flights_CARRIER_DELAY ...................... [RUN]
[0m23:11:46.709818 [info ] [Thread-2 (]: 2 of 17 START test is_positive_fact_flights_LATE_AIRCRAFT_DELAY ................ [RUN]
[0m23:11:46.711922 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec'
[0m23:11:46.713806 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa'
[0m23:11:46.714790 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m23:11:46.715818 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m23:11:46.786450 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m23:11:46.788921 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m23:11:46.791122 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (compile): 2025-11-26 23:11:46.721964 => 2025-11-26 23:11:46.790865
[0m23:11:46.792378 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (compile): 2025-11-26 23:11:46.716932 => 2025-11-26 23:11:46.792130
[0m23:11:46.795741 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m23:11:46.797053 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m23:11:46.922509 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m23:11:46.921784 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m23:11:46.925153 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"
[0m23:11:46.926447 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"
[0m23:11:46.927160 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where LATE_AIRCRAFT_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m23:11:46.927846 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where CARRIER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m23:11:46.928554 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:11:46.929204 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:11:48.065778 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:48.087378 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa (execute): 2025-11-26 23:11:46.798007 => 2025-11-26 23:11:48.087059
[0m23:11:48.089475 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa: Close
[0m23:11:48.092857 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:48.097978 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec (execute): 2025-11-26 23:11:46.813946 => 2025-11-26 23:11:48.097821
[0m23:11:48.098716 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec: Close
[0m23:11:48.494204 [info ] [Thread-1 (]: 1 of 17 PASS is_positive_fact_flights_CARRIER_DELAY ............................ [[32mPASS[0m in 1.78s]
[0m23:11:48.499613 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_CARRIER_DELAY.484000faec
[0m23:11:48.500859 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m23:11:48.502023 [info ] [Thread-1 (]: 3 of 17 START test is_positive_fact_flights_NAS_DELAY .......................... [RUN]
[0m23:11:48.504506 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3'
[0m23:11:48.505239 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m23:11:48.518996 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m23:11:48.520689 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (compile): 2025-11-26 23:11:48.505659 => 2025-11-26 23:11:48.520401
[0m23:11:48.521598 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m23:11:48.527068 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m23:11:48.529197 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"
[0m23:11:48.529930 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where NAS_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m23:11:48.530921 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:11:48.689776 [info ] [Thread-2 (]: 2 of 17 PASS is_positive_fact_flights_LATE_AIRCRAFT_DELAY ...................... [[32mPASS[0m in 1.98s]
[0m23:11:48.690741 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_LATE_AIRCRAFT_DELAY.27b5bdafaa
[0m23:11:48.691384 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m23:11:48.691981 [info ] [Thread-2 (]: 4 of 17 START test is_positive_fact_flights_SECURITY_DELAY ..................... [RUN]
[0m23:11:48.694170 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384'
[0m23:11:48.694906 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m23:11:48.707445 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m23:11:48.708573 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (compile): 2025-11-26 23:11:48.695274 => 2025-11-26 23:11:48.708415
[0m23:11:48.709151 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m23:11:48.715062 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m23:11:48.717367 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"
[0m23:11:48.718121 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where SECURITY_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m23:11:48.718732 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:11:49.528376 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:49.538632 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3 (execute): 2025-11-26 23:11:48.522063 => 2025-11-26 23:11:49.538257
[0m23:11:49.539876 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3: Close
[0m23:11:49.833850 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:49.839819 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384 (execute): 2025-11-26 23:11:48.709514 => 2025-11-26 23:11:49.839621
[0m23:11:49.840529 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384: Close
[0m23:11:49.932750 [info ] [Thread-1 (]: 3 of 17 PASS is_positive_fact_flights_NAS_DELAY ................................ [[32mPASS[0m in 1.43s]
[0m23:11:49.934533 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_NAS_DELAY.86e8dba5f3
[0m23:11:49.936172 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m23:11:49.937382 [info ] [Thread-1 (]: 5 of 17 START test is_positive_fact_flights_TAXI_IN_TIME ....................... [RUN]
[0m23:11:49.939539 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c'
[0m23:11:49.940342 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m23:11:49.961194 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m23:11:49.963051 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (compile): 2025-11-26 23:11:49.940878 => 2025-11-26 23:11:49.962785
[0m23:11:49.964094 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m23:11:49.974410 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m23:11:49.977210 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"
[0m23:11:49.978166 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_IN_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m23:11:49.979080 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:11:50.260671 [info ] [Thread-2 (]: 4 of 17 PASS is_positive_fact_flights_SECURITY_DELAY ........................... [[32mPASS[0m in 1.57s]
[0m23:11:50.261593 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_SECURITY_DELAY.4501cb0384
[0m23:11:50.262265 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m23:11:50.262755 [info ] [Thread-2 (]: 6 of 17 START test is_positive_fact_flights_TAXI_OUT_TIME ...................... [RUN]
[0m23:11:50.264132 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da'
[0m23:11:50.265081 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m23:11:50.275281 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m23:11:50.276447 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (compile): 2025-11-26 23:11:50.265774 => 2025-11-26 23:11:50.276273
[0m23:11:50.276966 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m23:11:50.283278 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m23:11:50.286093 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"
[0m23:11:50.286847 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where TAXI_OUT_TIME< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m23:11:50.287603 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:11:51.529711 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2 seconds
[0m23:11:51.536105 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c (execute): 2025-11-26 23:11:49.964926 => 2025-11-26 23:11:51.535852
[0m23:11:51.537101 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c: Close
[0m23:11:51.546259 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:51.551801 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da (execute): 2025-11-26 23:11:50.277270 => 2025-11-26 23:11:51.551582
[0m23:11:51.552670 [debug] [Thread-2 (]: On test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da: Close
[0m23:11:51.911816 [info ] [Thread-1 (]: 5 of 17 PASS is_positive_fact_flights_TAXI_IN_TIME ............................. [[32mPASS[0m in 1.97s]
[0m23:11:51.915673 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_IN_TIME.293996507c
[0m23:11:51.918916 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m23:11:51.921724 [info ] [Thread-1 (]: 7 of 17 START test is_positive_fact_flights_WEATHER_DELAY ...................... [RUN]
[0m23:11:51.926094 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474'
[0m23:11:51.927721 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m23:11:51.939798 [info ] [Thread-2 (]: 6 of 17 PASS is_positive_fact_flights_TAXI_OUT_TIME ............................ [[32mPASS[0m in 1.68s]
[0m23:11:51.952217 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_TAXI_OUT_TIME.0fd7b2b7da
[0m23:11:51.954492 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m23:11:51.955698 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m23:11:51.956945 [info ] [Thread-2 (]: 8 of 17 START test relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m23:11:51.958466 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9'
[0m23:11:51.959086 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m23:11:51.960951 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (compile): 2025-11-26 23:11:51.928900 => 2025-11-26 23:11:51.960719
[0m23:11:51.961707 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m23:11:51.981441 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m23:11:52.007366 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m23:11:52.008983 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"
[0m23:11:52.009579 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    select count(*) as records 
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where WEATHER_DELAY< 0
    having count(*)>0

      
    ) dbt_internal_test
[0m23:11:52.010077 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:11:52.013797 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (compile): 2025-11-26 23:11:51.959530 => 2025-11-26 23:11:52.013482
[0m23:11:52.014661 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m23:11:52.022936 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m23:11:52.025595 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"
[0m23:11:52.026259 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m23:11:52.026890 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:11:53.380623 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:53.386633 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474 (execute): 2025-11-26 23:11:51.967335 => 2025-11-26 23:11:53.386461
[0m23:11:53.387261 [debug] [Thread-1 (]: On test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474: Close
[0m23:11:53.445478 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:53.450226 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9 (execute): 2025-11-26 23:11:52.015141 => 2025-11-26 23:11:53.450007
[0m23:11:53.451022 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9: Close
[0m23:11:53.761682 [info ] [Thread-1 (]: 7 of 17 PASS is_positive_fact_flights_WEATHER_DELAY ............................ [[32mPASS[0m in 1.84s]
[0m23:11:53.762684 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.is_positive_fact_flights_WEATHER_DELAY.e6e4a9b474
[0m23:11:53.763401 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m23:11:53.763916 [info ] [Thread-1 (]: 9 of 17 START test relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m23:11:53.765532 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079'
[0m23:11:53.766120 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m23:11:53.782589 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m23:11:53.784069 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (compile): 2025-11-26 23:11:53.766649 => 2025-11-26 23:11:53.783801
[0m23:11:53.785030 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m23:11:53.790672 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m23:11:53.792820 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"
[0m23:11:53.793248 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Actual_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Actual_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m23:11:53.793610 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:11:53.809138 [info ] [Thread-2 (]: 8 of 17 PASS relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.85s]
[0m23:11:53.810076 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Arrival_Time_id__time_id__ref_dim_time_.6d96f941a9
[0m23:11:53.810718 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m23:11:53.811112 [info ] [Thread-2 (]: 10 of 17 START test relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [RUN]
[0m23:11:53.812280 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608'
[0m23:11:53.813132 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m23:11:53.826872 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m23:11:53.828285 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (compile): 2025-11-26 23:11:53.813631 => 2025-11-26 23:11:53.828117
[0m23:11:53.828847 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m23:11:53.834751 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m23:11:53.838093 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"
[0m23:11:53.838627 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Arrival_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Arrival_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m23:11:53.838992 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:11:54.835384 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:54.841545 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079 (execute): 2025-11-26 23:11:53.785500 => 2025-11-26 23:11:54.841329
[0m23:11:54.842321 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079: Close
[0m23:11:54.973521 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:54.980798 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608 (execute): 2025-11-26 23:11:53.829155 => 2025-11-26 23:11:54.980543
[0m23:11:54.981882 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608: Close
[0m23:11:55.332938 [info ] [Thread-1 (]: 9 of 17 PASS relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.57s]
[0m23:11:55.334323 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Actual_Departure_Time_id__time_id__ref_dim_time_.63ef8bb079
[0m23:11:55.335396 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m23:11:55.336556 [info ] [Thread-1 (]: 11 of 17 START test relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [RUN]
[0m23:11:55.338444 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932'
[0m23:11:55.338984 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m23:11:55.365932 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m23:11:55.367404 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (compile): 2025-11-26 23:11:55.339373 => 2025-11-26 23:11:55.367161
[0m23:11:55.368403 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m23:11:55.374422 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m23:11:55.377207 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"
[0m23:11:55.377934 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Scheduled_Departure_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Scheduled_Departure_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m23:11:55.378484 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:11:55.425306 [info ] [Thread-2 (]: 10 of 17 PASS relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.61s]
[0m23:11:55.426518 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Arrival_Time_id__time_id__ref_dim_time_.69d9d3b608
[0m23:11:55.427454 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m23:11:55.428907 [info ] [Thread-2 (]: 12 of 17 START test relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [RUN]
[0m23:11:55.432147 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5'
[0m23:11:55.433905 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m23:11:55.464381 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m23:11:55.466531 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (compile): 2025-11-26 23:11:55.434944 => 2025-11-26 23:11:55.466153
[0m23:11:55.467732 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m23:11:55.476864 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m23:11:55.481466 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"
[0m23:11:55.482552 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_Off_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_Off_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m23:11:55.483248 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:11:56.346209 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:56.354244 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932 (execute): 2025-11-26 23:11:55.369025 => 2025-11-26 23:11:56.354001
[0m23:11:56.355180 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932: Close
[0m23:11:56.606350 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:56.609470 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5 (execute): 2025-11-26 23:11:55.468759 => 2025-11-26 23:11:56.609353
[0m23:11:56.609913 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5: Close
[0m23:11:56.861234 [info ] [Thread-1 (]: 11 of 17 PASS relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.52s]
[0m23:11:56.863088 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Scheduled_Departure_Time_id__time_id__ref_dim_time_.d3bd2a4932
[0m23:11:56.864613 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m23:11:56.865523 [info ] [Thread-1 (]: 13 of 17 START test relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [RUN]
[0m23:11:56.868167 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850'
[0m23:11:56.869200 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m23:11:56.896000 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m23:11:56.897863 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (compile): 2025-11-26 23:11:56.870020 => 2025-11-26 23:11:56.897600
[0m23:11:56.898959 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m23:11:56.907569 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m23:11:56.911675 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"
[0m23:11:56.912748 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select Wheels_On_Time_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where Wheels_On_Time_id is not null
),

parent as (
    select time_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_time
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m23:11:56.913470 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:11:57.056108 [info ] [Thread-2 (]: 12 of 17 PASS relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.62s]
[0m23:11:57.058667 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_Off_Time_id__time_id__ref_dim_time_.c9bc3d25d5
[0m23:11:57.061210 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m23:11:57.063578 [info ] [Thread-2 (]: 14 of 17 START test relationships_fact_flights_date_id__date_id__ref_dim_date_ . [RUN]
[0m23:11:57.069131 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9'
[0m23:11:57.070690 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m23:11:57.100500 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m23:11:57.104775 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (compile): 2025-11-26 23:11:57.071704 => 2025-11-26 23:11:57.104387
[0m23:11:57.106318 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m23:11:57.116407 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m23:11:57.120860 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"
[0m23:11:57.121838 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select date_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where date_id is not null
),

parent as (
    select date_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_date
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m23:11:57.122973 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:11:58.017885 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:58.029335 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850 (execute): 2025-11-26 23:11:56.899803 => 2025-11-26 23:11:58.029042
[0m23:11:58.032922 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850: Close
[0m23:11:58.373003 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:58.381652 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9 (execute): 2025-11-26 23:11:57.107400 => 2025-11-26 23:11:58.381363
[0m23:11:58.383129 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9: Close
[0m23:11:58.404750 [info ] [Thread-1 (]: 13 of 17 PASS relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_  [[32mPASS[0m in 1.54s]
[0m23:11:58.406367 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_Wheels_On_Time_id__time_id__ref_dim_time_.6d9f544850
[0m23:11:58.407601 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m23:11:58.408766 [info ] [Thread-1 (]: 15 of 17 START test relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [RUN]
[0m23:11:58.411312 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5'
[0m23:11:58.412437 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m23:11:58.437011 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m23:11:58.438714 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (compile): 2025-11-26 23:11:58.413031 => 2025-11-26 23:11:58.438485
[0m23:11:58.439831 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m23:11:58.448629 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m23:11:58.452542 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"
[0m23:11:58.453400 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select destination_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where destination_id is not null
),

parent as (
    select destination_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_destination
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m23:11:58.454092 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:11:58.769756 [info ] [Thread-2 (]: 14 of 17 PASS relationships_fact_flights_date_id__date_id__ref_dim_date_ ....... [[32mPASS[0m in 1.70s]
[0m23:11:58.772367 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_date_id__date_id__ref_dim_date_.2df53f44e9
[0m23:11:58.776708 [debug] [Thread-2 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m23:11:58.778514 [info ] [Thread-2 (]: 16 of 17 START test relationships_fact_flights_origin_id__origin_id__ref_dim_origin_  [RUN]
[0m23:11:58.786652 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24'
[0m23:11:58.788435 [debug] [Thread-2 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m23:11:58.818085 [debug] [Thread-2 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m23:11:58.820149 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (compile): 2025-11-26 23:11:58.789563 => 2025-11-26 23:11:58.819757
[0m23:11:58.821637 [debug] [Thread-2 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m23:11:58.830843 [debug] [Thread-2 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m23:11:58.834424 [debug] [Thread-2 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"
[0m23:11:58.835279 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select origin_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where origin_id is not null
),

parent as (
    select origin_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_origin
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m23:11:58.836141 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:11:59.516938 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:59.527117 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5 (execute): 2025-11-26 23:11:58.440620 => 2025-11-26 23:11:59.526881
[0m23:11:59.528044 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5: Close
[0m23:11:59.842585 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:11:59.846300 [debug] [Thread-2 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24 (execute): 2025-11-26 23:11:58.822564 => 2025-11-26 23:11:59.846146
[0m23:11:59.847052 [debug] [Thread-2 (]: On test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24: Close
[0m23:11:59.948036 [info ] [Thread-1 (]: 15 of 17 PASS relationships_fact_flights_destination_id__destination_id__ref_dim_destination_  [[32mPASS[0m in 1.54s]
[0m23:11:59.949004 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_destination_id__destination_id__ref_dim_destination_.9490337ee5
[0m23:11:59.949744 [debug] [Thread-1 (]: Began running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m23:11:59.950727 [info ] [Thread-1 (]: 17 of 17 START test relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [RUN]
[0m23:11:59.952347 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa'
[0m23:11:59.952826 [debug] [Thread-1 (]: Began compiling node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m23:11:59.971511 [debug] [Thread-1 (]: Writing injected SQL for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m23:11:59.972606 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (compile): 2025-11-26 23:11:59.953156 => 2025-11-26 23:11:59.972459
[0m23:11:59.973113 [debug] [Thread-1 (]: Began executing node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m23:11:59.977338 [debug] [Thread-1 (]: Writing runtime sql for node "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m23:11:59.979788 [debug] [Thread-1 (]: Using snowflake connection "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"
[0m23:11:59.980370 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: /* {"app": "dbt", "dbt_version": "1.4.0", "profile_name": "airflow_dbt_project", "target_name": "snowflake_dev", "node_id": "test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select status_id as from_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.fact_flights
    where status_id is not null
),

parent as (
    select status_id as to_field
    from GP.-- u get the defualt target schema provided in profiles.yml-- else >>> the customized the schema

        mart_flight.dim_flight_status
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m23:11:59.980804 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:12:00.215801 [info ] [Thread-2 (]: 16 of 17 PASS relationships_fact_flights_origin_id__origin_id__ref_dim_origin_ . [[32mPASS[0m in 1.43s]
[0m23:12:00.217068 [debug] [Thread-2 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24
[0m23:12:01.113876 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1 seconds
[0m23:12:01.122290 [debug] [Thread-1 (]: Timing info for test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa (execute): 2025-11-26 23:11:59.973423 => 2025-11-26 23:12:01.121944
[0m23:12:01.123446 [debug] [Thread-1 (]: On test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa: Close
[0m23:12:01.629597 [info ] [Thread-1 (]: 17 of 17 PASS relationships_fact_flights_status_id__status_id__ref_dim_flight_status_  [[32mPASS[0m in 1.68s]
[0m23:12:01.630714 [debug] [Thread-1 (]: Finished running node test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa
[0m23:12:01.636680 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m23:12:01.638650 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:12:01.639210 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_origin_id__origin_id__ref_dim_origin_.b37c81fa24' was properly closed.
[0m23:12:01.639993 [debug] [MainThread]: Connection 'test.airflow_dbt_project.relationships_fact_flights_status_id__status_id__ref_dim_flight_status_.a647fbaaaa' was properly closed.
[0m23:12:01.640476 [info ] [MainThread]: 
[0m23:12:01.641057 [info ] [MainThread]: Finished running 17 tests in 0 hours 0 minutes and 17.16 seconds (17.16s).
[0m23:12:01.642652 [debug] [MainThread]: Command end result
[0m23:12:01.662370 [info ] [MainThread]: 
[0m23:12:01.663465 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:12:01.664231 [info ] [MainThread]: 
[0m23:12:01.664897 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=0 SKIP=0 TOTAL=17
[0m23:12:01.665847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d682f9f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d6846bc80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d680797c0>]}
[0m23:12:01.666678 [debug] [MainThread]: Flushing usage events
